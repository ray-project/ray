model_loading_config:
  model_id: meta-llama/Llama-3.1-8B-Instruct

accelerator_type: A10G

runtime_env:
  env_vars:
    VLLM_USE_V1: "0"

engine_kwargs:
  max_model_len: 8192
  tensor_parallel_size: 2
