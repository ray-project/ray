{
    "_dashboard_memory_usage_mb": 1251.663872,
    "_dashboard_test_success": true,
    "_peak_memory": 5.42,
    "_peak_process_memory": "PID\tMEM\tCOMMAND\n3604\t2.91GiB\t/home/ray/anaconda3/lib/python3.9/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/s\n3721\t0.97GiB\t/home/ray/anaconda3/bin/python /home/ray/anaconda3/lib/python3.9/site-packages/ray/dashboard/dashboa\n4584\t0.74GiB\tpython distributed/test_many_tasks.py --num-tasks=10000\n1262\t0.29GiB\t/app/product/go/infra/anyscaled/anyscaled_/anyscaled startv2 --control_plane_url=https://console.any\n2330\t0.27GiB\tvector --watch-config --log-format json --config-yaml /etc/vector/vector.yaml\n4842\t0.09GiB\tray::StateAPIGeneratorActor.start\n4788\t0.08GiB\tray::DashboardTester.run\n4377\t0.07GiB\tray::JobSupervisor\n2641\t0.07GiB\t/usr/bin/python3 /app/infra/dataplane/webterminal/webterminal_sidecar_image.binary.runfiles/product/\n3886\t0.07GiB\t/home/ray/anaconda3/bin/python -u /home/ray/anaconda3/lib/python3.9/site-packages/ray/_private/runti",
    "num_tasks": 10000,
    "perf_metrics": [
        {
            "perf_metric_name": "tasks_per_second",
            "perf_metric_type": "THROUGHPUT",
            "perf_metric_value": 582.2528587251263
        },
        {
            "perf_metric_name": "used_cpus_by_deadline",
            "perf_metric_type": "THROUGHPUT",
            "perf_metric_value": 2500.0
        },
        {
            "perf_metric_name": "dashboard_p50_latency_ms",
            "perf_metric_type": "LATENCY",
            "perf_metric_value": 274.662
        },
        {
            "perf_metric_name": "dashboard_p95_latency_ms",
            "perf_metric_type": "LATENCY",
            "perf_metric_value": 3995.805
        },
        {
            "perf_metric_name": "dashboard_p99_latency_ms",
            "perf_metric_type": "LATENCY",
            "perf_metric_value": 5377.161
        }
    ],
    "success": "1",
    "tasks_per_second": 582.2528587251263,
    "time": 317.1746687889099,
    "used_cpus": 2500.0
}
