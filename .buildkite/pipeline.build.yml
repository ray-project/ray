# the bulk of serve tests are now run on civ2 infra, and defined in
# serve.rayci.yaml
- label: "serve civ1 tests"
  conditions:
    [
        "RAY_CI_SERVE_AFFECTED",
        "RAY_CI_PYTHON_AFFECTED",
        "RAY_CI_ML_AFFECTED",
    ]
  instance_size: medium
  commands:
    - cleanup() { if [ "${BUILDKITE_PULL_REQUEST}" = "false" ]; then ./ci/build/upload_build_info.sh; fi }; trap cleanup EXIT
    - TORCH_VERSION=1.9.0 ./ci/env/install-dependencies.sh
    - bash ./ci/ci.sh prepare_docker
    - 'git clone https://github.com/wg/wrk.git /tmp/wrk && pushd /tmp/wrk && make -j && sudo cp wrk /usr/local/bin && popd'
    - ./ci/env/env_info.sh
    - bazel test --config=ci $(./ci/run/bazel_export_options)
      --test_tag_filters=-post_wheel_build,-gpu
      --test_env=DOCKER_HOST=tcp://docker:2376
      --test_env=DOCKER_TLS_VERIFY=1
      --test_env=DOCKER_CERT_PATH=/certs/client
      --test_env=DOCKER_TLS_CERTDIR=/certs
      --test_tag_filters=-post_wheel_build,-gpu,xcommit
      python/ray/serve/tests/...

- label: "core civ1 tests"
  conditions: ["RAY_CI_PYTHON_AFFECTED"]
  instance_size: medium
  commands:
    - cleanup() { if [ "${BUILDKITE_PULL_REQUEST}" = "false" ]; then ./ci/build/upload_build_info.sh; fi }; trap cleanup EXIT
    - bash ./ci/ci.sh prepare_docker
    - ./ci/env/env_info.sh
    - pip install ray[client]
    - bazel test --config=ci $(./ci/run/bazel_export_options)
      --test_tag_filters=xcommit
      --test_env=DOCKER_HOST=tcp://docker:2376
      --test_env=DOCKER_TLS_VERIFY=1
      --test_env=DOCKER_CERT_PATH=/certs/client
      --test_env=DOCKER_TLS_CERTDIR=/certs
      -- python/ray/tests/...

- label: ":kubernetes: operator"
  conditions: ["RAY_CI_LINUX_WHEELS_AFFECTED"]
  instance_size: medium
  commands:
    - |
      cleanup() {
        if [ "${BUILDKITE_PULL_REQUEST}" = "false" ]; then ./ci/build/upload_build_info.sh; fi
        python python/ray/tests/kuberay/setup/teardown_kuberay.py || true
        kind delete cluster
      }
      trap cleanup EXIT
    - ./ci/env/install-minimal.sh 3.8
    - PYTHON=3.8 ./ci/env/install-dependencies.sh
    # Specifying above somehow messes up the Ray install.
    # Uninstall and re-install Ray so that we can use Ray Client.
    # (Remove thirdparty_files to sidestep an issue with psutil.)
    - pip uninstall -y ray && rm -rf /ray/python/ray/thirdparty_files
    - pip install -e /ray/python
    - echo "--- Setting up local kind cluster."
    - ./ci/k8s/prep-k8s-environment.sh
    - echo "--- Building py38-cpu Ray image for the test."
    - LINUX_WHEELS=1 ./ci/ci.sh build
    - pip install -q docker
    - python ci/build/build-docker-images.py --py-versions py38 --device-types cpu --build-type LOCAL --build-base
    # Tag the image built in the last step. We want to be sure to distinguish the image from the real Ray nightly.
    - docker tag rayproject/ray:nightly-py38-cpu ray-ci:kuberay-test
    # Load the image into the kind node
    - kind load docker-image ray-ci:kuberay-test
    - echo "--- Setting up KubeRay operator."
    - python python/ray/tests/kuberay/setup/setup_kuberay.py
    - ./ci/env/env_info.sh
    - echo "--- Running the test."
    - bazel test --config=ci $(./ci/run/bazel_export_options)
      --test_tag_filters=kuberay_operator
      --test_env=RAY_IMAGE=docker.io/library/ray-ci:kuberay-test
      --test_env=PULL_POLICY=IfNotPresent
      --test_env=KUBECONFIG=/root/.kube/config
      python/ray/tests/...
