{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0039a6",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "In this guide, we discuss how to deploy and interact with a Ray cluster on Kubernetes.\n",
    "\n",
    "This guide is available at the Ray GitHub repo as an [executable Jupyter notebook](https://github.com/ray-project/ray/blob/master/doc/source/cluster/kuberay/quickstart.ipynb).\n",
    "\n",
    "\n",
    "## Preparation\n",
    "\n",
    "### Install Kubectl\n",
    "\n",
    "We will use kubectl to interact with Kubernetes. Find installation instructions at the [Kubernetes documentation](https://kubernetes.io/docs/tasks/tools/#kubectl).\n",
    "\n",
    "### Access a Kubernetes cluster\n",
    "\n",
    "We will need access to a Kubernetes cluster. There are two options here:\n",
    "1. Configure access to a remote Kubernetes cluster\n",
    "**OR**\n",
    "2. Run the examples locally by [installing kind](https://kind.sigs.k8s.io/docs/user/quick-start/#installation). Start your [kind](https://kind.sigs.k8s.io/) cluster by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kind create cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6bf55c",
   "metadata": {},
   "source": [
    "To run the example in this guide, make sure your Kubernetes cluster can accomodate\n",
    "additional resource requests of 4 CPU and 2.5Gi memory. \n",
    "\n",
    "## Deploying the KubeRay operator\n",
    "\n",
    "Deploy the KubeRay Operator by cloning the KubeRay repo and applying the relevant configuration files from the master branch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4933dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# After the KubeRay 0.3.0 release branch cut, this documentation will be updated to refer to 0.3.0 branch.\n",
    "git clone https://github.com/ray-project/kuberay\n",
    "# This creates the KubeRay operator and all of the resources it needs.\n",
    "kubectl create -k ray-operator/config/default\n",
    "# Note that we must use \"kubectl create\" in the above command.\"kubectl apply\" will not work due to https://github.com/ray-project/kuberay/issues/271"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d889973",
   "metadata": {},
   "source": [
    "Confirm that the operator is running in the namespace `ray-system`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0291f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl -n ray-system get pod --selector=app.kubernetes.io/component=kuberay-operator\n",
    "# NAME                                READY   STATUS    RESTARTS   AGE\n",
    "# kuberay-operator-557c6c8bcd-t9zkz   1/1     Running   0          XXs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b686d",
   "metadata": {},
   "source": [
    "### Namespace-scoped operator\n",
    "Note that the above command deploys the operator at _Kubernetes cluster scope_; the operator will manage resources in all Kubernetes namespaces.\n",
    "**If your use-case requires running the operator at namespaced-scope**, refer to [the instructions at the KubeRay docs](https://github.com/ray-project/kuberay#single-namespace-version)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387f1c7",
   "metadata": {},
   "source": [
    "## Deploying a Ray Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac1c06",
   "metadata": {},
   "source": [
    "Once the KubeRay operator is running, we are ready to deploy a Ray cluster by deploying a RayCluster Custom Resource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0762ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Ray cluster is named `raycluster-autoscaler` because it has the optional Ray Autoscaler support enabled.\n",
    "kubectl apply -f kuberay/ray-operator/samples/ray-cluster.autoscaler.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68791bfc",
   "metadata": {},
   "source": [
    "Once the RayCluster CR has been created, you can view it by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get raycluster\n",
    "# NAME                    AGE\n",
    "# raycluster-autoscaler   XXs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pods --selector=ray.io/cluster=raycluster-autoscaler\n",
    "# NAME                                             READY   STATUS    RESTARTS   AGE\n",
    "# raycluster-autoscaler-head-mlmmq                 2/2     Running   0          XXs\n",
    "# raycluster-autoscaler-worker-small-group-bt46r   1/1     Running   0          XXs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c0ec4",
   "metadata": {},
   "source": [
    "We see a Ray head with two containers -- the Ray container and autoscaler sidecar. We also a Ray worker with its single Ray container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40daa2",
   "metadata": {},
   "source": [
    "## Interacting with a Ray Cluster\n",
    "\n",
    "Now, let's interact with the Ray cluster we've deployed.\n",
    "\n",
    "### Accessing the cluster with kubectl exec\n",
    "\n",
    "The most straightforward way to experiment with your Ray cluster is to\n",
    "exec directly into the head pod. First, identify your cluster's head pod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d916bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pods --selector=ray.io/cluster=raycluster-autoscaler --selector=ray.io/node-type=head\\\n",
    " -o custom-columns=POD:metadata.name --no-headers\n",
    "# raycluster-autoscaler-head-mlmmq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b3e9d",
   "metadata": {},
   "source": [
    "Now, we can run a Ray program on the Ray head pod. The Ray program in the next cell asks the autoscaler to scale the cluster to a total of 3 CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda40f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute your output from the last cell in place of \"raycluster-autoscaler-head-mlmmq\"\n",
    "! kubectl exec raycluster-autoscaler-head-mlmmq -it -c ray-head -- python -c\\\n",
    " \"import ray; ray.init(); ray.autoscaler.sdk.request_resources(num_cpus=3)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a66b4",
   "metadata": {},
   "source": [
    "### Autoscaling\n",
    "\n",
    "The last command should have triggered Ray pod upscaling. To confirm the new worker pod is up, let's query the RayCluster's pods again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pod --selector=ray.io/cluster=raycluster-autoscaler\n",
    "# NAME                                             READY   STATUS    RESTARTS   AGE\n",
    "# raycluster-autoscaler-head-mlmmq                 2/2     Running   0          XXs\n",
    "# raycluster-autoscaler-worker-small-group-bt46r   1/1     Running   0          XXs\n",
    "# raycluster-autoscaler-worker-small-group-krgmp   1/1     Running   0          XXs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba7b39d",
   "metadata": {},
   "source": [
    "To get a summary of your cluster's status, run `ray status` on your cluster's Ray head node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a51d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl exec raycluster-autoscaler-head-mlmmq -it -c ray-head -- ray status \n",
    "# ======== Autoscaler status: 2022-07-21 14:38:20.849465 ========"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103e94e",
   "metadata": {},
   "source": [
    "Alternatively, to examine the full autoscaling logs, fetch the stdout of the Ray head pod's autoscaler sidecar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command gets the last 20 lines of autoscaler logs.\n",
    "! kubectl logs raycluster-autoscaler-head-mlmmq -c autoscaler | tail -n 20\n",
    "# ======== Autoscaler status: 2022-07-21 14:28:17.686505 ========\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c76dc",
   "metadata": {},
   "source": [
    "### The Ray head service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348aca51",
   "metadata": {},
   "source": [
    "The KubeRay operator configures a [Kubernetes service]() targeting the Ray head pod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52010a1",
   "metadata": {},
   "source": [
    "### Using Ray Job submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ac8e81",
   "metadata": {},
   "source": [
    "Ray provides a [Job Submission API]() which can be used to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9de9bd",
   "metadata": {},
   "source": [
    "### Viewing the Ray Dashboard\n",
    "\n",
    "### Accessing the cluster using Ray Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04297e42",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "### Deleting a Ray Cluster\n",
    "To delete the Ray Cluster we deployed in this example, you can run either of the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f846f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete by reference to the RayCluster custom resource\n",
    "! kubectl delete raycluster raycluster-autoscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7721d",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3219c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete by reference to the yaml file we used to define the RayCluster CR \n",
    "! kubectl delete -f raycluster-autoscaler.yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ecbdc",
   "metadata": {},
   "source": [
    "Confirm that the Ray Cluster's pods are gone by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408747a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f9bcb",
   "metadata": {},
   "source": [
    "Note that it may take several seconds for the Ray pods to be fully terminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21d54e",
   "metadata": {},
   "source": [
    "### Deleting the KubeRay operator\n",
    "In typical operation, the KubeRay operator should be left as a long-running process that manages many Ray clusters.\n",
    "If you would like to delete the operator and associated resources, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67863619",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl delete -k kuberay/ray-operator/config/default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c8bf4",
   "metadata": {},
   "source": [
    "### Deleting a local kind cluster\n",
    "Finally, if you'd like to delete your local kind cluster, run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafcde8",
   "metadata": {},
   "source": [
    "! kind delete cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
