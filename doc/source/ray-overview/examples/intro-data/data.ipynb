{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1b82d0",
   "metadata": {},
   "source": [
    "# Introduction to Ray Data\n",
    "\n",
    "This template provides a comprehensive introduction to **Ray Data** — a scalable data processing library for AI workloads built on [Ray](https://docs.ray.io/en/latest/). You will learn what Ray Data is, why it matters for ML pipelines, and how to use its core APIs hands-on with an MNIST image classification example.\n",
    "\n",
    "In the first half, we'll walk through the core Ray Data workflow — loading, transforming, and persisting data — with concepts explained along the way. The second half covers advanced topics you can explore as your workloads grow.\n",
    "\n",
    "**Core:**\n",
    "- **Part 1:** When to Use Ray Data\n",
    "- **Part 2:** Loading Data\n",
    "- **Part 3:** Lazy Execution\n",
    "- **Part 4:** Transforming Data with `map_batches`\n",
    "- **Part 5:** Stateful Transformations and Batch Inference\n",
    "- **Part 6:** Data Operations — Groupby, Aggregation\n",
    "- **Part 7:** Observability\n",
    "- **Part 8:** Materializing and Persisting Data\n",
    "\n",
    "**Advanced topics:**\n",
    "- **Part 9:** Preprocessing and Expressions\n",
    "- **Part 10:** Shuffling\n",
    "- **Part 11:** Resource Management and Performance Tuning\n",
    "- **Part 12:** Fault Tolerance and Checkpointing\n",
    "- **Summary and Next Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97241b8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82bf80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mSuccessfully registered `torch, torchvision` packages to be installed on all cluster nodes.\u001b[0m\n",
      "\u001b[92mView and update dependencies here: https://ci-b4g4tb.anyscale-dev.dev/cld_kvedZWag2qA8i5BjxUevf5i7/prj_yUuybX98Ac4CrUTGXumhdpBs/workspaces/expwrk_cu4z6r7chzpw6yny2dw9xqp3gr?workspace-tab=dependencies\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \"torch==2.10.0\" \"torchvision==0.25.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accb94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb0c20",
   "metadata": {},
   "source": [
    "### Note on Storage\n",
    "\n",
    "Throughout this tutorial, we use `/mnt/cluster_storage` to represent a shared storage location. In a multi-node cluster, Ray workers on different nodes cannot access the head node's local file system. Use a [shared storage solution](https://docs.anyscale.com/configuration/storage#shared) accessible from every node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1af30",
   "metadata": {},
   "source": "## Part 1: When to Use Ray Data\n\nConsider using Ray Data when your project meets one or more of these criteria:\n\n| **Challenge** | **Ray Data Solution** |\n|---------------|----------------------|\n| **Operating on large datasets** | Distributes data loading and processing across a Ray cluster with streaming execution |\n| **Feeding data into distributed training** | Streams data directly to [Ray Train](https://docs.ray.io/en/latest/train/user-guides/data-loading-preprocessing.html) workers with configurable batch sizes — no intermediate disk writes needed. See the **Introduction to Ray Train** template for a hands-on walkthrough. |\n| **Running batch inference at scale** | Maximizes GPU utilization by streaming data through model inference actors |\n| **Building reliable data pipelines** | Leverages Ray Core's fault-tolerance mechanisms — retries, checkpointing, and recovery |\n\nRay Data features a **streaming execution engine** that processes data in a pipelined fashion across a heterogeneous cluster of CPUs and GPUs. You write everything in native Python — your existing functions and libraries (NumPy, PyTorch, etc.) work as-is — and Ray Data handles the distribution, avoiding full materialization in memory and keeping all hardware utilized.\n\nTo understand why this matters, consider the difference between traditional batch processing and streaming:\n\n**Traditional batch processing** completes one stage fully before starting the next, leading to idle resources:\n\n<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/batch-processing.png\" width=\"80%\" alt=\"Traditional Batch Processing\">\n\n**Streaming pipelining** overlaps stages, keeping all hardware (CPUs and GPUs) busy simultaneously:\n\n<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/pipelining.png\" width=\"80%\" alt=\"Streaming Model Pipelining\">\n\nThis is critical for GPU-heavy workloads: while the GPU runs inference on one batch, the CPU can preprocess the next batch."
  },
  {
   "cell_type": "markdown",
   "id": "9fbab4ee",
   "metadata": {},
   "source": [
    "## Part 2: Loading Data\n",
    "\n",
    "Ray Data provides built-in connectors for common formats — Parquet, CSV, JSON, images, text — as well as sources such as HuggingFace Datasets, Delta Lake, Iceberg, and in-memory objects (NumPy, Pandas, PyTorch). See the full list in the [Input/Output docs](https://docs.ray.io/en/latest/data/api/input_output.html) and the [data loading guide](https://docs.ray.io/en/latest/data/loading-data.html).\n",
    "\n",
    "Under the hood, Ray Data uses Ray tasks to read data from remote storage. It creates read tasks proportional to the number of CPUs in your cluster, and each task produces output **blocks**:\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/intro-ai-libraries/dataset-read-many-to-many.png\" width=\"90%\">\n",
    "\n",
    "Let's load MNIST image data from S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8002f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ray.data.read_images(\n",
    "    \"s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/\",\n",
    "    include_paths=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3482c",
   "metadata": {},
   "source": [
    "A **Dataset** is a distributed collection of **blocks** — contiguous subsets of rows stored as PyArrow tables. Blocks are distributed across the cluster and processed in parallel. They live in the **Ray object store** — shared memory distributed across cluster nodes — so data passes between operators through zero-copy reads. When the object store fills up, Ray spills blocks to disk automatically.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/dataset-arch.svg\" width=\"90%\"/>\n",
    "\n",
    "Since a Dataset is a list of Ray object references, it can be freely passed between Ray tasks, actors, and libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd25321",
   "metadata": {},
   "source": "## Part 3: Lazy Execution\n\nIn Ray Data, most transformations are **lazy** — they build an execution plan rather than running immediately. The plan executes only when you call a method that *consumes* or *materializes* the dataset.\n\n**Execution-triggering methods include:**\n\n| **Category** | **Methods** |\n|-------------|------------|\n| Small samples | `take_batch()`, `take()`, `show()` |\n| Full materialization | `materialize()` |\n| Write to storage | `write_parquet()`, `write_csv()`, etc. |\n| Aggregations | `count()`, `mean()`, `min()`, `max()`, `sum()`, `std()` |\n| Joins and shuffles | `union()`, `random_shuffle()`, `sort()` |\n\nTo materialize a small subset for inspection, use `take`:"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0698a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:03,906\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_23_0\n",
      "2026-02-24 23:18:03,911\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_23_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:03,912\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_23_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> LimitOperator[limit=5] -> TaskPoolMapOperator[ReadFiles]\n",
      "2026-02-24 23:18:03,929\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_23_0 =======\n",
      "2026-02-24 23:18:03,930\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:03,931\tINFO logging_progress.py:227 -- Active & requested resources: 0/56 CPU, 0.0B/48.1GiB object store\n",
      "2026-02-24 23:18:03,931\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:03,932\tINFO logging_progress.py:231 -- ListFiles: 0/1\n",
      "2026-02-24 23:18:03,932\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:03,933\tINFO logging_progress.py:231 -- limit=5: 0/1\n",
      "2026-02-24 23:18:03,933\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:03,934\tINFO logging_progress.py:231 -- ReadFiles: 0/1\n",
      "2026-02-24 23:18:03,934\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:03,935\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:06,106\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_23_0 execution finished in 2.19 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = ds.take(5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "for ax, row in zip(axes, sample):\n",
    "    label = row[\"path\"].split(\"/\")[-2]\n",
    "    ax.imshow(row[\"image\"], cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd880d56",
   "metadata": {},
   "source": [
    "This lazy execution model lets Ray Data optimize the full pipeline before running it. When you chain transformations (e.g., `ds.map_batches(f1).map_batches(f2).write_parquet(...)`), Ray Data builds a **logical plan** of your declared operations, then produces an optimized **physical plan**. A key optimization is **operator fusion** — adjacent compatible operators are merged into a single task, reducing data movement between stages. You can use `ds.explain()` to inspect the execution plan.\n",
    "\n",
    "For a deeper dive into Ray Data internals, see the [Data Internals guide](https://docs.ray.io/en/latest/data/data-internals.html) and the [Key Concepts page](https://docs.ray.io/en/latest/data/key-concepts.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13644107",
   "metadata": {},
   "source": [
    "## Part 4: Transforming Data with `map_batches`\n",
    "\n",
    "The primary transformation API in Ray Data is `map_batches()`. It applies a user-defined function to each batch of data in parallel.\n",
    "\n",
    "A batch is a `dict[str, np.ndarray]` by default. Your function receives a batch and returns a transformed batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "919fda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "    \"\"\"Normalize MNIST images to [-1, 1] range using torchvision transforms.\"\"\"\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    batch[\"image\"] = [transform(image) for image in batch[\"image\"]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ade0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_normalized = ds.map_batches(normalize)  # Lazy — not executed yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391e9a1",
   "metadata": {},
   "source": [
    "Let's verify the transformation works on a small batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae09d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:06,674\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_25_0\n",
      "2026-02-24 23:18:06,680\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_25_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:06,681\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_25_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> LimitOperator[limit=10]\n",
      "2026-02-24 23:18:06,698\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_25_0 =======\n",
      "2026-02-24 23:18:06,699\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:06,700\tINFO logging_progress.py:227 -- Active & requested resources: 0/56 CPU, 0.0B/48.1GiB object store\n",
      "2026-02-24 23:18:06,701\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:06,701\tINFO logging_progress.py:231 -- ListFiles: 0/1\n",
      "2026-02-24 23:18:06,702\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:06,702\tINFO logging_progress.py:231 -- ReadFiles: 0/1\n",
      "2026-02-24 23:18:06,703\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:06,703\tINFO logging_progress.py:231 -- MapBatches(normalize): 0/1\n",
      "2026-02-24 23:18:06,704\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:06,704\tINFO logging_progress.py:231 -- limit=10: 0/1\n",
      "2026-02-24 23:18:06,705\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:06,706\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:13,009\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_25_0 execution finished in 6.33 seconds\n"
     ]
    }
   ],
   "source": [
    "normalized_batch = ds_normalized.take_batch(batch_size=10)\n",
    "\n",
    "for image in normalized_batch[\"image\"]:\n",
    "    assert image.shape == (1, 28, 28)  # channel, height, width\n",
    "    assert image.min() >= -1 and image.max() <= 1  # normalized range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74181cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1, 28, 28)\n",
      "Min value: -1.0000\n",
      "Max value: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Check the value ranges after normalization\n",
    "print(f\"Shape: {normalized_batch['image'][0].shape}\")\n",
    "print(f\"Min value: {normalized_batch['image'][0].min():.4f}\")\n",
    "print(f\"Max value: {normalized_batch['image'][0].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820b10a",
   "metadata": {},
   "source": [
    "**Key `map_batches` parameters:**\n",
    "\n",
    "| **Parameter** | **Purpose** |\n",
    "|--------------|-------------|\n",
    "| `batch_size` | Number of rows per batch (default: `None` = entire block) |\n",
    "| `batch_format` | `\"default\"`/`\"numpy\"` (dict), `\"pandas\"`, or `\"pyarrow\"` |\n",
    "| `num_cpus` / `num_gpus` | Resources per worker |\n",
    "| `fn_kwargs` | Keyword arguments to pass to your function |\n",
    "| `compute` | Execution strategy — `TaskPoolStrategy` for functions, `ActorPoolStrategy` for classes |\n",
    "\n",
    "**When to use `map` vs `map_batches`:** Use `map_batches` when the underlying computation is vectorized — for example, NumPy array operations, PyArrow transforms, or GPU inference. If your logic is row-by-row standard Python (such as string parsing or feature extraction), use `map` instead, which applies a function to each row individually and avoids the overhead of batch formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054ea53",
   "metadata": {},
   "source": "## Part 5: Stateful Transformations and Batch Inference\n\nIn the previous section, we specified a normalization step where individual tasks did not require maintaining any state — a stateless operation. It is however common that operations require some pre-stored state. For example, in batch inference, you want to load a model once and reuse it across many batches. Ray Data supports this via **callable classes** passed to `map_batches`:\n\n- `__init__`: Initialize expensive state (load model, set up connections)\n- `__call__`: Process each batch using the initialized state\n\nHere's an MNIST classifier that loads a pre-trained PyTorch model and runs inference:"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "970021bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.model = torch.jit.load(model_path)\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "        images = torch.tensor(batch[\"image\"]).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(images).numpy()\n",
    "\n",
    "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2379b",
   "metadata": {},
   "source": [
    "Download the model to shared storage, then apply the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2a639",
   "metadata": {},
   "outputs": [],
   "source": "!aws s3 cp --no-sign-request s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt /mnt/cluster_storage/model.pt"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee6b6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds = ds_normalized.map_batches(\n",
    "    MNISTClassifier,\n",
    "    fn_constructor_kwargs={\"model_path\": \"/mnt/cluster_storage/model.pt\"},\n",
    "    num_cpus=1,\n",
    "    batch_size=100,\n",
    "    compute=ray.data.ActorPoolStrategy(size=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6842ba",
   "metadata": {},
   "source": [
    "**Note:** We pass the class *uninitialized* — Ray Data creates the actor and passes `fn_constructor_kwargs` to `__init__`. This ensures the model is loaded once per worker, not once per batch. To run on GPUs instead, add `num_gpus=1` and move the model/tensors to CUDA. For more on batch inference patterns, see the [Batch Inference guide](https://docs.ray.io/en/latest/data/batch_inference.html).\n",
    "\n",
    "Let's verify predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b879b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:16,026\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_27_0\n",
      "2026-02-24 23:18:16,034\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_27_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:16,035\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_27_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)] -> LimitOperator[limit=5]\n",
      "2026-02-24 23:18:16,194\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_27_0 =======\n",
      "2026-02-24 23:18:16,195\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:16,196\tINFO logging_progress.py:227 -- Active & requested resources: 0/56 CPU, 0.0B/48.1GiB object store (pending: 1 CPU)\n",
      "2026-02-24 23:18:16,196\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:16,197\tINFO logging_progress.py:231 -- ListFiles: 0/1\n",
      "2026-02-24 23:18:16,198\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:16,199\tINFO logging_progress.py:231 -- ReadFiles: 0/1\n",
      "2026-02-24 23:18:16,199\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:16,200\tINFO logging_progress.py:231 -- MapBatches(normalize)->MapBatches(MNISTClassifier): 0/1\n",
      "2026-02-24 23:18:16,200\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]\n",
      "2026-02-24 23:18:16,201\tINFO logging_progress.py:231 -- limit=5: 0/1\n",
      "2026-02-24 23:18:16,201\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:16,202\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:20,154\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_27_0 execution finished in 4.12 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0, Predicted: 0\n",
      "True label: 0, Predicted: 0\n",
      "True label: 0, Predicted: 0\n",
      "True label: 0, Predicted: 0\n",
      "True label: 0, Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "preds = ds_preds.take(5)\n",
    "for p in preds:\n",
    "    digit = p[\"path\"].split(\"/\")[-2]\n",
    "    print(f\"True label: {digit}, Predicted: {p['predicted_label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15466a18",
   "metadata": {},
   "source": [
    "**Scaling up:** Increase the pool size to use more workers. For example, `compute=ray.data.ActorPoolStrategy(size=4)` creates a fixed pool of 4 actors, or `compute=ray.data.ActorPoolStrategy(min_size=1, max_size=4)` creates an autoscaling pool."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aabf9ae7",
   "metadata": {},
   "source": [
    "## Part 6: Materializing and Persisting Data\n",
    "\n",
    "Now that we've built a multi-step pipeline (read → normalize → inference), let's inspect the execution plan Ray Data created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k9vwffxn0oo",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfnj22u6vc",
   "metadata": {},
   "source": [
    "By default, Ray Data streams data lazily. This is the right point to **materialize** `ds_preds` — execute the pipeline fully and cache the results in the Ray object store (distributed across the cluster, spilling to disk if needed).\n",
    "\n",
    "Materializing here also releases the `ActorPoolStrategy` worker: as long as `ds_preds` is an unexecuted lazy plan, the GPU actor stays alive. Once materialized, the actor is freed and the GPU node can scale down.\n",
    "\n",
    "**When to materialize:**\n",
    "- When you need to reuse the same dataset multiple times (avoids re-computation)\n",
    "- When downstream operations require the full dataset (e.g., `groupby`, `random_shuffle`)\n",
    "- When using `ActorPoolStrategy` — to release the actor pool after execution\n",
    "\n",
    "**When NOT to materialize:**\n",
    "- For streaming pipelines where data flows through once (training ingest, write-to-sink)\n",
    "- When the dataset is too large to fit in the object store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "555f91f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:20,339\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_28_0\n",
      "2026-02-24 23:18:20,344\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_28_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:20,345\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_28_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)]\n",
      "2026-02-24 23:18:20,502\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_28_0 =======\n",
      "2026-02-24 23:18:20,503\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:20,504\tINFO logging_progress.py:227 -- Active & requested resources: 0/56 CPU, 0.0B/48.1GiB object store (pending: 1 CPU)\n",
      "2026-02-24 23:18:20,505\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:20,505\tINFO logging_progress.py:231 -- ListFiles: 0/1\n",
      "2026-02-24 23:18:20,506\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:20,507\tINFO logging_progress.py:231 -- ReadFiles: 0/1\n",
      "2026-02-24 23:18:20,508\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:20,508\tINFO logging_progress.py:231 -- MapBatches(normalize)->MapBatches(MNISTClassifier): 0/1\n",
      "2026-02-24 23:18:20,509\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]\n",
      "2026-02-24 23:18:20,510\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:25,049\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_28_0 execution finished in 4.70 seconds\n"
     ]
    }
   ],
   "source": [
    "ds_preds = ds_preds.materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8ab6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator 0 ReadFiles: \n",
      "\n",
      "Operator 1 ListFiles: 1 tasks executed, 1 blocks produced in 0.41s\n",
      "* Remote wall time: 406.32ms min, 406.32ms max, 406.32ms mean, 406.32ms total\n",
      "* Remote cpu time: 143.73ms min, 143.73ms max, 143.73ms mean, 143.73ms total\n",
      "* UDF time: 0us min, 0us max, 0.0us mean, 0us total\n",
      "* Peak heap memory usage (MiB): 134.44 min, 134.44 max, 134 mean\n",
      "* Output num rows per block: 500 min, 500 max, 500 mean, 500 total\n",
      "* Output size bytes per block: 50413 min, 50413 max, 50413 mean, 50413 total\n",
      "* Output rows per task: 500 min, 500 max, 500 mean, 1 tasks used\n",
      "* Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "* Operator throughput:\n",
      "\t* Total input num rows: 0 rows\n",
      "\t* Total output num rows: 500 rows\n",
      "\t* Ray Data throughput: 1230.5675327992697 rows/s\n",
      "\t* Estimated single task throughput: 1230.5675327992697 rows/s\n",
      "\n",
      "Operator 2 ReadFiles: 1 tasks executed, 1 blocks produced in 2.51s\n",
      "* Remote wall time: 2.51s min, 2.51s max, 2.51s mean, 2.51s total\n",
      "* Remote cpu time: 1.23s min, 1.23s max, 1.23s mean, 1.23s total\n",
      "* UDF time: 0us min, 0us max, 0.0us mean, 0us total\n",
      "* Peak heap memory usage (MiB): 446.77 min, 446.77 max, 446 mean\n",
      "* Output num rows per block: 500 min, 500 max, 500 mean, 500 total\n",
      "* Output size bytes per block: 436350 min, 436350 max, 436350 mean, 436350 total\n",
      "* Output rows per task: 500 min, 500 max, 500 mean, 1 tasks used\n",
      "* Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "* Operator throughput:\n",
      "\t* Total input num rows: 500 rows\n",
      "\t* Total output num rows: 500 rows\n",
      "\t* Ray Data throughput: 199.23489536552844 rows/s\n",
      "\t* Estimated single task throughput: 199.23489536552844 rows/s\n",
      "\n",
      "Operator 3 MapBatches(normalize)->MapBatches(MNISTClassifier): 1 tasks executed, 1 blocks produced in 0.75s\n",
      "* Remote wall time: 745.2ms min, 745.2ms max, 745.2ms mean, 745.2ms total\n",
      "* Remote cpu time: 748.12ms min, 748.12ms max, 748.12ms mean, 748.12ms total\n",
      "* UDF time: 801.8ms min, 801.8ms max, 801.8ms mean, 801.8ms total\n",
      "* Peak heap memory usage (MiB): 496.69 min, 496.69 max, 496 mean\n",
      "* Output num rows per block: 500 min, 500 max, 500 mean, 500 total\n",
      "* Output size bytes per block: 1616350 min, 1616350 max, 1616350 mean, 1616350 total\n",
      "* Output rows per task: 500 min, 500 max, 500 mean, 1 tasks used\n",
      "* Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
      "* Operator throughput:\n",
      "\t* Total input num rows: 500 rows\n",
      "\t* Total output num rows: 500 rows\n",
      "\t* Ray Data throughput: 670.9580832557652 rows/s\n",
      "\t* Estimated single task throughput: 670.9580832557652 rows/s\n",
      "\n",
      "Dataset throughput:\n",
      "\t* Ray Data throughput: 50.612815419000974 rows/s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check materialized dataset stats\n",
    "print(ds_preds.stats())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b46a71b",
   "metadata": {},
   "source": [
    "### Persisting to storage\n",
    "\n",
    "Write processed data to persistent storage using any of Ray Data's write functions. Ray Data supports writing to Parquet, CSV, JSON, TFRecords, and more. See the [Input/Output docs](https://docs.ray.io/en/latest/data/api/input_output.html) for the full list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a663827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:25,458\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_31_0\n",
      "2026-02-24 23:18:25,461\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_31_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:25,462\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_31_0: InputDataBuffer[Input] -> TaskPoolMapOperator[Write]\n",
      "2026-02-24 23:18:25,481\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_31_0 =======\n",
      "2026-02-24 23:18:25,482\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:25,483\tINFO logging_progress.py:227 -- Active & requested resources: 0/56 CPU, 0.0B/48.1GiB object store\n",
      "2026-02-24 23:18:25,484\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:25,485\tINFO logging_progress.py:231 -- Write: 0/1\n",
      "2026-02-24 23:18:25,485\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:25,486\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:25,579\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_31_0 execution finished in 0.12 seconds\n",
      "2026-02-24 23:18:25,605\tINFO dataset.py:5384 -- Data sink Parquet finished. 500 rows and 1.5MiB data written.\n"
     ]
    }
   ],
   "source": [
    "ds_preds.write_parquet(\"/mnt/cluster_storage/mnist_preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fce12",
   "metadata": {},
   "source": [
    "## Part 7: Data Operations\n",
    "\n",
    "### Adding Labels\n",
    "\n",
    "Let's add ground truth labels to our MNIST dataset by extracting them from the image paths. Since this is row-by-row Python string parsing, we use `map` instead of `map_batches`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0aa9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(row: dict[str, any]) -> dict[str, any]:\n",
    "    row[\"ground_truth_label\"] = int(row[\"path\"].split(\"/\")[-2])\n",
    "    return row\n",
    "\n",
    "\n",
    "ds_labeled = ds_normalized.map(add_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdac5b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:25,936\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_34_0\n",
      "2026-02-24 23:18:25,942\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_34_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:25,943\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_34_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)] -> LimitOperator[limit=1] -> TaskPoolMapOperator[Map(add_label)]\n",
      "2026-02-24 23:18:25,969\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_34_0 =======\n",
      "2026-02-24 23:18:25,971\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:25,972\tINFO logging_progress.py:227 -- Active & requested resources: 0/56 CPU, 0.0B/48.1GiB object store\n",
      "2026-02-24 23:18:25,972\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:25,973\tINFO logging_progress.py:231 -- ListFiles: 0/1\n",
      "2026-02-24 23:18:25,974\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:25,974\tINFO logging_progress.py:231 -- ReadFiles: 0/1\n",
      "2026-02-24 23:18:25,975\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:25,975\tINFO logging_progress.py:231 -- MapBatches(normalize): 0/1\n",
      "2026-02-24 23:18:25,976\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:25,976\tINFO logging_progress.py:231 -- limit=1: 0/1\n",
      "2026-02-24 23:18:25,976\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:25,977\tINFO logging_progress.py:231 -- Map(add_label): 0/1\n",
      "2026-02-24 23:18:25,977\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:25,978\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:29,112\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_34_0 execution finished in 3.17 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'image': array([[[-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -0.9764706 , -1.        , -1.        , -1.        ,\n",
       "           -0.9372549 , -1.        , -0.96862745, -0.9764706 ,\n",
       "           -0.92156863, -1.        , -1.        , -0.94509804,\n",
       "           -0.9607843 , -0.9764706 , -1.        , -0.99215686,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -0.99215686, -0.9764706 , -1.        ,\n",
       "           -1.        , -0.90588236, -0.8352941 , -1.        ,\n",
       "           -1.        , -0.92156863, -0.88235295, -1.        ,\n",
       "           -1.        , -0.94509804, -0.9137255 , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -0.88235295,\n",
       "           -1.        , -1.        , -1.        , -0.92941177,\n",
       "           -0.96862745, -1.        , -1.        , -0.85882354,\n",
       "           -1.        , -1.        , -0.90588236, -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -0.9137255 , -1.        , -1.        , -0.96862745,\n",
       "           -1.        , -0.92941177, -0.9843137 , -0.92941177,\n",
       "           -0.9529412 , -0.827451  , -1.        , -1.        ,\n",
       "           -0.88235295, -1.        , -1.        , -0.9372549 ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -0.9372549 , -1.        ,\n",
       "           -0.5294118 ,  0.5294118 ,  0.9137255 ,  0.254902  ,\n",
       "           -0.6627451 , -1.        , -1.        , -1.        ,\n",
       "           -0.9372549 , -1.        , -0.9372549 , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -0.9843137 , -0.96862745, -1.        , -0.8117647 ,\n",
       "            0.30980396,  0.92941177,  1.        ,  1.        ,\n",
       "            0.54509807, -0.6       , -0.85882354, -0.9529412 ,\n",
       "           -0.9764706 , -1.        , -0.9372549 , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -0.9529412 ,  0.10588241,\n",
       "            1.        ,  0.8901961 ,  0.8666667 ,  0.7882353 ,\n",
       "            1.        ,  0.84313726,  0.18431377, -1.        ,\n",
       "           -1.        , -0.8980392 , -1.        , -0.94509804,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -0.9764706 , -1.        , -0.4352941 ,  0.8666667 ,\n",
       "            0.8117647 ,  0.92156863,  0.7882353 , -0.78039217,\n",
       "           -0.02745098,  0.20000005,  0.92941177, -0.17647058,\n",
       "           -1.        , -1.        , -0.94509804, -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9529412 , -0.99215686, -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -0.9372549 , -0.9764706 ,  0.9607843 ,  1.        ,\n",
       "           -0.20784312, -0.88235295, -0.75686276, -0.99215686,\n",
       "           -0.8980392 , -1.        ,  0.84313726,  0.7254902 ,\n",
       "           -0.9764706 , -1.        , -0.99215686, -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -0.9843137 ,\n",
       "           -0.9372549 , -0.9843137 , -1.        , -0.92941177,\n",
       "           -1.        , -0.5372549 ,  0.9843137 ,  0.6862745 ,\n",
       "           -0.8509804 , -0.84313726, -1.        , -0.9607843 ,\n",
       "           -0.9529412 , -1.        ,  0.34901965,  0.8980392 ,\n",
       "           -0.12156862, -1.        , -0.92941177, -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.99215686, -1.        , -0.9843137 ,\n",
       "           -0.9529412 , -1.        , -1.        , -0.9529412 ,\n",
       "           -1.        ,  0.60784316,  0.92156863,  0.41960788,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -0.01176471,  0.94509804,\n",
       "            0.5686275 , -0.99215686, -1.        , -0.99215686,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-0.96862745, -0.9607843 , -1.        , -1.        ,\n",
       "           -0.99215686, -1.        , -1.        , -0.99215686,\n",
       "           -0.8666667 ,  0.96862745,  0.9843137 , -0.20784312,\n",
       "           -0.9764706 , -0.9137255 , -1.        , -0.92156863,\n",
       "           -1.        , -1.        , -0.01960784,  0.90588236,\n",
       "            0.64705884, -0.92941177, -1.        , -0.96862745,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9529412 , -1.        , -1.        ,\n",
       "           -0.9607843 , -0.90588236, -0.9607843 , -1.        ,\n",
       "           -0.6862745 ,  0.8901961 ,  0.34901965, -0.88235295,\n",
       "           -0.99215686, -0.99215686, -1.        , -0.99215686,\n",
       "           -0.99215686, -0.96862745, -0.09019607,  0.99215686,\n",
       "            0.5686275 , -0.92941177, -1.        , -0.9764706 ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9607843 , -0.96862745, -1.        ,\n",
       "           -0.9607843 , -0.9607843 , -1.        , -1.        ,\n",
       "           -0.0745098 ,  1.        , -0.3098039 , -1.        ,\n",
       "           -0.99215686, -1.        , -0.92941177, -1.        ,\n",
       "           -1.        , -0.9843137 , -0.25490195,  1.        ,\n",
       "            0.6       , -1.        , -0.88235295, -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9764706 , -0.9843137 , -0.9764706 ,\n",
       "           -1.        , -1.        , -1.        , -0.827451  ,\n",
       "            0.78039217,  0.96862745, -0.23137254, -1.        ,\n",
       "           -1.        , -0.85882354, -1.        , -0.9372549 ,\n",
       "           -1.        , -1.        , -0.01960784,  1.        ,\n",
       "            0.5921569 , -1.        , -0.9372549 , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-0.9607843 , -1.        , -1.        , -0.9607843 ,\n",
       "           -0.99215686, -1.        , -0.8352941 , -0.372549  ,\n",
       "            0.9764706 ,  0.94509804, -0.41960782, -1.        ,\n",
       "           -0.90588236, -1.        , -0.8980392 , -1.        ,\n",
       "           -0.99215686, -0.96862745,  0.4901961 ,  0.8745098 ,\n",
       "            0.49803925, -0.9529412 , -1.        , -0.96862745,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-0.9607843 , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -0.9843137 , -1.        , -0.2862745 ,\n",
       "            0.9607843 ,  0.7647059 , -0.9843137 , -1.        ,\n",
       "           -0.96862745, -1.        , -1.        , -0.9607843 ,\n",
       "           -1.        , -0.7882353 ,  0.8039216 ,  0.90588236,\n",
       "           -0.38823527, -1.        , -0.8901961 , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -0.99215686, -0.14509803,\n",
       "            1.        ,  0.5921569 , -0.96862745, -1.        ,\n",
       "           -1.        , -1.        , -0.96862745, -0.99215686,\n",
       "           -1.        ,  0.5137255 ,  1.        ,  0.7254902 ,\n",
       "           -1.        , -0.9764706 , -1.        , -0.8666667 ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9843137 , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -0.9607843 , -0.02745098,\n",
       "            1.        , -0.3098039 , -1.        , -0.8117647 ,\n",
       "           -1.        , -0.9372549 , -0.90588236, -1.        ,\n",
       "           -0.03529412,  1.        ,  0.9843137 ,  0.34901965,\n",
       "           -0.9764706 , -0.96862745, -1.        , -0.96862745,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9529412 , -1.        , -1.        ,\n",
       "           -0.9764706 , -1.        , -0.9843137 , -0.11372548,\n",
       "            0.9372549 ,  0.47450984, -0.77254903, -1.        ,\n",
       "           -1.        , -0.9607843 , -1.        , -0.41960782,\n",
       "            0.90588236,  0.9137255 ,  1.        , -0.52156866,\n",
       "           -1.        , -0.8117647 , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.92941177, -1.        , -1.        ,\n",
       "           -0.9529412 , -1.        , -1.        , -0.3960784 ,\n",
       "            0.92941177,  0.8666667 , -1.        , -0.9529412 ,\n",
       "           -0.92156863, -0.9137255 , -0.05882353,  1.        ,\n",
       "            1.        ,  0.81960785, -0.4980392 , -0.96862745,\n",
       "           -1.        , -1.        , -0.90588236, -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9372549 , -1.        , -0.9764706 ,\n",
       "           -0.96862745, -1.        , -1.        , -0.7176471 ,\n",
       "            0.88235295,  1.        ,  0.3803922 , -0.31764704,\n",
       "           -0.56078434,  0.70980394,  0.9843137 ,  0.90588236,\n",
       "            0.79607844, -0.5137255 , -1.        , -1.        ,\n",
       "           -0.9137255 , -0.8901961 , -1.        , -0.9529412 ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9607843 , -1.        , -0.9607843 ,\n",
       "           -1.        , -0.99215686, -1.        , -0.9529412 ,\n",
       "           -0.31764704,  1.        ,  0.9137255 ,  0.9529412 ,\n",
       "            1.        ,  0.8901961 ,  1.        ,  0.47450984,\n",
       "           -0.4352941 , -1.        , -0.8039216 , -0.92941177,\n",
       "           -1.        , -0.9764706 , -0.8980392 , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -0.9843137 , -1.        , -0.94509804,\n",
       "           -1.        , -0.99215686, -0.99215686, -1.        ,\n",
       "           -0.9843137 , -0.38039213,  0.70980394,  0.94509804,\n",
       "            0.9843137 ,  0.27843142, -0.5529412 , -0.8980392 ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -0.99215686, -0.96862745, -1.        , -0.9764706 ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ],\n",
       "          [-1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ,\n",
       "           -1.        , -1.        , -1.        , -1.        ]]],\n",
       "        dtype=float32),\n",
       "  'path': 'anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/0/img_11200.jpg',\n",
       "  'ground_truth_label': 0}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify labels were added\n",
    "ds_labeled.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebef9d4",
   "metadata": {},
   "source": [
    "### Groupby and Map Groups\n",
    "\n",
    "Use `groupby()` to group data by a key and `map_groups()` to apply per-group transformations. Here, we compute per-label accuracy using `ds_preds` from Part 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c69a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(group: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
    "    return {\n",
    "        \"accuracy\": [np.mean(group[\"predicted_label\"] == group[\"ground_truth_label\"])],\n",
    "        \"ground_truth_label\": group[\"ground_truth_label\"][:1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb7592e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:29,467\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_39_0\n",
      "2026-02-24 23:18:29,471\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_39_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:29,472\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_39_0: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(add_label)] -> HashShuffleOperator[Shuffle(key_columns=('ground_truth_label',), num_partitions=200)] -> TaskPoolMapOperator[MapBatches(compute_accuracy)] -> AllToAllOperator[Sort]\n",
      "2026-02-24 23:18:29,543\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_39_0 =======\n",
      "2026-02-24 23:18:29,547\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:29,549\tINFO logging_progress.py:227 -- Active & requested resources: 14/56 CPU, 0.0B/48.1GiB object store\n",
      "2026-02-24 23:18:29,550\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:29,553\tINFO logging_progress.py:231 -- Map(add_label): 0/1\n",
      "2026-02-24 23:18:29,554\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:29,555\tINFO logging_progress.py:231 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): 0/1\n",
      "2026-02-24 23:18:29,555\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 14.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:29,556\tINFO logging_progress.py:231 --     - Shuffle: 0/1\n",
      "2026-02-24 23:18:29,556\tINFO logging_progress.py:231 --     - Reduce: 0/1\n",
      "2026-02-24 23:18:29,557\tINFO logging_progress.py:231 -- MapBatches(compute_accuracy): 0/1\n",
      "2026-02-24 23:18:29,558\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:29,559\tINFO logging_progress.py:231 -- Sort: 0/1\n",
      "2026-02-24 23:18:29,559\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output\n",
      "2026-02-24 23:18:29,560\tINFO logging_progress.py:231 --     - Sort Sample: 0/1\n",
      "2026-02-24 23:18:29,561\tINFO logging_progress.py:231 --     - Shuffle Map: 0/1\n",
      "2026-02-24 23:18:29,564\tINFO logging_progress.py:231 --     - Shuffle Reduce: 0/1\n",
      "2026-02-24 23:18:29,564\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:39,632\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_39_0 =======\n",
      "2026-02-24 23:18:39,635\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:39,636\tINFO logging_progress.py:227 -- Active & requested resources: 15/56 CPU, 1.5MiB/48.1GiB object store\n",
      "2026-02-24 23:18:39,636\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:39,637\tINFO logging_progress.py:231 -- Map(add_label): 500/500\n",
      "2026-02-24 23:18:39,638\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 1.5MiB object store\n",
      "2026-02-24 23:18:39,639\tINFO logging_progress.py:231 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): 0/1\n",
      "2026-02-24 23:18:39,639\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 15.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:39,640\tINFO logging_progress.py:231 --     - Shuffle: 0/?\n",
      "2026-02-24 23:18:39,640\tINFO logging_progress.py:231 --     - Reduce: 0/1\n",
      "2026-02-24 23:18:39,641\tINFO logging_progress.py:231 -- MapBatches(compute_accuracy): 0/1\n",
      "2026-02-24 23:18:39,642\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:39,642\tINFO logging_progress.py:231 -- Sort: 0/1\n",
      "2026-02-24 23:18:39,643\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output\n",
      "2026-02-24 23:18:39,644\tINFO logging_progress.py:231 --     - Sort Sample: 0/1\n",
      "2026-02-24 23:18:39,644\tINFO logging_progress.py:231 --     - Shuffle Map: 0/1\n",
      "2026-02-24 23:18:39,645\tINFO logging_progress.py:231 --     - Shuffle Reduce: 0/1\n",
      "2026-02-24 23:18:39,645\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:44,395\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_39_0 execution finished in 14.92 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>ground_truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.98</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.98</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.98</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  ground_truth_label\n",
       "0      0.98                   0\n",
       "1      1.00                   1\n",
       "2      1.00                   2\n",
       "3      0.96                   3\n",
       "4      1.00                   4\n",
       "5      1.00                   5\n",
       "6      0.98                   6\n",
       "7      0.98                   7\n",
       "8      1.00                   8\n",
       "9      0.98                   9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_by_label = (\n",
    "    ds_preds\n",
    "    .map(add_label)\n",
    "    .groupby(\"ground_truth_label\")\n",
    "    .map_groups(compute_accuracy)\n",
    "    .sort(\"ground_truth_label\")\n",
    "    .to_pandas()\n",
    ")\n",
    "accuracy_by_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5165e62",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "\n",
    "Ray Data provides built-in aggregation functions: `count()`, `max()`, `mean()`, `min()`, `sum()`, `std()`. See the [aggregation API docs](https://docs.ray.io/en/latest/data/api/grouped_data.html#ray.data.aggregate.AggregateFn) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a074987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:44,688\tINFO logging.py:392 -- Registered dataset logger for dataset dataset_43_0\n",
      "2026-02-24 23:18:44,696\tINFO streaming_executor.py:182 -- Starting execution of Dataset dataset_43_0. Full logs are in /tmp/ray/session_2026-02-24_23-06-22_660137_2741/logs/ray-data\n",
      "2026-02-24 23:18:44,697\tINFO streaming_executor.py:183 -- Execution plan of Dataset dataset_43_0: InputDataBuffer[Input] -> TaskPoolMapOperator[Map(add_label)->MapBatches(compute_accuracy)] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n",
      "2026-02-24 23:18:44,735\tINFO logging_progress.py:174 -- ======= Running Dataset: dataset_43_0 =======\n",
      "2026-02-24 23:18:44,737\tINFO logging_progress.py:225 -- Total Progress: 0/?\n",
      "2026-02-24 23:18:44,739\tINFO logging_progress.py:227 -- Active & requested resources: 0.25/56 CPU, 0.0B/48.1GiB object store\n",
      "2026-02-24 23:18:44,741\tINFO logging_progress.py:181 -- \n",
      "2026-02-24 23:18:44,741\tINFO logging_progress.py:231 -- Map(add_label)->MapBatches(compute_accuracy): 0/1\n",
      "2026-02-24 23:18:44,743\tINFO logging_progress.py:233 --   Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-24 23:18:44,745\tINFO logging_progress.py:231 -- HashAggregate(key_columns=(), num_partitions=1): 0/1\n",
      "2026-02-24 23:18:44,747\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.2 CPU, 0.0B object store\n",
      "2026-02-24 23:18:44,754\tINFO logging_progress.py:231 --     - Shuffle: 0/1\n",
      "2026-02-24 23:18:44,755\tINFO logging_progress.py:231 --     - Aggregation: 0/1\n",
      "2026-02-24 23:18:44,756\tINFO logging_progress.py:231 -- limit=1: 0/1\n",
      "2026-02-24 23:18:44,757\tINFO logging_progress.py:233 --   Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store\n",
      "2026-02-24 23:18:44,765\tINFO logging_progress.py:192 -- =============================================\n",
      "2026-02-24 23:18:46,421\tINFO streaming_executor.py:300 -- ✔️  Dataset dataset_43_0 execution finished in 1.72 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy across all digits: 0.9880\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = ds_preds.map(add_label).map_batches(compute_accuracy).mean(on=\"accuracy\")\n",
    "print(f\"Mean accuracy across all digits: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb51b49",
   "metadata": {},
   "source": [
    "**Key takeaway:** `groupby` + `map_groups` lets you apply per-group logic, while built-in aggregation functions cover common statistical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cfb00",
   "metadata": {},
   "source": [
    "## Part 8: Observability\n",
    "\n",
    "Ray Data provides several tools for understanding what your pipeline is doing:\n",
    "\n",
    "- `ds.stats()` — programmatic breakdown of per-operator throughput and timing\n",
    "- `ds.explain()` — view the execution plan\n",
    "- **Ray Dashboard** — cluster utilization, per-operator metrics, object store usage\n",
    "- **Anyscale Metrics tab** — GPU utilization, memory, network, disk I/O\n",
    "\n",
    "Use `set_name()` to label your dataset in the Ray Dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abd51083",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_preds.set_name(\"mnist_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b6c71",
   "metadata": {},
   "source": "The **Ray Workloads** view shows each operator in your pipeline, its status, row counts, and throughput — so you can quickly identify which stage is the bottleneck:\n\n<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/intro-ai-libraries/ray-data-workloads.png\" width=\"90%\" alt=\"Ray Data Workloads view showing per-operator status and throughput\">\n\nThe **Ray Dashboard Metrics** tab gives you time-series charts for bytes and blocks generated per second, rows processed per second, object store memory usage and more — useful for spotting throughput drops or memory pressure over time:\n\n<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/intro-ai-libraries/ray-data-dashboard.png\" width=\"90%\" alt=\"Ray Dashboard Metrics showing throughput and object store memory\">\n\nFor detailed guidance, see the [Anyscale monitoring and debugging guide](https://docs.anyscale.com/monitoring)."
  },
  {
   "cell_type": "markdown",
   "id": "cdd7a00d",
   "metadata": {},
   "source": [
    "You've built a complete Ray Data pipeline — from loading through persistence. The following sections cover advanced topics organized by theme, and can be read in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822bd9c",
   "metadata": {},
   "source": [
    "## Additional APIs\n",
    "\n",
    "*Ray Data offers higher-level tools beyond `map` and `map_batches`.*\n",
    "\n",
    "### Part 9: Preprocessing and Expressions\n",
    "\n",
    "#### Preprocessors\n",
    "\n",
    "When a transform needs to compute statistics over the full dataset first (such as mean and standard deviation for normalization), Ray Data provides built-in Preprocessors that follow the familiar scikit-learn `fit` / `transform` pattern. See the [Preprocessor API reference](https://docs.ray.io/en/latest/data/api/preprocessor.html) for the full list of built-ins. You can also chain them with `Chain`:\n",
    "\n",
    "```python\n",
    "from ray.data.preprocessors import StandardScaler, Chain, LabelEncoder\n",
    "\n",
    "# Example with tabular data — fit computes statistics, transform applies them\n",
    "preprocessor = Chain(\n",
    "    StandardScaler(columns=[\"feature_a\", \"feature_b\"]),\n",
    "    LabelEncoder(label_column=\"label\"),\n",
    ")\n",
    "# preprocessor = preprocessor.fit(ds_tabular)\n",
    "# ds_processed = preprocessor.transform(ds_tabular)\n",
    "```\n",
    "\n",
    "#### Expressions API\n",
    "\n",
    "Before writing a custom `map` or `map_batches` function, check if the **Expressions API** can handle it for you. Expressions are built-in helper functions for common column operations — string manipulation, list operations, struct field access, arithmetic, and more — so you don't have to write boilerplate UDFs yourself.\n",
    "\n",
    "Use `col()` to reference columns, `lit()` for literal values, and chain operations with namespaces such as `.str`, `.list`, and `.struct`:\n",
    "\n",
    "```python\n",
    "from ray.data.expressions import col\n",
    "\n",
    "# Add an uppercase column without writing a custom function\n",
    "ds_example = ray.data.from_items([{\"name\": \"alice\"}, {\"name\": \"bob\"}, {\"name\": \"charlie\"}])\n",
    "ds_example = ds_example.with_column(\"upper_name\", col(\"name\").str.upper())\n",
    "ds_example.show()\n",
    "```\n",
    "\n",
    "Expressions also support arithmetic (`col(\"a\") + col(\"b\")`), comparisons (`col(\"score\") > 0.5`), and custom UDFs through the `@udf` decorator. See the full [Expressions API reference](https://docs.ray.io/en/latest/data/api/expressions.html) for the complete list of available operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721e151",
   "metadata": {},
   "source": [
    "## Scaling and Performance\n",
    "\n",
    "*As your data and cluster grow, these tools help you stay fast.*\n",
    "\n",
    "### Part 10: Shuffling\n",
    "\n",
    "Ray Data offers three shuffle strategies with increasing randomness and cost:\n",
    "\n",
    "| **Strategy** | **API** | **Randomness** | **Cost** |\n",
    "|-------------|---------|---------------|----------|\n",
    "| File-based shuffle on read | `read_images(..., shuffle=\"files\")` | Low | Low |\n",
    "| Block order shuffle | `ds.randomize_block_order()` | Medium | Medium |\n",
    "| Global row shuffle | `ds.random_shuffle()` | High | High |\n",
    "\n",
    "#### Pull-based vs push-based shuffle\n",
    "\n",
    "Under the hood, global shuffle (`random_shuffle()`, `sort()`) uses a **sort-based shuffle** with two available implementations:\n",
    "\n",
    "| | **Pull-based (default)** | **Push-based** |\n",
    "|---|---|---|\n",
    "| **How it works** | Classic MapReduce-style: all map tasks run first, then reduce tasks pull and combine outputs | Pipelined: map and merge tasks overlap in rounds, with a final reduce stage |\n",
    "| **Best for** | Smaller datasets (<1 TB, <1000 blocks) | Large datasets (>1 TB, >1000 blocks) |\n",
    "| **Trade-off** | Simpler, well-tested | Better throughput and memory for large shuffles |\n",
    "\n",
    "Try push-based shuffle if your dataset has more than 1000 blocks or is larger than 1 TB in size:\n",
    "\n",
    "```python\n",
    "ctx = ray.data.DataContext.get_current()\n",
    "ctx.shuffle_strategy = \"sort_shuffle_push_based\"  # Or set RAY_DATA_PUSH_BASED_SHUFFLE=1\n",
    "```\n",
    "\n",
    "### Part 11: Resource Management and Performance Tuning\n",
    "\n",
    "Ray Data's **ResourceManager** tracks CPU, GPU, heap memory, and object store usage across all operators. It dynamically allocates budgets to keep the pipeline balanced.\n",
    "\n",
    "- **Per-operator resources:** Set `num_cpus`, `num_gpus`, and `memory` on `map_batches` to control what each worker gets\n",
    "- **Backpressure:** Ray Data automatically throttles upstream operators when downstream operators can't keep up, preventing OOM errors and disk spilling\n",
    "- **Autoscaling:** Ray Data can request more cluster resources when operators are bottlenecked:\n",
    "  - *Reactive autoscaling* (default): triggers when operators stall waiting for resources\n",
    "  - *Proactive autoscaling*: triggers at 75% utilization threshold, requesting whole nodes\n",
    "\n",
    "When your pipeline isn't performing as expected, follow this systematic approach:\n",
    "\n",
    "1. **Establish a baseline** — measure single-operator throughput in isolation\n",
    "2. **Scale up** — run the full pipeline on the target cluster size\n",
    "3. **Root cause analysis** — check for GPU under-utilization, disk spilling, or OOM errors\n",
    "4. **Iterate** — change one parameter at a time and measure impact\n",
    "\n",
    "#### Block size tuning\n",
    "\n",
    "Block size is an important performance lever. Larger blocks reduce scheduling overhead and improve throughput, but increase memory usage per task. Smaller blocks improve parallelism and reduce per-task memory, but add more scheduling overhead. Start with the defaults and adjust based on your workload.\n",
    "\n",
    "```python\n",
    "ctx = ray.data.DataContext.get_current()\n",
    "ctx.target_max_block_size = 128 * 1024 * 1024  # 128 MB max block size\n",
    "ctx.target_min_block_size = 1 * 1024 * 1024     # 1 MB min block size\n",
    "```\n",
    "\n",
    "#### Eager free\n",
    "\n",
    "By default, Ray Data relies on Python garbage collection and Ray reference counting to free block memory. Enabling eager free releases block references from the object store as soon as they're no longer needed, reducing memory pressure in streaming pipelines:\n",
    "\n",
    "```python\n",
    "ctx = ray.data.DataContext.get_current()\n",
    "ctx.eager_free = True  # Or set RAY_DATA_EAGER_FREE=1\n",
    "```\n",
    "\n",
    "#### Polars for sort operations\n",
    "\n",
    "You can speed up `sort()` and operations that sort internally (such as `map_groups()`) by enabling Polars as the sorting backend. This can significantly improve performance for large tabular datasets. When enabled, Ray Data uses Polars instead of PyArrow for the internal sorting step. This doesn't affect other operations such as `map_batches`.\n",
    "\n",
    "```python\n",
    "ctx = ray.data.DataContext.get_current()\n",
    "ctx.use_polars_sort = True  # Requires: pip install polars\n",
    "```\n",
    "\n",
    "See the [execution configurations docs](https://docs.ray.io/en/latest/data/execution-configurations.html) and [performance tips](https://docs.ray.io/en/latest/data/performance-tips.html) for more tuning guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7884e4",
   "metadata": {},
   "source": "## Reliability\n\n*For production pipelines that need to handle failures.*\n\n### Part 12: Fault Tolerance and Checkpointing\n\nRay Data provides fault tolerance at two levels:\n\n#### Worker-level retry\n\nIf a worker task fails (e.g., OOM, transient network error), Ray Data automatically retries the task. Configure retry behavior:\n\n```python\nctx = ray.data.DataContext.get_current()\nctx.retried_io_errors = [IOError, ConnectionError]  # Retry on these errors\nctx.max_errored_blocks = 5  # Allow up to 5 failed blocks before aborting\n```\n\n#### Job-level checkpointing\n\nFor recovering from driver failures, head node crashes, or job pre-emptions, RayTurbo Data provides **job-level checkpointing**:\n\n- Checkpoints are written after each block reaches the sink:\n\n<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-data-deep-dive/ray_data_checkpointing_storing.png\" alt=\"Ray Data Checkpoint Storing Flow\" width=\"80%\">\n\n- On restart, the pipeline skips already-processed rows by matching an ID column:\n\n<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-data-deep-dive/ray_data_checkpointing_restore.png\" alt=\"Ray Data Checkpoint Restore Flow\" width=\"80%\">\n\n```python\nfrom ray.anyscale.data.checkpoint import CheckpointConfig\n\nctx = ray.data.DataContext.get_current()\nctx.checkpoint_config = CheckpointConfig(\n    id_column=\"row_id\",\n    checkpoint_path=\"/mnt/cluster_storage/ray_data_checkpoint/\",\n    delete_checkpoint_on_success=True,\n)\n```"
  },
  {
   "cell_type": "markdown",
   "id": "3b07fb29",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this template, you learned:\n",
    "\n",
    "- **What** Ray Data is — a scalable, streaming data processing library for AI workloads\n",
    "- **Why** to use it — streaming execution across heterogeneous CPU/GPU clusters for batch inference, training data ingest, and reliable data pipelines\n",
    "- **How** to use it — loading data, transforming with `map` and `map_batches`, stateful batch inference, data operations, materialization, observability, and persistence\n",
    "- **Advanced topics** — additional transform APIs, Ray Train integration, shuffling strategies, performance tuning, and fault tolerance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **[Ray Data User Guide](https://docs.ray.io/en/latest/data/user-guide.html)** — In-depth guides for specific use cases\n",
    "2. **[Batch Inference Guide](https://docs.ray.io/en/latest/data/batch_inference.html)** — Detailed patterns for scaling inference\n",
    "3. **[Ray Data + Ray Train Integration](https://docs.ray.io/en/latest/train/user-guides/data-loading-preprocessing.html)** — Feeding Ray Data into distributed training\n",
    "4. **[Performance Tips](https://docs.ray.io/en/latest/data/performance-tips.html)** — Tuning for production workloads\n",
    "5. **[Ray Data API Reference](https://docs.ray.io/en/latest/data/api/api.html)** — Complete API documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}