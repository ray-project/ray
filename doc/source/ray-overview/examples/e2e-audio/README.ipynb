{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Audio data curation with Ray\n",
    "\n",
    "<div align=\"left\">\n",
    "<a target=\"_blank\" href=\"https://console.anyscale.com/\"><img src=\"https://img.shields.io/badge/ðŸš€ Run_on-Anyscale-9hf\"></a>&nbsp;\n",
    "<a href=\"https://github.com/anyscale/e2e-audio\" role=\"button\"><img src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
    "</div>\n",
    "\n",
    "This example demonstrates how to build a scalable, end-to-end audio curation pipeline with Ray with the following steps:\n",
    "\n",
    "1. Stream the English validation split of [Common Voice 11.0](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0) into a Ray Dataset.\n",
    "2. Resample each clip to 16 kHz for compatibility with Whisper.\n",
    "3. Transcribe the audio with the `openai/whisper-large-v3-turbo` model.\n",
    "4. Judge the educational quality of each transcription with a small Llama-3 model.\n",
    "5. Persist only clips that score â‰¥ 3 to a Parquet dataset.\n",
    "\n",
    "Because this example expresses every as a Ray transformation the same script scales seamlessly from a laptop to a multi-node GPU cluster.\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "```bash\n",
    "# Install dependencies.\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
