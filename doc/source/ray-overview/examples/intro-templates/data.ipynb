{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a1b82d0",
      "metadata": {},
      "source": [
        "# Introduction to Ray Data\n",
        "\n",
        "This template provides a comprehensive introduction to **Ray Data** — a scalable data processing library for AI workloads built on [Ray](https://docs.ray.io/en/latest/). You will learn what Ray Data is, why it matters for ML pipelines, and how to use its core APIs hands-on with an MNIST image classification example.\n",
        "\n",
        "In the first half, we'll walk through the core Ray Data workflow — loading, transforming, and persisting data — with concepts explained along the way. The second half covers advanced topics you can explore as your workloads grow.\n",
        "\n",
        "**Here is the roadmap for this template:**\n",
        "\n",
        "**Core:**\n",
        "- **Part 1:** When to Use Ray Data\n",
        "- **Part 2:** Loading Data\n",
        "- **Part 3:** Lazy Execution\n",
        "- **Part 4:** Transforming Data with `map_batches`\n",
        "- **Part 5:** Stateful Transformations and Batch Inference\n",
        "- **Part 6:** Data Operations — Groupby, Aggregation\n",
        "- **Part 7:** Observability\n",
        "- **Part 8:** Materializing and Persisting Data\n",
        "\n",
        "**Advanced topics:**\n",
        "- **Part 9:** Preprocessing and Expressions\n",
        "- **Part 10:** Shuffling\n",
        "- **Part 11:** Resource Management and Performance Tuning\n",
        "- **Part 12:** Fault Tolerance and Checkpointing\n",
        "- **Summary and Next Steps**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97241b8",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "accb94fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import ray"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70eb0c20",
      "metadata": {},
      "source": [
        "### Note on Storage\n",
        "\n",
        "Throughout this tutorial, we use `/mnt/cluster_storage` to represent a shared storage location. In a multi-node cluster, Ray workers on different nodes cannot access the head node's local file system. Use a [shared storage solution](https://docs.anyscale.com/configuration/storage#shared) accessible from every node."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85c1af30",
      "metadata": {},
      "source": [
        "## Part 1: When to Use Ray Data\n",
        "\n",
        "Consider using Ray Data when your project meets one or more of these criteria:\n",
        "\n",
        "| **Challenge** | **Ray Data Solution** |\n",
        "|---------------|----------------------|\n",
        "| **Operating on large datasets** | Distributes data loading and processing across a Ray cluster with streaming execution |\n",
        "| **Feeding data into distributed training** | Streams data directly to [Ray Train](https://docs.ray.io/en/latest/train/user-guides/data-loading-preprocessing.html) workers with configurable batch sizes — no intermediate disk writes needed. See the **Introduction to Ray Train** template for a hands-on walkthrough. |\n",
        "| **Running batch inference at scale** | Maximizes GPU utilization by streaming data through model inference actors |\n",
        "| **Building reliable data pipelines** | Leverages Ray Core's fault-tolerance mechanisms — retries, checkpointing, and recovery |\n",
        "\n",
        "Ray Data features a **streaming execution engine** that processes data in a pipelined fashion across a heterogeneous cluster of CPUs and GPUs. You write everything in native Python — your existing functions and libraries (NumPy, PyTorch, etc.) work as-is — and Ray Data handles the distribution, avoiding full materialization in memory and keeping all hardware utilized.\n",
        "\n",
        "To understand why this matters, consider the difference between traditional batch processing and streaming:\n",
        "\n",
        "**Traditional batch processing** completes one stage fully before starting the next, leading to idle resources:\n",
        "\n",
        "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/batch-processing.png\" width=\"800\" alt=\"Traditional Batch Processing\">\n",
        "\n",
        "**Streaming pipelining** overlaps stages, keeping all hardware (CPUs and GPUs) busy simultaneously:\n",
        "\n",
        "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/cko-2025-q1/pipelining.png\" width=\"800\" alt=\"Streaming Model Pipelining\">\n",
        "\n",
        "This is critical for GPU-heavy workloads: while the GPU runs inference on one batch, the CPU can preprocess the next batch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fbab4ee",
      "metadata": {},
      "source": [
        "## Part 2: Loading Data\n",
        "\n",
        "Ray Data provides built-in connectors for common formats — Parquet, CSV, JSON, images, text — as well as sources such as HuggingFace Datasets, Delta Lake, Iceberg, and in-memory objects (NumPy, Pandas, PyTorch). See the full list in the [Input/Output docs](https://docs.ray.io/en/latest/data/api/input_output.html) and the [data loading guide](https://docs.ray.io/en/latest/data/loading-data.html).\n",
        "\n",
        "Under the hood, Ray Data uses Ray tasks to read data from remote storage. It creates read tasks proportional to the number of CPUs in your cluster, and each task produces output **blocks**:\n",
        "\n",
        "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/intro-ai-libraries/dataset-read-many-to-many.png\" width=\"90%\">\n",
        "\n",
        "Let's load MNIST image data from S3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8002f06b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-13 23:59:46,507\tINFO worker.py:1821 -- Connecting to existing Ray cluster at address: 10.0.55.63:6379...\n",
            "2026-02-13 23:59:46,520\tINFO worker.py:1998 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-4m21i7i1x1y6hvvwbhtjq6iv24.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
            "2026-02-13 23:59:46,523\tINFO packaging.py:463 -- Pushing file package 'gcs://_ray_pkg_6cbb9e1e125ab4ff76982edb0def3f26184a8474.zip' (0.12MiB) to Ray cluster...\n",
            "2026-02-13 23:59:46,524\tINFO packaging.py:476 -- Successfully pushed file package 'gcs://_ray_pkg_6cbb9e1e125ab4ff76982edb0def3f26184a8474.zip'.\n",
            "/home/ray/anaconda3/lib/python3.12/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "ds = ray.data.read_images(\n",
        "    \"s3://anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/\",\n",
        "    include_paths=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e3482c",
      "metadata": {},
      "source": [
        "A **Dataset** is a distributed collection of **blocks** — contiguous subsets of rows stored as PyArrow tables. Blocks are distributed across the cluster and processed in parallel. They live in the **Ray object store** — shared memory distributed across cluster nodes — so data passes between operators through zero-copy reads. When the object store fills up, Ray spills blocks to disk automatically.\n",
        "\n",
        "<img src=\"https://docs.ray.io/en/latest/_images/dataset-arch.svg\" width=\"90%\"/>\n",
        "\n",
        "Since a Dataset is a list of Ray object references, it can be freely passed between Ray tasks, actors, and libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd25321",
      "metadata": {},
      "source": [
        "## Part 3: Lazy Execution\n",
        "\n",
        "In Ray Data, most transformations are **lazy** — they build an execution plan rather than running immediately. The plan executes only when you call a method that *consumes* or *materializes* the dataset.\n",
        "\n",
        "**Execution-triggering methods include:**\n",
        "\n",
        "| **Category** | **Methods** |\n",
        "|-------------|------------|\n",
        "| Small samples | `take_batch()`, `take()`, `show()` |\n",
        "| Full materialization | `materialize()` |\n",
        "| Write to storage | `write_parquet()`, `write_csv()`, etc. |\n",
        "| Aggregations | `count()`, `mean()`, `min()`, `max()`, `sum()`, `std()` |\n",
        "\n",
        "To materialize a small subset for inspection, use `take`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2a0698a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-13 23:59:47,054\tINFO dataset.py:3641 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
            "2026-02-13 23:59:47,058\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_34_0\n",
            "2026-02-13 23:59:47,081\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_34_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-13 23:59:47,082\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_34_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> LimitOperator[limit=5] -> TaskPoolMapOperator[ReadFiles]\n",
            "2026-02-13 23:59:47,083\tINFO streaming_executor.py:687 -- [dataset]: A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True` and `ray.data.DataContext.get_current().use_ray_tqdm = False`.\n",
            "2026-02-13 23:59:47,083\tINFO progress_bar.py:155 -- Progress bar disabled because stdout is a non-interactive terminal.\n",
            "2026-02-13 23:59:47,085\tWARNING resource_manager.py:136 -- ⚠️  Ray's object store is configured to use only 27.9% of available memory (44.7GiB out of 160.0GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
            "2026-02-13 23:59:47,111\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-13 23:59:47,113\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:47,113\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=5} ===\n",
            "2026-02-13 23:59:47,114\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:47,115\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-13 23:59:47,116\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:47,116\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-13 23:59:47,117\tINFO progress_bar.py:215 -- Running Dataset: dataset_34_0. Active & requested resources: 0/32 CPU, 0.0B/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:51,271\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_34_0 execution finished in 4.19 seconds\n",
            "INFO:openlineage.client.client:OpenLineageClient will use `composite` transport\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAEICAYAAACOB0fcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwLUlEQVR4nO3deZRU5Z3/8ae6qrqqeqWbTVREcYEYXBIRNJIIGoVOUOAEiHpM4njEiEoyrjGZGIwZg6go0TEEMRhzMm5DGPGYhOgIzBxnDIoZzOCE0CC4EYHupvfqWu/vj/nFY4L1+TZ9rdtd+H6d4z+86y5VdZ97bz0UVsjzPM8BAAAAAAAAASrr7x0AAAAAAADAxw+TUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIHJNSJWbXrl0uFAq5e+655yNb54YNG1woFHIbNmz4yNYJ4P8wZoHSwpgFSgtjFigtjFn8LSalAvCzn/3MhUIht2nTpv7elaJ599133dy5c92gQYNcTU2NmzFjhnvjjTf6e7eAPmHMAqWFMQuUFsYsUFoYsyimSH/vAEpfZ2enmzJlimtra3Pf+c53XDQadffdd587++yz3ebNm93gwYP7excBfABjFigtjFmgtDBmgdLCmO1fTErBtx//+MeusbHRvfzyy+700093zjnX0NDgxo0b55YsWeJ++MMf9vMeAvggxixQWhizQGlhzAKlhTHbv/jnewNEOp123/ve99xpp53mamtrXWVlpfvsZz/r1q9fX3CZ++67z40aNcolEgl39tlnuy1bthzwmK1bt7rZs2e7+vp6F4/H3fjx490zzzxj7k93d7fbunWra2pqMh+7atUqd/rpp78/gJ1zbuzYse7cc891Tz31lLk8UIoYs0BpYcwCpYUxC5QWxiz6ikmpAaK9vd09/PDDbvLkyW7x4sXutttuc/v27XNTp051mzdvPuDxP//5z93999/vrrnmGvftb3/bbdmyxZ1zzjluz5497z/m9ddfd2eccYb74x//6G655Ra3ZMkSV1lZ6WbOnOn+9V//Ve7Pyy+/7D7xiU+4f/qnf5KPy+fz7g9/+IMbP378AW3ChAlux44drqOjo3cvAlBCGLNAaWHMAqWFMQuUFsYs+op/vjdA1NXVuV27drny8vL3/2zevHlu7Nix7oEHHnA//elP/+rx27dvd42Nje6II45wzjk3bdo0N3HiRLd48WJ37733Ouec++Y3v+mOOuoo98orr7hYLOacc+7qq692kyZNct/61rfcrFmzfO93S0uLS6VSbsSIEQe0v/zZ7t273ZgxY3xvCxhIGLNAaWHMAqWFMQuUFsYs+opvSg0Q4XD4/QGcz+ddS0uLy2azbvz48e73v//9AY+fOXPm+wPYuf+bxZ04caL79a9/7Zz7v8G1bt06N3fuXNfR0eGamppcU1OTa25udlOnTnWNjY3u3XffLbg/kydPdp7nudtuu03udzKZdM65908SHxSPx//qMcChhDELlBbGLFBaGLNAaWHMoq+YlBpAHn30UXfyySe7eDzuBg8e7IYOHep+9atfuba2tgMee/zxxx/wZyeccILbtWuXc+7/Zp49z3O33nqrGzp06F/9t3DhQuecc3v37vW9z4lEwjnnXCqVOqD19PT81WOAQw1jFigtjFmgtDBmgdLCmEVf8M/3Bohf/OIX7rLLLnMzZ850N910kxs2bJgLh8Nu0aJFbseOHQe9vnw+75xz7sYbb3RTp0790Mccd9xxvvbZOefq6+tdLBZzf/7znw9of/mzww8/3Pd2gIGGMQuUFsYsUFoYs0BpYcyir5iUGiBWrVrlRo8e7VavXu1CodD7f/6XWeC/1djYeMCfbdu2zR199NHOOedGjx7tnHMuGo26z3/+8x/9Dv9/ZWVl7qSTTnKbNm06oG3cuNGNHj3aVVdXF237QH9hzAKlhTELlBbGLFBaGLPoK/753gARDoedc855nvf+n23cuNG99NJLH/r4p59++q/+De3LL7/sNm7c6BoaGpxzzg0bNsxNnjzZLV++/ENnffft2yf352B+QnP27NnulVde+auB/Kc//cmtW7fOzZkzx1weKEWMWaC0MGaB0sKYBUoLYxZ9xTelArRy5Uq3du3aA/78m9/8pps+fbpbvXq1mzVrlvviF7/odu7c6X7yk5+4E0880XV2dh6wzHHHHecmTZrk5s+f71KplFu6dKkbPHiwu/nmm99/zIMPPugmTZrkTjrpJDdv3jw3evRot2fPHvfSSy+5d955x7322msF9/Xll192U6ZMcQsXLjT/53BXX321W7FihfviF7/obrzxRheNRt29997rhg8f7m644Ybev0DAAMOYBUoLYxYoLYxZoLQwZlEUHorukUce8ZxzBf97++23vXw+7/3whz/0Ro0a5cViMe9Tn/qU9+yzz3pf+9rXvFGjRr2/rp07d3rOOe/uu+/2lixZ4o0cOdKLxWLeZz/7We+11147YNs7duzwvvrVr3qHHXaYF41GvSOOOMKbPn26t2rVqvcfs379es85561fv/6AP1u4cGGvnuPbb7/tzZ4926upqfGqqqq86dOne42NjX19yYB+xZgFSgtjFigtjFmgtDBmUUwhz/vA9+sAAAAAAACAAPD/lAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgIr19YCgUKuZ+DGjhcFj2XC5X1O3H43HZe3p6ZI9E9NvseZ7ssVhM9u7ubtkt1vrz+XyfmnP2e2Md19ZrU2x+tv9xHrMVFRWyW8esdUymUinZo9Go7JlMRnaLNaaz2azsgwYNkr21tfUg9+ivJRKJgs3v+crva1dsjNn+UVtbK3tbW1tRt2+NeasX+5xk3ceoMdvZ2SmXtah1O+dcMpn0tX6/GLPFUVam/97b6tZ1zOL3Olls1pgspmJ/bik2xmxxWMekNaas65Df7VvHrd8xbx0bfo8dddz29+fNYuvN8+ObUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAhcyPM8r1cPDIWKvS8ly3ptysr03F8ul/O1/aqqKtkTiYTs+/bt87X9iooK2aPRqOxtbW193nYsFpM9EonI3tXV1edtB6GXw/NDMWYLi8fjsltjtru7W/bq6mrZOzo6ZLfGbE9Pj+x+jhvn7HOKNW7C4XDBls1m+7RPf2GdTzKZjK/1+8WY7Zvy8nLZ0+l0Ubc/ZMgQ2a3jtrW11df2KysrZbeOq1QqJbt1n6HOidZrn8/nZR/oGLN9Y41Z6zpqXcfUdaQ367euBdb6rTFjLW/dn/ods362bb12yWSyz9sOAmO2b/xeZ63jxroWWNu3jlvr3rmUWcel3/Nhse+hLL0Zs3xTCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIELeZ7n9eqBoVCx9+Vjq7a2Vva2traibj+RSMieyWRkz2azvrZfX18ve0tLS5/XXVVVJXtnZ2ef1x2EXg7PD/VxHrN+x1QsFpM9lUrJHolEZLfGTFmZ/vuCfD4v++DBg2Vvbm6Wvby8XPZ0Oi17OBwu2KzXtqenR/ZoNCq79d4UG2O2f1jHhXUdK7aKigrZu7u7fa3fuo4nk0lf61cqKytlt84X/f3eMGb7h7pOOOf/OmS9N9Z12Np+Lpfz1S3WuFLPz++9bbHPV34xZvsmHo/Lbt1/Wax7V4t1b+uXdf9pHVfF7NZz93PMDwS92X++KQUAAAAAAIDAMSkFAAAAAACAwDEpBQAAAAAAgMAxKQUAAAAAAIDAMSkFAAAAAACAwDEpBQAAAAAAgMAxKQUAAAAAAIDAhTzP83r1wFCo2PsyYFVWVsre1dXla/2RSET2bDYreyKRkD2VSskei8Vkz+Vysg8aNEj2vXv3ym6pra0t2Nra2nytOx6Py97T0+Nr/X71cnh+qI/zmLWEw2HZrWPeGnPJZPKg9+lgWGPWGvMW6/UpLy+XvdjPfyBjzPaPsjL9d2z5fF72+vp62VtaWg56nz7I2r/q6mrZrWuddU6wtq9Y43mgX0ctjNm+8Xsdsq4jmUxGdj/vWxCi0ajs1pj0ex1XrON2oL+2jNniGD58uOxNTU2yW/fO1jnjnHPOkf2WW26Rvbu7W/aGhgbZUTy9GbN8UwoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBi/T3DpSCrq4uX8vH43HZe3p6ZJ80aZLsixYtkv3UU0+V/Ze//KXsd999t+yvv/667H6lUqk+L+v3tUdpikT0qa22tlb25uZm2a1jcvbs2bKfccYZsl988cWy19fXy24d93feeafs3/72t2XPZDKyK5WVlbJbYzKXy/V52xi4QqGQ7NYx397eLns+n5e9paVFdos1pu+//37ZP/GJT8heXl7uq2ezWdkfffTRgu2GG26Qy3Z0dMiOQ1M4HPa1fDqdln3x4sWy33zzzb62/7vf/U72pUuXyr5mzRrZi31/GY1GCzbrOmmdD63zsed5sqM0DR06VPY9e/b4Wv/MmTNlt641p59+uuxz5syRvazM33dxrOO+mOPC2nfrc491vh0I+KYUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAhfp7x0oBWVleu7O6j09PbIfdthhsl9zzTWyn3baabInEgnZv/a1r8l+/PHHy/6Nb3xD9p07d8re2dkpeyaTkR34W9FoVPbm5mbZFyxYIPv48eNlb2hokH3QoEGyW/ufTqd9dc/zZLdY+5fNZgu2rq4uuWw4HJa9oqJC9u7ubtkxMFnHpDVmLbW1tbK3tbXJ/t3vflf2mTNnym5dp4stl8vJrsaNdQ/R3t4uezwel926R8LAZJ1r6+vrZb/uuutknzNnzkHv0wclk0nZY7GY7CtXrpR96dKlsm/fvl32V199VfZt27bJ7mfcWNdZq1v3GBiYrHu3LVu2+Fr/2LFjZbeuk6eccoqv7b/zzjuy5/N5X+v3yxpXinUNPxTGJN+UAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOBCnud5vXpgKFTsfTlklZeXy75o0SLZr7/+etnb29tlz+Vysnd1dcl+5JFHyt7U1CT7qlWrZJ8/f77sSnV1tewdHR2yx2Ix2VOp1EHv00epl8PzQzFmCxs5cqTsO3fulD0cDvvafjKZlN167+LxuOzWcfPEE0/Iftddd8m+efNm2f0oK9N/V5LP54u27Y8CY7ZvIpGI7NlsVna/53JrTK1cuVL2iy++WPZ0Oi279fw7Ozt9LV9RUSG78t///d+yW9fwjRs39nnbQWDM9o11b/utb31L9ttvv93X9t9++23ZX3jhBdl7enpkv+qqq2S3xrT1+qxbt072W2+9Vfb/+q//Ktis47KyslJ263zT3xizxWHdfy1evFj2r3zlK7IPHz5cdus6HY1GZbfGvPV5e/fu3bK/+eabslvnFMX6XGHd+/oZE0Hozf7xTSkAAAAAAAAEjkkpAAAAAAAABI5JKQAAAAAAAASOSSkAAAAAAAAEjkkpAAAAAAAABI5JKQAAAAAAAAQu5PXyNwQ/zj+haf1MYy6Xk33atGmyP/bYY7JbP5FZU1Mje0tLi+xnnnmm7JdddpnsI0eOlN36idAbbrhB9mXLlsmu+P2Z8P7Gz972TW1trexNTU2yWz/17HdMWqxzjt+foraOqy1btsg+d+5c2Xfs2NHnbVv73t3dLXt/Y8wWh/VT0NbPJVvX6fXr18t+6qmnym4dtxUVFbJbrHOO32tdJpMp2KqqquSyM2bMkN36me6uri7Zi40x2zfWvZ91Hclms7IPGjRI9meeeUb273//+7Jffvnlsg8bNkz2E088UXZr/w8//HDZm5ubZX/ooYcKtrvvvlsu297eLrs15js7O2UvNsZs31jXUXUdcM65devWyf6Zz3xGdus6aV2nI5GI7NZ9QFmZ/i7Ohg0bZF++fLnsv/nNb2Rva2uT/VDWmzHLN6UAAAAAAAAQOCalAAAAAAAAEDgmpQAAAAAAABA4JqUAAAAAAAAQOCalAAAAAAAAEDgmpQAAAAAAABA4JqUAAAAAAAAQuJDneV6vHhgKyV5eXi57JpORvZe70S/i8bjs1nNLJpOyR6NR2a+88krZn3rqKdkHDRok+1tvvSV7VVWV7B0dHbLv27dP9ra2NtnHjBlTsOVyObmsddwO5OPOOX/7F4lEZLdeO+u4tPYtm83KbqmoqCjYrGPy+eefl/2YY46Rvbq6WvZ0Oi279do9++yzst93332yH3/88bJfd911slvPPxaLyb5lyxbZL7roooJt69atclnruLTOxz09PbIXm58xa52vis26jltjOp/PF2zW+ch63fweF9aYvemmm2T/u7/7O9nVdco5+/lZ7711H2GN2VQqJXsikSjY1PvqnHNPPPGE7NZrZ703xVbKY7Y/jR8/Xva1a9fKPnjwYF/bP++882Rft26d7HV1dbI3NzfLrsaMc/ax8cwzz8h+zjnnyK7unc8880y5rHUdHugYs31jXeOtc/FVV10l+wMPPCB7WZn+Lswll1wi+3PPPSf7HXfcIXtDQ4Pso0aNkt36vP+DH/xA9n/8x38s2KzPDda2rc9FnZ2dshdbb8Ys35QCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4CIf1YrS6bSv5cvK9PxYeXm5r+3n8/mCLZFIyGWTyaTsZ511luzhcFj2rVu3yr569WrZo9Go7G+++aav5VOplOyWf//3f5f9/PPPl33BggUF29KlS+Wy8Xhcduu9LWW5XE5267jMZDK+th+LxWS3jqu6urqCbcWKFXLZk08+WXbLv/zLv8h+6aWXyh4KhWRX5yPn7NfeGlNr1qyR/cc//rHs06dPl33cuHGyq3E5Y8YMuWwkoi9L7e3tspcy6zpojSmLdb7zex1Xstms7NaYsVhjxrrOz549W/bRo0fL3tnZKbv1/AcNGiS79frs27fP1/qVjo4O2a17mGIeV+g/xx9/vOzqGt4br7zyiuzr16+X3brONjc3y26db/3eP7700kuyT548WXY1pq3zYU1Njeye58lunRMwMFn3GEOHDpX9S1/6kuxNTU0HvU8fZI35/fv3y64+Lzpnfy767W9/K7v1efXGG2+U/X/+538Ktl/96ldyWWsexLoHKQV8UwoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBi3xUKwqFQrJ7nudr/fl83ldXcrlcn5d1zrn7779f9p6eHtnfeOMN2Zubmw96nw5GJpMp6vr/8Ic/yD59+nTZL7roooLtRz/6kVw2mUzKXuzjdiArK9Nz0ta4CIfDsluvrWXkyJEFW0NDg1zWet/+9Kc/yf7www/Lnk6nZbfEYjFfy1v27Nkj+xVXXCH7nXfeKfuFF14o++c///mCbfny5XLZr3zlK7JXVlbK3tXVJftAZl3HrPOZxRqTVo9Go7KrcWeNGWvMDhkyRPampibZrePixBNPlD2bzcpeVVUluyWVSsn+v//7v7JfeeWVss+fP1/2r371qwVbPB6Xy06aNEl263xnPXcMTCeccILsnZ2dsltjZvXq1bJb56va2lrZ29raZLeOS+t8GInoj1jW+q17MHVO3bFjh1wWH0/W59EzzjhD9gkTJsheU1Mj++WXXy679XnYGtPt7e2yW66//nrZ58yZI/t3v/vdPq9/zZo1clmLdb6x7mEGAr4pBQAAAAAAgMAxKQUAAAAAAIDAMSkFAAAAAACAwDEpBQAAAAAAgMAxKQUAAAAAAIDAMSkFAAAAAACAwDEpBQAAAAAAgMBFev3AiH5oKBSSPZPJyJ7P530t74e17rq6OtlPPvlk2cvK9Nzf008/LXs4HJY9Ho/L3tXVJXtFRYXs3d3dsls8z5Pdev3V/lnPPZlMym69ttlsVvaBzDrurNfdGvOxWEx267irqqqS/ZJLLinYrPfVet9uvfVW2Z977jnZhw0bJntzc7PsuVxOdot1vq2srJR9//79si9cuFD21tZW2W+++eaC7bzzzpPLTpo0SfbNmzfLXspqampkb29v97X+RCIhu3VOSKVSvravWOfipqYm2SdMmCD7k08+Kbt1HbS2b7120WhU9p/+9KeyL1myRPZdu3bJftxxx8mu9i+dTstlH3nkEdmtaxFK09SpU2W3zmeWRx991Nfy1r2rdc6xrtPWmLe6dc6yrvPWfYZSXl4uuzXmcWiaNWuW7NaYtq6TfrW1tfla3tr/119/XfYpU6bIbp1z1P1tfX29XLalpUX2QwF3CgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAhcpLcPzGazspeXl/veGSUS0bsai8VkT6VSBVsmk5HLDh8+XPbu7m7Zn3/+edmfeuop2fP5vK/tW5LJpOyhUEj2cDjsa/2VlZWy+31+iud5RVt3f7PeN4t13HV1dfla/5gxY2S/9tprCzbruXV2dsq+YcMG2S179+6V3TofptNp2aurq2W3XnurW+t/7733ZF+xYoXsF154YcF2zDHHyGWXLVsm+0knnSR7Kevp6ZHdOu7LyvTfM6nroHPO5XI52S3qWmCd563nbu3b7bffLvvRRx8t+5///GfZR4wYIbvFuod64IEHZN+1a5fs8Xhcdut829TUVLANGTJELmtdR617AJSmt956S/YzzzzT1/pbW1tlt+5RrG5dp61zjnXvay1/9tlnyx6NRmVXz8/6TGRdK6zPXNb5DKXpk5/8pK/lrePmF7/4hezWmLQ+r9fU1Mje1tYmuzUurDFt3VsriUSiz8s6d2iMSb4pBQAAAAAAgMAxKQUAAAAAAIDAMSkFAAAAAACAwDEpBQAAAAAAgMAxKQUAAAAAAIDAMSkFAAAAAACAwDEpBQAAAAAAgMBFPqoVeZ6nNxTRm8pms762n0qlZM9kMn1e94UXXih7TU2N7KtWrZK9ra1N9lAoJLv12icSCdmTyaTslnw+L/u+fftkt56fOnasfa+trZXdeu1LWS6Xkz0ej8ve09Pja/vl5eWyH3nkkbJbx4Vy7733yt7U1CS79dpYY846H1ms85U15qzXrqOj46D36YO2b98u+1133VWwPfzww3LZcePGyT5//nzZly1bJvtAlk6nZbfeV2vMW6LRqK/e3d1dsLW3t8tl6+rqZF+7dq3sEydOlH3//v2yjxgxQnbrWvNv//Zvsn/jG9+Q3TonlZXpv0Osrq6W/aGHHpL9e9/7XsHW2Ngol73mmmtkf/LJJ2VHadq0aZPs1r1zOByWffTo0bLv2rVL9q6uLtmtzx3W+da6T7C2b92bW/un7o2tZf1eK1Carr32WtnPPfdc2a3rYENDg+zWmPF7b2p9prM+l1j3YNb96wMPPCC7urf3+1n8UMA3pQAAAAAAABA4JqUAAAAAAAAQOCalAAAAAAAAEDgmpQAAAAAAABA4JqUAAAAAAAAQOCalAAAAAAAAEDgmpQAAAAAAABC4yEe1onw+L7vnebKHw2HZM5nMQe9Tbw0bNkz2BQsWyJ7NZmVPJBIHvU8fZL129fX1sre0tMgej8dl7+npkd1674866ijZLdbzV1KplK9tH8qs982vsjI95z127FjZ29vbC7bW1la57D//8z/Lbu2bdcwPGTJEduu4i0T0qdfavnW+zOVyskejUV/LV1ZWyv7II48UbOedd55c9uKLL5b9jjvukH3ZsmWyl7KqqirZOzo6fK3fulb5Wb91nfrBD34g+5QpU2RPp9OyV1RUyG6xrkMXXnih7NaYt+4jrDE/btw42a+44grZu7u7CzbrHuHaa6+V3TrfFPP+DsUzadIk2a3zSWdnp+xdXV2+ut/rpMXa/oQJE2Tfv3+/7NY5q7y8vGDze3+n1u2cfb7FwGSdy60xad07W8e0dQ9hnTOsrj43OGcft9a16thjj5XdOuckk8mCzRrv1ucCdQ0vFXxTCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIGL9PaB0WhU9kwm42tHrPXn83nZPc+TfejQoQXbZz7zGbnsiBEjZM9ms7K/9957sluqqqpkb2lpkb26ulr2jo4O2UOhkOzhcFj2KVOmyN7a2ip7Z2dnwVZeXi6X7enpkT0S0UPAem8HssrKStm7urp8rd967azXfvz48bLX1NQUbE1NTXLZbdu2yV5fXy+7Naas7cfjcdmt18ZiHfe5XE72dDote0VFhezWOUOdE9ra2uSy1pizntuhzO9xY0kmk7Jb19nRo0cXbHfccYdc9qKLLpLdYu2bxTpnzJo1S/ZEIiG79dpaZs+eLfuMGTNkV/dAzul7MHUNds65VCole1kZf/95KKqtrZXdGpPWva11XFn3IH5Z67fufW+66SbZhw0bdtD79EHqc5f12ltj0rpHQGkaM2aM7NaYtDQ3N/ta3rpO+r2OWvfO1nF/7rnnym6ds9S9tfXcuru7ZT8UcKcAAAAAAACAwDEpBQAAAAAAgMAxKQUAAAAAAIDAMSkFAAAAAACAwDEpBQAAAAAAgMAxKQUAAAAAAIDAMSkFAAAAAACAwEX6ewf+IpPJ+Fq+rEzPr+3bt69gq6yslMvm83nZ9+zZI/tvf/tb2S09PT2+lu/o6JA9Go3Kbr03w4cPl33s2LGyRyL6MLzvvvsKtnQ6LZetqamRvb29XfZS1tXVVdT153I52UOhkOye58mujlvrmLW27fd8U2zl5eWyJ5PJoq7f7+ujjo3HH39cLnvVVVfJbp2vGxoaZP/Nb34juyUWi/lavpjb9vu+WePmy1/+suyXX355wXb++ef3aZ/+IpvNym4999bWVtnnzZsn+7Zt22SvqKiQ/f7775f9k5/8pOxHHHGE7EcddZTs1uuj7nOee+45uWxjY6Ps1nGF0mTdm1rvu3X/Zo0p6x7EL+ucYyn2tcJ6/RTrc82hzPq86Pd8Zb221r1vMX3605/2tbw15v0e87W1tbJbn2usMev3nGFt37q3Vu+99dpVV1fLbn3WLwV8UwoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBi/T2gZlMppj74Vs+n5c9FAoVbPX19XLZaDQq+969e2UvK9Nzf9a+Z7NZ2S2RiH6b/a7/sccek33EiBGy79ixQ/ZnnnmmYAuHw3LZ9vZ22evq6mTfv3+/7KXMeu2s49bvOeHVV1+Vfc6cOQVbIpGQyy5ZskT266+/Xvba2lrZ29raZLfGVGVlpexdXV2yV1RUyB6Px2VvaWmR3eJn3FjPvbm5WfbBgwfLfuKJJ8r+4osvyt7R0SF7KpWS3Q/rXN3Z2Sm732vNJZdcIntDQ4Ps559/fsHmeZ5c1jpXW2PSet9WrFgh+ymnnCL7xIkTZb/99ttlt95b670pLy+X3Xr+1dXVsq9Zs6Zgu+yyy+Sy1r5b56vu7m7ZMTD96Ec/kv2MM86QfdCgQbI/+OCDsk+bNk1265i37mH8HtejRo2SPZ1Oy26NeXUdt+4BLNZ1zjqfD2TWvhf7uanPo87Z13F1LbGuM+o875xzn/70p2W37m2t1846pq17a2t56/O6Neat5a17X4u6h7POJ7t375bd7/3fQMA3pQAAAAAAABA4JqUAAAAAAAAQOCalAAAAAAAAEDgmpQAAAAAAABA4JqUAAAAAAAAQOCalAAAAAAAAEDgmpQAAAAAAABC4yEe1orIyPb+Vz+c/qk31SSRS+KnW1tb6WveSJUtkz2azsh922GGyv/fee7LH43HZ1XN3zrnOzk7Z/+Ef/kH2z33uc7Jb7/3mzZtlD4fDBVsoFJLLWjo6OnwtP5DFYjHZU6mU7LlcTna/r/1rr73W52W7urpkr6qqkn3o0KGy79u3T3brfGeN+fLyctn9amlp8bW8dc6wXv9EIlGw9fT0yGUHDx4se3Nzs+yvvvqq7MlkUvZoNCq753my+2GNWeu4ss61p5xyiuwzZ86U/VOf+pTsfljX4b1798peUVEh+7x582QfMWKE7H6l02nZrXOCNW6sY2PLli2yr127tmCzxoR13HV3d8uO0vTcc8/JvnDhQtlvvPFG2adOnSr7/PnzZV+2bJnsfh1zzDGyjxw5Una/91C/+93vCjbrfGHdwxTzOtffBvpzs94bdX9mnasbGxtlb29vl72mpkb25cuXy27dY1isMWNdZ637DOv+s7KyUnbrc5Nafvv27XJZv3MVbW1tvpYPAt+UAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOAiH9mKInpV6XTa1/rD4bDsuVyuz72rq0su29PTI/sVV1wh+3/+53/K/vbbb8tusZ67tf8NDQ2y33LLLbJ3dnbKXlVVJfvSpUtlV8/vsMMOk8u+9957smezWdlLWT6fL+r6rTFp9cbGRtm3b99esB1zzDFy2Xnz5sl+zz33yG4d08lkUvby8nLZrfOhNWas/bNEo1HZM5mMr/WPGDGiYPvJT37ia927du2SfcOGDb7WX1NT42t5P6xrkcXa9wULFsg+Y8YMX9tXx411rk0kErLX19fLbt2D1NbWyv7OO+/IfuSRR8re0dEhe3V1teytra2yr169Wvbdu3fL/tBDD8mu7kOs48q6x8ChybrHePzxx2W37v2sc8Zdd90lezwel/1nP/uZ7Nb5+Otf/7rsdXV1slus1/f555/v87qte4BUKtXndcMf6/5LHRfWmHniiSdkv/TSS2X/whe+IPu0adNkv/XWW2W/7bbbZPc8T3Z17+mcc9dee63s3/nOd2S37v2t+5A777yzYKuoqJDLtrW1yX4o4JtSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACFzI8zyvVw8MhWRPJBKyJ5PJ3u/VhygvL5c9nU73ed0XXHCB7E8++aTsPT09stfX18tuPbdIJCK79d4sWLBA9kWLFslu2bNnj+wXXXSR7C+++KLs2Wz2oPfpL6qqqmTv7Ozs87qD0Mvh+aGs48I67vL5vOzWvuVyOdnD4bDsixcvLthuuOEGuax1zLS2tsp+1llnyd7Y2Ci7n/fNOedqa2tlt86n1vnQOqdYr99pp50m+/Llywu24447Ti67efNm2b/0pS/Jvn//ftmt47qsTP9djd9xoVjXCuu5Wa677jrZFy5cKHtNTY3s6pxjXSet5zZixAjZLdYxbY0Ja/+qq6tlf+GFF2T/+te/LntLS4vsHR0dshdTMe/PglDM6+yhLB6Py26973V1dbKvXr1a9s997nO+tv/000/L/uUvf1l26zpsvT7WmH333Xdlnzx5csFmnS+s45YxW7zl/d4f+mF9Vj/88MNl//3vf+9r+xUVFbJb9wm//vWvZZ87d67smUxGdmvcDB8+XPbXXntN9lNPPVV2xfrMZPX+HtO9Oe75phQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAAIX8nr525TWT2BaP31q/cyj9VOG1vatn3tWrJ8o37Rpk+zWz7evWbNG9scff1z2N998U/af//znsh977LGyd3d3y97e3i77xRdfLPt//Md/yG6prKws2Kzjxtr3gf5T1sX82VvruVtjKp/PH/Q+HYxx48YVbEuXLpXLnnnmmbJbP0tr/fz7ggULZF+7dq3szc3NshdbJBKR/YILLpB90aJFso8ZM6Zg27Ztm1y2oaFB9jfeeEN261pk/SRwLpeT3dKfP1VtHddPPvmk7F/4whdkLyvr+99jWa97NBqV3bqH8Pu+W+c767XbuHGj7NY5YdeuXbJXVVXJ3tnZKXssFpNdXQ+sn64vdf05Zj/O6urqZE+lUrL/8Y9/lP2oo46S/a233pLdOqcMGzZM9mQyKbt1D2adU8466yzZD2X9OWat66DVrXvnYt9bK9aY+fu//3vZr776atmt65B1nbeWt+6thwwZIrvFOuecf/75sqtraVdXl1zWOi6s49rvva1fvRmzfFMKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgQt5nuf16oGhkOzRaFT2TCZT1OWt/VNPs7y8XC47a9Ys2Z944gnZOzs7Zbe2b/X29nbZa2pqZH/hhRdkv+eee2Rfu3at7CNGjJC9tbVV9mQyWbCFw2G5bEVFhewdHR2y97deDs8PZY2JsjI9J53P5/u8beeci8fjsudyOdnVmJ8wYYJc9vvf/77s06ZN6/O2e+PFF1+U/Ze//KXsTz/9tOynn3667JdeeqnsgwYNkv3UU0+V3Rp3jz/+eMG2ePFiueybb74peywWkz2VSslujQu/48bPsWNt27oWWGPu0Ucfld0a81VVVbKfcMIJBdvRRx8tl7Xet61bt8re2Ngo++rVq331yspK2VtaWmS33hvr+VvXgkgkIns2m5Vdsd5365i39j2dTh/0Pn2UinmdPZT5vW+3WGPG2v6qVatknzhxouzWvXNPT4/siURCdmtMWp8tLr/88oLNOpdb3dr37u5u2YutP8esdQ9grd967a3nptbv9/7Gui+3HHvssbJv2LBB9traWtmrq6tlt64lDz30kOx79+6VfeXKlbLv3r1bdnVOU591DwW9GbN8UwoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBY1IKAAAAAAAAgWNSCgAAAAAAAIFjUgoAAAAAAACBC3me5/XqgaGQ7GVlen4rn8/LHovFZE+lUrJb+6dYL4H13C644ALZ7777btmPOuoo2aPRqOyPPfaY7A8++KDsr7/+uuwdHR2yF5t6b8PhsFw2m83Kbi2fy+VkL7ZeDs8PZY0J67lbrNfGOm6tc4JafyQSkctaz23lypWyX3LJJbJbOjs7Za+qqpLdem2s4yKTycgej8dlt6xYsUL2K6+8smCz3jtrzFrHld/l0+m07BY/Y9Z6bfyej6qrq2X3e66fO3duwWbtu3Wd3blzp+ybNm2S3XrfrTFjKS8vl906rvxei6znZ+1fV1eX7Irf+7f+Vszr7MeZ3zGRSCRkTyaTsldUVMh+3nnnyX7NNdf4Wt7ywgsvyL506VLZn3322YLN72e2/r73tfgZs37vfS3W/Vt/8jsma2pqZO/u7pbd732Atbx1LbLee2v/rXOKdf/p5/6yrq5O9v379/d53UHozZjlm1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIHJNSAAAAAAAACByTUgAAAAAAAAgck1IAAAAAAAAIXMjzPK9XDwyFir0vAP5GL4fnh2LMAsFjzAKlhTELlBbGLFBaejNm+aYUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAsekFAAAAAAAAALHpBQAAAAAAAACx6QUAAAAAAAAAhfyPM/r750AAAAAAADAxwvflAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOCYlAIAAAAAAEDgmJQCAAAAAABA4JiUAgAAAAAAQOD+Hz0SqGx92kjqAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1200x300 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample = ds.take(5)\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
        "for ax, row in zip(axes, sample):\n",
        "    label = row[\"path\"].split(\"/\")[-2]\n",
        "    ax.imshow(row[\"image\"], cmap=\"gray\")\n",
        "    ax.set_title(f\"Label: {label}\")\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd880d56",
      "metadata": {},
      "source": [
        "This lazy execution model lets Ray Data optimize the full pipeline before running it. When you chain transformations (e.g., `ds.map_batches(f1).map_batches(f2).write_parquet(...)`), Ray Data builds a **logical plan** of your declared operations, then produces an optimized **physical plan**. A key optimization is **operator fusion** — adjacent compatible operators are merged into a single task, reducing data movement between stages. You can use `ds.explain()` to inspect the execution plan (we'll do this in Part 5 once we've built a more interesting pipeline).\n",
        "\n",
        "For a deeper dive into Ray Data internals, see the [Data Internals guide](https://docs.ray.io/en/latest/data/data-internals.html) and the [Key Concepts page](https://docs.ray.io/en/latest/data/key-concepts.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13644107",
      "metadata": {},
      "source": [
        "## Part 4: Transforming Data with `map_batches`\n",
        "\n",
        "The primary transformation API in Ray Data is `map_batches()`. It applies a user-defined function to each batch of data in parallel.\n",
        "\n",
        "A batch is a `dict[str, np.ndarray]` by default. Your function receives a batch and returns a transformed batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "919fda71",
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
        "    \"\"\"Normalize MNIST images to [-1, 1] range using torchvision transforms.\"\"\"\n",
        "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
        "    batch[\"image\"] = [transform(image) for image in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6ade0e45",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_normalized = ds.map_batches(normalize)  # Lazy — not executed yet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7391e9a1",
      "metadata": {},
      "source": [
        "Let's verify the transformation works on a small batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ae09d972",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-13 23:59:51,810\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_36_0\n",
            "2026-02-13 23:59:51,816\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_36_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-13 23:59:51,817\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_36_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> LimitOperator[limit=10] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)]\n",
            "2026-02-13 23:59:51,834\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-13 23:59:51,835\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:51,836\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=10} ===\n",
            "2026-02-13 23:59:51,837\tINFO progress_bar.py:215 -- limit=10: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:51,837\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-13 23:59:51,838\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:51,839\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(normalize)} ===\n",
            "2026-02-13 23:59:51,840\tINFO progress_bar.py:215 -- MapBatches(normalize): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:51,840\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-13 23:59:51,841\tINFO progress_bar.py:215 -- Running Dataset: dataset_36_0. Active & requested resources: 0/32 CPU, 0.0B/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:54,927\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_36_0 execution finished in 3.11 seconds\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
          ]
        }
      ],
      "source": [
        "normalized_batch = ds_normalized.take_batch(batch_size=10)\n",
        "\n",
        "for image in normalized_batch[\"image\"]:\n",
        "    assert image.shape == (1, 28, 28)  # channel, height, width\n",
        "    assert image.min() >= -1 and image.max() <= 1  # normalized range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "74181cd0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (1, 28, 28)\n",
            "Min value: -1.0000\n",
            "Max value: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Check the value ranges after normalization\n",
        "print(f\"Shape: {normalized_batch['image'][0].shape}\")\n",
        "print(f\"Min value: {normalized_batch['image'][0].min():.4f}\")\n",
        "print(f\"Max value: {normalized_batch['image'][0].max():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f820b10a",
      "metadata": {},
      "source": [
        "**Key `map_batches` parameters:**\n",
        "\n",
        "| **Parameter** | **Purpose** |\n",
        "|--------------|-------------|\n",
        "| `batch_size` | Number of rows per batch (default: `None` = entire block) |\n",
        "| `batch_format` | `\"default\"`/`\"numpy\"` (dict), `\"pandas\"`, or `\"pyarrow\"` |\n",
        "| `num_cpus` / `num_gpus` | Resources per worker |\n",
        "| `fn_kwargs` | Keyword arguments to pass to your function |\n",
        "| `compute` | Execution strategy — `TaskPoolStrategy` for functions, `ActorPoolStrategy` for classes |\n",
        "\n",
        "**When to use `map` vs `map_batches`:** Use `map_batches` when the underlying computation is vectorized — for example, NumPy array operations, PyArrow transforms, or GPU inference. If your logic is row-by-row standard Python (such as string parsing or feature extraction), use `map` instead, which applies a function to each row individually and avoids the overhead of batch formatting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6054ea53",
      "metadata": {},
      "source": [
        "## Part 5: Stateful Transformations and Batch Inference\n",
        "\n",
        "For operations like batch inference, you want to load a model once and reuse it across many batches. Ray Data supports this via **callable classes** passed to `map_batches`:\n",
        "\n",
        "- `__init__`: Initialize expensive state (load model, set up connections)\n",
        "- `__call__`: Process each batch using the initialized state\n",
        "\n",
        "Here's an MNIST classifier that loads a pre-trained PyTorch model and runs inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "970021bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MNISTClassifier:\n",
        "    def __init__(self, model_path: str):\n",
        "        self.model = torch.jit.load(model_path)\n",
        "        self.model.eval()\n",
        "\n",
        "    def __call__(self, batch: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
        "        images = torch.tensor(batch[\"image\"]).float()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(images).numpy()\n",
        "\n",
        "        batch[\"predicted_label\"] = np.argmax(logits, axis=1)\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f2379b",
      "metadata": {},
      "source": [
        "Download the model to shared storage, then apply the classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "71b2a639",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "download: s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt to ../../../mnt/cluster_storage/model.pt\n"
          ]
        }
      ],
      "source": [
        "!aws s3 cp s3://anyscale-public-materials/ray-ai-libraries/mnist/model/model.pt /mnt/cluster_storage/model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ee6b6896",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_preds = ds_normalized.map_batches(\n",
        "    MNISTClassifier,\n",
        "    fn_constructor_kwargs={\"model_path\": \"/mnt/cluster_storage/model.pt\"},\n",
        "    num_cpus=1,\n",
        "    batch_size=100,\n",
        "    compute=ray.data.ActorPoolStrategy(size=1),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff6842ba",
      "metadata": {},
      "source": [
        "**Note:** We pass the class *uninitialized* — Ray Data creates the actor and passes `fn_constructor_kwargs` to `__init__`. This ensures the model is loaded once per worker, not once per batch. To run on GPUs instead, add `num_gpus=1` and move the model/tensors to CUDA. For more on batch inference patterns, see the [Batch Inference guide](https://docs.ray.io/en/latest/data/batch_inference.html).\n",
        "\n",
        "Let's verify predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b879b6b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-13 23:59:57,328\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_38_0\n",
            "2026-02-13 23:59:57,331\tINFO limit_pushdown.py:140 -- Skipping push down of limit 5 through map MapBatches[MapBatches(MNISTClassifier)] because it requires 100 rows to produce stable outputs\n",
            "2026-02-13 23:59:57,336\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_38_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-13 23:59:57,337\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_38_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)] -> LimitOperator[limit=5]\n",
            "2026-02-13 23:59:57,499\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-13 23:59:57,500\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:57,501\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-13 23:59:57,501\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:57,502\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(normalize)->MapBatches(MNISTClassifier)} ===\n",
            "2026-02-13 23:59:57,503\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:57,503\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=5} ===\n",
            "2026-02-13 23:59:57,504\tINFO progress_bar.py:215 -- limit=5: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-13 23:59:57,505\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-13 23:59:57,505\tINFO progress_bar.py:215 -- Running Dataset: dataset_38_0. Active & requested resources: 0/32 CPU, 0.0B/27.0GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n",
            "2026-02-14 00:00:01,875\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_38_0 execution finished in 4.54 seconds\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True label: 0, Predicted: 0\n",
            "True label: 0, Predicted: 0\n",
            "True label: 0, Predicted: 0\n",
            "True label: 0, Predicted: 0\n",
            "True label: 0, Predicted: 0\n"
          ]
        }
      ],
      "source": [
        "preds = ds_preds.take(5)\n",
        "for p in preds:\n",
        "    digit = p[\"path\"].split(\"/\")[-2]\n",
        "    print(f\"True label: {digit}, Predicted: {p['predicted_label']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15466a18",
      "metadata": {},
      "source": [
        "**Scaling up:** Increase the pool size to use more workers. For example, `compute=ray.data.ActorPoolStrategy(size=4)` creates a fixed pool of 4 actors, or `compute=ray.data.ActorPoolStrategy(min_size=1, max_size=4)` creates an autoscaling pool.\n",
        "\n",
        "Now that we've built a multi-step pipeline (read → normalize → inference), let's inspect the execution plan Ray Data created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "287389b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "-------- Logical Plan --------\n",
            "MapBatches[MapBatches(MNISTClassifier)]\n",
            "+- MapBatches[MapBatches(normalize)]\n",
            "   +- ReadFiles[ReadFiles]\n",
            "      +- ListFiles[ListFiles]\n",
            "\n",
            "-------- Logical Plan (Optimized) --------\n",
            "MapBatches[MapBatches(MNISTClassifier)]\n",
            "+- MapBatches[MapBatches(normalize)]\n",
            "   +- ReadFiles[ReadFiles]\n",
            "      +- ListFiles[ListFiles]\n",
            "\n",
            "-------- Physical Plan --------\n",
            "ActorPoolMapOperator[MapBatches(MNISTClassifier)]\n",
            "+- TaskPoolMapOperator[MapBatches(normalize)]\n",
            "   +- TaskPoolMapOperator[ReadFiles]\n",
            "      +- TaskPoolMapOperator[ListFiles]\n",
            "         +- InputDataBuffer[Input]\n",
            "\n",
            "-------- Physical Plan (Optimized) --------\n",
            "ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)]\n",
            "+- TaskPoolMapOperator[ReadFiles]\n",
            "   +- TaskPoolMapOperator[ListFiles]\n",
            "      +- InputDataBuffer[Input]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ds_preds.explain()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd6fce12",
      "metadata": {},
      "source": [
        "## Part 6: Data Operations\n",
        "\n",
        "### Adding Labels\n",
        "\n",
        "Let's add ground truth labels to our MNIST dataset by extracting them from the image paths. Since this is row-by-row Python string parsing, we use `map` instead of `map_batches`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a0aa9881",
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_label(row: dict[str, any]) -> dict[str, any]:\n",
        "    row[\"ground_truth_label\"] = int(row[\"path\"].split(\"/\")[-2])\n",
        "    return row\n",
        "\n",
        "\n",
        "ds_labeled = ds_normalized.map(add_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fdac5b62",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-14 00:00:02,075\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_40_0\n",
            "2026-02-14 00:00:02,082\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_40_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-14 00:00:02,083\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_40_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> LimitOperator[limit=1] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(normalize)->Map(add_label)]\n",
            "2026-02-14 00:00:02,103\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-14 00:00:02,105\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:02,106\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=1} ===\n",
            "2026-02-14 00:00:02,106\tINFO progress_bar.py:215 -- limit=1: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:02,107\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-14 00:00:02,108\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:02,108\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(normalize)->Map(add_label)} ===\n",
            "2026-02-14 00:00:02,109\tINFO progress_bar.py:215 -- MapBatches(normalize)->Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:02,109\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-14 00:00:02,110\tINFO progress_bar.py:215 -- Running Dataset: dataset_40_0. Active & requested resources: 0/32 CPU, 0.0B/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,378\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_40_0 execution finished in 2.29 seconds\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'image': array([[[-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -0.9764706 , -1.        , -1.        , -1.        ,\n",
              "           -0.9372549 , -1.        , -0.96862745, -0.9764706 ,\n",
              "           -0.92156863, -1.        , -1.        , -0.94509804,\n",
              "           -0.9607843 , -0.9764706 , -1.        , -0.99215686,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -0.99215686, -0.9764706 , -1.        ,\n",
              "           -1.        , -0.90588236, -0.8352941 , -1.        ,\n",
              "           -1.        , -0.92156863, -0.88235295, -1.        ,\n",
              "           -1.        , -0.94509804, -0.9137255 , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -0.88235295,\n",
              "           -1.        , -1.        , -1.        , -0.92941177,\n",
              "           -0.96862745, -1.        , -1.        , -0.85882354,\n",
              "           -1.        , -1.        , -0.90588236, -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -0.9137255 , -1.        , -1.        , -0.96862745,\n",
              "           -1.        , -0.92941177, -0.9843137 , -0.92941177,\n",
              "           -0.9529412 , -0.827451  , -1.        , -1.        ,\n",
              "           -0.88235295, -1.        , -1.        , -0.9372549 ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -0.9372549 , -1.        ,\n",
              "           -0.5294118 ,  0.5294118 ,  0.9137255 ,  0.254902  ,\n",
              "           -0.6627451 , -1.        , -1.        , -1.        ,\n",
              "           -0.9372549 , -1.        , -0.9372549 , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -0.9843137 , -0.96862745, -1.        , -0.8117647 ,\n",
              "            0.30980396,  0.92941177,  1.        ,  1.        ,\n",
              "            0.54509807, -0.6       , -0.85882354, -0.9529412 ,\n",
              "           -0.9764706 , -1.        , -0.9372549 , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -0.9529412 ,  0.10588241,\n",
              "            1.        ,  0.8901961 ,  0.8666667 ,  0.7882353 ,\n",
              "            1.        ,  0.84313726,  0.18431377, -1.        ,\n",
              "           -1.        , -0.8980392 , -1.        , -0.94509804,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -0.9764706 , -1.        , -0.4352941 ,  0.8666667 ,\n",
              "            0.8117647 ,  0.92156863,  0.7882353 , -0.78039217,\n",
              "           -0.02745098,  0.20000005,  0.92941177, -0.17647058,\n",
              "           -1.        , -1.        , -0.94509804, -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9529412 , -0.99215686, -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -0.9372549 , -0.9764706 ,  0.9607843 ,  1.        ,\n",
              "           -0.20784312, -0.88235295, -0.75686276, -0.99215686,\n",
              "           -0.8980392 , -1.        ,  0.84313726,  0.7254902 ,\n",
              "           -0.9764706 , -1.        , -0.99215686, -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -0.9843137 ,\n",
              "           -0.9372549 , -0.9843137 , -1.        , -0.92941177,\n",
              "           -1.        , -0.5372549 ,  0.9843137 ,  0.6862745 ,\n",
              "           -0.8509804 , -0.84313726, -1.        , -0.9607843 ,\n",
              "           -0.9529412 , -1.        ,  0.34901965,  0.8980392 ,\n",
              "           -0.12156862, -1.        , -0.92941177, -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.99215686, -1.        , -0.9843137 ,\n",
              "           -0.9529412 , -1.        , -1.        , -0.9529412 ,\n",
              "           -1.        ,  0.60784316,  0.92156863,  0.41960788,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -0.01176471,  0.94509804,\n",
              "            0.5686275 , -0.99215686, -1.        , -0.99215686,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-0.96862745, -0.9607843 , -1.        , -1.        ,\n",
              "           -0.99215686, -1.        , -1.        , -0.99215686,\n",
              "           -0.8666667 ,  0.96862745,  0.9843137 , -0.20784312,\n",
              "           -0.9764706 , -0.9137255 , -1.        , -0.92156863,\n",
              "           -1.        , -1.        , -0.01960784,  0.90588236,\n",
              "            0.64705884, -0.92941177, -1.        , -0.96862745,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9529412 , -1.        , -1.        ,\n",
              "           -0.9607843 , -0.90588236, -0.9607843 , -1.        ,\n",
              "           -0.6862745 ,  0.8901961 ,  0.34901965, -0.88235295,\n",
              "           -0.99215686, -0.99215686, -1.        , -0.99215686,\n",
              "           -0.99215686, -0.96862745, -0.09019607,  0.99215686,\n",
              "            0.5686275 , -0.92941177, -1.        , -0.9764706 ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9607843 , -0.96862745, -1.        ,\n",
              "           -0.9607843 , -0.9607843 , -1.        , -1.        ,\n",
              "           -0.0745098 ,  1.        , -0.3098039 , -1.        ,\n",
              "           -0.99215686, -1.        , -0.92941177, -1.        ,\n",
              "           -1.        , -0.9843137 , -0.25490195,  1.        ,\n",
              "            0.6       , -1.        , -0.88235295, -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9764706 , -0.9843137 , -0.9764706 ,\n",
              "           -1.        , -1.        , -1.        , -0.827451  ,\n",
              "            0.78039217,  0.96862745, -0.23137254, -1.        ,\n",
              "           -1.        , -0.85882354, -1.        , -0.9372549 ,\n",
              "           -1.        , -1.        , -0.01960784,  1.        ,\n",
              "            0.5921569 , -1.        , -0.9372549 , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-0.9607843 , -1.        , -1.        , -0.9607843 ,\n",
              "           -0.99215686, -1.        , -0.8352941 , -0.372549  ,\n",
              "            0.9764706 ,  0.94509804, -0.41960782, -1.        ,\n",
              "           -0.90588236, -1.        , -0.8980392 , -1.        ,\n",
              "           -0.99215686, -0.96862745,  0.4901961 ,  0.8745098 ,\n",
              "            0.49803925, -0.9529412 , -1.        , -0.96862745,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-0.9607843 , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -0.9843137 , -1.        , -0.2862745 ,\n",
              "            0.9607843 ,  0.7647059 , -0.9843137 , -1.        ,\n",
              "           -0.96862745, -1.        , -1.        , -0.9607843 ,\n",
              "           -1.        , -0.7882353 ,  0.8039216 ,  0.90588236,\n",
              "           -0.38823527, -1.        , -0.8901961 , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -0.99215686, -0.14509803,\n",
              "            1.        ,  0.5921569 , -0.96862745, -1.        ,\n",
              "           -1.        , -1.        , -0.96862745, -0.99215686,\n",
              "           -1.        ,  0.5137255 ,  1.        ,  0.7254902 ,\n",
              "           -1.        , -0.9764706 , -1.        , -0.8666667 ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9843137 , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -0.9607843 , -0.02745098,\n",
              "            1.        , -0.3098039 , -1.        , -0.8117647 ,\n",
              "           -1.        , -0.9372549 , -0.90588236, -1.        ,\n",
              "           -0.03529412,  1.        ,  0.9843137 ,  0.34901965,\n",
              "           -0.9764706 , -0.96862745, -1.        , -0.96862745,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9529412 , -1.        , -1.        ,\n",
              "           -0.9764706 , -1.        , -0.9843137 , -0.11372548,\n",
              "            0.9372549 ,  0.47450984, -0.77254903, -1.        ,\n",
              "           -1.        , -0.9607843 , -1.        , -0.41960782,\n",
              "            0.90588236,  0.9137255 ,  1.        , -0.52156866,\n",
              "           -1.        , -0.8117647 , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.92941177, -1.        , -1.        ,\n",
              "           -0.9529412 , -1.        , -1.        , -0.3960784 ,\n",
              "            0.92941177,  0.8666667 , -1.        , -0.9529412 ,\n",
              "           -0.92156863, -0.9137255 , -0.05882353,  1.        ,\n",
              "            1.        ,  0.81960785, -0.4980392 , -0.96862745,\n",
              "           -1.        , -1.        , -0.90588236, -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9372549 , -1.        , -0.9764706 ,\n",
              "           -0.96862745, -1.        , -1.        , -0.7176471 ,\n",
              "            0.88235295,  1.        ,  0.3803922 , -0.31764704,\n",
              "           -0.56078434,  0.70980394,  0.9843137 ,  0.90588236,\n",
              "            0.79607844, -0.5137255 , -1.        , -1.        ,\n",
              "           -0.9137255 , -0.8901961 , -1.        , -0.9529412 ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9607843 , -1.        , -0.9607843 ,\n",
              "           -1.        , -0.99215686, -1.        , -0.9529412 ,\n",
              "           -0.31764704,  1.        ,  0.9137255 ,  0.9529412 ,\n",
              "            1.        ,  0.8901961 ,  1.        ,  0.47450984,\n",
              "           -0.4352941 , -1.        , -0.8039216 , -0.92941177,\n",
              "           -1.        , -0.9764706 , -0.8980392 , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -0.9843137 , -1.        , -0.94509804,\n",
              "           -1.        , -0.99215686, -0.99215686, -1.        ,\n",
              "           -0.9843137 , -0.38039213,  0.70980394,  0.94509804,\n",
              "            0.9843137 ,  0.27843142, -0.5529412 , -0.8980392 ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -0.99215686, -0.96862745, -1.        , -0.9764706 ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ],\n",
              "          [-1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ,\n",
              "           -1.        , -1.        , -1.        , -1.        ]]],\n",
              "        dtype=float32),\n",
              "  'path': 'anyscale-public-materials/ray-ai-libraries/mnist/50_per_index/0/img_11200.jpg',\n",
              "  'ground_truth_label': 0}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify labels were added\n",
        "ds_labeled.take(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eebef9d4",
      "metadata": {},
      "source": [
        "### Groupby and Map Groups\n",
        "\n",
        "Use `groupby()` to group data by a key and `map_groups()` to apply per-group transformations. Here, we compute per-label accuracy using `ds_preds` from Part 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7c69a472",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_accuracy(group: dict[str, np.ndarray]) -> dict[str, np.ndarray]:\n",
        "    return {\n",
        "        \"accuracy\": [np.mean(group[\"predicted_label\"] == group[\"ground_truth_label\"])],\n",
        "        \"ground_truth_label\": group[\"ground_truth_label\"][:1],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cb7592e7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(normalize)->Map(add_label) pid=24361, ip=10.0.20.48)\u001b[0m /tmp/ray/session_2026-02-13_23-18-25_427086_2605/runtime_resources/pip/2846e47e856485a52a6631b2694f1888cd561c49/virtualenv/lib/python3.12/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:213.)\n",
            "\u001b[36m(MapBatches(normalize)->Map(add_label) pid=24361, ip=10.0.20.48)\u001b[0m   img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
            "2026-02-14 00:00:04,516\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_45_0\n",
            "/home/ray/anaconda3/lib/python3.12/site-packages/ray/anyscale/data/_internal/util/dependencies.py:42: UserWarning: Numba isn't available. Install numba>=0.61>=0.61 to get better performance for hash partitioning operations. Falling back to slower Python implementation for RayTurbo optimizations.\n",
            "  warnings.warn(\n",
            "2026-02-14 00:00:04,526\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_45_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-14 00:00:04,527\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_45_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)] -> TaskPoolMapOperator[Map(add_label)] -> HashShuffleOperator[Shuffle(key_columns=('ground_truth_label',), num_partitions=200)] -> TaskPoolMapOperator[MapBatches(compute_accuracy)] -> AllToAllOperator[Sort]\n",
            "2026-02-14 00:00:04,787\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-14 00:00:04,788\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,789\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-14 00:00:04,790\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,790\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(normalize)->MapBatches(MNISTClassifier)} ===\n",
            "2026-02-14 00:00:04,791\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,792\tINFO progress_bar.py:213 -- === Ray Data Progress {Map(add_label)} ===\n",
            "2026-02-14 00:00:04,792\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,793\tINFO progress_bar.py:213 -- === Ray Data Progress {Shuffle(key_columns=('ground_truth_label',), num_partitions=200)} ===\n",
            "2026-02-14 00:00:04,794\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,794\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(compute_accuracy)} ===\n",
            "2026-02-14 00:00:04,795\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,796\tINFO progress_bar.py:213 -- === Ray Data Progress {Sort} ===\n",
            "2026-02-14 00:00:04,796\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:04,797\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-14 00:00:04,797\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 32/32 CPU, 0.0B/27.0GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,798\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,798\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,799\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,800\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,801\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,801\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,802\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:09,803\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 33/32 CPU, 384.0MiB/27.0GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(autoscaler +26s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[36m(autoscaler +26s)\u001b[0m [autoscaler] [8CPU-32GB] Attempting to add 1 node to the cluster (increasing from 0 to 1).\n",
            "\u001b[36m(autoscaler +26s)\u001b[0m [autoscaler] [8CPU-32GB|m5.2xlarge] [us-west-2a] [on-demand] Launched 1 instance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-14 00:00:14,807\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:14,808\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:14,809\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:14,810\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:14,810\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:14,811\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:14,812\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:14,813\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 33/32 CPU, 384.0MiB/27.0GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,823\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,824\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,824\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,825\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,825\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,826\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,827\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:19,827\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,834\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,835\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,836\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,836\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,837\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,838\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,838\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:24,839\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,835\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,836\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,836\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,837\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,837\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,838\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,839\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:29,839\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,875\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,875\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,876\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,877\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,877\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,878\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,878\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:34,879\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,883\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,884\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,885\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,885\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,886\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,887\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,887\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:39,889\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,935\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,936\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,937\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,938\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,938\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,939\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,939\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:44,939\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,945\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,945\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,946\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,947\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,948\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,948\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,949\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:49,949\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,952\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,953\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,953\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,954\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,955\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,955\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,956\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:54,957\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(autoscaler +1m11s)\u001b[0m [autoscaler] Cluster upscaled to {40 CPU, 0 GPU}.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-14 00:00:59,959\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:59,960\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:59,960\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:59,961\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:59,962\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:59,963\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:59,963\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:00:59,964\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,968\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,969\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,969\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,970\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,971\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,971\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,972\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:04,972\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/32 CPU, 384.0MiB/27.0GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,977\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,977\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,978\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,979\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,979\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,980\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,980\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:09,981\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,982\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,983\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,984\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,985\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,985\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,986\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,987\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:14,987\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,992\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,993\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,994\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,995\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,995\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,996\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,997\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:19,997\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,001\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,002\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,003\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,003\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,004\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,005\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,005\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:25,006\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,006\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,006\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,007\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,008\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,008\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,009\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,010\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:30,010\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,019\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,020\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,020\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,021\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,022\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,022\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,023\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:35,024\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,025\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,026\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,026\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,027\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,027\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,028\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,028\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:40,029\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,029\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,030\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,030\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,030\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,031\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,031\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,032\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:45,032\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,040\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,041\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,041\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,042\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,043\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,043\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,044\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:50,044\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,050\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,051\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,052\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,052\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,053\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,054\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,055\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:01:55,056\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,058\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,059\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,060\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,061\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,061\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,062\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,062\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:00,063\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,068\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,069\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,069\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,070\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,071\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,071\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,072\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:05,072\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,077\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,078\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,078\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,079\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,079\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,080\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,080\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:10,081\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,087\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,088\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,089\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,089\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,090\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,091\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,091\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:15,092\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,098\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,099\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,100\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,100\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,101\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,102\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,102\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:20,103\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,109\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,110\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,111\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,112\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,113\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,114\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,115\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:25,115\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,113\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,114\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,114\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,115\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,116\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,116\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,117\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:30,117\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,118\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,119\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,119\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,120\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,121\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,122\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,122\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:35,124\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 34/40 CPU, 384.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:40,210\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:40,211\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 426.1KiB object store: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:40,211\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 1; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store; [0/1 objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:40,212\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:40,212\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0 [backpressured:tasks]; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:40,213\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:40,213\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:40,214\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 33/40 CPU, 384.4MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:40,810\tINFO progress_bar.py:213 -- === Ray Data Progress {*- Shuffle} ===\n",
            "2026-02-14 00:02:40,811\tINFO progress_bar.py:215 -- *- Shuffle: Progress Completed 500 / 1\n",
            "2026-02-14 00:02:40,913\tINFO progress_bar.py:213 -- === Ray Data Progress {*- Reduce} ===\n",
            "2026-02-14 00:02:40,914\tINFO progress_bar.py:215 -- *- Reduce: Progress Completed 50 / ?\n",
            "2026-02-14 00:02:44,512\tINFO progress_bar.py:213 -- === Ray Data Progress {*- Sort Sample} ===\n",
            "2026-02-14 00:02:44,512\tINFO progress_bar.py:215 -- *- Sort Sample: Progress Completed 7 / 1\n",
            "2026-02-14 00:02:45,839\tINFO progress_bar.py:213 -- === Ray Data Progress {*- Shuffle Map} ===\n",
            "2026-02-14 00:02:45,840\tINFO progress_bar.py:215 -- *- Shuffle Map: Progress Completed 10 / 1\n",
            "2026-02-14 00:02:46,521\tINFO progress_bar.py:213 -- === Ray Data Progress {*- Shuffle Reduce} ===\n",
            "2026-02-14 00:02:46,522\tINFO progress_bar.py:215 -- *- Shuffle Reduce: Progress Completed 10 / 1\n",
            "2026-02-14 00:02:46,538\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:46,539\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:46,540\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [0/1 objects local]: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:46,540\tINFO progress_bar.py:215 -- Map(add_label): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:46,541\tINFO progress_bar.py:215 -- Shuffle(key_columns=('ground_truth_label',), num_partitions=200): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 32.0 CPU, 0.0B object store: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:46,542\tINFO progress_bar.py:215 -- MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 160.0B object store: Progress Completed 10 / ?\n",
            "2026-02-14 00:02:46,543\tINFO progress_bar.py:215 -- Sort: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; 0 rows output: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:46,544\tINFO progress_bar.py:215 -- Running Dataset: dataset_45_0. Active & requested resources: 32/40 CPU, 160.0B/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:46,649\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_45_0 execution finished in 162.11 seconds\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>ground_truth_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.98</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.96</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.00</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.00</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.98</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.98</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.00</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.98</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  ground_truth_label\n",
              "0      0.98                   0\n",
              "1      1.00                   1\n",
              "2      1.00                   2\n",
              "3      0.96                   3\n",
              "4      1.00                   4\n",
              "5      1.00                   5\n",
              "6      0.98                   6\n",
              "7      0.98                   7\n",
              "8      1.00                   8\n",
              "9      0.98                   9"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_by_label = (\n",
        "    ds_preds\n",
        "    .map(add_label)\n",
        "    .groupby(\"ground_truth_label\")\n",
        "    .map_groups(compute_accuracy)\n",
        "    .sort(\"ground_truth_label\")\n",
        "    .to_pandas()\n",
        ")\n",
        "accuracy_by_label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5165e62",
      "metadata": {},
      "source": [
        "### Aggregations\n",
        "\n",
        "Ray Data provides built-in aggregation functions: `count()`, `max()`, `mean()`, `min()`, `sum()`, `std()`. See the [aggregation API docs](https://docs.ray.io/en/latest/data/api/grouped_data.html#ray.data.aggregate.AggregateFn) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a074987f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-14 00:02:46,872\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_49_0\n",
            "2026-02-14 00:02:46,883\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_49_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-14 00:02:46,884\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_49_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)] -> TaskPoolMapOperator[Map(add_label)->MapBatches(compute_accuracy)] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n",
            "2026-02-14 00:02:47,044\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-14 00:02:47,045\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:47,046\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-14 00:02:47,047\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:47,048\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(normalize)->MapBatches(MNISTClassifier)} ===\n",
            "2026-02-14 00:02:47,049\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:47,049\tINFO progress_bar.py:213 -- === Ray Data Progress {Map(add_label)->MapBatches(compute_accuracy)} ===\n",
            "2026-02-14 00:02:47,050\tINFO progress_bar.py:215 -- Map(add_label)->MapBatches(compute_accuracy): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:47,051\tINFO progress_bar.py:213 -- === Ray Data Progress {HashAggregate(key_columns=(), num_partitions=1)} ===\n",
            "2026-02-14 00:02:47,052\tINFO progress_bar.py:215 -- HashAggregate(key_columns=(), num_partitions=1): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.2 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:47,053\tINFO progress_bar.py:213 -- === Ray Data Progress {limit=1} ===\n",
            "2026-02-14 00:02:47,053\tINFO progress_bar.py:215 -- limit=1: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:47,054\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-14 00:02:47,055\tINFO progress_bar.py:215 -- Running Dataset: dataset_49_0. Active & requested resources: 0.25/40 CPU, 0.0B/33.7GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,095\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 1; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store; [0/1 objects local]: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:52,110\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 500 / 500\n",
            "2026-02-14 00:02:52,111\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 426.1KiB object store: Progress Completed 500 / 500\n",
            "2026-02-14 00:02:52,112\tINFO progress_bar.py:215 -- Map(add_label)->MapBatches(compute_accuracy): Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,113\tINFO progress_bar.py:215 -- HashAggregate(key_columns=(), num_partitions=1): Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.2 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,114\tINFO progress_bar.py:215 -- limit=1: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,114\tINFO progress_bar.py:215 -- Running Dataset: dataset_49_0. Active & requested resources: 1.25/40 CPU, 5.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,154\tINFO progress_bar.py:213 -- === Ray Data Progress {*- Shuffle} ===\n",
            "2026-02-14 00:02:52,155\tINFO progress_bar.py:215 -- *- Shuffle: Progress Completed 1 / 1\n",
            "2026-02-14 00:02:52,169\tINFO progress_bar.py:213 -- === Ray Data Progress {*- Aggregation} ===\n",
            "2026-02-14 00:02:52,169\tINFO progress_bar.py:215 -- *- Aggregation: Progress Completed 1 / ?\n",
            "2026-02-14 00:02:52,191\tINFO streaming_executor.py:305 -- ✔️  Dataset dataset_49_0 execution finished in 5.31 seconds\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean accuracy across all digits: 0.9880\n"
          ]
        }
      ],
      "source": [
        "mean_accuracy = ds_preds.map(add_label).map_batches(compute_accuracy).mean(on=\"accuracy\")\n",
        "print(f\"Mean accuracy across all digits: {mean_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cb51b49",
      "metadata": {},
      "source": [
        "**Key takeaway:** `groupby` + `map_groups` lets you apply per-group logic, while built-in aggregation functions cover common statistical operations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "271cfb00",
      "metadata": {},
      "source": [
        "## Part 7: Observability\n",
        "\n",
        "Ray Data provides several tools for understanding what your pipeline is doing:\n",
        "\n",
        "- `ds.stats()` — programmatic breakdown of per-operator throughput and timing\n",
        "- `ds.explain()` — view the execution plan\n",
        "- **Ray Dashboard** — cluster utilization, per-operator metrics, object store usage\n",
        "- **Anyscale Metrics tab** — GPU utilization, memory, network, disk I/O\n",
        "\n",
        "Use `set_name()` to label your dataset in the Ray Dashboard:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "abd51083",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_preds.set_name(\"mnist_predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146b6c71",
      "metadata": {},
      "source": [
        "The **Ray Workloads** view shows each operator in your pipeline, its status, row counts, and throughput — so you can quickly identify which stage is the bottleneck:\n",
        "\n",
        "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/intro-ai-libraries/ray-data-workloads.png\" width=\"900\" alt=\"Ray Data Workloads view showing per-operator status and throughput\">\n",
        "\n",
        "The **Ray Dashboard Metrics** tab gives you time-series charts for bytes and blocks generated per second, rows processed per second, object store memory usage and more — useful for spotting throughput drops or memory pressure over time:\n",
        "\n",
        "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/intro-ai-libraries/ray-data-dashboard.png\" width=\"900\" alt=\"Ray Dashboard Metrics showing throughput and object store memory\">\n",
        "\n",
        "For detailed guidance, see the [Anyscale monitoring and debugging guide](https://docs.anyscale.com/monitoring)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fe03d37",
      "metadata": {},
      "source": [
        "## Part 8: Materializing and Persisting Data\n",
        "\n",
        "By default, Ray Data streams data lazily. You can **materialize** a dataset to eagerly execute the full pipeline and store results in the Ray object store (distributed across the cluster, spilling to disk if needed).\n",
        "\n",
        "**When to materialize:**\n",
        "- When you need to reuse the same dataset multiple times (avoids re-computation)\n",
        "- When downstream operations require the full dataset (e.g., `groupby`, `random_shuffle`)\n",
        "\n",
        "**When NOT to materialize:**\n",
        "- For streaming pipelines where data flows through once (training ingest, write-to-sink)\n",
        "- When the dataset is too large to fit in the object store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "effa2423",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-14 00:02:52,310\tINFO logging.py:397 -- Registered dataset logger for dataset mnist_predictions_50_0\n",
            "2026-02-14 00:02:52,315\tINFO streaming_executor.py:178 -- Starting execution of Dataset mnist_predictions_50_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-14 00:02:52,315\tINFO streaming_executor.py:179 -- Execution plan of Dataset mnist_predictions_50_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)]\n",
            "2026-02-14 00:02:52,466\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-14 00:02:52,467\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,467\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-14 00:02:52,468\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,469\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(normalize)->MapBatches(MNISTClassifier)} ===\n",
            "2026-02-14 00:02:52,470\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:52,470\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-14 00:02:52,471\tINFO progress_bar.py:215 -- Running Dataset: mnist_predictions_50_0. Active & requested resources: 0/40 CPU, 0.0B/33.7GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n",
            "2026-02-14 00:02:57,487\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 500 / 500\n",
            "2026-02-14 00:02:57,488\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 426.1KiB object store: Progress Completed 500 / ?\n",
            "2026-02-14 00:02:57,488\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 1; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:57,489\tINFO progress_bar.py:215 -- Running Dataset: mnist_predictions_50_0. Active & requested resources: 1/40 CPU, 384.4MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:57,928\tINFO streaming_executor.py:305 -- ✔️  Dataset mnist_predictions_50_0 execution finished in 5.61 seconds\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bfdf97c44d449eab6e8b05905e07a83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "MaterializedDataset(\n",
              "   name=mnist_predictions,\n",
              "   num_blocks=1,\n",
              "   num_rows=500,\n",
              "   schema={\n",
              "      image: ArrowTensorTypeV2(shape=(1, 28, 28), dtype=float),\n",
              "      path: string,\n",
              "      predicted_label: int64\n",
              "   }\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_materialized = ds_preds.materialize()\n",
        "ds_materialized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2e57246e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operator 0 ReadFiles: \n",
            "\n",
            "Operator 1 ListFiles: 1 tasks executed, 1 blocks produced in 0.33s\n",
            "* Remote wall time: 329.81ms min, 329.81ms max, 329.81ms mean, 329.81ms total\n",
            "* Remote cpu time: 34.32ms min, 34.32ms max, 34.32ms mean, 34.32ms total\n",
            "* UDF time: 0us min, 0us max, 0.0us mean, 0us total\n",
            "* Peak heap memory usage (MiB): 120.46 min, 120.46 max, 120 mean\n",
            "* Output num rows per block: 500 min, 500 max, 500 mean, 500 total\n",
            "* Output size bytes per block: 50413 min, 50413 max, 50413 mean, 50413 total\n",
            "* Output rows per task: 500 min, 500 max, 500 mean, 1 tasks used\n",
            "* Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
            "* Operator throughput:\n",
            "\t* Total input num rows: 0 rows\n",
            "\t* Total output num rows: 500 rows\n",
            "\t* Ray Data throughput: 1516.0036424231423 rows/s\n",
            "\t* Estimated single task throughput: 1516.0036424231423 rows/s\n",
            "\n",
            "Operator 2 ReadFiles: 1 tasks executed, 1 blocks produced in 2.56s\n",
            "* Remote wall time: 2.56s min, 2.56s max, 2.56s mean, 2.56s total\n",
            "* Remote cpu time: 993.78ms min, 993.78ms max, 993.78ms mean, 993.78ms total\n",
            "* UDF time: 0us min, 0us max, 0.0us mean, 0us total\n",
            "* Peak heap memory usage (MiB): 135.22 min, 135.22 max, 135 mean\n",
            "* Output num rows per block: 500 min, 500 max, 500 mean, 500 total\n",
            "* Output size bytes per block: 436350 min, 436350 max, 436350 mean, 436350 total\n",
            "* Output rows per task: 500 min, 500 max, 500 mean, 1 tasks used\n",
            "* Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
            "* Operator throughput:\n",
            "\t* Total input num rows: 500 rows\n",
            "\t* Total output num rows: 500 rows\n",
            "\t* Ray Data throughput: 195.36066670656746 rows/s\n",
            "\t* Estimated single task throughput: 195.36066670656746 rows/s\n",
            "\n",
            "Operator 3 MapBatches(normalize)->MapBatches(MNISTClassifier): 1 tasks executed, 1 blocks produced in 0.71s\n",
            "* Remote wall time: 705.31ms min, 705.31ms max, 705.31ms mean, 705.31ms total\n",
            "* Remote cpu time: 706.96ms min, 706.96ms max, 706.96ms mean, 706.96ms total\n",
            "* UDF time: 780.36ms min, 780.36ms max, 780.36ms mean, 780.36ms total\n",
            "* Peak heap memory usage (MiB): 500.18 min, 500.18 max, 500 mean\n",
            "* Output num rows per block: 500 min, 500 max, 500 mean, 500 total\n",
            "* Output size bytes per block: 1616350 min, 1616350 max, 1616350 mean, 1616350 total\n",
            "* Output rows per task: 500 min, 500 max, 500 mean, 1 tasks used\n",
            "* Tasks per node: 1 min, 1 max, 1 mean; 1 nodes used\n",
            "* Operator throughput:\n",
            "\t* Total input num rows: 500 rows\n",
            "\t* Total output num rows: 500 rows\n",
            "\t* Ray Data throughput: 708.9073959089421 rows/s\n",
            "\t* Estimated single task throughput: 708.9073959089421 rows/s\n",
            "\n",
            "Dataset throughput:\n",
            "\t* Ray Data throughput: 0.28513494220171837 rows/s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check materialized dataset stats\n",
        "print(ds_materialized.stats())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b988b9",
      "metadata": {},
      "source": [
        "### Persisting to storage\n",
        "\n",
        "Write processed data to persistent storage using any of Ray Data's write functions. Ray Data supports writing to Parquet, CSV, JSON, TFRecords, and more. See the [Input/Output docs](https://docs.ray.io/en/latest/data/api/input_output.html) for the full list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "31f64c27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-14 00:02:58,117\tINFO logging.py:397 -- Registered dataset logger for dataset mnist_predictions_53_0\n",
            "2026-02-14 00:02:58,122\tINFO streaming_executor.py:178 -- Starting execution of Dataset mnist_predictions_53_0. Full logs are in /tmp/ray/session_2026-02-13_23-18-25_427086_2605/logs/ray-data\n",
            "2026-02-14 00:02:58,123\tINFO streaming_executor.py:179 -- Execution plan of Dataset mnist_predictions_53_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> ActorPoolMapOperator[MapBatches(normalize)->MapBatches(MNISTClassifier)] -> TaskPoolMapOperator[Write]\n",
            "2026-02-14 00:02:58,278\tINFO progress_bar.py:213 -- === Ray Data Progress {ListFiles} ===\n",
            "2026-02-14 00:02:58,280\tINFO progress_bar.py:215 -- ListFiles: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:58,280\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadFiles} ===\n",
            "2026-02-14 00:02:58,281\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:58,282\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(normalize)->MapBatches(MNISTClassifier)} ===\n",
            "2026-02-14 00:02:58,283\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:58,283\tINFO progress_bar.py:213 -- === Ray Data Progress {Write} ===\n",
            "2026-02-14 00:02:58,284\tINFO progress_bar.py:215 -- Write: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:02:58,284\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
            "2026-02-14 00:02:58,285\tINFO progress_bar.py:215 -- Running Dataset: mnist_predictions_53_0. Active & requested resources: 0/40 CPU, 0.0B/33.7GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n",
            "2026-02-14 00:03:03,319\tINFO progress_bar.py:215 -- MapBatches(normalize)->MapBatches(MNISTClassifier): Tasks: 1; Actors: 1; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store; [all objects local]: Progress Completed 500 / ?\n",
            "2026-02-14 00:03:03,327\tINFO progress_bar.py:215 -- ListFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store: Progress Completed 500 / 500\n",
            "2026-02-14 00:03:03,328\tINFO progress_bar.py:215 -- ReadFiles: Tasks: 0; Actors: 0; Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 426.1KiB object store: Progress Completed 500 / 500\n",
            "2026-02-14 00:03:03,329\tINFO progress_bar.py:215 -- Write: Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 384.0MiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:03:03,329\tINFO progress_bar.py:215 -- Running Dataset: mnist_predictions_53_0. Active & requested resources: 1/40 CPU, 5.0MiB/33.7GiB object store: Progress Completed 0 / ?\n",
            "2026-02-14 00:03:03,414\tINFO streaming_executor.py:305 -- ✔️  Dataset mnist_predictions_53_0 execution finished in 5.29 seconds\n",
            "INFO:openlineage.client.transport.composite:Stopping OpenLineage CompositeTransport emission after the first successful delivery because `continue_on_success=False`. Transport that emitted the event: <HttpTransport(name=first, kind=http, priority=1)>\n",
            "2026-02-14 00:03:03,436\tINFO dataset.py:5344 -- Data sink Parquet finished. 500 rows and 1.5MiB data written.\n"
          ]
        }
      ],
      "source": [
        "ds_preds.write_parquet(\"/mnt/cluster_storage/mnist_preds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd7a00d",
      "metadata": {},
      "source": [
        "You've built a complete Ray Data pipeline — from loading through persistence. The following sections cover advanced topics organized by theme, and can be read in any order."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6822bd9c",
      "metadata": {},
      "source": [
        "## Additional APIs\n",
        "\n",
        "*Ray Data offers higher-level tools beyond `map` and `map_batches`.*\n",
        "\n",
        "### Part 9: Preprocessing and Expressions\n",
        "\n",
        "#### Preprocessors\n",
        "\n",
        "When a transform needs to compute statistics over the full dataset first (such as mean and standard deviation for normalization), Ray Data provides built-in Preprocessors that follow the familiar scikit-learn `fit` / `transform` pattern. See the [Preprocessor API reference](https://docs.ray.io/en/latest/data/api/preprocessor.html) for the full list of built-ins. You can also chain them with `Chain`:\n",
        "\n",
        "```python\n",
        "from ray.data.preprocessors import StandardScaler, Chain, LabelEncoder\n",
        "\n",
        "# Example with tabular data — fit computes statistics, transform applies them\n",
        "preprocessor = Chain(\n",
        "    StandardScaler(columns=[\"feature_a\", \"feature_b\"]),\n",
        "    LabelEncoder(label_column=\"label\"),\n",
        ")\n",
        "# preprocessor = preprocessor.fit(ds_tabular)\n",
        "# ds_processed = preprocessor.transform(ds_tabular)\n",
        "```\n",
        "\n",
        "#### Expressions API\n",
        "\n",
        "Before writing a custom `map` or `map_batches` function, check if the **Expressions API** can handle it for you. Expressions are built-in helper functions for common column operations — string manipulation, list operations, struct field access, arithmetic, and more — so you don't have to write boilerplate UDFs yourself.\n",
        "\n",
        "Use `col()` to reference columns, `lit()` for literal values, and chain operations with namespaces such as `.str`, `.list`, and `.struct`:\n",
        "\n",
        "```python\n",
        "from ray.data.expressions import col\n",
        "\n",
        "# Add an uppercase column without writing a custom function\n",
        "ds_example = ray.data.from_items([{\"name\": \"alice\"}, {\"name\": \"bob\"}, {\"name\": \"charlie\"}])\n",
        "ds_example = ds_example.with_column(\"upper_name\", col(\"name\").str.upper())\n",
        "ds_example.show()\n",
        "```\n",
        "\n",
        "Expressions also support arithmetic (`col(\"a\") + col(\"b\")`), comparisons (`col(\"score\") > 0.5`), and custom UDFs through the `@udf` decorator. See the full [Expressions API reference](https://docs.ray.io/en/latest/data/api/expressions.html) for the complete list of available operations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d721e151",
      "metadata": {},
      "source": [
        "## Scaling and Performance\n",
        "\n",
        "*As your data and cluster grow, these tools help you stay fast.*\n",
        "\n",
        "### Part 10: Shuffling\n",
        "\n",
        "Ray Data offers three shuffle strategies with increasing randomness and cost:\n",
        "\n",
        "| **Strategy** | **API** | **Randomness** | **Cost** |\n",
        "|-------------|---------|---------------|----------|\n",
        "| File-based shuffle on read | `read_images(..., shuffle=\"files\")` | Low | Low |\n",
        "| Block order shuffle | `ds.randomize_block_order()` | Medium | Medium |\n",
        "| Global row shuffle | `ds.random_shuffle()` | High | High |\n",
        "\n",
        "#### Pull-based vs push-based shuffle\n",
        "\n",
        "Under the hood, global shuffle (`random_shuffle()`, `sort()`) uses a **sort-based shuffle** with two available implementations:\n",
        "\n",
        "| | **Pull-based (default)** | **Push-based** |\n",
        "|---|---|---|\n",
        "| **How it works** | Classic MapReduce-style: all map tasks run first, then reduce tasks pull and combine outputs | Pipelined: map and merge tasks overlap in rounds, with a final reduce stage |\n",
        "| **Best for** | Smaller datasets (<1 TB, <1000 blocks) | Large datasets (>1 TB, >1000 blocks) |\n",
        "| **Trade-off** | Simpler, well-tested | Better throughput and memory for large shuffles |\n",
        "\n",
        "Try push-based shuffle if your dataset has more than 1000 blocks or is larger than 1 TB in size:\n",
        "\n",
        "```python\n",
        "ctx = ray.data.DataContext.get_current()\n",
        "ctx.shuffle_strategy = \"sort_shuffle_push_based\"  # Or set RAY_DATA_PUSH_BASED_SHUFFLE=1\n",
        "```\n",
        "\n",
        "### Part 11: Resource Management and Performance Tuning\n",
        "\n",
        "Ray Data's **ResourceManager** tracks CPU, GPU, heap memory, and object store usage across all operators. It dynamically allocates budgets to keep the pipeline balanced.\n",
        "\n",
        "- **Per-operator resources:** Set `num_cpus`, `num_gpus`, and `memory` on `map_batches` to control what each worker gets\n",
        "- **Backpressure:** Ray Data automatically throttles upstream operators when downstream operators can't keep up, preventing OOM errors and disk spilling\n",
        "- **Autoscaling:** Ray Data can request more cluster resources when operators are bottlenecked:\n",
        "  - *Reactive autoscaling* (default): triggers when operators stall waiting for resources\n",
        "  - *Proactive autoscaling*: triggers at 75% utilization threshold, requesting whole nodes\n",
        "\n",
        "When your pipeline isn't performing as expected, follow this systematic approach:\n",
        "\n",
        "1. **Establish a baseline** — measure single-operator throughput in isolation\n",
        "2. **Scale up** — run the full pipeline on the target cluster size\n",
        "3. **Root cause analysis** — check for GPU under-utilization, disk spilling, or OOM errors\n",
        "4. **Iterate** — change one parameter at a time and measure impact\n",
        "\n",
        "#### Block size tuning\n",
        "\n",
        "Block size is an important performance lever. Larger blocks reduce scheduling overhead and improve throughput, but increase memory usage per task. Smaller blocks improve parallelism and reduce per-task memory, but add more scheduling overhead. Start with the defaults and adjust based on your workload.\n",
        "\n",
        "```python\n",
        "ctx = ray.data.DataContext.get_current()\n",
        "ctx.target_max_block_size = 128 * 1024 * 1024  # 128 MB max block size\n",
        "ctx.target_min_block_size = 1 * 1024 * 1024     # 1 MB min block size\n",
        "```\n",
        "\n",
        "#### Eager free\n",
        "\n",
        "By default, Ray Data relies on Python garbage collection and Ray reference counting to free block memory. Enabling eager free releases block references from the object store as soon as they're no longer needed, reducing memory pressure in streaming pipelines:\n",
        "\n",
        "```python\n",
        "ctx = ray.data.DataContext.get_current()\n",
        "ctx.eager_free = True  # Or set RAY_DATA_EAGER_FREE=1\n",
        "```\n",
        "\n",
        "#### Polars for sort operations\n",
        "\n",
        "You can speed up `sort()` and operations that sort internally (such as `map_groups()`) by enabling Polars as the sorting backend. This can significantly improve performance for large tabular datasets. When enabled, Ray Data uses Polars instead of PyArrow for the internal sorting step. This doesn't affect other operations such as `map_batches`.\n",
        "\n",
        "```python\n",
        "ctx = ray.data.DataContext.get_current()\n",
        "ctx.use_polars_sort = True  # Requires: pip install polars\n",
        "```\n",
        "\n",
        "See the [execution configurations docs](https://docs.ray.io/en/latest/data/execution-configurations.html) and [performance tips](https://docs.ray.io/en/latest/data/performance-tips.html) for more tuning guidance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7884e4",
      "metadata": {},
      "source": [
        "## Reliability\n",
        "\n",
        "*For production pipelines that need to handle failures.*\n",
        "\n",
        "### Part 12: Fault Tolerance and Checkpointing\n",
        "\n",
        "Ray Data provides fault tolerance at two levels:\n",
        "\n",
        "#### Worker-level retry\n",
        "\n",
        "If a worker task fails (e.g., OOM, transient network error), Ray Data automatically retries the task. Configure retry behavior:\n",
        "\n",
        "```python\n",
        "ctx = ray.data.DataContext.get_current()\n",
        "ctx.retried_io_errors = [IOError, ConnectionError]  # Retry on these errors\n",
        "ctx.max_errored_blocks = 5  # Allow up to 5 failed blocks before aborting\n",
        "```\n",
        "\n",
        "#### Job-level checkpointing\n",
        "\n",
        "For recovering from driver failures, head node crashes, or job pre-emptions, RayTurbo Data provides **job-level checkpointing**:\n",
        "\n",
        "- Checkpoints are written after each block reaches the sink:\n",
        "\n",
        "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-data-deep-dive/ray_data_checkpointing_storing.png\" alt=\"Ray Data Checkpoint Storing Flow\" width=\"800\">\n",
        "\n",
        "- On restart, the pipeline skips already-processed rows by matching an ID column:\n",
        "\n",
        "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-data-deep-dive/ray_data_checkpointing_restore.png\" alt=\"Ray Data Checkpoint Restore Flow\" width=\"800\">\n",
        "\n",
        "```python\n",
        "from ray.anyscale.data.checkpoint import CheckpointConfig\n",
        "\n",
        "ctx = ray.data.DataContext.get_current()\n",
        "ctx.checkpoint_config = CheckpointConfig(\n",
        "    id_column=\"row_id\",\n",
        "    checkpoint_path=\"/mnt/cluster_storage/ray_data_checkpoint/\",\n",
        "    delete_checkpoint_on_success=True,\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b07fb29",
      "metadata": {},
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "In this template, you learned:\n",
        "\n",
        "- **What** Ray Data is — a scalable, streaming data processing library for AI workloads\n",
        "- **Why** to use it — streaming execution across heterogeneous CPU/GPU clusters for batch inference, training data ingest, and reliable data pipelines\n",
        "- **How** to use it — loading data, transforming with `map` and `map_batches`, stateful batch inference, data operations, materialization, observability, and persistence\n",
        "- **Advanced topics** — additional transform APIs, Ray Train integration, shuffling strategies, performance tuning, and fault tolerance\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **[Ray Data User Guide](https://docs.ray.io/en/latest/data/user-guide.html)** — In-depth guides for specific use cases\n",
        "2. **[Batch Inference Guide](https://docs.ray.io/en/latest/data/batch_inference.html)** — Detailed patterns for scaling inference\n",
        "3. **[Ray Data + Ray Train Integration](https://docs.ray.io/en/latest/train/user-guides/data-loading-preprocessing.html)** — Feeding Ray Data into distributed training\n",
        "4. **[Performance Tips](https://docs.ray.io/en/latest/data/performance-tips.html)** — Tuning for production workloads\n",
        "5. **[Ray Data API Reference](https://docs.ray.io/en/latest/data/api/api.html)** — Complete API documentation"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
