(serve-examples)=

# Ray Serve Examples

```{toctree}
:caption: Ray Serve Examples
:maxdepth: '-1'
:name: serve-tutorials
:hidden:

serve-ml-models
stable-diffusion
text-classification
object-detection
aws-neuron-core-inference
aws-neuron-core-inference-stable-diffusion
intel-habana-gaudi-inference
gradio-integration
batch
streaming
java
triton-server-integration
```

Below are tutorials for exploring Ray Serve capabilities and learning how to integrate different modeling frameworks.

Beginner
--------

```{list-table}
  * - [Serve ML Models](serve-ml-models)
  * - [Serve a Stable Diffusion Model](stable-diffusion)
  * - [Serve a Text Classification Model](text-classification)
  * - [Serve an Object Detection Model](object-detection)
```

Intermediate
------------

```{list-table}
  * - [Serve an Inference Model on AWS NeuronCores Using FastAPI](aws-neuron-core-inference)
  * - [Serve an Inference with Stable Diffusion Model on AWS NeuronCores Using FastAPI](aws-neuron-core-inference-stable-diffusion)
  * - [Scale a Gradio App with Ray Serve](gradio-integration)
  * - [Serve a Text Generator with Request Batching](batch.md)
  * - [Serve a Chatbot with Request and Response Streaming](streaming)
```

Advanced
--------

```{list-table}
  * - [Serve a Java App](java)
```