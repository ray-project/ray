{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq-IHSrRPYjc"
   },
   "source": [
    "# Asynchronous Inference with Ray Serve\n",
    "\n",
    "**⏱️ Time to complete**: 30 minutes\n",
    "\n",
    "This template demonstrates how to build scalable asynchronous inference services using Ray Serve. Learn how to handle long-running PDF processing tasks without blocking HTTP responses, using Celery task queues and Redis as a message broker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBGu_yjLPYje"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Traditional synchronous APIs block until processing completes, causing timeouts for long-running tasks. Ray Serve's asynchronous inference pattern decouples request lifetime from compute time by:\n",
    "\n",
    "1. Accepting HTTP requests and immediately returning a task ID\n",
    "2. Enqueuing work to background processors (Celery workers)\n",
    "3. Allowing clients to poll for status and retrieve results\n",
    "\n",
    "This example implements a **PDF processing service** that extracts text and generates summaries from PDF documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUj7ohuhPYje"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- Ray 2.50.0+\n",
    "- Redis (for message broker and result backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8O5Bk2gPYje"
   },
   "source": [
    "## Step 1: Setup Redis\n",
    "\n",
    "Redis serves as both the message broker (task queue) and result backend.\n",
    "\n",
    "**Install and start Redis (Google Colab compatible)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Zsr4HD0_PYje",
    "outputId": "3ecc8fe0-5a73-4793-8735-d2517d38c82d"
   },
   "outputs": [],
   "source": [
    "# Install and start Redis server\n",
    "!sudo apt-get update -qq\n",
    "!sudo apt-get install -y redis-server\n",
    "!redis-server --port 6399 --save \"\" --appendonly no --daemonize yes\n",
    "\n",
    "# Verify Redis is running\n",
    "!redis-cli -p 6399 ping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzPQjYzmPYjf"
   },
   "source": [
    "**Alternative methods:**\n",
    "\n",
    "- macOS: `brew install redis && brew services start redis`\n",
    "- Docker: `docker run -d -p 6379:6379 redis:latest`\n",
    "- [Official Redis Installation Guide](https://redis.io/docs/getting-started/installation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ6ahzMPPYjf"
   },
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2KQe0ROXPYjf"
   },
   "outputs": [],
   "source": [
    "!pip install -q ray[serve-async-inference]>=2.50.0 requests>=2.31.0 PyPDF2>=3.0.0 celery[redis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqLdlKIhPYjf"
   },
   "source": [
    "\n",
    "## Step 3: Start the Ray Serve Application\n",
    "\n",
    "First, let's run the complete example to see it in action. We have the server code written in `server.py`, where we have mentioned our app with producer and consumer deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK24ZGxXgpy4"
   },
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from server import app\n",
    "\n",
    "serve.run(\n",
    "    target=app,\n",
    "    blocking=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Server Code\n",
    "\n",
    "Now let's break down the key components of `server.py` that make asynchronous inference work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Configure the Task Adapter\n",
    "\n",
    "First, we configure the Celery adapter to connect to Redis:\n",
    "\n",
    "```python\n",
    "from ray.serve.asynchronous_inference.celery import CeleryAdapterConfig\n",
    "from ray.serve.asynchronous_inference import TaskProcessorConfig\n",
    "\n",
    "TASK_PROCESSOR_CONFIG = TaskProcessorConfig(\n",
    "    queue_name=\"pdf_processing_queue\",\n",
    "    adapter_config=CeleryAdapterConfig(\n",
    "        broker_url=\"redis://127.0.0.1:6399/0\",\n",
    "        backend_url=\"redis://127.0.0.1:6399/0\",\n",
    "    ),\n",
    "    max_retries=3,\n",
    "    failed_task_queue_name=\"failed_pdfs\",\n",
    "    unprocessable_task_queue_name=\"invalid_pdfs\",\n",
    ")\n",
    "```\n",
    "\n",
    "This tells Ray Serve where to send tasks (broker) and store results (backend)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create the Task Consumer Deployment\n",
    "\n",
    "The `PDFProcessor` deployment processes PDF tasks from the queue:\n",
    "\n",
    "```python\n",
    "@serve.deployment(num_replicas=2, max_ongoing_requests=5)\n",
    "@task_consumer(\n",
    "    TaskProcessorConfig(\n",
    "        queue_name=\"pdf_processing_queue\",\n",
    "        adapter_config=adapter_config,\n",
    "        max_retries=3,\n",
    "    )\n",
    ")\n",
    "class PDFProcessor:\n",
    "    @task_handler(name=\"process_pdf\")\n",
    "    def process_pdf(self, pdf_url: str, max_summary_paragraphs: int = 3):\n",
    "        # Download and process PDF\n",
    "        response = requests.get(pdf_url)\n",
    "        pdf_reader = PdfReader(BytesIO(response.content))\n",
    "        \n",
    "        # Extract text from all pages\n",
    "        full_text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            full_text += page.extract_text()\n",
    "        \n",
    "        # Generate summary (first N paragraphs)\n",
    "        paragraphs = [p.strip() for p in full_text.split(\"\\n\\n\") if p.strip()]\n",
    "        summary = \"\\n\\n\".join(paragraphs[:max_summary_paragraphs])\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"page_count\": len(pdf_reader.pages),\n",
    "            \"word_count\": len(full_text.split()),\n",
    "            \"summary\": summary,\n",
    "            \"processing_time_seconds\": time.time() - start_time,\n",
    "        }\n",
    "```\n",
    "\n",
    "Key points:\n",
    "- `num_replicas=2` scales to 2 worker instances for parallel processing\n",
    "- `@task_consumer` decorator makes this deployment consume tasks from the queue\n",
    "- `@task_handler` decorator registers the `process_pdf` method as a task handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the API Ingress Deployment\n",
    "\n",
    "The `AsyncPDFAPI` deployment handles HTTP requests and enqueues tasks:\n",
    "\n",
    "```python\n",
    "@serve.deployment\n",
    "class AsyncPDFAPI:\n",
    "    def __init__(self, pdf_processor_handle):\n",
    "        self.pdf_processor_handle = pdf_processor_handle\n",
    "        self.adapter = CeleryAdapter(adapter_config)\n",
    "    \n",
    "    @serve.route(\"/process\", methods=[\"POST\"])\n",
    "    async def process_pdf(self, request: Request):\n",
    "        data = await request.json()\n",
    "        \n",
    "        # Enqueue task and immediately return task ID\n",
    "        task_id = await self.adapter.enqueue_task(\n",
    "            task_name=\"process_pdf\",\n",
    "            kwargs={\n",
    "                \"pdf_url\": data[\"pdf_url\"],\n",
    "                \"max_summary_paragraphs\": data.get(\"max_summary_paragraphs\", 3),\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        return {\"task_id\": task_id.dict(), \"status\": \"PENDING\"}\n",
    "    \n",
    "    @serve.route(\"/status/{task_id}\", methods=[\"GET\"])\n",
    "    async def get_status(self, task_id: str):\n",
    "        # Check task status in Redis\n",
    "        status = await self.adapter.get_task_status(TaskID(id=task_id))\n",
    "        \n",
    "        response = {\n",
    "            \"task_id\": task_id,\n",
    "            \"status\": status.state.value,\n",
    "        }\n",
    "        \n",
    "        if status.state == TaskState.SUCCESS:\n",
    "            response[\"result\"] = status.result\n",
    "        elif status.state == TaskState.FAILURE:\n",
    "            response[\"error\"] = str(status.result)\n",
    "        \n",
    "        return response\n",
    "```\n",
    "\n",
    "Key points:\n",
    "- `/process` endpoint enqueues tasks and returns immediately with a task ID\n",
    "- `/status/{task_id}` endpoint polls Redis to check task status\n",
    "- No blocking - responses are instant regardless of processing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Bind Deployments into an Application\n",
    "\n",
    "Finally, we wire everything together:\n",
    "\n",
    "```python\n",
    "pdf_processor = PDFProcessor.bind()\n",
    "\n",
    "app = AsyncPDFAPI.bind(pdf_processor)\n",
    "```\n",
    "\n",
    "The `pdf_processor` handle is passed to the API so it knows which deployment's queue to enqueue tasks to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sptelPO5PYjg"
   },
   "source": [
    "## Step 4: Test the Service\n",
    "\n",
    "Now we will execute the `client.py`, which basically calls our above-created ray serve application to process the PDF, and then poll those task ids for the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dIIQ6j0gPYjg",
    "outputId": "a9bd6435-51d3-4e4f-8044-227e2606ace1"
   },
   "outputs": [],
   "source": [
    "# Run the client to test the async PDF processing service\n",
    "!python client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HqX42FQPYjg"
   },
   "source": [
    "### Understanding the Client Code\n",
    "\n",
    "Now let's break down how the async workflow works. We'll use the client methods interactively:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import time\n",
    "\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pInTwMZzPYjg"
   },
   "source": [
    "#### 1. Submit a PDF Processing Task\n",
    "\n",
    "Submit returns immediately with a task ID, without waiting for processing:\n",
    "\n",
    "```python\n",
    "pdf_url = \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\"\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/process\",\n",
    "    json={\n",
    "        \"pdf_url\": pdf_url,\n",
    "        \"max_summary_paragraphs\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "task_data = response.json()\n",
    "task_id = task_data[\"task_id\"][\"id\"]\n",
    "\n",
    "print(f\"✓ Task submitted!\")\n",
    "print(f\"  Task ID: {task_id}\")\n",
    "print(f\"  Status: {task_data['status']}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5PWUvDmPYjg"
   },
   "source": [
    "#### 2. Poll for Task Status\n",
    "\n",
    "Check the task status to see if it's complete:\n",
    "\n",
    "```python\n",
    "# Check status (may need to run this cell multiple times)\n",
    "response = requests.get(f\"{BASE_URL}/status/{task_id}\")\n",
    "status_data = response.json()\n",
    "\n",
    "print(f\"Task status: {status_data['status']}\")\n",
    "\n",
    "if status_data['status'] == 'SUCCESS':\n",
    "    result = status_data['result']\n",
    "    print(f\"\\n✓ Complete!\")\n",
    "    print(f\"  Pages: {result['page_count']}\")\n",
    "    print(f\"  Words: {result['word_count']}\")\n",
    "    print(f\"  Time: {result['processing_time_seconds']}s\")\n",
    "elif status_data['status'] == 'FAILURE':\n",
    "    print(f\"\\n✗ Failed: {status_data.get('error')}\")\n",
    "else:\n",
    "    print(f\"  Still processing... (Status: {status_data['status']})\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylP1We1sPYjh"
   },
   "source": [
    "#### 3. Wait for Completion\n",
    "\n",
    "Or use a polling loop to automatically wait:\n",
    "\n",
    "```python\n",
    "# Submit a new task and wait for completion\n",
    "pdf_url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/process\",\n",
    "    json={\"pdf_url\": pdf_url, \"max_summary_paragraphs\": 3}\n",
    ")\n",
    "\n",
    "task_id = response.json()[\"task_id\"][\"id\"]\n",
    "print(f\"Task submitted: {task_id}\\n\")\n",
    "\n",
    "# Poll until complete\n",
    "max_attempts = 40\n",
    "for attempt in range(max_attempts):\n",
    "    response = requests.get(f\"{BASE_URL}/status/{task_id}\")\n",
    "    status_data = response.json()\n",
    "    \n",
    "    if status_data['status'] == 'SUCCESS':\n",
    "        result = status_data['result']\n",
    "        print(f\"\\n✓ Complete!\")\n",
    "        print(f\"  Pages: {result['page_count']}\")\n",
    "        print(f\"  Words: {result['word_count']}\")\n",
    "        print(f\"  Time: {result['processing_time_seconds']}s\")\n",
    "        print(f\"\\n  Summary preview:\")\n",
    "        print(f\"  {result['summary'][:200]}...\")\n",
    "        break\n",
    "    elif status_data['status'] == 'FAILURE':\n",
    "        print(f\"✗ Failed: {status_data.get('error')}\")\n",
    "        break\n",
    "    elif attempt % 5 == 0:\n",
    "        print(f\"  Still processing... ({status_data['status']})\")\n",
    "    \n",
    "    time.sleep(3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXwBYDRWPYjh"
   },
   "source": [
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────┐\n",
    "│   Client    │\n",
    "└──────┬──────┘\n",
    "       │ HTTP POST /process\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   AsyncPDFAPI       │ ← Ingress Deployment\n",
    "│ (HTTP Endpoints)    │\n",
    "└──────┬──────────────┘\n",
    "       │ enqueue_task()\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   Redis Queue       │ ← Message Broker\n",
    "│ (Celery Backend)    │\n",
    "└──────┬──────────────┘\n",
    "       │ consume tasks\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   PDFProcessor      │ ← Task Consumer Deployment\n",
    "│ @task_consumer      │   (Scaled to N replicas)\n",
    "│ - process_pdf       │\n",
    "└─────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdEBU0WHPYjh"
   },
   "source": [
    "## Key Concepts\n",
    "\n",
    "### Task Consumer\n",
    "\n",
    "The `@task_consumer` decorator transforms a Ray Serve deployment into a Celery worker that processes tasks from a queue:\n",
    "\n",
    "```python\n",
    "@serve.deployment(num_replicas=2, max_ongoing_requests=5)\n",
    "@task_consumer(\n",
    "    TaskProcessorConfig(\n",
    "        queue_name=\"pdf_processing_queue\",\n",
    "        adapter_config=CeleryAdapterConfig(...),\n",
    "        max_retries=3,\n",
    "    )\n",
    ")\n",
    "class PDFProcessor:\n",
    "    ...\n",
    "```\n",
    "\n",
    "### Task Handler\n",
    "\n",
    "The `@task_handler` decorator marks a method that processes a specific task type:\n",
    "\n",
    "```python\n",
    "@task_handler(name=\"process_pdf\")\n",
    "def process_pdf(self, pdf_url: str, max_summary_paragraphs: int = 3):\n",
    "    # Download PDF, extract text, generate summary\n",
    "    return {\"status\": \"success\", ...}\n",
    "```\n",
    "\n",
    "### Task Adapter\n",
    "\n",
    "The adapter provides methods to interact with the task queue:\n",
    "\n",
    "```python\n",
    "# Enqueue a task\n",
    "task_id = adapter.enqueue_task_sync(\n",
    "    task_name=\"process_pdf\",\n",
    "    kwargs={\"pdf_url\": url}\n",
    ")\n",
    "\n",
    "# Check status\n",
    "status = adapter.get_task_status_sync(task_id)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toB6IzUzPYjh"
   },
   "source": [
    "## Deploy to Anyscale\n",
    "\n",
    "1. Update Redis configuration in `server.py` with your production Redis instance\n",
    "2. Deploy using the Anyscale CLI:\n",
    "\n",
    "```bash\n",
    "anyscale service deploy -f service.yaml\n",
    "```\n",
    "\n",
    "3. Get your service URL:\n",
    "\n",
    "```bash\n",
    "anyscale service status\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77GW0zVFPYjh"
   },
   "source": [
    "## Learn More\n",
    "\n",
    "- [Ray Serve Documentation](https://docs.ray.io/en/latest/serve/index.html)\n",
    "- [Asynchronous Inference Guide](https://docs.ray.io/en/master/serve/asynchronous-inference.html)\n",
    "- [Celery Documentation](https://docs.celeryq.dev/)\n",
    "- [Anyscale Platform](https://docs.anyscale.com/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
