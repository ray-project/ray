{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq-IHSrRPYjc"
   },
   "source": [
    "# Asynchronous Inference with Ray Serve\n",
    "\n",
    "**⏱️ Time to complete:** 30 minutes\n",
    "\n",
    "This template demonstrates how to build scalable asynchronous inference services using Ray Serve. Learn how to handle long-running PDF processing tasks without blocking HTTP responses, using Celery task queues and Redis as a message broker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBGu_yjLPYje"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Traditional synchronous APIs block until processing completes, causing timeouts for long-running tasks. Ray Serve's asynchronous inference pattern decouples request lifetime from compute time by:\n",
    "\n",
    "1. Accepting HTTP requests and immediately returning a task ID\n",
    "2. Enqueuing work to background processors (Celery workers)\n",
    "3. Allowing clients to poll for status and retrieve results\n",
    "\n",
    "This example implements a **PDF processing service** that extracts text and generates summaries from PDF documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXwBYDRWPYjh"
   },
   "source": [
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────┐\n",
    "│   Client    │\n",
    "└──────┬──────┘\n",
    "       │ HTTP POST /process\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   AsyncPDFAPI       │ ← Ingress Deployment\n",
    "│ (HTTP Endpoints)    │\n",
    "└──────┬──────────────┘\n",
    "       │ enqueue_task()\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   Redis Queue       │ ← Message Broker\n",
    "│ (Celery Backend)    │\n",
    "└──────┬──────────────┘\n",
    "       │ consume tasks\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   PDFProcessor      │ ← Task Consumer Deployment\n",
    "│ @task_consumer      │   (Scaled to N replicas)\n",
    "│ - process_pdf       │\n",
    "└─────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUj7ohuhPYje"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- Ray 2.50.0+\n",
    "- Redis (for message broker and result backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8O5Bk2gPYje"
   },
   "source": [
    "## Step 1: Setup Redis\n",
    "\n",
    "Redis serves as both the message broker (task queue) and result backend.\n",
    "\n",
    "**Install and start Redis (Google Colab compatible):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Zsr4HD0_PYje",
    "outputId": "3ecc8fe0-5a73-4793-8735-d2517d38c82d"
   },
   "outputs": [],
   "source": [
    "# Install and start Redis server\n",
    "!sudo apt-get update -qq\n",
    "!sudo apt-get install -y redis-server\n",
    "!redis-server --port 6399 --save \"\" --appendonly no --daemonize yes\n",
    "\n",
    "# Verify Redis is running\n",
    "!redis-cli -p 6399 ping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzPQjYzmPYjf"
   },
   "source": [
    "**Alternative methods:**\n",
    "\n",
    "- **macOS:** `brew install redis && brew services start redis`\n",
    "- **Docker:** `docker run -d -p 6379:6379 redis:latest`\n",
    "- **Other platforms:** [Official Redis Installation Guide](https://redis.io/docs/getting-started/installation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```note\n",
    "If you're using a hosted Redis instance, ensure that your Ray Serve cluster can access it. For example, when using AWS ElastiCache for Redis:\n",
    "\n",
    "- Launch the ElastiCache instance in the same VPC that's attached to your Anyscale cloud.\n",
    "- Attach IAM roles with read/write access to ElastiCache to your cluster instances.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ6ahzMPPYjf"
   },
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KQe0ROXPYjf"
   },
   "outputs": [],
   "source": [
    "!pip install -q ray[serve-async-inference]>=2.50.0 requests>=2.31.0 PyPDF2>=3.0.0 celery[redis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqLdlKIhPYjf"
   },
   "source": [
    "## Step 3: Start the Ray Serve Application\n",
    "\n",
    "Let's see and run the code for the service. We will go through each component independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Ingress Deployment to Handle HTTP Requests\n",
    "\n",
    "The `AsyncPDFAPI` deployment handles HTTP requests and enqueues tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel, HttpUrl\n",
    "from ray import serve\n",
    "from ray.serve.handle import DeploymentHandle\n",
    "from ray.serve.schema import TaskProcessorConfig\n",
    "from ray.serve.task_consumer import instantiate_adapter_from_config\n",
    "\n",
    "fastapi_app = FastAPI(title=\"Async PDF Processing API\")\n",
    "logger = logging.getLogger(\"ray.serve\")\n",
    "\n",
    "@serve.deployment(ray_actor_options={\"num_cpus\": 0.1})\n",
    "@serve.ingress(fastapi_app)\n",
    "class AsyncPDFAPI:\n",
    "    \"\"\"\n",
    "    HTTP API for submitting and checking PDF processing tasks.\n",
    "\n",
    "    Endpoints:\n",
    "    - POST /process: Submit a PDF processing task\n",
    "    - GET /status/{task_id}: Check task status and get results\n",
    "    \"\"\"\n",
    "\n",
    "    class ProcessPDFRequest(BaseModel):\n",
    "        \"\"\"Request schema for PDF processing.\"\"\"\n",
    "        pdf_url: HttpUrl\n",
    "        max_summary_paragraphs: int = 3\n",
    "\n",
    "    def __init__(self, task_processor_config: TaskProcessorConfig, handler: DeploymentHandle):\n",
    "        \"\"\"Initialize the API with task adapter.\"\"\"\n",
    "        self.adapter = instantiate_adapter_from_config(task_processor_config)\n",
    "        logger.info(\"AsyncPDFAPI initialized\")\n",
    "\n",
    "    @fastapi_app.post(\"/process\")\n",
    "    async def process_pdf(self, request: ProcessPDFRequest):\n",
    "        \"\"\"\n",
    "        Submit a PDF processing task.\n",
    "\n",
    "        Returns task_id immediately without waiting for processing to complete.\n",
    "        Client should poll /status/{task_id} to check progress.\n",
    "        \"\"\"\n",
    "        task_result = self.adapter.enqueue_task_sync(\n",
    "            task_name=\"process_pdf\",\n",
    "            kwargs={\n",
    "                \"pdf_url\": str(request.pdf_url),\n",
    "                \"max_summary_paragraphs\": request.max_summary_paragraphs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Enqueued task: {task_result}\")\n",
    "\n",
    "        return {\n",
    "            \"task_id\": task_result.id,\n",
    "            \"status\": task_result.status,\n",
    "            \"message\": \"PDF processing task submitted successfully\",\n",
    "        }\n",
    "\n",
    "    @fastapi_app.get(\"/status/{task_id}\")\n",
    "    async def get_status(self, task_id: str):\n",
    "        \"\"\"\n",
    "        Get task status and results.\n",
    "\n",
    "        Status values:\n",
    "        - PENDING: Task queued, waiting for worker\n",
    "        - STARTED: Worker is processing the task\n",
    "        - SUCCESS: Task completed successfully (result available)\n",
    "        - FAILURE: Task failed (error message available)\n",
    "        \"\"\"\n",
    "        status = self.adapter.get_task_status_sync(task_id)\n",
    "\n",
    "        return {\n",
    "            \"task_id\": task_id,\n",
    "            \"status\": status.status,\n",
    "            \"result\": status.result if status.status == \"SUCCESS\" else None,\n",
    "            \"error\": str(status.result) if status.status == \"FAILURE\" else None,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key points:**\n",
    "\n",
    "- `/process` endpoint enqueues tasks and returns immediately with a task ID\n",
    "- `/status/{task_id}` endpoint polls Redis to check task status\n",
    "- No blocking - responses are instant regardless of processing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create the Task Consumer Deployment\n",
    "\n",
    "Now, below is the deployment consumer code, which will read from the task queue and implement the tasks.\n",
    "\n",
    "**What's a Task Consumer?**\n",
    "\n",
    "The `@task_consumer` decorator transforms a Ray Serve deployment into a worker that consumes tasks from a queue.\n",
    "\n",
    "**What's a Task Handler?**\n",
    "\n",
    "The `@task_handler` decorator registers a method to process a specific task type. Each handler corresponds to a task name that producers use when enqueuing work.\n",
    "\n",
    "For more details, see the [Asynchronous Inference Guide](https://docs.ray.io/en/master/serve/asynchronous-inference.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from ray import serve\n",
    "from ray.serve.schema import CeleryAdapterConfig, TaskProcessorConfig\n",
    "from ray.serve.task_consumer import (\n",
    "    task_consumer,\n",
    "    task_handler,\n",
    ")\n",
    "\n",
    "TASK_PROCESSOR_CONFIG = TaskProcessorConfig(\n",
    "    queue_name=\"pdf_processing_queue\",\n",
    "    adapter_config=CeleryAdapterConfig(\n",
    "        broker_url=\"redis://127.0.0.1:6399/0\",\n",
    "        backend_url=\"redis://127.0.0.1:6399/0\",\n",
    "    ),\n",
    "    max_retries=3,\n",
    "    failed_task_queue_name=\"failed_pdfs\",\n",
    "    unprocessable_task_queue_name=\"invalid_pdfs\",\n",
    ")\n",
    "\n",
    "@serve.deployment(num_replicas=2, max_ongoing_requests=5, ray_actor_options={\"num_cpus\": 0.1})\n",
    "@task_consumer(task_processor_config=TASK_PROCESSOR_CONFIG)\n",
    "class PDFProcessor:\n",
    "    \"\"\"\n",
    "    Background worker that processes PDF documents asynchronously.\n",
    "\n",
    "    Configuration:\n",
    "    - num_replicas=2: Run 2 worker instances\n",
    "    - max_ongoing_requests=5: Each worker handles up to 5 concurrent tasks\n",
    "    - max_retries=3: Retry failed tasks up to 3 times\n",
    "    \"\"\"\n",
    "\n",
    "    @task_handler(name=\"process_pdf\")\n",
    "    def process_pdf(\n",
    "        self, pdf_url: str, max_summary_paragraphs: int = 3\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Download PDF, extract text, and generate summary.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Processing PDF: {pdf_url}\")\n",
    "\n",
    "        try:\n",
    "            # Download PDF from URL\n",
    "            response = requests.get(pdf_url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Parse PDF content\n",
    "            pdf_file = io.BytesIO(response.content)\n",
    "            try:\n",
    "                pdf_reader = PdfReader(pdf_file)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Invalid PDF file: {str(e)}\")\n",
    "\n",
    "            if len(pdf_reader.pages) == 0:\n",
    "                raise ValueError(\"PDF contains no pages\")\n",
    "\n",
    "            # Extract text from all pages\n",
    "            full_text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    full_text += text + \"\\n\"\n",
    "\n",
    "            if not full_text.strip():\n",
    "                raise ValueError(\"PDF contains no extractable text\")\n",
    "\n",
    "            # Generate summary (first N paragraphs)\n",
    "            paragraphs = [p.strip() for p in full_text.split(\"\\n\\n\") if p.strip()]\n",
    "            summary = \"\\n\\n\".join(paragraphs[:max_summary_paragraphs])\n",
    "\n",
    "            # Calculate metadata\n",
    "            result = {\n",
    "                \"status\": \"success\",\n",
    "                \"pdf_url\": pdf_url,\n",
    "                \"page_count\": len(pdf_reader.pages),\n",
    "                \"word_count\": len(full_text.split()),\n",
    "                \"full_text\": full_text,\n",
    "                \"summary\": summary,\n",
    "                \"processing_time_seconds\": round(time.time() - start_time, 2),\n",
    "            }\n",
    "\n",
    "            logger.info(f\"Processed PDF: {result['page_count']} pages, {result['word_count']} words\")\n",
    "            return result\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_msg = f\"Failed to download PDF: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Failed to process PDF: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key points:**\n",
    "\n",
    "- `num_replicas=2` scales to 2 worker instances for parallel processing\n",
    "- The consumer automatically polls the queue and processes tasks\n",
    "- Failed tasks retry up to `max_retries` times before moving to the dead letter queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Bind Deployments into an Application\n",
    "\n",
    "Now, we will combine the deployments and run the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK24ZGxXgpy4"
   },
   "outputs": [],
   "source": [
    "consumer = PDFProcessor.bind()\n",
    "\n",
    "app = AsyncPDFAPI.bind(task_processor_config=TASK_PROCESSOR_CONFIG, handler=consumer)\n",
    "\n",
    "serve.run(\n",
    "    target=app,\n",
    "    blocking=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sptelPO5PYjg"
   },
   "source": [
    "## Step 4: Test the service\n",
    "\n",
    "Let's execute the client code, which calls the Ray Serve application to process PDFs and then polls for results using task IDs. First, define the base URL to query and import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, Any\n",
    "\n",
    "import requests\n",
    "\n",
    "# Base URL of your Ray Serve/FastAPI app\n",
    "BASE_URL = \"http://localhost:8000\".rstrip(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit two tasks. The application returns a `task_id` for each request that you can use to poll for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_url: str, max_summary_paragraphs: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Submit a PDF processing task and return the task_id.\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/process\",\n",
    "        json={\n",
    "            \"pdf_url\": pdf_url,\n",
    "            \"max_summary_paragraphs\": max_summary_paragraphs,\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data[\"task_id\"]\n",
    "\n",
    "\n",
    "pdf_urls = [\n",
    "    \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\",\n",
    "    \"https://arxiv.org/pdf/1706.03762.pdf\",\n",
    "]\n",
    "\n",
    "task_ids = []\n",
    "\n",
    "for i, url in enumerate(pdf_urls, 1):\n",
    "        task_id = process_pdf(url)\n",
    "        task_ids.append((task_id, url))\n",
    "        print(f\"   ✓ Task {i} submitted: {task_id}  ({url})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, poll the Ray Serve application using the `task_id` obtained in the previous step to retrieve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_status(task_id: str) -> Dict[str, Any]:\n",
    "    response = requests.get(f\"{BASE_URL}/status/{task_id}\")\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def wait_for_task_completion(task_id: str, timeout: int = 120, poll_interval: float = 2.0) -> Dict[str, Any]:\n",
    "    \"\"\"Poll for task completion with timeout.\"\"\"\n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        result = get_task_status(task_id)\n",
    "        status = result.get(\"status\")\n",
    "        if status in (\"SUCCESS\", \"FAILURE\"):\n",
    "            return result\n",
    "        print(f\"   ⏳ Status: {status}, waiting...\")\n",
    "        time.sleep(poll_interval)\n",
    "    raise TimeoutError(f\"Task {task_id} did not complete within {timeout} seconds\")\n",
    "\n",
    "for i, (task_id, url) in enumerate(task_ids, 1):\n",
    "        print(f\"\\nTask {i} ({url.split('/')[-1]}):\")\n",
    "        result = wait_for_task_completion(task_id)\n",
    "        res = result.get(\"result\")\n",
    "        if res:\n",
    "            print(f\"   ✓ Complete: {res.get('page_count')} pages, {res.get('word_count')} words\")\n",
    "            print(f\"   ✓ Processing time: {res.get('processing_time_seconds')}s\")\n",
    "        else:\n",
    "            error = result.get(\"error\")\n",
    "            print(f\"   ✗ Task failed: {error}\" if error else \"   ✗ No result payload found in response.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toB6IzUzPYjh"
   },
   "source": [
    "## Deploy to Anyscale\n",
    "\n",
    "To deploy this application to production on Anyscale:\n",
    "\n",
    "1. Update Redis configuration in your server code with your production Redis instance\n",
    "2. Deploy using the Anyscale CLI:\n",
    "\n",
    "   ```bash\n",
    "   anyscale service deploy -f service.yaml\n",
    "   ```\n",
    "\n",
    "3. Get your service URL:\n",
    "\n",
    "   ```bash\n",
    "   anyscale service status\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77GW0zVFPYjh"
   },
   "source": [
    "## Learn More\n",
    "\n",
    "- [Ray Serve Documentation](https://docs.ray.io/en/latest/serve/index.html)\n",
    "- [Asynchronous Inference Guide](https://docs.ray.io/en/master/serve/asynchronous-inference.html)\n",
    "- [Celery Documentation](https://docs.celeryq.dev/)\n",
    "- [Anyscale Platform](https://docs.anyscale.com/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
