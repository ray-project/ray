# 1 g5.16xlarge + 15 g5.4xlarge --> 16 GPUs, 256G RAM on trainer and 64G RAM on workers
head_node_type:
  name: head_node_type
  instance_type: g5.16xlarge
  resources:
    large_cpu_mem: 1

worker_node_types:
- name: gpu_worker
  instance_type: g5.4xlarge
  min_workers: 15
  max_workers: 15
  use_spot: false
  resources:
    medium_cpu_mem: 1
