{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98e0d4f3",
   "metadata": {},
   "source": [
    "# Scaling Many Model Training with Ray Tune\n",
    "\n",
    "This template is a quickstart to using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) for batch inference. Ray Tune is one of many libraries under the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html). See [this blog post](https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray) for more information on the benefits of performing many model training with Ray!\n",
    "\n",
    "This template walks through time-series forecasting using `statsforecast`, but the framework and data format can be swapped out easily -- they are there just to help you build your own application!\n",
    "\n",
    "At a high level, this template will:\n",
    "\n",
    "1. [Define the training function for a single partition of data.](https://docs.ray.io/en/latest/tune/tutorials/tune-run.html)\n",
    "2. [Define a Tune search space to run training over many partitions of data.](https://docs.ray.io/en/latest/tune/tutorials/tune-search-spaces.html)\n",
    "3. [Extract the best model per dataset partition from the Tune experiment output.](https://docs.ray.io/en/latest/tune/examples/tune_analyze_results.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56bb4d0",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "First, we'll need to install necessary dependencies in the Anyscale Workspace. To do so, first open up a terminal, and follow one of the following install steps, depending on which size template you picked:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99c151",
   "metadata": {
    "tags": [
     "small"
    ]
   },
   "source": [
    "### Install Dependencies (Small-scale Template)\n",
    "\n",
    "The small-scale template only runs on a single node (the head node), so we just need to install the requirements *locally*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6fc93",
   "metadata": {
    "tags": [
     "small"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee8e43",
   "metadata": {
    "tags": [
     "large"
    ]
   },
   "source": [
    "### Install Cluster-wide Dependencies (Large-scale Template)\n",
    "\n",
    "When running in a distributed Ray Cluster, all nodes need to have access to the installed packages.\n",
    "For this, we'll use `pip install --user` to install the necessary requirements.\n",
    "On an [Anyscale Workspace](https://docs.anyscale.com/user-guide/develop-and-debug/workspaces),\n",
    "this will install packages to a *shared filesystem* that will be available to all nodes in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b3dec",
   "metadata": {
    "tags": [
     "large"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install --user -r requirements.txt --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e65f8d",
   "metadata": {},
   "source": [
    "> Slot in your code below wherever you see the ✂️ icon to build a many model training Ray application off of this template!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389adc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyarrow import parquet as pq\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "\n",
    "try:\n",
    "    from statsforecast import StatsForecast\n",
    "    from statsforecast.models import AutoARIMA, AutoETS\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(\"Did you follow the steps above to install dependencies?\") from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc83d0",
   "metadata": {},
   "source": [
    "> ✂️ Replace this value to change the number of data partitions you will use. This will be total the number of Tune trials you will run!\n",
    ">\n",
    "> Note that this template fits two models per data partition and reports the best performing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e91a5",
   "metadata": {
    "tags": [
     "small"
    ]
   },
   "outputs": [],
   "source": [
    "# Default values for the small-scale template\n",
    "NUM_DATA_PARTITIONS: int = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390c232",
   "metadata": {
    "tags": [
     "large"
    ]
   },
   "outputs": [],
   "source": [
    "# Default values for the large-scale template\n",
    "NUM_DATA_PARTITIONS: int = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c260d8f8",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "If you're running the small-scale version of the template, try setting\n",
    "the number of trials to the recommended number of trials for the large-scale version.\n",
    "It'll be much slower, but you'll see the dramatic speedup once distributing the load\n",
    "to a multi-node Ray cluster in the large-scale version!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f3d16",
   "metadata": {},
   "source": [
    "> ✂️ Replace the following with your own data-loading and evaluation helper functions. (Or, just delete these!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b14061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m5_partition(unique_id: str) -> pd.DataFrame:\n",
    "    df = (\n",
    "        pq.read_table(\n",
    "            \"s3://anonymous@m5-benchmarks/data/train/target.parquet\",\n",
    "            columns=[\"item_id\", \"timestamp\", \"demand\"],\n",
    "            filters=[(\"item_id\", \"=\", unique_id)],\n",
    "        )\n",
    "        .to_pandas()\n",
    "        .rename(columns={\"item_id\": \"unique_id\", \"timestamp\": \"ds\", \"demand\": \"y\"})\n",
    "    )\n",
    "    df[\"unique_id\"] = df[\"unique_id\"].astype(str)\n",
    "    df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def evaluate_cross_validation(df, metric):\n",
    "    models = df.drop(columns=[\"ds\", \"cutoff\", \"y\"]).columns.tolist()\n",
    "    evals = []\n",
    "    for model in models:\n",
    "        eval_ = (\n",
    "            df.groupby([\"unique_id\", \"cutoff\"])\n",
    "            .apply(lambda x: metric(x[\"y\"].values, x[model].values))\n",
    "            .to_frame()\n",
    "        )\n",
    "        eval_.columns = [model]\n",
    "        evals.append(eval_)\n",
    "    evals = pd.concat(evals, axis=1)\n",
    "    evals = evals.groupby([\"unique_id\"]).mean(numeric_only=True)\n",
    "    evals[\"best_model\"] = evals.idxmin(axis=1)\n",
    "    return evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ee3ce",
   "metadata": {},
   "source": [
    "> ✂️ Replace this with your own training logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = [AutoARIMA, AutoETS]\n",
    "n_windows = 1\n",
    "\n",
    "\n",
    "def train_fn(config: dict):\n",
    "    data_partition_id = config[\"data_partition_id\"]\n",
    "    train_df = get_m5_partition(data_partition_id)\n",
    "\n",
    "    models = [model_cls() for model_cls in model_classes]\n",
    "    forecast_horizon = 4\n",
    "\n",
    "    sf = StatsForecast(\n",
    "        df=train_df,\n",
    "        models=models,\n",
    "        freq=\"D\",\n",
    "        n_jobs=n_windows * len(models),\n",
    "    )\n",
    "    cv_df = sf.cross_validation(\n",
    "        h=forecast_horizon,\n",
    "        step_size=forecast_horizon,\n",
    "        n_windows=n_windows,\n",
    "    )\n",
    "\n",
    "    eval_df = evaluate_cross_validation(df=cv_df, metric=mean_squared_error)\n",
    "    best_model = eval_df[\"best_model\"][data_partition_id]\n",
    "    forecast_mse = eval_df[best_model][data_partition_id]\n",
    "\n",
    "    # Report the best-performing model and its corresponding eval metric.\n",
    "    session.report({\"forecast_mse\": forecast_mse, \"best_model\": best_model})\n",
    "\n",
    "\n",
    "trainable = train_fn\n",
    "trainable = tune.with_resources(\n",
    "    trainable, resources={\"CPU\": len(model_classes) * n_windows}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c7c58",
   "metadata": {},
   "source": [
    "```{note}\n",
    "`tune.with_resources` is used at the end to specify the number of resources to assign *each trial*.\n",
    "Feel free to change this to the resources required by your application! You can also comment out the `tune.with_resources` block to assign `1 CPU` (the default) to each trial.\n",
    "\n",
    "Note that this is purely for Tune to know how many trials to schedule concurrently -- setting the number of CPUs does not actually enforce any kind of resource isolation!\n",
    "```\n",
    "\n",
    "See [Ray Tune's guide on assigning resources](https://docs.ray.io/en/latest/tune/tutorials/tune-resources.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89741e7a",
   "metadata": {},
   "source": [
    "> ✂️ Replace this with your desired hyperparameter search space!\n",
    ">\n",
    "> For example, this template searches over the data partition ID to train a model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partitions = list(pd.read_csv(\"item_ids.csv\")[\"item_id\"])\n",
    "if NUM_DATA_PARTITIONS > len(data_partitions):\n",
    "    print(f\"There are only {len(data_partitions)} partitions!\")\n",
    "\n",
    "param_space = {\n",
    "    \"data_partition_id\": tune.grid_search(data_partitions[:NUM_DATA_PARTITIONS]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4dd3e",
   "metadata": {},
   "source": [
    "Run many model training using Ray Tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = tune.Tuner(trainable, param_space=param_space)\n",
    "result_grid = tuner.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a07d0",
   "metadata": {},
   "source": [
    "> ✂️ Replace the metric and mode below with the metric you reported in your training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7baa29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_result = result_grid[0]\n",
    "sample_result.metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "265d195fda5292fe8f69c6e37c435a5634a1ed3b6799724e66a975f68fa21517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
