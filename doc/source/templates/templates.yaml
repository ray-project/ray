# Update anyscale/backend/workspace-template.yaml
# <unique-template-id>:
#   emoji: ðŸ“Š
#   title: Batch Inference
#   description: Description
#   path: Relative path to the template directory, from the Ray root directory
#   labels:
#     - ...
#   cluster_env:
#   ## Some sample `build_id`'s to choose from:
#   ## - anyscaleray-ml240-py39-gpu -> anyscale/ray-ml:2.4.0-py39-gpu
#   ## - anyscale240-py39 -> anyscale/ray:2.4.0-py39
#     build_id: anyscaleray-ml240-py39-gpu
#   ## OR, use a publicly hosted image
#   # byod:
#   #   docker_image: url of docker image
#   #   ray_version: 2.4.0
#   ## Make sure these compute configs don't contain region/cloud ID
#   compute_config:
#     GCP: doc/source/templates/configs/compute/gpu/gce.yaml
#     AWS: doc/source/templates/configs/compute/gpu/aws.yaml
batch-inference-ray-data:
  emoji: ðŸ“Š
  title: Batch Inference
  description: Parallelize batch inference of a dataset on a distributed Ray cluster with the Ray Data library. This template runs GPU batch inference on an image dataset using a PyTorch model.
  path: doc/source/templates/01_batch_inference
  labels:
    - Ray Data
  cluster_env:
    build_id: anyscaleray-ml240-py39-gpu
  compute_config:
    GCP: doc/source/templates/configs/compute/gpu/gce.yaml
    AWS: doc/source/templates/configs/compute/gpu/aws.yaml
many-model-training-ray-tune:
  emoji: âš¡
  title: Many Model Training
  description: Train thousands of models in parallel on a distributed Ray cluster using the Ray Tune library. This template trains multiple forecasting models for different partitions of a time-series dataset and selects the best-performing model for each partition.
  path: doc/source/templates/02_many_model_training
  labels:
    - Ray Tune
  cluster_env:
    build_id: anyscaleray-ml240-py39-gpu
  compute_config:
    GCP: doc/source/templates/configs/compute/cpu/gce.yaml
    AWS: doc/source/templates/configs/compute/cpu/aws.yaml
serve-stable-diffusion-model-ray-serve:
  emoji: ðŸ“¡
  title: Serving a Stable Diffusion Model
  description: Deploy a stable diffusion model using the Ray Serve library and showcase its capabilities by generating images from text prompts! This template loads a pre-trained stable diffusion model from HuggingFace and serves it to a local endpoint.
  path: doc/source/templates/03_serving_stable_diffusion
  labels:
    - Ray Serve
  cluster_env:
    byod:
      docker_image: us-docker.pkg.dev/anyscale-workspace-templates/workspace-templates/serve-stable-diffusion-model-ray-serve:2.4.0
      ray_version: 2.4.0
  compute_config:
    GCP: doc/source/templates/configs/compute/gpu/gce.yaml
    AWS: doc/source/templates/configs/compute/gpu/aws.yaml