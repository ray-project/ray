{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fbc3e3c",
   "metadata": {},
   "source": [
    "# Scaling Batch Inference with Ray Data\n",
    "\n",
    "| Template Specification | Description |\n",
    "| ---------------------- | ----------- |\n",
    "| Summary | This template walks through GPU batch inference on an image dataset using a PyTorch ResNet model. |\n",
    "| Time to Run | Less than 2 minutes to compute predictions on the dataset. |\n",
    "| Minimum Compute Requirements | No hard requirements. The default is 4 nodes, each with 1 NVIDIA T4 GPU. |\n",
    "| Cluster Environment | This template uses the latest Anyscale-provided Ray ML image using Python 3.9: [`anyscale/ray-ml:2.4.0-py39-gpu`](https://docs.anyscale.com/reference/base-images/ray-240/py39#ray-ml-2-4-0-py39). If you want to change to a different cluster environment, make sure that it is based off of this image! |\n",
    "\n",
    "By the end, we will have classified > 3000 images using the pre-trained ResNet model and saved these predictions to a local directory.\n",
    "\n",
    "> Slot in your code below wherever you see the ✂️ icon to build off of this template!\n",
    ">\n",
    "> The framework and data format used in this template can be easily replaced to suit your own application!\n",
    "\n",
    "We'll start with some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from typing import Dict\n",
    "\n",
    "import ray\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0edfc6e2",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b6f2352",
   "metadata": {},
   "source": [
    "> ✂️ Replace this function with logic to load your own data with Ray Data.\n",
    ">\n",
    "> See [the Ray Data guide on creating datasets](https://docs.ray.io/en/latest/data/creating-datasets.html) to learn how to create a dataset based on the data type and how file storage format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ray_dataset():\n",
    "    from ray.data.datasource.partitioning import Partitioning\n",
    "\n",
    "    s3_uri = \"s3://anonymous@air-example-data-2/imagenette2/val/\"\n",
    "    partitioning = Partitioning(\"dir\", field_names=[\"class\"], base_dir=s3_uri)\n",
    "    ds = ray.data.read_images(\n",
    "        s3_uri, size=(256, 256), partitioning=partitioning, mode=\"RGB\"\n",
    "    )\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_ray_dataset()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f183c51",
   "metadata": {},
   "source": [
    "Let's inspect the first few images of our dataset. We'll use a pre-trained ResNet model\n",
    "to classify these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = [sample[\"image\"] for sample in ds.take(5)]\n",
    "\n",
    "_, axs = plt.subplots(1, 5, figsize=(10, 5))\n",
    "\n",
    "for i, image in enumerate(sample_images):\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis(\"off\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7671aa0",
   "metadata": {},
   "source": [
    "## Preprocess the dataset\n",
    "\n",
    "We may need to preprocess the dataset before passing it to the model.\n",
    "This just amounts to writing a function that performs the preprocessing logic, and then\n",
    "applying the function to the entire dataset with a call to `map_batches`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39d01e3c",
   "metadata": {},
   "source": [
    "> ✂️ Replace this function with your own data preprocessing logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652121bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "    import torch\n",
    "    from torchvision import transforms\n",
    "\n",
    "    def to_tensor(batch: np.ndarray) -> torch.Tensor:\n",
    "        tensor = torch.as_tensor(batch, dtype=torch.float)\n",
    "        # (B, H, W, C) -> (B, C, H, W)\n",
    "        tensor = tensor.permute(0, 3, 1, 2).contiguous()\n",
    "        # [0., 255.] -> [0., 1.]\n",
    "        tensor = tensor.div(255)\n",
    "        return tensor\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Lambda(to_tensor),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    return {\"image\": transform(batch[\"image\"]).numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map_batches(preprocess, batch_format=\"numpy\")\n",
    "\n",
    "print(\"Dataset schema:\\n\", ds.schema())\n",
    "print(\"Number of images:\", ds.count())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaa3653b",
   "metadata": {},
   "source": [
    "## Set up your model for inference\n",
    "\n",
    "Define a class that loads the model on initialization, and also performs inference with the loaded model whenever the class is called (by implementing `__call__`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad059e54",
   "metadata": {},
   "source": [
    "> ✂️ Replace parts of this callable class with your own model initialization and inference logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cac828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictCallable:\n",
    "    def __init__(self):\n",
    "        # <Replace this with your own model initialization>\n",
    "        import torch\n",
    "        from torchvision import models\n",
    "        from torchvision.models import ResNet152_Weights\n",
    "\n",
    "        self.model = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "        self.model.eval()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        # <Replace this with your own model inference logic>\n",
    "        import torch\n",
    "\n",
    "        input_data = torch.as_tensor(batch[\"image\"], device=self.device)\n",
    "        with torch.inference_mode():\n",
    "            pred = self.model(input_data)\n",
    "        return {\"predicted_class_index\": pred.argmax(dim=1).detach().cpu().numpy()}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d63f352",
   "metadata": {},
   "source": [
    "## Run batch inference\n",
    "\n",
    "We'll first configure the number of workers and the resource requirements of each worker.\n",
    "\n",
    "These defaults will assume that your cluster has 4 GPUs available.\n",
    "Be sure to stay within the resource constraints of your Ray Cluster if autoscaling is not enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49681f-baf0-4ed8-9740-5c4e38744311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS: int = 4\n",
    "USE_GPU: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419658c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_WORKERS > ray.available_resources()[\"GPU\"]:\n",
    "    print(\n",
    "        \"Your cluster does not currently have enough resources to run with these settings. \"\n",
    "        \"Consider decreasing the number of workers, decreasing the resources needed \"\n",
    "        \"per worker, or restarting the cluster with more GPU nodes.\"\n",
    "        \"Ignore this if your cluster auto-scales.\"\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d170d2b",
   "metadata": {},
   "source": [
    "You can check the available resources in your Ray Cluster with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89dff216",
   "metadata": {},
   "source": [
    "Now, use Ray Data to perform batch inference using `NUM_WORKERS` copies of the `PredictCallable` class you defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ds.map_batches(\n",
    "    PredictCallable,\n",
    "    batch_size=128,\n",
    "    compute=ray.data.ActorPoolStrategy(size=NUM_WORKERS),\n",
    "    num_gpus=1 if USE_GPU else 0,\n",
    "    batch_format=\"numpy\",\n",
    ")\n",
    "\n",
    "preds = predictions.materialize()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05c48946",
   "metadata": {},
   "source": [
    "## View the predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2565ba08",
   "metadata": {},
   "source": [
    "Show the first few predictions, which will show the predicted class labels of the images shown earlier! These first few predictions should show index 0, which maps to the class label `\"tench\"` (a type of fish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d606556",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.take(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90ec67e8",
   "metadata": {},
   "source": [
    "Shard the predictions into a few partitions, and save each partition to a file.\n",
    "\n",
    "This currently saves to the local filesystem under a temporary directory, but you could also save to a cloud bucket (e.g., `s3://predictions-bucket`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1887e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shards = 3\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# The `local://` prefix is need to make sure all results get written on the head node.\n",
    "predictions.repartition(num_shards).write_parquet(f\"local://{temp_dir}\")\n",
    "print(f\"Predictions saved to `{temp_dir}`!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b7b5d91",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This template used [Ray Data](https://docs.ray.io/en/latest/data/dataset.html) to scale out batch inference. Ray Data is one of many libraries under the [Ray AI Runtime](https://docs.ray.io/en/latest/ray-air/getting-started.html). See [this blog post](https://www.anyscale.com/blog/model-batch-inference-in-ray-actors-actorpool-and-datasets) for more details on batch inference with Ray!\n",
    "\n",
    "At a high level, this template showed how to:\n",
    "1. [Load your dataset using Ray Data.](https://docs.ray.io/en/latest/data/loading-data.html)\n",
    "2. [Preprocess your dataset before feeding it to your model.](https://docs.ray.io/en/latest/data/transforming-data.html)\n",
    "3. [Initialize your model and perform inference on a shard of your dataset with a remote actor.](https://docs.ray.io/en/latest/data/transforming-data.html#reduce-setup-overheads-using-actors)\n",
    "4. [Save your prediction results.](https://docs.ray.io/en/latest/data/api/input_output.html)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1658235",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "265d195fda5292fe8f69c6e37c435a5634a1ed3b6799724e66a975f68fa21517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
