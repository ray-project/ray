{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data in and out of Tune\n",
    "\n",
    "Often, you will find yourself needing to pass data into Tune [Trainables](tune_60_seconds_trainables) (datasets, models, other large parameters) and get data out of them (metrics, checkpoints, other artifacts). In this guide, we'll explore different ways of doing that and see in what circumstances they should be used.\n",
    "\n",
    "1. Getting data in  \n",
    "    1.1 Search space  \n",
    "    1.2 Parameters  \n",
    "    1.3 Loading data in Trainable  \n",
    "2. Getting data out  \n",
    "    2.1 Reporting metrics  \n",
    "    2.2 Logging metrics with callbacks  \n",
    "    2.3 Checkpoints & other artifacts  \n",
    "\n",
    "Let's start by defining a simple Trainable function. We'll be expanding this function with different functionality as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def training_function(config, checkpoint_dir=None):\n",
    "    # For now, we have nothing here.\n",
    "    data = None\n",
    "    model = {\"hyperparameter_a\": None, \"hyperparameter_b\": None}\n",
    "    epochs = 0\n",
    "\n",
    "    # Simulate training & evaluation - we obtain back a \"metric\" and a \"trained_model\".\n",
    "    for epoch in range(epochs):\n",
    "        # Simulate doing something expensive.\n",
    "        time.sleep(1)\n",
    "        metric = (0.1 + model[\"hyperparameter_a\"] * epoch / 100) ** (\n",
    "            -1\n",
    "        ) + model[\"hyperparameter_b\"] * 0.1 * data[\"A\"].sum()\n",
    "        trained_model = {\"state\": model, \"epoch\": epoch}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `training_function` function requires a pandas DataFrame, a model with some hyperparameters and the number of epochs to train the model for as inputs. The hyperparameters of the model impact the metric returned, and in each epoch (iteration of training), the `trained_model` state is changed.\n",
    "\n",
    "We will run hyperparameter optimization using the [Tuner API](tune-run-ref)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package pickle5 becomes unnecessary in Python 3.8 and above. Its presence may confuse libraries including Ray. Please uninstall the package.\n"
     ]
    }
   ],
   "source": [
    "from ray.tune import Tuner\n",
    "from ray import tune\n",
    "\n",
    "tuner = Tuner(training_function, tune_config=tune.TuneConfig(num_samples=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data in\n",
    "\n",
    "First order of business is to provide the inputs for the Trainable. We can broadly separate them into two categories - variables and constants.\n",
    "\n",
    "Variables are the parameters we want to tune. They will be different for every [Trial](tune_60_seconds_trials). For example, those may be the learning rate and batch size for a neural network, number of trees and the maximum depth for a random forest, or the data partition if you are using Tune as an execution engine for batch training.\n",
    "\n",
    "Constants are the parameters that are the same for every Trial. Those can be the number of epochs, model hyperparameters we want to set but not tune, the dataset and so on. Often, the constants will be quite large (eg. the dataset or the model).\n",
    "\n",
    "### Search space\n",
    "\n",
    "The first way of passing inputs into Trainables is the [*search space*](tune_60_seconds_search_spaces) (it may also be called *parameter space* or *config*). In the Trainable itself, it maps to the `config` dict passed in as an argument to the function. You define the search space using the `param_space` argument of the `Tuner`. The search space is a dict and may be composed of [*distributions*](<tune-sample-docs>), which will sample a different value for each Trial, or out of constant values. The search space may be composed out of nested dictionaries, and those in turn can have distributions as well.\n",
    "\n",
    "```{warning}\n",
    "Each value in the search space will be saved directly in the Trial metadata. This means that every value in the search space **must** be serializable and take up a small amount of memory.\n",
    "```\n",
    "\n",
    "For example, passing in a large pandas DataFrame or an unserializable model object as a value in the search space will at best cause large slowdowns and disk space usage as Trial metadata saved to disk will also contain this data, or at worst, an exception as the data cannot be sent over to the Trial workers. For more details, see {ref}`tune-bottlenecks`.\n",
    "\n",
    "Instead, use strings or other identifiers as your values, and initialize/load the objects inside your Trainable directly depending on those.\n",
    "\n",
    "```{note}\n",
    "[Ray Datasets](datasets_getting_started) can be used as values in the search space directly.\n",
    "```\n",
    "\n",
    "In our example, we want to tune the two model hyperparameters. We also want to set the number of epochs, so that we can easily tweak it later. For the hyperparameters, we will use the `tune.uniform` distribution. We will also modify the `training_function` to obtain those values from the `config` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(config, checkpoint_dir=None):\n",
    "    # For now, we have nothing here.\n",
    "    data = None\n",
    "\n",
    "    model = {\n",
    "        \"hyperparameter_a\": config[\"hyperparameter_a\"],\n",
    "        \"hyperparameter_b\": config[\"hyperparameter_b\"],\n",
    "    }\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    # Simulate training & evaluation - we obtain back a \"metric\" and a \"trained_model\".\n",
    "    for epoch in range(epochs):\n",
    "        # Simulate doing something expensive.\n",
    "        time.sleep(1)\n",
    "        metric = (0.1 + model[\"hyperparameter_a\"] * epoch / 100) ** (\n",
    "            -1\n",
    "        ) + model[\"hyperparameter_b\"] * 0.1 * data[\"A\"].sum()\n",
    "        trained_model = {\"state\": model, \"epoch\": epoch}\n",
    "\n",
    "\n",
    "tuner = Tuner(\n",
    "    training_function,\n",
    "    param_space={\n",
    "        \"hyperparameter_a\": tune.uniform(0, 20),\n",
    "        \"hyperparameter_b\": tune.uniform(-100, 100),\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    tune_config=tune.TuneConfig(num_samples=4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "If we have large objects that are constant across Trials, we can use the [`tune.with_parameters`](tune-with-parameters) utility to pass them into the Trainable directly. The objects will be stored in the [Ray object store](serialization-guide) so that each Trial worker may access them to obtain a local copy to use in its process.\n",
    "\n",
    "```{warning}\n",
    "Objects put into the Ray object store must be serializable.\n",
    "```\n",
    "\n",
    "Note that the serialization (once) and deserialization (for each Trial) of large objects may incur a performance overhead.\n",
    "\n",
    "In our example, we will pass the `data` DataFrame using `tune.with_parameters`. In order to do that, we need to modify our function signature to include `data` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(config, data, checkpoint_dir=None):\n",
    "    model = {\n",
    "        \"hyperparameter_a\": config[\"hyperparameter_a\"],\n",
    "        \"hyperparameter_b\": config[\"hyperparameter_b\"],\n",
    "    }\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    # Simulate training & evaluation - we obtain back a \"metric\" and a \"trained_model\".\n",
    "    for epoch in range(epochs):\n",
    "        # Simulate doing something expensive.\n",
    "        time.sleep(1)\n",
    "        metric = (0.1 + model[\"hyperparameter_a\"] * epoch / 100) ** (\n",
    "            -1\n",
    "        ) + model[\"hyperparameter_b\"] * 0.1 * data[\"A\"].sum()\n",
    "        trained_model = {\"state\": model, \"epoch\": epoch}\n",
    "\n",
    "\n",
    "tuner = Tuner(\n",
    "    training_function,\n",
    "    param_space={\n",
    "        \"hyperparameter_a\": tune.uniform(0, 20),\n",
    "        \"hyperparameter_b\": tune.uniform(-100, 100),\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to wrap the `training_function` using `tune.with_parameters` before passing it into the `Tuner`. Every keyword argument of the `tune.with_parameters` call will be mapped to the keyword arguments in the Trainable signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
    "\n",
    "tuner = Tuner(\n",
    "    tune.with_parameters(training_function, data=data),\n",
    "    param_space={\n",
    "        \"hyperparameter_a\": tune.uniform(0, 20),\n",
    "        \"hyperparameter_b\": tune.uniform(-100, 100),\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    tune_config=tune.TuneConfig(num_samples=4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data in Trainable\n",
    "\n",
    "You can also load data directly in Trainable from eg. cloud storage, NFS or from disk.\n",
    "\n",
    "```{warning}\n",
    "When loading from disk, ensure that all nodes in your cluster have access to the file you are trying to load.\n",
    "```\n",
    "\n",
    "A common use-case is to load the dataset from S3 or any other cloud storage with pandas, arrow or any other framework.\n",
    "\n",
    "The working directory of the Trainable worker will be automatically changed to the corresponding Trial directory. For more details, see {ref}`tune-working-dir`.\n",
    "\n",
    "For brevity, we will not use this approach in our example.\n",
    "\n",
    "Our tuning run can now be run, though we will not yet obtain any meaningful outputs back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-29 00:00:27</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:15.01        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.7/31.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/11.83 GiB heap, 0.0/5.92 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  hyperparameter_a</th><th style=\"text-align: right;\">  hyperparameter_b</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_cb758_00000</td><td>TERMINATED</td><td>172.31.43.110:566809</td><td style=\"text-align: right;\">           13.1449</td><td style=\"text-align: right;\">           33.7213</td></tr>\n",
       "<tr><td>training_function_cb758_00001</td><td>TERMINATED</td><td>172.31.43.110:566874</td><td style=\"text-align: right;\">           17.2479</td><td style=\"text-align: right;\">          -84.5562</td></tr>\n",
       "<tr><td>training_function_cb758_00002</td><td>TERMINATED</td><td>172.31.43.110:566876</td><td style=\"text-align: right;\">           19.0947</td><td style=\"text-align: right;\">          -99.0795</td></tr>\n",
       "<tr><td>training_function_cb758_00003</td><td>TERMINATED</td><td>172.31.43.110:566878</td><td style=\"text-align: right;\">           14.6521</td><td style=\"text-align: right;\">           50.3226</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial training_function_cb758_00000 completed. Last result: \n",
      "Trial training_function_cb758_00001 completed. Last result: \n",
      "Trial training_function_cb758_00003 completed. Last result: \n",
      "Trial training_function_cb758_00002 completed. Last result: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 00:00:27,573\tINFO tune.py:762 -- Total run time: 15.72 seconds (15.01 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data out\n",
    "\n",
    "We can now run our tuning run using the `training_function` Trainable. The next step is to report *metrics* to Tune that can be used to guide the optimization. We will also want to *checkpoint* our trained models so that we can resume the training after an interruption, and to use them for prediction later.\n",
    "\n",
    "The [`ray.air.session`](air-session-ref) API is used to get data out of the Trainable workers. `session.report` can be called multiple times in the Trainable function. Each call corresponds to one iteration (epoch, step, tree) of training.\n",
    "\n",
    "### Reporting metrics\n",
    "\n",
    "*Metrics* are values passed through the `metrics` argument in a `session.report` call. Metrics can be used by Tune [Search Algorithms](search-alg-ref) and [Schedulers](schedulers-ref) to direct the search. After the tuning run is complete, you can [analyze the results](/tune/examples/tune_analyze_results), which include the reported metrics.\n",
    "\n",
    "```{warning}\n",
    "Similarly to search space values, each value reported as a metric will be saved directly in the Trial metadata. This means that every value reported as a metric **must** be serializable and take up a small amount of memory.\n",
    "```\n",
    "\n",
    "```{note}\n",
    "Tune will automatically include some metrics, such as the training iteration, timestamp and more.\n",
    "```\n",
    "\n",
    "In our example, we want to maximize the `metric`. We will report it each epoch to Tune, and set the `metric` and `mode` arguments in `tune.TuneConfig` to let Tune know that it should use it as the optimization objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import session\n",
    "\n",
    "\n",
    "def training_function(config, data, checkpoint_dir=None):\n",
    "    model = {\n",
    "        \"hyperparameter_a\": config[\"hyperparameter_a\"],\n",
    "        \"hyperparameter_b\": config[\"hyperparameter_b\"],\n",
    "    }\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    # Simulate training & evaluation - we obtain back a \"metric\" and a \"trained_model\".\n",
    "    for epoch in range(epochs):\n",
    "        # Simulate doing something expensive.\n",
    "        time.sleep(1)\n",
    "        metric = (0.1 + model[\"hyperparameter_a\"] * epoch / 100) ** (\n",
    "            -1\n",
    "        ) + model[\"hyperparameter_b\"] * 0.1 * data[\"A\"].sum()\n",
    "        trained_model = {\"state\": model, \"epoch\": epoch}\n",
    "        session.report(metrics={\"metric\": metric})\n",
    "\n",
    "\n",
    "tuner = Tuner(\n",
    "    tune.with_parameters(training_function, data=data),\n",
    "    param_space={\n",
    "        \"hyperparameter_a\": tune.uniform(0, 20),\n",
    "        \"hyperparameter_b\": tune.uniform(-100, 100),\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    tune_config=tune.TuneConfig(num_samples=4, metric=\"metric\", mode=\"max\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging metrics with callbacks\n",
    "\n",
    "Every metric logged using `session.report` can be accessed during the tuning run through Tune [Callbacks](tune-logging). Ray AIR provides [several built-in integrations](air-builtin-callbacks) with popular frameworks, such as MLFlow, Weights & Biases, CometML and more. You can also use the [Callback API](tune-callbacks-docs) to create your own callbacks.\n",
    "\n",
    "Callbacks are passed in the `callback` argument of the `Tuner`'s `RunConfig`.\n",
    "\n",
    "In our example, we'll use the MLFlow callback to track the progress of our tuning run and the changing value of the `metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import RunConfig\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "\n",
    "\n",
    "def training_function(config, data, checkpoint_dir=None):\n",
    "    model = {\n",
    "        \"hyperparameter_a\": config[\"hyperparameter_a\"],\n",
    "        \"hyperparameter_b\": config[\"hyperparameter_b\"],\n",
    "    }\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    # Simulate training & evaluation - we obtain back a \"metric\" and a \"trained_model\".\n",
    "    for epoch in range(epochs):\n",
    "        # Simulate doing something expensive.\n",
    "        time.sleep(1)\n",
    "        metric = (0.1 + model[\"hyperparameter_a\"] * epoch / 100) ** (\n",
    "            -1\n",
    "        ) + model[\"hyperparameter_b\"] * 0.1 * data[\"A\"].sum()\n",
    "        trained_model = {\"state\": model, \"epoch\": epoch}\n",
    "        session.report(metrics={\"metric\": metric})\n",
    "\n",
    "\n",
    "tuner = Tuner(\n",
    "    tune.with_parameters(training_function, data=data),\n",
    "    param_space={\n",
    "        \"hyperparameter_a\": tune.uniform(0, 20),\n",
    "        \"hyperparameter_b\": tune.uniform(-100, 100),\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    tune_config=tune.TuneConfig(num_samples=4, metric=\"metric\", mode=\"max\"),\n",
    "    run_config=RunConfig(\n",
    "        callbacks=[MLflowLoggerCallback(experiment_name=\"example\")]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints & other artifacts\n",
    "\n",
    "Aside from metrics, you may want to save the state of your trained model and any other artifacts to allow resumption from training failure and further inspection and usage. Those cannot be saved as metrics, as they often are far too large and may not be easily serializable. Finally, they should be persisted on disk or cloud storage to allow access after the Tune run is interrupted or terminated.\n",
    "\n",
    "Ray AIR (which contains Ray Tune) provides a [`Checkpoint`](air-checkpoints-doc) API for that purpose. `Checkpoint` objects can be created from various sources (dictionaries, directories, cloud storage) and used between different AIR components.\n",
    "\n",
    "In Tune, `Checkpoints` are created by the user in their Trainable functions and reported using the optional `checkpoint` argument of `session.report`. `Checkpoints` can contain arbitrary data and can be freely passed around the Ray cluster. After a tuning run is over, `Checkpoints` can be [obtained from the results](/tune/examples/tune_analyze_results).\n",
    "\n",
    "Ray Tune can be configured to [automatically sync checkpoints to cloud storage](tune-checkpoint-syncing), [keep only a certain number of checkpoints to save space](air-session-ref) and more.\n",
    "\n",
    "```{note}\n",
    "The experiment state itself is checkpointed separately. See {ref}`tune-two-types-of-ckpt` for more details.\n",
    "```\n",
    "\n",
    "In our example, we want to be able to resume the training from the latest checkpoint, and to save the `trained_model` in a checkpoint every iteration. To accomplish this, we will use the `session` and `Checkpoint` APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air import Checkpoint\n",
    "\n",
    "\n",
    "def training_function(config, data, checkpoint_dir=None):\n",
    "    model = {\n",
    "        \"hyperparameter_a\": config[\"hyperparameter_a\"],\n",
    "        \"hyperparameter_b\": config[\"hyperparameter_b\"],\n",
    "    }\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    # Load the checkpoint, if there is any.\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint is not None:\n",
    "        last_epoch = loaded_checkpoint[\"epoch\"] + 1\n",
    "    else:\n",
    "        last_epoch = 0\n",
    "\n",
    "    # Simulate training & evaluation - we obtain back a \"metric\" and a \"trained_model\".\n",
    "    for epoch in range(last_epoch, epochs):\n",
    "        # Simulate doing something expensive.\n",
    "        time.sleep(1)\n",
    "        metric = (0.1 + model[\"hyperparameter_a\"] * epoch / 100) ** (\n",
    "            -1\n",
    "        ) + model[\"hyperparameter_b\"] * 0.1 * data[\"A\"].sum()\n",
    "        trained_model = {\"state\": model, \"epoch\": epoch}\n",
    "\n",
    "        # Create the checkpoint.\n",
    "        checkpoint = Checkpoint.from_dict({\"model\": trained_model})\n",
    "        session.report(metrics={\"metric\": metric}, checkpoint=checkpoint)\n",
    "\n",
    "\n",
    "tuner = Tuner(\n",
    "    tune.with_parameters(training_function, data=data),\n",
    "    param_space={\n",
    "        \"hyperparameter_a\": tune.uniform(0, 20),\n",
    "        \"hyperparameter_b\": tune.uniform(-100, 100),\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    "    tune_config=tune.TuneConfig(num_samples=4, metric=\"metric\", mode=\"max\"),\n",
    "    run_config=RunConfig(\n",
    "        callbacks=[MLflowLoggerCallback(experiment_name=\"example\")]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of those changes implemented, we can now run our tuning and obtain meaningful metrics and artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-29 00:01:07</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:15.49        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.7/31.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/11.83 GiB heap, 0.0/5.92 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  hyperparameter_a</th><th style=\"text-align: right;\">  hyperparameter_b</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  metric</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_e3653_00000</td><td>TERMINATED</td><td>172.31.43.110:567338</td><td style=\"text-align: right;\">          16.5098 </td><td style=\"text-align: right;\">           56.7657</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.3257</td><td style=\"text-align: right;\">34.69   </td></tr>\n",
       "<tr><td>training_function_e3653_00001</td><td>TERMINATED</td><td>172.31.43.110:567406</td><td style=\"text-align: right;\">           3.19302</td><td style=\"text-align: right;\">           94.0236</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.3026</td><td style=\"text-align: right;\">58.9957 </td></tr>\n",
       "<tr><td>training_function_e3653_00002</td><td>TERMINATED</td><td>172.31.43.110:567407</td><td style=\"text-align: right;\">          12.8895 </td><td style=\"text-align: right;\">           14.6021</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.2733</td><td style=\"text-align: right;\"> 9.55486</td></tr>\n",
       "<tr><td>training_function_e3653_00003</td><td>TERMINATED</td><td>172.31.43.110:567409</td><td style=\"text-align: right;\">          12.4421 </td><td style=\"text-align: right;\">           91.7   </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         10.2   </td><td style=\"text-align: right;\">55.8398 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 00:01:07,624\tINFO tune.py:762 -- Total run time: 15.61 seconds (15.48 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x7f62edb96430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = tuner.fit()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on how to interact with the returned `ResultGrid` object, see {doc}`/tune/examples/tune_analyze_results`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c0d54d489a08ae47a06eae2fd00ff032d6cddb527c382959b7b2575f6a8167f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
