{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988326f5",
   "metadata": {},
   "source": [
    "# Running Tune experiments with HyperOpt\n",
    "\n",
    "This example demonstrates the usage of HyperOpt with Ray Tune, including conditional search spaces.\n",
    "\n",
    "We also combine the search algorithm based on `HyperOptSearch` with `AsyncHyperBandScheduler` scheduler to demonstrate Ray Tune's modularity.\n",
    "\n",
    "Background information:\n",
    "- [HyperOpt website](http://hyperopt.github.io/hyperopt)\n",
    "\n",
    "Necessary requirements:\n",
    "- `pip install ray[tune]`\n",
    "- `pip install hyperopt==0.2.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfa6b1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install ray[tune]\n",
    "!pip install hyperopt==0.2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d593ee6e",
   "metadata": {},
   "source": [
    "Click below to see all the imports we need for this example.\n",
    "You can also launch directly into a Binder instance to run this notebook yourself.\n",
    "Just click on the rocket symbol at the top of the navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103a0f09",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bb691",
   "metadata": {},
   "source": [
    "Let's start by defining a simple evaluation function.\n",
    "We artificially sleep for a bit (`0.1` seconds) to simulate a long-running ML experiment.\n",
    "This setup assumes that we're running multiple `step`s of an experiment and try to tune two hyperparameters,\n",
    "namely `width` and `height`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab02f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(step, width, height):\n",
    "    time.sleep(0.1)\n",
    "    return (0.1 + width * step / 100) ** (-1) + height * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79e7e4",
   "metadata": {},
   "source": [
    "Next, our ``objective`` function takes a Tune ``config``, evaluates the `score` of your experiment in a training loop,\n",
    "and uses `tune.report` to report the `score` back to Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):\n",
    "    for step in range(config[\"steps\"]):\n",
    "        score = evaluate(step, config[\"width\"], config[\"height\"])\n",
    "        tune.report(iterations=step, mean_loss=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641f3c4",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ray.init(configure_logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c665a29",
   "metadata": {},
   "source": [
    "While defining the search algorithm, we may choose to provide an initial set of hyperparameters that we believe are especially promising or informative, and\n",
    "pass this information as a helpful starting point for the `HyperOptSearch` object.\n",
    "\n",
    "We also set the maximum concurrent trials to `4` with a `ConcurrencyLimiter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16880d43",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "initial_params = [\n",
    "    {\"width\": 1, \"height\": 2},\n",
    "    {\"width\": 4, \"height\": 2},\n",
    "]\n",
    "algo = HyperOptSearch(points_to_evaluate=initial_params)\n",
    "algo = ConcurrencyLimiter(algo, max_concurrent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa8c269",
   "metadata": {},
   "source": [
    "The number of samples this Tune run is set to `1000`.\n",
    "(you can decrease this if it takes too long on your machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83353bd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603610e9",
   "metadata": {},
   "source": [
    "Furthermore, we define a `scheduler` to go along with our algorithm to showcase the modularity of Ray Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93085ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AsyncHyperBandScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29dff7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# If 1000 samples take too long, you can reduce this number.\n",
    "# We override this number here for our smoke tests.\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597b0b9",
   "metadata": {},
   "source": [
    "Finally, all that's left is to define a search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34063a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"steps\": 100,\n",
    "    \"width\": tune.uniform(0, 20),\n",
    "    \"height\": tune.uniform(-100, 100),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a030537",
   "metadata": {},
   "source": [
    "And run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    objective,\n",
    "    search_alg=algo,\n",
    "    scheduler=scheduler,\n",
    "    metric=\"mean_loss\",\n",
    "    mode=\"min\",\n",
    "    name=\"hyperopt_exp\",\n",
    "    num_samples=num_samples,\n",
    "    config=search_space,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefbed22",
   "metadata": {},
   "source": [
    "Here are the hyperparamters found to minimize the mean loss of the defined objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e78783",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe9159",
   "metadata": {},
   "source": [
    "## Conditional search spaces\n",
    "\n",
    "Sometimes we may want to build a more complicated search space that has conditional dependencies on other hyperparameters. In this case, we pass a nested dictionary to `objective_two`, which has been slightly adjusted from `objective` to deal with the conditional search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d275d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_fn(step, width, height, mult=1):\n",
    "    return (0.1 + width * step / 100) ** (-1) + height * 0.1 * mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3eab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_two(config):\n",
    "    width, height = config[\"width\"], config[\"height\"]\n",
    "    sub_dict = config[\"activation\"]\n",
    "    mult = sub_dict.get(\"mult\", 1)\n",
    "    \n",
    "    for step in range(config[\"steps\"]):\n",
    "        intermediate_score = evaluation_fn(step, width, height, mult)\n",
    "        tune.report(iterations=step, mean_loss=intermediate_score)\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_space = {\n",
    "    \"activation\": hp.choice(\n",
    "        \"activation\",\n",
    "        [\n",
    "            {\"activation\": \"relu\", \"mult\": hp.uniform(\"mult\", 1, 2)},\n",
    "            {\"activation\": \"tanh\"},\n",
    "        ],\n",
    "    ),\n",
    "    \"width\": hp.uniform(\"width\", 0, 20),\n",
    "    \"height\": hp.uniform(\"height\", -100, 100),\n",
    "    \"steps\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e180f51",
   "metadata": {},
   "source": [
    "Now we the define the search algorithm built from `HyperOptSearch` constrained by `ConcurrencyLimiter`. When the hyperparameter search space is conditional, we pass it (`config_space`) into `HyperOptSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = HyperOptSearch(space=config_space, metric=\"mean_loss\", mode=\"min\")\n",
    "algo = ConcurrencyLimiter(algo, max_concurrent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd671b",
   "metadata": {},
   "source": [
    "We can also define a `scheduler` to go along with our algorithm to showcase the modularity of Ray Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AsyncHyperBandScheduler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f7d66",
   "metadata": {},
   "source": [
    "Now we run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cfbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    objective_two,\n",
    "    metric=\"mean_loss\",\n",
    "    mode=\"min\",\n",
    "    search_alg=algo,\n",
    "    scheduler=scheduler,\n",
    "    num_samples=num_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeb47e4",
   "metadata": {},
   "source": [
    "Finally, we again show the hyperparameters that minimize the mean loss defined by the score of the objective function above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dcd64",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orphan": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
