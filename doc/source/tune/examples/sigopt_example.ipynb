{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56e9bc8",
   "metadata": {},
   "source": [
    "# Running Tune experiments with SigOpt\n",
    "\n",
    "This example demonstrates the usage of SigOpt with Ray Tune. Please note that usage of `SigOpt` requires an API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23ba3",
   "metadata": {},
   "source": [
    "We also combine the search algorithm based on `SigOptSearch` with `AsyncHyperBandScheduler` scheduler to demonstrate Ray Tune's modularity.\n",
    "\n",
    "Click below to see all the imports we need for this example.\n",
    "You can also launch directly into a Binder instance to run this notebook yourself.\n",
    "Just click on the rocket symbol at the top of the navigation.\n",
    "\n",
    "Necessary requirements:\n",
    "- `pip install ray[tune]`\n",
    "- `pip install sigopt==7.5.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574dea5",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# !pip install ray[tune]\n",
    "!pip install sigopt==7.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7aa06d",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.sigopt import SigOptSearch\n",
    "\n",
    "if \"SIGOPT_KEY\" not in os.environ:\n",
    "    raise ValueError(\n",
    "        \"SigOpt API Key not found. Please set the SIGOPT_KEY \"\n",
    "        \"environment variable.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9ea63",
   "metadata": {},
   "source": [
    "Let's start by defining a simple evaluation function.\n",
    "We artificially sleep for a bit (`0.1` seconds) to simulate a long-running ML experiment.\n",
    "This setup assumes that we're running multiple `step`s of an experiment and try to tune two hyperparameters,\n",
    "namely `width` and `height`, and `activation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103168bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(step, width, height, activation):\n",
    "    time.sleep(0.1)\n",
    "    activation_boost = 10 if activation==\"relu\" else 1\n",
    "    return (0.1 + width * step / 100) ** (-1) + height * 0.1 + activation_boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114904d4",
   "metadata": {},
   "source": [
    "Next, our ``objective`` function takes a Tune ``config``, evaluates the `score` of your experiment in a training loop,\n",
    "and uses `tune.report` to report the `score` back to Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):\n",
    "    for step in range(config[\"steps\"]):\n",
    "        score = evaluate(step, config[\"width\"], config[\"height\"], config[\"activation\"])\n",
    "        tune.report(iterations=step, mean_loss=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafae3e4",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ray.init(configure_logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078740ab",
   "metadata": {},
   "source": [
    "Next we define the search algorithm built from `SigOptSearch`, constrained  to a maximum of `1` concurrent trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69771128",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [\n",
    "    {\n",
    "        \"name\": \"width\",\n",
    "        \"type\": \"int\",\n",
    "        \"bounds\": {\"min\": 0, \"max\": 20},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"height\",\n",
    "        \"type\": \"int\",\n",
    "        \"bounds\": {\"min\": -100, \"max\": 100},\n",
    "    },\n",
    "]\n",
    "\n",
    "algo = SigOptSearch(\n",
    "    space,\n",
    "    name=\"SigOpt Example Experiment\",\n",
    "    max_concurrent=1,\n",
    "    metric=\"mean_loss\",\n",
    "    mode=\"min\",\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b4d6d",
   "metadata": {},
   "source": [
    "Furthermore, we define a `scheduler` to go along with our algorithm to showcase the modularity of Ray Tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = AsyncHyperBandScheduler() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c6919",
   "metadata": {},
   "source": [
    "The number of samples this Tune run is set to `1000`.\n",
    "(you can decrease this if it takes too long on your machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7528840",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc6405",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# If 1000 samples take too long, you can reduce this number.\n",
    "# We override this number here for our smoke tests.\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01c3f8",
   "metadata": {},
   "source": [
    "Finally, all that's left is to define a search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9fd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_config = {\n",
    "    \"steps\": 100,\n",
    "    \"width\": tune.randint(0, 10),\n",
    "    \"height\": tune.quniform(-10, 10, 1e-2),\n",
    "    \"activation\": tune.choice([\"relu, tanh\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50135a01",
   "metadata": {},
   "source": [
    "And run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    objective,\n",
    "    search_alg=algo,\n",
    "    scheduler=scheduler,\n",
    "    metric=\"mean_loss\",\n",
    "    mode=\"min\",\n",
    "    name=\"sigopt_exp\",\n",
    "    num_samples=num_samples,\n",
    "    config=search_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b64c8",
   "metadata": {},
   "source": [
    "Here are the hyperparamters found to minimize the mean loss of the defined objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59398e6d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0dad6d",
   "metadata": {},
   "source": [
    "## Multi-objective optimization with Sigopt\n",
    "\n",
    "We define another simple objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9b150",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "vector1 = np.random.normal(0, 0.1, 100)\n",
    "vector2 = np.random.normal(0, 0.1, 100)\n",
    "\n",
    "def evaluate(w1, w2):\n",
    "    total = w1 * vector1 + w2 * vector2\n",
    "    return total.mean(), total.std()\n",
    "\n",
    "\n",
    "def multi_objective(config):\n",
    "    w1 = config[\"w1\"]\n",
    "    w2 = config[\"total_weight\"] - w1\n",
    "    \n",
    "    average, std = evaluate(w1, w2)\n",
    "    tune.report(average=average, std=std, sharpe=average / std)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95601f31",
   "metadata": {},
   "source": [
    "We define the space manually for `SigOptSearch`\n",
    "\n",
    "space = [\n",
    "    {\n",
    "        \"name\": \"w1\",\n",
    "        \"type\": \"double\",\n",
    "        \"bounds\": {\"min\": 0, \"max\": 1},\n",
    "    },\n",
    "]\n",
    "\n",
    "algo = SigOptSearch(\n",
    "    space,\n",
    "    name=\"sigopt_multiobj_exp\",\n",
    "    observation_budget=num_samples,\n",
    "    max_concurrent=1,\n",
    "    metric=[\"average\", \"std\", \"sharpe\"],\n",
    "    mode=[\"max\", \"min\", \"obs\"],\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    multi_objective,\n",
    "    name=\"sigopt_multiobj_exp\",\n",
    "    search_alg=algo,\n",
    "    num_samples=num_samples,\n",
    "    config={\"total_weight\": 1},\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.get_best_config(\"average\", \"min\"))\n",
    "```\n",
    "\n",
    "## Incorporating prior beliefs with Sigopt\n",
    "\n",
    "We start with defining another objective.\n",
    "\n",
    "```python\n",
    "np.random.seed(0)\n",
    "vector1 = np.random.normal(0.0, 0.1, 100)\n",
    "vector2 = np.random.normal(0.0, 0.1, 100)\n",
    "vector3 = np.random.normal(0.0, 0.1, 100)\n",
    "\n",
    "def evaluate(w1, w2, w3):\n",
    "    total = w1 * vector1 + w2 * vector2 + w3 * vector3\n",
    "    return total.mean(), total.std()\n",
    "\n",
    "def multi_objective_two(config):\n",
    "    w1 = config[\"w1\"]\n",
    "    w2 = config[\"w2\"]\n",
    "    total = w1 + w2\n",
    "    if total > 1:\n",
    "    w3 = 0\n",
    "    w1 /= total\n",
    "    w2 /= total\n",
    "    else:\n",
    "    w3 = 1 - total\n",
    "    \n",
    "    average, std = evaluate(w1, w2, w3)\n",
    "    tune.report(average=average, std=std)\n",
    "```\n",
    "\n",
    "Now we set up the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = num_samples\n",
    "\n",
    "conn = Connection(client_token=os.environ[\"SIGOPT_KEY\"])\n",
    "experiment = conn.experiments().create(\n",
    "    name=\"prior experiment example\",\n",
    "    parameters=[\n",
    "        {\n",
    "            \"name\": \"w1\",\n",
    "            \"bounds\": {\"max\": 1, \"min\": 0},\n",
    "            \"prior\": {\"mean\": 1 / 3, \"name\": \"normal\", \"scale\": 0.2},\n",
    "            \"type\": \"double\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"w2\",\n",
    "            \"bounds\": {\"max\": 1, \"min\": 0},\n",
    "            \"prior\": {\"mean\": 1 / 3, \"name\": \"normal\", \"scale\": 0.2},\n",
    "            \"type\": \"double\",\n",
    "        },  \n",
    "    ],\n",
    "    metrics=[\n",
    "        dict(name=\"std\", objective=\"minimize\", strategy=\"optimize\"),\n",
    "        dict(name=\"average\", strategy=\"store\"),\n",
    "    ],\n",
    "    observation_budget=samples,\n",
    "    parallel_bandwidth=1,\n",
    ")\n",
    "\n",
    "algo = SigOptSearch(\n",
    "    connection=conn,\n",
    "    experiment_id=experiment.id,\n",
    "    name=\"sigopt_prior_multi_exp\",\n",
    "    max_concurrent=1,\n",
    "    metric=[\"average\", \"std\"],\n",
    "    mode=[\"obs\", \"min\"],\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    easy_objective, name=\"my_exp\", search_alg=algo, num_samples=samples, config={}\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.get_best_config(\"average\", \"min\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9f21b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orphan": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
