{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Stable Diffusion and generate images with Intel Habana Gaudi\n",
    "In this tutorial, we will go through how to finetune a stable diffusion model and generate images with Intel Habana Gaudi(HPU). Moreover, we will show how to adapt an existing HPU example to use Ray. Once you learned how to make the adaption, you can easily access more models and optimizations that has been developed for HPU by \"Ray-ifying\" examples from [optimum-habana/examples](https://github.com/huggingface/optimum-habana/tree/main/examples) and [Model References](https://github.com/HabanaAI/Model-References)!\n",
    "\n",
    "Now, let's see how we can \"Ray-ify\" this [stable diffusion example](https://github.com/huggingface/optimum-habana/tree/main/examples/stable-diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning with Textual Inversion\n",
    "First, let's start with fine-tuning. Download this [script](https://github.com/huggingface/optimum-habana/blob/main/examples/stable-diffusion/training/textual_inversion.py) which fine-tunes a Stable Diffusion model on HPU. You can follow [this document](https://github.com/huggingface/optimum-habana/blob/main/examples/stable-diffusion/training/README.md#textual-inversion) and try it once without using Ray.\n",
    "\n",
    "In order to run this script on Ray, we need to make some changes. But don't worry, it's actually pretty simple. Basically, we just need to identify the main training loop, and run it in TorchTrainer.\n",
    "\n",
    "First, check this block at the end of the file:\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "Originally, this script will be started by MPI if multiple workers are used. But with Ray, we should setup TorchTrainer and supply a main function, which is `main()` in this example.\n",
    "\n",
    "Therefore, it becomes straight-forward to make these changes:\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    import ray\n",
    "    from ray import train\n",
    "    from ray.train import ScalingConfig, Checkpoint, CheckpointConfig, RunConfig\n",
    "    from ray.train.torch import TorchTrainer, TorchConfig\n",
    "\n",
    "    ray.init(address=\"auto\")\n",
    "\n",
    "    # Configure computation resources\n",
    "    # In ScalingConfig, require an HPU for each worker\n",
    "    scaling_config = ScalingConfig(num_workers=1, resources_per_worker={\"CPU\": 1, \"HPU\": 1})\n",
    "    # Set backend to hccl in TorchConfig\n",
    "    torch_config = TorchConfig(backend = \"hccl\")\n",
    "    # Initialize a Ray TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=main,\n",
    "        torch_config=torch_config,\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "\n",
    "    result = trainer.fit()\n",
    "```\n",
    "\n",
    "Before we try to run, we need to inspect the `main` function to see if it can work in such way. As we skim through the function, it's clear that it does not take any input parameters, but it calls `parse_args` to get all configurations. Originally, these configurations are set in command line by MPI. But because we switch to Ray to start the workers, command line arguments are no longer accessible. Therefore, `parse_args` should be called in the main program and passed to `main` function.\n",
    "\n",
    "Apart from this, no other changes are necessary. By inserting the following code, you can now run the script on Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Replace lines below:\n",
    "# def main():\n",
    "#     args = parse_args()\n",
    "# with these lines:\n",
    "def main(config):\n",
    "    args = config[\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Replace lines below:\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "# with these lines:\n",
    "if __name__ == \"__main__\":\n",
    "    import ray\n",
    "    from ray import train\n",
    "    from ray.train import ScalingConfig, Checkpoint, CheckpointConfig, RunConfig\n",
    "    from ray.train.torch import TorchTrainer, TorchConfig\n",
    "\n",
    "    ray.init(address=\"auto\")\n",
    "\n",
    "    # Configure computation resources\n",
    "    # In ScalingConfig, require an HPU for each worker\n",
    "    scaling_config = ScalingConfig(num_workers=1, resources_per_worker={\"CPU\": 1, \"HPU\": 1})\n",
    "    # Set backend to hccl in TorchConfig\n",
    "    torch_config = TorchConfig(backend = \"hccl\")\n",
    "    # Initialize a Ray TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=main,\n",
    "\t\ttrain_loop_config={\"args\": parse_args()},\n",
    "        torch_config=torch_config,\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "\n",
    "    result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing: remember to use absolute path in the command line arguments. The reason is similar to why we move `parse_args` out, Ray's workers do not share the current working directory. Now, you can run the fine-tuning of Stable Diffusion on Ray! Below is an example output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "[WARNING|utils.py:185] 2024-05-09 05:21:00,359 >> optimum-habana v1.10.4 has been validated for SynapseAI v1.14.0 but habana-frameworks v1.15.1.15 was found, this could lead to undefined behavior!\n",
      "[WARNING|utils.py:198] 2024-05-09 05:21:01,810 >> optimum-habana v1.10.4 has been validated for SynapseAI v1.14.0 but the driver version is v1.15.0, this could lead to undefined behavior!\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2024-05-09 05:21:02,195\tINFO worker.py:1564 -- Connecting to existing Ray cluster at address: 172.17.0.2:6379...\n",
      "2024-05-09 05:21:02,200\tINFO worker.py:1740 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\n",
      "View detailed results here: /root/ray_results/TorchTrainer_2024-05-09_05-21-02\n",
      "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-05-09_05-19-45_397857_439/artifacts/2024-05-09_05-21-02/TorchTrainer_2024-05-09_05-21-02/driver_artifacts`\n",
      "\u001b[36m(TrainTrainable pid=15530)\u001b[0m [WARNING|utils.py:185] 2024-05-09 05:21:06,843 >> optimum-habana v1.10.4 has been validated for SynapseAI v1.14.0 but habana-frameworks v1.15.1.15 was found, this could lead to undefined behavior!\n",
      "\u001b[36m(TrainTrainable pid=15530)\u001b[0m [WARNING|utils.py:198] 2024-05-09 05:21:08,275 >> optimum-habana v1.10.4 has been validated for SynapseAI v1.14.0 but the driver version is v1.15.0, this could lead to undefined behavior!\n",
      "\u001b[36m(TrainTrainable pid=15530)\u001b[0m /usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "\u001b[36m(TrainTrainable pid=15530)\u001b[0m   torch.utils._pytree._register_pytree_node(\n",
      "\n",
      "Training started with configuration:\n",
      "╭───────────────────────────────────────────────╮\n",
      "│ Training config                               │\n",
      "├───────────────────────────────────────────────┤\n",
      "│ train_loop_config/args   ...t_warmup_steps=3) │\n",
      "╰───────────────────────────────────────────────╯\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=15530)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=15530)\u001b[0m - (ip=172.17.0.2, pid=15683) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m [WARNING|utils.py:185] 2024-05-09 05:21:13,961 >> optimum-habana v1.10.4 has been validated for SynapseAI v1.14.0 but habana-frameworks v1.15.1.15 was found, this could lead to undefined behavior!\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m [WARNING|utils.py:198] 2024-05-09 05:21:15,401 >> optimum-habana v1.10.4 has been validated for SynapseAI v1.14.0 but the driver version is v1.15.0, this could lead to undefined behavior!\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m /usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m   torch.utils._pytree._register_pytree_node(\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m /usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:15 - INFO - __main__ - Distributed environment: MULTI_HPU  Backend: hccl\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Num processes: 1\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Process index: 0\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Local process index: 0\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Device: hpu\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Mixed precision type: bf16\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m \n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m {'timestep_spacing', 'rescale_betas_zero_snr', 'dynamic_thresholding_ratio', 'prediction_type', 'thresholding', 'sample_max_value', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m ============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m  PT_HPU_LAZY_MODE = 1\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m  PT_RECIPE_CACHE_PATH = \n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m  PT_CACHE_FOLDER_DELETE = 0\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m  PT_HPU_RECIPE_CACHE_CONFIG = \n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m  PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m  PT_HPU_LAZY_ACC_PAR_MODE = 0\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m  PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m ---------------------------: System Configuration :---------------------------\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Num CPU Cores : 152\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m CPU RAM       : 1056440348 KB\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m ------------------------------------------------------------------------------\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m {'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m {'addition_embed_type', 'resnet_out_scale_factor', 'transformer_layers_per_block', 'attention_type', 'conv_out_kernel', 'time_embedding_type', 'addition_embed_type_num_heads', 'dropout', 'only_cross_attention', 'projection_class_embeddings_input_dim', 'num_attention_heads', 'upcast_attention', 'reverse_transformer_layers_per_block', 'resnet_time_scale_shift', 'resnet_skip_time_act', 'time_embedding_act_fn', 'class_embeddings_concat', 'time_cond_proj_dim', 'num_class_embeds', 'mid_block_type', 'cross_attention_norm', 'addition_time_embed_dim', 'dual_cross_attention', 'mid_block_only_cross_attention', 'encoder_hid_dim_type', 'time_embedding_dim', 'class_embed_type', 'conv_in_kernel', 'timestep_post_act', 'encoder_hid_dim', 'use_linear_projection'} was not found in config. Values will be initialized to default values.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:20 - INFO - __main__ - ***** Running training *****\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:20 - INFO - __main__ -   Num examples = 600\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:20 - INFO - __main__ -   Num Epochs = 20\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:20 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:20 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:20 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:21:20 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:   0%|          | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/hpu/__init__.py:158: UserWarning: torch.hpu.setDeterministic is deprecated and will be removed in next release. Please use torch.use_deterministic_algorithms instead.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m [2024-05-09 05:21:20,951] [INFO] [real_accelerator.py:178:get_accelerator] Setting ds_accelerator to hpu (auto detect)\n",
      "Steps:   0%|          | 1/3000 [00:51<42:39:29, 51.21s/it, loss=0.138, lr=0.002]\n",
      "Steps:   0%|          | 2/3000 [01:01<22:39:08, 27.20s/it, loss=0.136, lr=0.002]\n",
      "Steps:   0%|          | 3/3000 [01:02<12:39:46, 15.21s/it, loss=0.107, lr=0.002]\n",
      "Steps:   0%|          | 4/3000 [01:43<21:05:03, 25.34s/it, loss=0.131, lr=0.002]\n",
      "Steps:   0%|          | 5/3000 [01:43<13:34:54, 16.33s/it, loss=0.104, lr=0.002]\n",
      "Steps:   0%|          | 6/3000 [01:44<9:03:26, 10.89s/it, loss=0.232, lr=0.002] \n",
      "Steps:   0%|          | 7/3000 [01:44<6:11:14,  7.44s/it, loss=0.137, lr=0.002]\n",
      "Steps:   0%|          | 8/3000 [01:44<4:18:22,  5.18s/it, loss=0.0495, lr=0.002]\n",
      "Steps:   0%|          | 9/3000 [01:45<3:02:43,  3.67s/it, loss=0.022, lr=0.002] \n",
      "Steps:   0%|          | 10/3000 [01:45<2:11:31,  2.64s/it, loss=0.0864, lr=0.002]\n",
      "Steps:   0%|          | 11/3000 [01:45<1:36:14,  1.93s/it, loss=0.12, lr=0.002]  \n",
      "Steps:   0%|          | 12/3000 [01:46<1:12:01,  1.45s/it, loss=0.115, lr=0.002]\n",
      "Steps:   0%|          | 13/3000 [01:46<55:22,  1.11s/it, loss=0.0954, lr=0.002] \n",
      "Steps:   0%|          | 14/3000 [01:46<43:33,  1.14it/s, loss=0.133, lr=0.002] \n",
      "Steps:   0%|          | 15/3000 [01:47<35:22,  1.41it/s, loss=0.0585, lr=0.002]\n",
      "Steps:   1%|          | 16/3000 [01:47<29:40,  1.68it/s, loss=0.115, lr=0.002] \n",
      "Steps:   1%|          | 17/3000 [01:47<25:43,  1.93it/s, loss=0.122, lr=0.002]\n",
      "Steps:   1%|          | 18/3000 [01:48<23:07,  2.15it/s, loss=0.22, lr=0.002] \n",
      "Steps:   1%|          | 19/3000 [01:48<21:07,  2.35it/s, loss=0.256, lr=0.002]\n",
      "Steps:   1%|          | 20/3000 [01:48<19:46,  2.51it/s, loss=0.0762, lr=0.002]\n",
      "Steps:   1%|          | 21/3000 [01:49<18:49,  2.64it/s, loss=0.109, lr=0.002] \n",
      "Steps:   1%|          | 22/3000 [01:49<18:08,  2.74it/s, loss=0.0355, lr=0.002]\n",
      "Steps:   1%|          | 23/3000 [01:49<17:36,  2.82it/s, loss=0.187, lr=0.002] \n",
      "Steps:   1%|          | 24/3000 [01:50<17:26,  2.84it/s, loss=0.0222, lr=0.002]\n",
      "Steps:   1%|          | 25/3000 [01:50<17:10,  2.89it/s, loss=0.121, lr=0.002] \n",
      "Steps:   1%|          | 26/3000 [01:50<17:11,  2.88it/s, loss=0.0938, lr=0.002]\n",
      "Steps:   1%|          | 27/3000 [01:51<17:06,  2.90it/s, loss=0.0926, lr=0.002]\n",
      "Steps:   1%|          | 28/3000 [01:51<17:02,  2.91it/s, loss=0.0362, lr=0.002]\n",
      "Steps:   1%|          | 29/3000 [01:51<16:51,  2.94it/s, loss=0.113, lr=0.002] \n",
      "Steps:   1%|          | 30/3000 [01:52<16:56,  2.92it/s, loss=0.3, lr=0.002]  \n",
      "Steps:   1%|          | 31/3000 [01:52<16:49,  2.94it/s, loss=0.0813, lr=0.002]\n",
      "Steps:   1%|          | 32/3000 [01:52<16:44,  2.95it/s, loss=0.0756, lr=0.002]\n",
      "Steps:   1%|          | 33/3000 [01:53<16:41,  2.96it/s, loss=0.0951, lr=0.002]\n",
      "Steps:   1%|          | 34/3000 [01:53<17:11,  2.88it/s, loss=0.0855, lr=0.002]\n",
      "Steps:   1%|          | 35/3000 [01:53<16:55,  2.92it/s, loss=0.114, lr=0.002] \n",
      "Steps:   1%|          | 36/3000 [01:54<16:52,  2.93it/s, loss=0.0763, lr=0.002]\n",
      "Steps:   1%|          | 37/3000 [01:54<16:51,  2.93it/s, loss=0.216, lr=0.002] \n",
      "Steps:   1%|▏         | 38/3000 [01:54<16:43,  2.95it/s, loss=0.0959, lr=0.002]\n",
      "Steps:   1%|▏         | 39/3000 [01:55<16:47,  2.94it/s, loss=0.114, lr=0.002] \n",
      "Steps:   1%|▏         | 40/3000 [01:55<19:15,  2.56it/s, loss=0.0831, lr=0.002]\n",
      "Steps:   1%|▏         | 41/3000 [01:56<18:25,  2.68it/s, loss=0.203, lr=0.002] \n",
      "Steps:   1%|▏         | 42/3000 [01:56<18:05,  2.73it/s, loss=0.24, lr=0.002] \n",
      "Steps:   1%|▏         | 43/3000 [01:56<17:45,  2.77it/s, loss=0.216, lr=0.002]\n",
      "Steps:   1%|▏         | 44/3000 [01:57<17:18,  2.85it/s, loss=0.318, lr=0.002]\n",
      "Steps:   2%|▏         | 45/3000 [01:57<17:03,  2.89it/s, loss=0.069, lr=0.002]\n",
      "Steps:   2%|▏         | 46/3000 [01:57<16:51,  2.92it/s, loss=0.1, lr=0.002]  \n",
      "Steps:   2%|▏         | 47/3000 [01:58<16:51,  2.92it/s, loss=0.244, lr=0.002]\n",
      "Steps:   2%|▏         | 48/3000 [01:58<16:34,  2.97it/s, loss=0.183, lr=0.002]\n",
      "Steps:   2%|▏         | 49/3000 [01:58<16:30,  2.98it/s, loss=0.0724, lr=0.002]\n",
      "Steps:   2%|▏         | 50/3000 [01:59<16:34,  2.97it/s, loss=0.0213, lr=0.002]\n",
      "Steps:   2%|▏         | 51/3000 [01:59<16:46,  2.93it/s, loss=0.152, lr=0.002] \n",
      "Steps:   2%|▏         | 52/3000 [01:59<16:42,  2.94it/s, loss=0.161, lr=0.002]\n",
      "Steps:   2%|▏         | 53/3000 [02:00<16:31,  2.97it/s, loss=0.114, lr=0.002]\n",
      "Steps:   2%|▏         | 54/3000 [02:00<16:41,  2.94it/s, loss=0.151, lr=0.002]\n",
      "Steps:   2%|▏         | 55/3000 [02:00<16:39,  2.95it/s, loss=0.114, lr=0.002]\n",
      "Steps:   2%|▏         | 56/3000 [02:01<16:34,  2.96it/s, loss=0.166, lr=0.002]\n",
      "Steps:   2%|▏         | 57/3000 [02:01<16:38,  2.95it/s, loss=0.152, lr=0.002]\n",
      "Steps:   2%|▏         | 58/3000 [02:01<16:20,  3.00it/s, loss=0.109, lr=0.002]\n",
      "Steps:   2%|▏         | 59/3000 [02:02<16:24,  2.99it/s, loss=0.183, lr=0.002]\n",
      "Steps:   2%|▏         | 60/3000 [02:02<16:32,  2.96it/s, loss=0.197, lr=0.002]\n",
      "Steps:   2%|▏         | 61/3000 [02:02<16:22,  2.99it/s, loss=0.0248, lr=0.002]\n",
      "Steps:   2%|▏         | 62/3000 [02:03<16:21,  2.99it/s, loss=0.213, lr=0.002] \n",
      "Steps:   2%|▏         | 63/3000 [02:03<16:26,  2.98it/s, loss=0.201, lr=0.002]\n",
      "Steps:   2%|▏         | 64/3000 [02:03<16:11,  3.02it/s, loss=0.0967, lr=0.002]\n",
      "Steps:   2%|▏         | 65/3000 [02:04<16:15,  3.01it/s, loss=0.255, lr=0.002] \n",
      "Steps:   2%|▏         | 66/3000 [02:04<16:29,  2.96it/s, loss=0.125, lr=0.002]\n",
      "Steps:   2%|▏         | 67/3000 [02:04<16:32,  2.96it/s, loss=0.252, lr=0.002]\n",
      "Steps:   2%|▏         | 68/3000 [02:05<17:15,  2.83it/s, loss=0.0696, lr=0.002]\n",
      "Steps:   2%|▏         | 69/3000 [02:05<17:05,  2.86it/s, loss=0.107, lr=0.002] \n",
      "Steps:   2%|▏         | 70/3000 [02:05<16:55,  2.89it/s, loss=0.113, lr=0.002]\n",
      "Steps:   2%|▏         | 71/3000 [02:06<16:47,  2.91it/s, loss=0.253, lr=0.002]\n",
      "Steps:   2%|▏         | 72/3000 [02:06<16:39,  2.93it/s, loss=0.235, lr=0.002]\n",
      "Steps:   2%|▏         | 73/3000 [02:06<16:26,  2.97it/s, loss=0.0777, lr=0.002]\n",
      "Steps:   2%|▏         | 74/3000 [02:07<16:28,  2.96it/s, loss=0.0685, lr=0.002]\n",
      "Steps:   2%|▎         | 75/3000 [02:07<16:30,  2.95it/s, loss=0.0889, lr=0.002]\n",
      "Steps:   3%|▎         | 76/3000 [02:07<16:36,  2.93it/s, loss=0.0857, lr=0.002]\n",
      "Steps:   3%|▎         | 77/3000 [02:08<16:27,  2.96it/s, loss=0.0924, lr=0.002]\n",
      "Steps:   3%|▎         | 78/3000 [02:08<16:29,  2.95it/s, loss=0.0804, lr=0.002]\n",
      "Steps:   3%|▎         | 79/3000 [02:08<16:32,  2.94it/s, loss=0.164, lr=0.002] \n",
      "Steps:   3%|▎         | 80/3000 [02:09<16:32,  2.94it/s, loss=0.21, lr=0.002] \n",
      "Steps:   3%|▎         | 81/3000 [02:09<16:35,  2.93it/s, loss=0.245, lr=0.002]\n",
      "Steps:   3%|▎         | 82/3000 [02:09<16:35,  2.93it/s, loss=0.124, lr=0.002]\n",
      "Steps:   3%|▎         | 83/3000 [02:10<16:25,  2.96it/s, loss=0.0777, lr=0.002]\n",
      "Steps:   3%|▎         | 84/3000 [02:10<16:23,  2.96it/s, loss=0.129, lr=0.002] \n",
      "Steps:   3%|▎         | 85/3000 [02:10<16:33,  2.93it/s, loss=0.124, lr=0.002]\n",
      "Steps:   3%|▎         | 86/3000 [02:11<16:42,  2.91it/s, loss=0.122, lr=0.002]\n",
      "Steps:   3%|▎         | 87/3000 [02:11<16:35,  2.93it/s, loss=0.112, lr=0.002]\n",
      "Steps:   3%|▎         | 88/3000 [02:12<16:29,  2.94it/s, loss=0.0563, lr=0.002]\n",
      "Steps:   3%|▎         | 89/3000 [02:12<16:19,  2.97it/s, loss=0.186, lr=0.002] \n",
      "Steps:   3%|▎         | 90/3000 [02:12<16:13,  2.99it/s, loss=0.373, lr=0.002]\n",
      "Steps:   3%|▎         | 91/3000 [02:13<16:16,  2.98it/s, loss=0.0924, lr=0.002]\n",
      "Steps:   3%|▎         | 92/3000 [02:13<16:25,  2.95it/s, loss=0.0562, lr=0.002]\n",
      "Steps:   3%|▎         | 93/3000 [02:13<16:06,  3.01it/s, loss=0.139, lr=0.002] \n",
      "Steps:   3%|▎         | 94/3000 [02:14<16:35,  2.92it/s, loss=0.0903, lr=0.002]\n",
      "Steps:   3%|▎         | 95/3000 [02:14<16:35,  2.92it/s, loss=0.141, lr=0.002] \n",
      "Steps:   3%|▎         | 96/3000 [02:14<16:34,  2.92it/s, loss=0.0979, lr=0.002]\n",
      "Steps:   3%|▎         | 97/3000 [02:15<18:46,  2.58it/s, loss=0.181, lr=0.002] \n",
      "Steps:   3%|▎         | 98/3000 [02:15<18:03,  2.68it/s, loss=0.159, lr=0.002]\n",
      "Steps:   3%|▎         | 99/3000 [02:15<17:25,  2.77it/s, loss=0.0343, lr=0.002]\n",
      "Steps:   3%|▎         | 100/3000 [02:16<17:13,  2.81it/s, loss=0.202, lr=0.002] \n",
      "Steps:   3%|▎         | 101/3000 [02:16<16:49,  2.87it/s, loss=0.155, lr=0.002]\n",
      "Steps:   3%|▎         | 102/3000 [02:16<17:12,  2.81it/s, loss=0.179, lr=0.002]\n",
      "Steps:   3%|▎         | 103/3000 [02:17<17:04,  2.83it/s, loss=0.024, lr=0.002]\n",
      "Steps:   3%|▎         | 104/3000 [02:17<16:51,  2.86it/s, loss=0.185, lr=0.002]\n",
      "Steps:   4%|▎         | 105/3000 [02:17<16:29,  2.93it/s, loss=0.0317, lr=0.002]\n",
      "Steps:   4%|▎         | 106/3000 [02:18<16:32,  2.92it/s, loss=0.202, lr=0.002] \n",
      "Steps:   4%|▎         | 107/3000 [02:18<16:37,  2.90it/s, loss=0.0875, lr=0.002]\n",
      "Steps:   4%|▎         | 108/3000 [02:18<16:20,  2.95it/s, loss=0.0521, lr=0.002]\n",
      "Steps:   4%|▎         | 109/3000 [02:19<16:22,  2.94it/s, loss=0.12, lr=0.002]  \n",
      "Steps:   4%|▎         | 110/3000 [02:19<16:18,  2.95it/s, loss=0.104, lr=0.002]\n",
      "Steps:   4%|▎         | 111/3000 [02:19<16:22,  2.94it/s, loss=0.124, lr=0.002]\n",
      "Steps:   4%|▎         | 112/3000 [02:20<16:17,  2.96it/s, loss=0.153, lr=0.002]\n",
      "Steps:   4%|▍         | 113/3000 [02:20<16:21,  2.94it/s, loss=0.136, lr=0.002]\n",
      "Steps:   4%|▍         | 114/3000 [02:21<16:18,  2.95it/s, loss=0.139, lr=0.002]\n",
      "Steps:   4%|▍         | 115/3000 [02:21<16:15,  2.96it/s, loss=0.186, lr=0.002]\n",
      "Steps:   4%|▍         | 116/3000 [02:21<16:14,  2.96it/s, loss=0.145, lr=0.002]\n",
      "Steps:   4%|▍         | 117/3000 [02:22<16:18,  2.95it/s, loss=0.121, lr=0.002]\n",
      "Steps:   4%|▍         | 118/3000 [02:22<16:12,  2.96it/s, loss=0.147, lr=0.002]\n",
      "Steps:   4%|▍         | 119/3000 [02:22<16:07,  2.98it/s, loss=0.224, lr=0.002]\n",
      "Steps:   4%|▍         | 120/3000 [02:23<16:12,  2.96it/s, loss=0.0603, lr=0.002]\n",
      "Steps:   4%|▍         | 121/3000 [02:23<16:13,  2.96it/s, loss=0.0674, lr=0.002]\n",
      "Steps:   4%|▍         | 122/3000 [02:23<16:02,  2.99it/s, loss=0.0261, lr=0.002]\n",
      "Steps:   4%|▍         | 123/3000 [02:24<16:12,  2.96it/s, loss=0.155, lr=0.002] \n",
      "Steps:   4%|▍         | 124/3000 [02:24<16:18,  2.94it/s, loss=0.0326, lr=0.002]\n",
      "Steps:   4%|▍         | 125/3000 [02:24<16:07,  2.97it/s, loss=0.106, lr=0.002] \n",
      "Steps:   4%|▍         | 126/3000 [02:25<16:00,  2.99it/s, loss=0.0228, lr=0.002]\n",
      "Steps:   4%|▍         | 127/3000 [02:25<16:08,  2.97it/s, loss=0.0744, lr=0.002]\n",
      "Steps:   4%|▍         | 128/3000 [02:25<16:07,  2.97it/s, loss=0.0689, lr=0.002]\n",
      "Steps:   4%|▍         | 129/3000 [02:26<16:16,  2.94it/s, loss=0.161, lr=0.002] \n",
      "Steps:   4%|▍         | 130/3000 [02:26<16:17,  2.94it/s, loss=0.153, lr=0.002]\n",
      "Steps:   4%|▍         | 131/3000 [02:26<16:10,  2.96it/s, loss=0.0996, lr=0.002]\n",
      "Steps:   4%|▍         | 132/3000 [02:27<16:00,  2.99it/s, loss=0.162, lr=0.002] \n",
      "Steps:   4%|▍         | 133/3000 [02:27<16:02,  2.98it/s, loss=0.165, lr=0.002]\n",
      "Steps:   4%|▍         | 134/3000 [02:27<16:08,  2.96it/s, loss=0.1, lr=0.002]  \n",
      "Steps:   4%|▍         | 135/3000 [02:28<15:52,  3.01it/s, loss=0.161, lr=0.002]\n",
      "Steps:   5%|▍         | 136/3000 [02:28<15:54,  3.00it/s, loss=0.0862, lr=0.002]\n",
      "Steps:   5%|▍         | 137/3000 [02:28<15:53,  3.00it/s, loss=0.0946, lr=0.002]\n",
      "Steps:   5%|▍         | 138/3000 [02:29<15:47,  3.02it/s, loss=0.169, lr=0.002] \n",
      "Steps:   5%|▍         | 139/3000 [02:29<15:55,  3.00it/s, loss=0.108, lr=0.002]\n",
      "Steps:   5%|▍         | 140/3000 [02:29<16:01,  2.98it/s, loss=0.0302, lr=0.002]\n",
      "Steps:   5%|▍         | 141/3000 [02:30<15:52,  3.00it/s, loss=0.146, lr=0.002] \n",
      "Steps:   5%|▍         | 142/3000 [02:30<15:56,  2.99it/s, loss=0.107, lr=0.002]\n",
      "Steps:   5%|▍         | 143/3000 [02:30<15:53,  2.99it/s, loss=0.0518, lr=0.002]\n",
      "Steps:   5%|▍         | 144/3000 [02:31<15:54,  2.99it/s, loss=0.209, lr=0.002] \n",
      "Steps:   5%|▍         | 145/3000 [02:31<15:49,  3.01it/s, loss=0.0685, lr=0.002]\n",
      "Steps:   5%|▍         | 146/3000 [02:31<15:53,  2.99it/s, loss=0.196, lr=0.002] \n",
      "Steps:   5%|▍         | 147/3000 [02:32<15:49,  3.00it/s, loss=0.082, lr=0.002]\n",
      "Steps:   5%|▍         | 148/3000 [02:32<15:47,  3.01it/s, loss=0.277, lr=0.002]\n",
      "Steps:   5%|▍         | 149/3000 [02:32<15:53,  2.99it/s, loss=0.19, lr=0.002] \n",
      "Steps:   5%|▌         | 150/3000 [02:32<14:24,  3.30it/s, loss=0.26, lr=0.002]\n",
      "Steps:   5%|▌         | 151/3000 [02:33<16:13,  2.93it/s, loss=0.0878, lr=0.002]\n",
      "Steps:   5%|▌         | 152/3000 [02:33<16:03,  2.95it/s, loss=0.131, lr=0.002] \n",
      "Steps:   5%|▌         | 153/3000 [02:34<16:03,  2.96it/s, loss=0.0795, lr=0.002]\n",
      "Steps:   5%|▌         | 154/3000 [02:34<18:44,  2.53it/s, loss=0.113, lr=0.002] \n",
      "Steps:   5%|▌         | 155/3000 [02:34<17:54,  2.65it/s, loss=0.0775, lr=0.002]\n",
      "Steps:   5%|▌         | 156/3000 [02:35<17:08,  2.77it/s, loss=0.15, lr=0.002]  \n",
      "Steps:   5%|▌         | 157/3000 [02:35<16:48,  2.82it/s, loss=0.259, lr=0.002]\n",
      "Steps:   5%|▌         | 158/3000 [02:35<16:28,  2.88it/s, loss=0.164, lr=0.002]\n",
      "Steps:   5%|▌         | 159/3000 [02:36<16:17,  2.91it/s, loss=0.127, lr=0.002]\n",
      "Steps:   5%|▌         | 160/3000 [02:36<16:22,  2.89it/s, loss=0.0507, lr=0.002]\n",
      "Steps:   5%|▌         | 161/3000 [02:36<16:16,  2.91it/s, loss=0.177, lr=0.002] \n",
      "Steps:   5%|▌         | 162/3000 [02:37<16:20,  2.90it/s, loss=0.264, lr=0.002]\n",
      "Steps:   5%|▌         | 163/3000 [02:37<16:18,  2.90it/s, loss=0.131, lr=0.002]\n",
      "Steps:   5%|▌         | 164/3000 [02:37<16:14,  2.91it/s, loss=0.128, lr=0.002]\n",
      "Steps:   6%|▌         | 165/3000 [02:38<16:10,  2.92it/s, loss=0.0452, lr=0.002]\n",
      "Steps:   6%|▌         | 166/3000 [02:38<16:05,  2.93it/s, loss=0.0264, lr=0.002]\n",
      "Steps:   6%|▌         | 167/3000 [02:39<15:55,  2.97it/s, loss=0.166, lr=0.002] \n",
      "Steps:   6%|▌         | 168/3000 [02:39<16:01,  2.95it/s, loss=0.197, lr=0.002]\n",
      "Steps:   6%|▌         | 169/3000 [02:39<16:00,  2.95it/s, loss=0.144, lr=0.002]\n",
      "Steps:   6%|▌         | 170/3000 [02:40<16:04,  2.94it/s, loss=0.0802, lr=0.002]\n",
      "Steps:   6%|▌         | 171/3000 [02:40<16:02,  2.94it/s, loss=0.234, lr=0.002] \n",
      "Steps:   6%|▌         | 172/3000 [02:40<16:06,  2.93it/s, loss=0.113, lr=0.002]\n",
      "Steps:   6%|▌         | 173/3000 [02:41<16:06,  2.92it/s, loss=0.12, lr=0.002] \n",
      "Steps:   6%|▌         | 174/3000 [02:41<15:54,  2.96it/s, loss=0.0874, lr=0.002]\n",
      "Steps:   6%|▌         | 175/3000 [02:41<15:57,  2.95it/s, loss=0.143, lr=0.002] \n",
      "Steps:   6%|▌         | 176/3000 [02:42<15:41,  3.00it/s, loss=0.061, lr=0.002]\n",
      "Steps:   6%|▌         | 177/3000 [02:42<15:48,  2.98it/s, loss=0.107, lr=0.002]\n",
      "Steps:   6%|▌         | 178/3000 [02:42<15:40,  3.00it/s, loss=0.0687, lr=0.002]\n",
      "Steps:   6%|▌         | 179/3000 [02:43<15:43,  2.99it/s, loss=0.126, lr=0.002] \n",
      "Steps:   6%|▌         | 180/3000 [02:43<15:39,  3.00it/s, loss=0.121, lr=0.002]\n",
      "Steps:   6%|▌         | 181/3000 [02:43<15:44,  2.99it/s, loss=0.0236, lr=0.002]\n",
      "Steps:   6%|▌         | 182/3000 [02:44<15:50,  2.96it/s, loss=0.204, lr=0.002] \n",
      "Steps:   6%|▌         | 183/3000 [02:44<15:49,  2.97it/s, loss=0.105, lr=0.002]\n",
      "Steps:   6%|▌         | 184/3000 [02:44<15:41,  2.99it/s, loss=0.0435, lr=0.002]\n",
      "Steps:   6%|▌         | 185/3000 [02:45<15:46,  2.97it/s, loss=0.065, lr=0.002] \n",
      "Steps:   6%|▌         | 186/3000 [02:45<15:44,  2.98it/s, loss=0.135, lr=0.002]\n",
      "Steps:   6%|▌         | 187/3000 [02:45<15:37,  3.00it/s, loss=0.117, lr=0.002]\n",
      "Steps:   6%|▋         | 188/3000 [02:46<15:42,  2.98it/s, loss=0.137, lr=0.002]\n",
      "Steps:   6%|▋         | 189/3000 [02:46<15:42,  2.98it/s, loss=0.226, lr=0.002]\n",
      "Steps:   6%|▋         | 190/3000 [02:46<15:35,  3.00it/s, loss=0.173, lr=0.002]\n",
      "Steps:   6%|▋         | 191/3000 [02:47<15:33,  3.01it/s, loss=0.22, lr=0.002] \n",
      "Steps:   6%|▋         | 192/3000 [02:47<15:25,  3.03it/s, loss=0.109, lr=0.002]\n",
      "Steps:   6%|▋         | 193/3000 [02:47<15:27,  3.03it/s, loss=0.0567, lr=0.002]\n",
      "Steps:   6%|▋         | 194/3000 [02:48<15:23,  3.04it/s, loss=0.092, lr=0.002] \n",
      "Steps:   6%|▋         | 195/3000 [02:48<15:24,  3.03it/s, loss=0.0235, lr=0.002]\n",
      "Steps:   7%|▋         | 196/3000 [02:48<15:25,  3.03it/s, loss=0.0353, lr=0.002]\n",
      "Steps:   7%|▋         | 197/3000 [02:49<16:00,  2.92it/s, loss=0.187, lr=0.002] \n",
      "Steps:   7%|▋         | 198/3000 [02:49<15:44,  2.97it/s, loss=0.153, lr=0.002]\n",
      "Steps:   7%|▋         | 199/3000 [02:49<15:48,  2.95it/s, loss=0.28, lr=0.002] \n",
      "Steps:   7%|▋         | 200/3000 [02:50<15:39,  2.98it/s, loss=0.0988, lr=0.002]\n",
      "Steps:   7%|▋         | 201/3000 [02:50<15:35,  2.99it/s, loss=0.13, lr=0.002]  \n",
      "Steps:   7%|▋         | 202/3000 [02:50<15:44,  2.96it/s, loss=0.303, lr=0.002]\n",
      "Steps:   7%|▋         | 203/3000 [02:51<15:39,  2.98it/s, loss=0.139, lr=0.002]\n",
      "Steps:   7%|▋         | 204/3000 [02:51<15:39,  2.98it/s, loss=0.0891, lr=0.002]\n",
      "Steps:   7%|▋         | 205/3000 [02:51<15:29,  3.01it/s, loss=0.208, lr=0.002] \n",
      "Steps:   7%|▋         | 206/3000 [02:52<15:25,  3.02it/s, loss=0.0722, lr=0.002]\n",
      "Steps:   7%|▋         | 207/3000 [02:52<15:37,  2.98it/s, loss=0.124, lr=0.002] \n",
      "Steps:   7%|▋         | 208/3000 [02:52<15:27,  3.01it/s, loss=0.176, lr=0.002]\n",
      "Steps:   7%|▋         | 209/3000 [02:53<15:30,  3.00it/s, loss=0.203, lr=0.002]\n",
      "Steps:   7%|▋         | 210/3000 [02:53<15:25,  3.01it/s, loss=0.0533, lr=0.002]\n",
      "Steps:   7%|▋         | 211/3000 [02:53<17:30,  2.66it/s, loss=0.168, lr=0.002] \n",
      "Steps:   7%|▋         | 212/3000 [02:54<16:54,  2.75it/s, loss=0.117, lr=0.002]\n",
      "Steps:   7%|▋         | 213/3000 [02:54<16:29,  2.82it/s, loss=0.163, lr=0.002]\n",
      "Steps:   7%|▋         | 214/3000 [02:54<16:27,  2.82it/s, loss=0.0223, lr=0.002]\n",
      "Steps:   7%|▋         | 215/3000 [02:55<16:11,  2.87it/s, loss=0.0248, lr=0.002]\n",
      "Steps:   7%|▋         | 216/3000 [02:55<15:56,  2.91it/s, loss=0.117, lr=0.002] \n",
      "Steps:   7%|▋         | 217/3000 [02:55<15:40,  2.96it/s, loss=0.063, lr=0.002]\n",
      "Steps:   7%|▋         | 218/3000 [02:56<15:33,  2.98it/s, loss=0.147, lr=0.002]\n",
      "Steps:   7%|▋         | 219/3000 [02:56<15:34,  2.98it/s, loss=0.123, lr=0.002]\n",
      "Steps:   7%|▋         | 220/3000 [02:56<15:34,  2.98it/s, loss=0.16, lr=0.002] \n",
      "Steps:   7%|▋         | 221/3000 [02:57<15:39,  2.96it/s, loss=0.181, lr=0.002]\n",
      "Steps:   7%|▋         | 222/3000 [02:57<15:39,  2.96it/s, loss=0.17, lr=0.002] \n",
      "Steps:   7%|▋         | 223/3000 [02:57<15:46,  2.93it/s, loss=0.198, lr=0.002]\n",
      "Steps:   7%|▋         | 224/3000 [02:58<15:42,  2.95it/s, loss=0.273, lr=0.002]\n",
      "Steps:   8%|▊         | 225/3000 [02:58<15:43,  2.94it/s, loss=0.102, lr=0.002]\n",
      "Steps:   8%|▊         | 226/3000 [02:58<15:26,  3.00it/s, loss=0.076, lr=0.002]\n",
      "Steps:   8%|▊         | 227/3000 [02:59<15:34,  2.97it/s, loss=0.14, lr=0.002] \n",
      "Steps:   8%|▊         | 228/3000 [02:59<15:30,  2.98it/s, loss=0.18, lr=0.002]\n",
      "Steps:   8%|▊         | 229/3000 [02:59<15:31,  2.97it/s, loss=0.177, lr=0.002]\n",
      "Steps:   8%|▊         | 230/3000 [03:00<15:35,  2.96it/s, loss=0.12, lr=0.002] \n",
      "Steps:   8%|▊         | 231/3000 [03:00<15:42,  2.94it/s, loss=0.153, lr=0.002]\n",
      "Steps:   8%|▊         | 232/3000 [03:00<15:34,  2.96it/s, loss=0.0385, lr=0.002]\n",
      "Steps:   8%|▊         | 233/3000 [03:01<15:34,  2.96it/s, loss=0.135, lr=0.002] \n",
      "Steps:   8%|▊         | 234/3000 [03:01<15:24,  2.99it/s, loss=0.195, lr=0.002]\n",
      "Steps:   8%|▊         | 235/3000 [03:01<15:28,  2.98it/s, loss=0.144, lr=0.002]\n",
      "Steps:   8%|▊         | 236/3000 [03:02<15:27,  2.98it/s, loss=0.136, lr=0.002]\n",
      "Steps:   8%|▊         | 237/3000 [03:02<15:26,  2.98it/s, loss=0.176, lr=0.002]\n",
      "Steps:   8%|▊         | 238/3000 [03:02<15:21,  3.00it/s, loss=0.206, lr=0.002]\n",
      "Steps:   8%|▊         | 239/3000 [03:03<15:17,  3.01it/s, loss=0.14, lr=0.002] \n",
      "Steps:   8%|▊         | 240/3000 [03:03<15:44,  2.92it/s, loss=0.0854, lr=0.002]\n",
      "Steps:   8%|▊         | 241/3000 [03:04<15:43,  2.92it/s, loss=0.102, lr=0.002] \n",
      "Steps:   8%|▊         | 242/3000 [03:04<15:31,  2.96it/s, loss=0.161, lr=0.002]\n",
      "Steps:   8%|▊         | 243/3000 [03:04<15:26,  2.98it/s, loss=0.165, lr=0.002]\n",
      "Steps:   8%|▊         | 244/3000 [03:05<15:32,  2.96it/s, loss=0.103, lr=0.002]\n",
      "Steps:   8%|▊         | 245/3000 [03:05<15:33,  2.95it/s, loss=0.336, lr=0.002]\n",
      "Steps:   8%|▊         | 246/3000 [03:05<15:18,  3.00it/s, loss=0.184, lr=0.002]\n",
      "Steps:   8%|▊         | 247/3000 [03:05<15:06,  3.04it/s, loss=0.151, lr=0.002]\n",
      "Steps:   8%|▊         | 248/3000 [03:06<15:18,  3.00it/s, loss=0.121, lr=0.002]\n",
      "Steps:   8%|▊         | 249/3000 [03:06<15:28,  2.96it/s, loss=0.236, lr=0.002]\n",
      "Steps:   8%|▊         | 250/3000 [03:07<15:22,  2.98it/s, loss=0.134, lr=0.002]\n",
      "Steps:   8%|▊         | 251/3000 [03:07<15:30,  2.95it/s, loss=0.176, lr=0.002]\n",
      "Steps:   8%|▊         | 252/3000 [03:07<15:30,  2.95it/s, loss=0.116, lr=0.002]\n",
      "Steps:   8%|▊         | 253/3000 [03:08<15:17,  3.00it/s, loss=0.256, lr=0.002]\n",
      "Steps:   8%|▊         | 254/3000 [03:08<15:06,  3.03it/s, loss=0.173, lr=0.002]\n",
      "Steps:   8%|▊         | 255/3000 [03:08<15:10,  3.01it/s, loss=0.074, lr=0.002]\n",
      "Steps:   9%|▊         | 256/3000 [03:09<15:13,  3.00it/s, loss=0.0693, lr=0.002]\n",
      "Steps:   9%|▊         | 257/3000 [03:09<15:20,  2.98it/s, loss=0.117, lr=0.002] \n",
      "Steps:   9%|▊         | 258/3000 [03:09<15:16,  2.99it/s, loss=0.0997, lr=0.002]\n",
      "Steps:   9%|▊         | 259/3000 [03:10<15:12,  3.01it/s, loss=0.0779, lr=0.002]\n",
      "Steps:   9%|▊         | 260/3000 [03:10<15:12,  3.00it/s, loss=0.115, lr=0.002] \n",
      "Steps:   9%|▊         | 261/3000 [03:10<15:11,  3.00it/s, loss=0.154, lr=0.002]\n",
      "Steps:   9%|▊         | 262/3000 [03:11<15:11,  3.01it/s, loss=0.126, lr=0.002]\n",
      "Steps:   9%|▉         | 263/3000 [03:11<15:05,  3.02it/s, loss=0.261, lr=0.002]\n",
      "Steps:   9%|▉         | 264/3000 [03:11<15:07,  3.01it/s, loss=0.102, lr=0.002]\n",
      "Steps:   9%|▉         | 265/3000 [03:11<14:57,  3.05it/s, loss=0.279, lr=0.002]\n",
      "Steps:   9%|▉         | 266/3000 [03:12<15:08,  3.01it/s, loss=0.139, lr=0.002]\n",
      "Steps:   9%|▉         | 267/3000 [03:12<15:12,  2.99it/s, loss=0.112, lr=0.002]\n",
      "Steps:   9%|▉         | 268/3000 [03:13<16:46,  2.72it/s, loss=0.184, lr=0.002]\n",
      "Steps:   9%|▉         | 269/3000 [03:13<16:23,  2.78it/s, loss=0.203, lr=0.002]\n",
      "Steps:   9%|▉         | 270/3000 [03:13<15:52,  2.87it/s, loss=0.146, lr=0.002]\n",
      "Steps:   9%|▉         | 271/3000 [03:14<15:36,  2.91it/s, loss=0.183, lr=0.002]\n",
      "Steps:   9%|▉         | 272/3000 [03:14<15:29,  2.93it/s, loss=0.136, lr=0.002]\n",
      "Steps:   9%|▉         | 273/3000 [03:14<15:26,  2.94it/s, loss=0.165, lr=0.002]\n",
      "Steps:   9%|▉         | 274/3000 [03:15<15:25,  2.95it/s, loss=0.237, lr=0.002]\n",
      "Steps:   9%|▉         | 275/3000 [03:15<15:27,  2.94it/s, loss=0.0667, lr=0.002]\n",
      "Steps:   9%|▉         | 276/3000 [03:15<15:18,  2.97it/s, loss=0.169, lr=0.002] \n",
      "Steps:   9%|▉         | 277/3000 [03:16<15:14,  2.98it/s, loss=0.23, lr=0.002] \n",
      "Steps:   9%|▉         | 278/3000 [03:16<15:06,  3.00it/s, loss=0.167, lr=0.002]\n",
      "Steps:   9%|▉         | 279/3000 [03:16<15:13,  2.98it/s, loss=0.0954, lr=0.002]\n",
      "Steps:   9%|▉         | 280/3000 [03:17<15:12,  2.98it/s, loss=0.0378, lr=0.002]\n",
      "Steps:   9%|▉         | 281/3000 [03:17<15:06,  3.00it/s, loss=0.14, lr=0.002]  \n",
      "Steps:   9%|▉         | 282/3000 [03:17<15:12,  2.98it/s, loss=0.116, lr=0.002]\n",
      "Steps:   9%|▉         | 283/3000 [03:18<15:02,  3.01it/s, loss=0.118, lr=0.002]\n",
      "Steps:   9%|▉         | 284/3000 [03:18<15:00,  3.02it/s, loss=0.213, lr=0.002]\n",
      "Steps:  10%|▉         | 285/3000 [03:18<15:02,  3.01it/s, loss=0.18, lr=0.002] \n",
      "Steps:  10%|▉         | 286/3000 [03:19<15:02,  3.01it/s, loss=0.0584, lr=0.002]\n",
      "Steps:  10%|▉         | 287/3000 [03:19<15:06,  2.99it/s, loss=0.108, lr=0.002] \n",
      "Steps:  10%|▉         | 288/3000 [03:19<14:50,  3.05it/s, loss=0.248, lr=0.002]\n",
      "Steps:  10%|▉         | 289/3000 [03:20<14:50,  3.04it/s, loss=0.101, lr=0.002]\n",
      "Steps:  10%|▉         | 290/3000 [03:20<14:59,  3.01it/s, loss=0.141, lr=0.002]\n",
      "Steps:  10%|▉         | 291/3000 [03:20<14:58,  3.01it/s, loss=0.228, lr=0.002]\n",
      "Steps:  10%|▉         | 292/3000 [03:21<15:03,  3.00it/s, loss=0.204, lr=0.002]\n",
      "Steps:  10%|▉         | 293/3000 [03:21<15:04,  2.99it/s, loss=0.266, lr=0.002]\n",
      "Steps:  10%|▉         | 294/3000 [03:21<15:04,  2.99it/s, loss=0.143, lr=0.002]\n",
      "Steps:  10%|▉         | 295/3000 [03:22<14:58,  3.01it/s, loss=0.13, lr=0.002] \n",
      "Steps:  10%|▉         | 296/3000 [03:22<15:07,  2.98it/s, loss=0.076, lr=0.002]\n",
      "Steps:  10%|▉         | 297/3000 [03:22<15:01,  3.00it/s, loss=0.303, lr=0.002]\n",
      "Steps:  10%|▉         | 298/3000 [03:23<15:01,  3.00it/s, loss=0.132, lr=0.002]\n",
      "Steps:  10%|▉         | 299/3000 [03:23<15:10,  2.97it/s, loss=0.11, lr=0.002] \n",
      "Steps:  10%|█         | 300/3000 [03:23<13:43,  3.28it/s, loss=0.0883, lr=0.002]\n",
      "Steps:  10%|█         | 301/3000 [03:24<15:52,  2.83it/s, loss=0.101, lr=0.002] \n",
      "Steps:  10%|█         | 302/3000 [03:24<15:39,  2.87it/s, loss=0.0798, lr=0.002]\n",
      "Steps:  10%|█         | 303/3000 [03:24<15:26,  2.91it/s, loss=0.178, lr=0.002] \n",
      "Steps:  10%|█         | 304/3000 [03:25<15:18,  2.94it/s, loss=0.0894, lr=0.002]\n",
      "Steps:  10%|█         | 305/3000 [03:25<15:22,  2.92it/s, loss=0.089, lr=0.002] \n",
      "Steps:  10%|█         | 306/3000 [03:25<15:17,  2.94it/s, loss=0.11, lr=0.002] \n",
      "Steps:  10%|█         | 307/3000 [03:26<15:07,  2.97it/s, loss=0.107, lr=0.002]\n",
      "Steps:  10%|█         | 308/3000 [03:26<15:05,  2.97it/s, loss=0.0594, lr=0.002]\n",
      "Steps:  10%|█         | 309/3000 [03:26<15:01,  2.99it/s, loss=0.107, lr=0.002] \n",
      "Steps:  10%|█         | 310/3000 [03:27<15:01,  2.98it/s, loss=0.071, lr=0.002]\n",
      "Steps:  10%|█         | 311/3000 [03:27<15:05,  2.97it/s, loss=0.144, lr=0.002]\n",
      "Steps:  10%|█         | 312/3000 [03:27<15:12,  2.95it/s, loss=0.123, lr=0.002]\n",
      "Steps:  10%|█         | 313/3000 [03:28<15:05,  2.97it/s, loss=0.177, lr=0.002]\n",
      "Steps:  10%|█         | 314/3000 [03:28<15:00,  2.98it/s, loss=0.0646, lr=0.002]\n",
      "Steps:  10%|█         | 315/3000 [03:28<14:57,  2.99it/s, loss=0.0225, lr=0.002]\n",
      "Steps:  11%|█         | 316/3000 [03:29<14:48,  3.02it/s, loss=0.0576, lr=0.002]\n",
      "Steps:  11%|█         | 317/3000 [03:29<14:58,  2.99it/s, loss=0.113, lr=0.002] \n",
      "Steps:  11%|█         | 318/3000 [03:29<14:52,  3.00it/s, loss=0.111, lr=0.002]\n",
      "Steps:  11%|█         | 319/3000 [03:30<14:58,  2.98it/s, loss=0.106, lr=0.002]\n",
      "Steps:  11%|█         | 320/3000 [03:30<14:56,  2.99it/s, loss=0.21, lr=0.002] \n",
      "Steps:  11%|█         | 321/3000 [03:30<14:47,  3.02it/s, loss=0.137, lr=0.002]\n",
      "Steps:  11%|█         | 322/3000 [03:31<14:52,  3.00it/s, loss=0.109, lr=0.002]\n",
      "Steps:  11%|█         | 323/3000 [03:31<14:47,  3.02it/s, loss=0.128, lr=0.002]\n",
      "Steps:  11%|█         | 324/3000 [03:31<14:41,  3.04it/s, loss=0.183, lr=0.002]\n",
      "Steps:  11%|█         | 325/3000 [03:32<16:22,  2.72it/s, loss=0.185, lr=0.002]\n",
      "Steps:  11%|█         | 326/3000 [03:32<16:00,  2.78it/s, loss=0.155, lr=0.002]\n",
      "Steps:  11%|█         | 327/3000 [03:32<15:50,  2.81it/s, loss=0.2, lr=0.002]  \n",
      "Steps:  11%|█         | 328/3000 [03:33<15:37,  2.85it/s, loss=0.127, lr=0.002]\n",
      "Steps:  11%|█         | 329/3000 [03:33<15:31,  2.87it/s, loss=0.105, lr=0.002]\n",
      "Steps:  11%|█         | 330/3000 [03:33<15:10,  2.93it/s, loss=0.149, lr=0.002]\n",
      "Steps:  11%|█         | 331/3000 [03:34<15:06,  2.94it/s, loss=0.0372, lr=0.002]\n",
      "Steps:  11%|█         | 332/3000 [03:34<14:58,  2.97it/s, loss=0.0872, lr=0.002]\n",
      "Steps:  11%|█         | 333/3000 [03:34<15:04,  2.95it/s, loss=0.0749, lr=0.002]\n",
      "Steps:  11%|█         | 334/3000 [03:35<15:05,  2.94it/s, loss=0.182, lr=0.002] \n",
      "Steps:  11%|█         | 335/3000 [03:35<14:58,  2.97it/s, loss=0.153, lr=0.002]\n",
      "Steps:  11%|█         | 336/3000 [03:36<14:54,  2.98it/s, loss=0.158, lr=0.002]\n",
      "Steps:  11%|█         | 337/3000 [03:36<15:03,  2.95it/s, loss=0.0779, lr=0.002]\n",
      "Steps:  11%|█▏        | 338/3000 [03:36<15:00,  2.95it/s, loss=0.222, lr=0.002] \n",
      "Steps:  11%|█▏        | 339/3000 [03:37<14:53,  2.98it/s, loss=0.0557, lr=0.002]\n",
      "Steps:  11%|█▏        | 340/3000 [03:37<14:56,  2.97it/s, loss=0.0964, lr=0.002]\n",
      "Steps:  11%|█▏        | 341/3000 [03:37<15:01,  2.95it/s, loss=0.148, lr=0.002] \n",
      "Steps:  11%|█▏        | 342/3000 [03:38<14:53,  2.97it/s, loss=0.16, lr=0.002] \n",
      "Steps:  11%|█▏        | 343/3000 [03:38<14:58,  2.96it/s, loss=0.129, lr=0.002]\n",
      "Steps:  11%|█▏        | 344/3000 [03:38<14:55,  2.97it/s, loss=0.148, lr=0.002]\n",
      "Steps:  12%|█▏        | 345/3000 [03:39<14:49,  2.99it/s, loss=0.212, lr=0.002]\n",
      "Steps:  12%|█▏        | 346/3000 [03:39<14:42,  3.01it/s, loss=0.125, lr=0.002]\n",
      "Steps:  12%|█▏        | 347/3000 [03:39<14:49,  2.98it/s, loss=0.149, lr=0.002]\n",
      "Steps:  12%|█▏        | 348/3000 [03:40<14:52,  2.97it/s, loss=0.2, lr=0.002]  \n",
      "Steps:  12%|█▏        | 349/3000 [03:40<14:50,  2.98it/s, loss=0.211, lr=0.002]\n",
      "Steps:  12%|█▏        | 350/3000 [03:40<14:46,  2.99it/s, loss=0.11, lr=0.002] \n",
      "Steps:  12%|█▏        | 351/3000 [03:41<14:37,  3.02it/s, loss=0.101, lr=0.002]\n",
      "Steps:  12%|█▏        | 352/3000 [03:41<14:45,  2.99it/s, loss=0.0918, lr=0.002]\n",
      "Steps:  12%|█▏        | 353/3000 [03:41<15:12,  2.90it/s, loss=0.0781, lr=0.002]\n",
      "Steps:  12%|█▏        | 354/3000 [03:42<14:55,  2.96it/s, loss=0.196, lr=0.002] \n",
      "Steps:  12%|█▏        | 355/3000 [03:42<14:53,  2.96it/s, loss=0.0928, lr=0.002]\n",
      "Steps:  12%|█▏        | 356/3000 [03:42<14:56,  2.95it/s, loss=0.0962, lr=0.002]\n",
      "Steps:  12%|█▏        | 357/3000 [03:43<14:45,  2.98it/s, loss=0.0791, lr=0.002]\n",
      "Steps:  12%|█▏        | 358/3000 [03:43<14:51,  2.96it/s, loss=0.0622, lr=0.002]\n",
      "Steps:  12%|█▏        | 359/3000 [03:43<14:44,  2.99it/s, loss=0.306, lr=0.002] \n",
      "Steps:  12%|█▏        | 360/3000 [03:44<14:40,  3.00it/s, loss=0.107, lr=0.002]\n",
      "Steps:  12%|█▏        | 361/3000 [03:44<14:45,  2.98it/s, loss=0.123, lr=0.002]\n",
      "Steps:  12%|█▏        | 362/3000 [03:44<14:44,  2.98it/s, loss=0.169, lr=0.002]\n",
      "Steps:  12%|█▏        | 363/3000 [03:45<14:47,  2.97it/s, loss=0.0258, lr=0.002]\n",
      "Steps:  12%|█▏        | 364/3000 [03:45<14:49,  2.96it/s, loss=0.235, lr=0.002] \n",
      "Steps:  12%|█▏        | 365/3000 [03:45<14:49,  2.96it/s, loss=0.107, lr=0.002]\n",
      "Steps:  12%|█▏        | 366/3000 [03:46<14:45,  2.98it/s, loss=0.0831, lr=0.002]\n",
      "Steps:  12%|█▏        | 367/3000 [03:46<14:42,  2.98it/s, loss=0.181, lr=0.002] \n",
      "Steps:  12%|█▏        | 368/3000 [03:46<14:30,  3.02it/s, loss=0.162, lr=0.002]\n",
      "Steps:  12%|█▏        | 369/3000 [03:47<14:38,  2.99it/s, loss=0.12, lr=0.002] \n",
      "Steps:  12%|█▏        | 370/3000 [03:47<14:37,  3.00it/s, loss=0.0703, lr=0.002]\n",
      "Steps:  12%|█▏        | 371/3000 [03:47<14:45,  2.97it/s, loss=0.169, lr=0.002] \n",
      "Steps:  12%|█▏        | 372/3000 [03:48<14:47,  2.96it/s, loss=0.23, lr=0.002] \n",
      "Steps:  12%|█▏        | 373/3000 [03:48<14:51,  2.95it/s, loss=0.108, lr=0.002]\n",
      "Steps:  12%|█▏        | 374/3000 [03:48<14:54,  2.94it/s, loss=0.144, lr=0.002]\n",
      "Steps:  12%|█▎        | 375/3000 [03:49<14:47,  2.96it/s, loss=0.129, lr=0.002]\n",
      "Steps:  13%|█▎        | 376/3000 [03:49<14:38,  2.99it/s, loss=0.0919, lr=0.002]\n",
      "Steps:  13%|█▎        | 377/3000 [03:49<14:41,  2.97it/s, loss=0.152, lr=0.002] \n",
      "Steps:  13%|█▎        | 378/3000 [03:50<14:47,  2.95it/s, loss=0.0703, lr=0.002]\n",
      "Steps:  13%|█▎        | 379/3000 [03:50<15:17,  2.86it/s, loss=0.0899, lr=0.002]\n",
      "Steps:  13%|█▎        | 380/3000 [03:50<15:09,  2.88it/s, loss=0.256, lr=0.002] \n",
      "Steps:  13%|█▎        | 381/3000 [03:51<14:58,  2.92it/s, loss=0.0608, lr=0.002]\n",
      "Steps:  13%|█▎        | 382/3000 [03:51<16:44,  2.61it/s, loss=0.0775, lr=0.002]\n",
      "Steps:  13%|█▎        | 383/3000 [03:52<16:07,  2.70it/s, loss=0.0778, lr=0.002]\n",
      "Steps:  13%|█▎        | 384/3000 [03:52<15:52,  2.75it/s, loss=0.0284, lr=0.002]\n",
      "Steps:  13%|█▎        | 385/3000 [03:52<15:36,  2.79it/s, loss=0.0975, lr=0.002]\n",
      "Steps:  13%|█▎        | 386/3000 [03:53<15:21,  2.84it/s, loss=0.16, lr=0.002]  \n",
      "Steps:  13%|█▎        | 387/3000 [03:53<15:11,  2.87it/s, loss=0.207, lr=0.002]\n",
      "Steps:  13%|█▎        | 388/3000 [03:53<15:01,  2.90it/s, loss=0.108, lr=0.002]\n",
      "Steps:  13%|█▎        | 389/3000 [03:54<14:49,  2.93it/s, loss=0.119, lr=0.002]\n",
      "Steps:  13%|█▎        | 390/3000 [03:54<14:51,  2.93it/s, loss=0.296, lr=0.002]\n",
      "Steps:  13%|█▎        | 391/3000 [03:54<14:38,  2.97it/s, loss=0.0831, lr=0.002]\n",
      "Steps:  13%|█▎        | 392/3000 [03:55<14:27,  3.00it/s, loss=0.131, lr=0.002] \n",
      "Steps:  13%|█▎        | 393/3000 [03:55<14:29,  3.00it/s, loss=0.0646, lr=0.002]\n",
      "Steps:  13%|█▎        | 394/3000 [03:55<14:39,  2.96it/s, loss=0.0973, lr=0.002]\n",
      "Steps:  13%|█▎        | 395/3000 [03:56<14:38,  2.97it/s, loss=0.114, lr=0.002] \n",
      "Steps:  13%|█▎        | 396/3000 [03:56<14:57,  2.90it/s, loss=0.221, lr=0.002]\n",
      "Steps:  13%|█▎        | 397/3000 [03:56<14:56,  2.90it/s, loss=0.183, lr=0.002]\n",
      "Steps:  13%|█▎        | 398/3000 [03:57<14:51,  2.92it/s, loss=0.127, lr=0.002]\n",
      "Steps:  13%|█▎        | 399/3000 [03:57<14:54,  2.91it/s, loss=0.179, lr=0.002]\n",
      "Steps:  13%|█▎        | 400/3000 [03:57<14:41,  2.95it/s, loss=0.309, lr=0.002]\n",
      "Steps:  13%|█▎        | 401/3000 [03:58<14:40,  2.95it/s, loss=0.0993, lr=0.002]\n",
      "Steps:  13%|█▎        | 402/3000 [03:58<14:39,  2.95it/s, loss=0.275, lr=0.002] \n",
      "Steps:  13%|█▎        | 403/3000 [03:58<14:35,  2.97it/s, loss=0.0911, lr=0.002]\n",
      "Steps:  13%|█▎        | 404/3000 [03:59<14:27,  2.99it/s, loss=0.119, lr=0.002] \n",
      "Steps:  14%|█▎        | 405/3000 [03:59<14:33,  2.97it/s, loss=0.0541, lr=0.002]\n",
      "Steps:  14%|█▎        | 406/3000 [03:59<14:23,  3.00it/s, loss=0.0742, lr=0.002]\n",
      "Steps:  14%|█▎        | 407/3000 [04:00<14:26,  2.99it/s, loss=0.112, lr=0.002] \n",
      "Steps:  14%|█▎        | 408/3000 [04:00<14:24,  3.00it/s, loss=0.263, lr=0.002]\n",
      "Steps:  14%|█▎        | 409/3000 [04:00<14:22,  3.00it/s, loss=0.12, lr=0.002] \n",
      "Steps:  14%|█▎        | 410/3000 [04:01<14:22,  3.00it/s, loss=0.0984, lr=0.002]\n",
      "Steps:  14%|█▎        | 411/3000 [04:01<14:13,  3.03it/s, loss=0.271, lr=0.002] \n",
      "Steps:  14%|█▎        | 412/3000 [04:01<14:13,  3.03it/s, loss=0.0924, lr=0.002]\n",
      "Steps:  14%|█▍        | 413/3000 [04:02<14:15,  3.02it/s, loss=0.176, lr=0.002] \n",
      "Steps:  14%|█▍        | 414/3000 [04:02<14:22,  3.00it/s, loss=0.14, lr=0.002] \n",
      "Steps:  14%|█▍        | 415/3000 [04:02<14:07,  3.05it/s, loss=0.126, lr=0.002]\n",
      "Steps:  14%|█▍        | 416/3000 [04:03<14:08,  3.05it/s, loss=0.117, lr=0.002]\n",
      "Steps:  14%|█▍        | 417/3000 [04:03<14:14,  3.02it/s, loss=0.0882, lr=0.002]\n",
      "Steps:  14%|█▍        | 418/3000 [04:03<14:19,  3.00it/s, loss=0.164, lr=0.002] \n",
      "Steps:  14%|█▍        | 419/3000 [04:04<14:20,  3.00it/s, loss=0.129, lr=0.002]\n",
      "Steps:  14%|█▍        | 420/3000 [04:04<14:31,  2.96it/s, loss=0.0827, lr=0.002]\n",
      "Steps:  14%|█▍        | 421/3000 [04:04<14:27,  2.97it/s, loss=0.0465, lr=0.002]\n",
      "Steps:  14%|█▍        | 422/3000 [04:05<14:23,  2.98it/s, loss=0.0935, lr=0.002]\n",
      "Steps:  14%|█▍        | 423/3000 [04:05<14:31,  2.96it/s, loss=0.11, lr=0.002]  \n",
      "Steps:  14%|█▍        | 424/3000 [04:05<14:23,  2.98it/s, loss=0.207, lr=0.002]\n",
      "Steps:  14%|█▍        | 425/3000 [04:06<14:19,  3.00it/s, loss=0.0826, lr=0.002]\n",
      "Steps:  14%|█▍        | 426/3000 [04:06<14:29,  2.96it/s, loss=0.139, lr=0.002] \n",
      "Steps:  14%|█▍        | 427/3000 [04:06<14:28,  2.96it/s, loss=0.139, lr=0.002]\n",
      "Steps:  14%|█▍        | 428/3000 [04:07<14:28,  2.96it/s, loss=0.142, lr=0.002]\n",
      "Steps:  14%|█▍        | 429/3000 [04:07<14:21,  2.98it/s, loss=0.1, lr=0.002]  \n",
      "Steps:  14%|█▍        | 430/3000 [04:07<14:28,  2.96it/s, loss=0.16, lr=0.002]\n",
      "Steps:  14%|█▍        | 431/3000 [04:08<14:40,  2.92it/s, loss=0.104, lr=0.002]\n",
      "Steps:  14%|█▍        | 432/3000 [04:08<14:33,  2.94it/s, loss=0.109, lr=0.002]\n",
      "Steps:  14%|█▍        | 433/3000 [04:08<14:28,  2.96it/s, loss=0.0401, lr=0.002]\n",
      "Steps:  14%|█▍        | 434/3000 [04:09<14:20,  2.98it/s, loss=0.127, lr=0.002] \n",
      "Steps:  14%|█▍        | 435/3000 [04:09<14:20,  2.98it/s, loss=0.187, lr=0.002]\n",
      "Steps:  15%|█▍        | 436/3000 [04:09<14:26,  2.96it/s, loss=0.111, lr=0.002]\n",
      "Steps:  15%|█▍        | 437/3000 [04:10<14:26,  2.96it/s, loss=0.125, lr=0.002]\n",
      "Steps:  15%|█▍        | 438/3000 [04:10<14:28,  2.95it/s, loss=0.189, lr=0.002]\n",
      "Steps:  15%|█▍        | 439/3000 [04:11<16:22,  2.61it/s, loss=0.103, lr=0.002]\n",
      "Steps:  15%|█▍        | 440/3000 [04:11<15:52,  2.69it/s, loss=0.218, lr=0.002]\n",
      "Steps:  15%|█▍        | 441/3000 [04:11<15:21,  2.78it/s, loss=0.139, lr=0.002]\n",
      "Steps:  15%|█▍        | 442/3000 [04:12<15:03,  2.83it/s, loss=0.059, lr=0.002]\n",
      "Steps:  15%|█▍        | 443/3000 [04:12<14:39,  2.91it/s, loss=0.168, lr=0.002]\n",
      "Steps:  15%|█▍        | 444/3000 [04:12<14:32,  2.93it/s, loss=0.141, lr=0.002]\n",
      "Steps:  15%|█▍        | 445/3000 [04:13<14:27,  2.95it/s, loss=0.0869, lr=0.002]\n",
      "Steps:  15%|█▍        | 446/3000 [04:13<14:25,  2.95it/s, loss=0.234, lr=0.002] \n",
      "Steps:  15%|█▍        | 447/3000 [04:13<14:19,  2.97it/s, loss=0.0732, lr=0.002]\n",
      "Steps:  15%|█▍        | 448/3000 [04:14<14:20,  2.96it/s, loss=0.0875, lr=0.002]\n",
      "Steps:  15%|█▍        | 449/3000 [04:14<14:22,  2.96it/s, loss=0.223, lr=0.002] \n",
      "Steps:  15%|█▌        | 450/3000 [04:14<12:59,  3.27it/s, loss=0.197, lr=0.002]\n",
      "Steps:  15%|█▌        | 451/3000 [04:15<14:45,  2.88it/s, loss=0.0855, lr=0.002]\n",
      "Steps:  15%|█▌        | 452/3000 [04:15<14:34,  2.91it/s, loss=0.256, lr=0.002] \n",
      "Steps:  15%|█▌        | 453/3000 [04:15<14:29,  2.93it/s, loss=0.065, lr=0.002]\n",
      "Steps:  15%|█▌        | 454/3000 [04:16<14:09,  3.00it/s, loss=0.144, lr=0.002]\n",
      "Steps:  15%|█▌        | 455/3000 [04:16<14:13,  2.98it/s, loss=0.0862, lr=0.002]\n",
      "Steps:  15%|█▌        | 456/3000 [04:16<14:15,  2.97it/s, loss=0.122, lr=0.002] \n",
      "Steps:  15%|█▌        | 457/3000 [04:17<14:09,  2.99it/s, loss=0.0717, lr=0.002]\n",
      "Steps:  15%|█▌        | 458/3000 [04:17<14:03,  3.01it/s, loss=0.254, lr=0.002] \n",
      "Steps:  15%|█▌        | 459/3000 [04:17<14:07,  3.00it/s, loss=0.107, lr=0.002]\n",
      "Steps:  15%|█▌        | 460/3000 [04:18<14:07,  3.00it/s, loss=0.158, lr=0.002]\n",
      "Steps:  15%|█▌        | 461/3000 [04:18<14:10,  2.98it/s, loss=0.163, lr=0.002]\n",
      "Steps:  15%|█▌        | 462/3000 [04:18<14:05,  3.00it/s, loss=0.0177, lr=0.002]\n",
      "Steps:  15%|█▌        | 463/3000 [04:19<14:08,  2.99it/s, loss=0.0876, lr=0.002]\n",
      "Steps:  15%|█▌        | 464/3000 [04:19<14:15,  2.96it/s, loss=0.13, lr=0.002]  \n",
      "Steps:  16%|█▌        | 465/3000 [04:19<14:09,  2.98it/s, loss=0.0305, lr=0.002]\n",
      "Steps:  16%|█▌        | 466/3000 [04:20<14:09,  2.98it/s, loss=0.243, lr=0.002] \n",
      "Steps:  16%|█▌        | 467/3000 [04:20<14:10,  2.98it/s, loss=0.0213, lr=0.002]\n",
      "Steps:  16%|█▌        | 468/3000 [04:20<14:18,  2.95it/s, loss=0.1, lr=0.002]   \n",
      "Steps:  16%|█▌        | 469/3000 [04:21<14:20,  2.94it/s, loss=0.0792, lr=0.002]\n",
      "Steps:  16%|█▌        | 470/3000 [04:21<14:14,  2.96it/s, loss=0.0985, lr=0.002]\n",
      "Steps:  16%|█▌        | 471/3000 [04:21<14:10,  2.97it/s, loss=0.163, lr=0.002] \n",
      "Steps:  16%|█▌        | 472/3000 [04:22<14:06,  2.98it/s, loss=0.0908, lr=0.002]\n",
      "Steps:  16%|█▌        | 473/3000 [04:22<14:08,  2.98it/s, loss=0.0811, lr=0.002]\n",
      "Steps:  16%|█▌        | 474/3000 [04:22<14:18,  2.94it/s, loss=0.0401, lr=0.002]\n",
      "Steps:  16%|█▌        | 475/3000 [04:23<14:20,  2.94it/s, loss=0.189, lr=0.002] \n",
      "Steps:  16%|█▌        | 476/3000 [04:23<14:21,  2.93it/s, loss=0.101, lr=0.002]\n",
      "Steps:  16%|█▌        | 477/3000 [04:23<14:17,  2.94it/s, loss=0.0769, lr=0.002]\n",
      "Steps:  16%|█▌        | 478/3000 [04:24<14:17,  2.94it/s, loss=0.304, lr=0.002] \n",
      "Steps:  16%|█▌        | 479/3000 [04:24<14:19,  2.93it/s, loss=0.116, lr=0.002]\n",
      "Steps:  16%|█▌        | 480/3000 [04:24<14:14,  2.95it/s, loss=0.0576, lr=0.002]\n",
      "Steps:  16%|█▌        | 481/3000 [04:25<14:17,  2.94it/s, loss=0.0711, lr=0.002]\n",
      "Steps:  16%|█▌        | 482/3000 [04:25<14:23,  2.92it/s, loss=0.114, lr=0.002] \n",
      "Steps:  16%|█▌        | 483/3000 [04:25<14:20,  2.93it/s, loss=0.194, lr=0.002]\n",
      "Steps:  16%|█▌        | 484/3000 [04:26<14:15,  2.94it/s, loss=0.181, lr=0.002]\n",
      "Steps:  16%|█▌        | 485/3000 [04:26<14:15,  2.94it/s, loss=0.121, lr=0.002]\n",
      "Steps:  16%|█▌        | 486/3000 [04:26<14:08,  2.96it/s, loss=0.127, lr=0.002]\n",
      "Steps:  16%|█▌        | 487/3000 [04:27<14:08,  2.96it/s, loss=0.151, lr=0.002]\n",
      "Steps:  16%|█▋        | 488/3000 [04:27<14:06,  2.97it/s, loss=0.142, lr=0.002]\n",
      "Steps:  16%|█▋        | 489/3000 [04:27<13:57,  3.00it/s, loss=0.34, lr=0.002] \n",
      "Steps:  16%|█▋        | 490/3000 [04:28<13:56,  3.00it/s, loss=0.0753, lr=0.002]\n",
      "Steps:  16%|█▋        | 491/3000 [04:28<13:58,  2.99it/s, loss=0.207, lr=0.002] \n",
      "Steps:  16%|█▋        | 492/3000 [04:28<13:57,  2.99it/s, loss=0.103, lr=0.002]\n",
      "Steps:  16%|█▋        | 493/3000 [04:29<13:59,  2.99it/s, loss=0.188, lr=0.002]\n",
      "Steps:  16%|█▋        | 494/3000 [04:29<13:51,  3.01it/s, loss=0.126, lr=0.002]\n",
      "Steps:  16%|█▋        | 495/3000 [04:29<13:51,  3.01it/s, loss=0.102, lr=0.002]\n",
      "Steps:  17%|█▋        | 496/3000 [04:30<15:16,  2.73it/s, loss=0.142, lr=0.002]\n",
      "Steps:  17%|█▋        | 497/3000 [04:30<15:00,  2.78it/s, loss=0.096, lr=0.002]\n",
      "Steps:  17%|█▋        | 498/3000 [04:30<14:49,  2.81it/s, loss=0.21, lr=0.002] \n",
      "Steps:  17%|█▋        | 499/3000 [04:31<14:37,  2.85it/s, loss=0.141, lr=0.002]\n",
      "Steps:  17%|█▋        | 500/3000 [04:31<14:23,  2.89it/s, loss=0.141, lr=0.002]05/09/2024 05:25:52 - INFO - __main__ - Saving embeddings\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:25:52 - INFO - accelerate.accelerator - Saving current state to /tmp/textual_inversion_cat/checkpoint-500\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:25:53 - INFO - accelerate.checkpointing - Model weights saved in /tmp/textual_inversion_cat/checkpoint-500/model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:25:54 - INFO - accelerate.checkpointing - Optimizer state saved in /tmp/textual_inversion_cat/checkpoint-500/optimizer.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:25:54 - INFO - accelerate.checkpointing - Scheduler state saved in /tmp/textual_inversion_cat/checkpoint-500/scheduler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:25:54 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /tmp/textual_inversion_cat/checkpoint-500/sampler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:25:54 - INFO - accelerate.checkpointing - Random states saved in /tmp/textual_inversion_cat/checkpoint-500/random_states_0.pkl\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:25:54 - INFO - __main__ - Saved state to /tmp/textual_inversion_cat/checkpoint-500\n",
      "Steps:  17%|█▋        | 500/3000 [04:33<14:23,  2.89it/s, loss=0.128, lr=0.002]\n",
      "Steps:  17%|█▋        | 501/3000 [04:42<2:29:41,  3.59s/it, loss=0.162, lr=0.002]\n",
      "Steps:  17%|█▋        | 502/3000 [04:43<1:49:25,  2.63s/it, loss=0.254, lr=0.002]\n",
      "Steps:  17%|█▋        | 503/3000 [04:43<1:20:53,  1.94s/it, loss=0.0222, lr=0.002]\n",
      "Steps:  17%|█▋        | 504/3000 [04:43<1:01:00,  1.47s/it, loss=0.0759, lr=0.002]\n",
      "Steps:  17%|█▋        | 505/3000 [04:44<46:53,  1.13s/it, loss=0.216, lr=0.002]   \n",
      "Steps:  17%|█▋        | 506/3000 [04:44<36:58,  1.12it/s, loss=0.17, lr=0.002] \n",
      "Steps:  17%|█▋        | 507/3000 [04:44<30:04,  1.38it/s, loss=0.214, lr=0.002]\n",
      "Steps:  17%|█▋        | 508/3000 [04:45<25:22,  1.64it/s, loss=0.0828, lr=0.002]\n",
      "Steps:  17%|█▋        | 509/3000 [04:45<21:55,  1.89it/s, loss=0.206, lr=0.002] \n",
      "Steps:  17%|█▋        | 510/3000 [04:45<19:35,  2.12it/s, loss=0.119, lr=0.002]\n",
      "Steps:  17%|█▋        | 511/3000 [04:46<17:57,  2.31it/s, loss=0.116, lr=0.002]\n",
      "Steps:  17%|█▋        | 512/3000 [04:46<16:38,  2.49it/s, loss=0.121, lr=0.002]\n",
      "Steps:  17%|█▋        | 513/3000 [04:46<15:51,  2.62it/s, loss=0.13, lr=0.002] \n",
      "Steps:  17%|█▋        | 514/3000 [04:47<15:11,  2.73it/s, loss=0.198, lr=0.002]\n",
      "Steps:  17%|█▋        | 515/3000 [04:47<14:39,  2.83it/s, loss=0.0745, lr=0.002]\n",
      "Steps:  17%|█▋        | 516/3000 [04:47<14:35,  2.84it/s, loss=0.084, lr=0.002] \n",
      "Steps:  17%|█▋        | 517/3000 [04:48<14:20,  2.89it/s, loss=0.106, lr=0.002]\n",
      "Steps:  17%|█▋        | 518/3000 [04:48<14:19,  2.89it/s, loss=0.173, lr=0.002]\n",
      "Steps:  17%|█▋        | 519/3000 [04:48<14:20,  2.88it/s, loss=0.176, lr=0.002]\n",
      "Steps:  17%|█▋        | 520/3000 [04:49<14:05,  2.93it/s, loss=0.189, lr=0.002]\n",
      "Steps:  17%|█▋        | 521/3000 [04:49<14:09,  2.92it/s, loss=0.159, lr=0.002]\n",
      "Steps:  17%|█▋        | 522/3000 [04:49<14:05,  2.93it/s, loss=0.0777, lr=0.002]\n",
      "Steps:  17%|█▋        | 523/3000 [04:50<14:03,  2.94it/s, loss=0.129, lr=0.002] \n",
      "Steps:  17%|█▋        | 524/3000 [04:50<13:55,  2.96it/s, loss=0.119, lr=0.002]\n",
      "Steps:  18%|█▊        | 525/3000 [04:50<13:49,  2.98it/s, loss=0.137, lr=0.002]\n",
      "Steps:  18%|█▊        | 526/3000 [04:51<13:52,  2.97it/s, loss=0.122, lr=0.002]\n",
      "Steps:  18%|█▊        | 527/3000 [04:51<13:54,  2.96it/s, loss=0.182, lr=0.002]\n",
      "Steps:  18%|█▊        | 528/3000 [04:52<14:14,  2.89it/s, loss=0.103, lr=0.002]\n",
      "Steps:  18%|█▊        | 529/3000 [04:52<14:14,  2.89it/s, loss=0.0296, lr=0.002]\n",
      "Steps:  18%|█▊        | 530/3000 [04:52<14:19,  2.87it/s, loss=0.164, lr=0.002] \n",
      "Steps:  18%|█▊        | 531/3000 [04:53<14:12,  2.90it/s, loss=0.331, lr=0.002]\n",
      "Steps:  18%|█▊        | 532/3000 [04:53<14:02,  2.93it/s, loss=0.0588, lr=0.002]\n",
      "Steps:  18%|█▊        | 533/3000 [04:53<13:58,  2.94it/s, loss=0.197, lr=0.002] \n",
      "Steps:  18%|█▊        | 534/3000 [04:54<13:50,  2.97it/s, loss=0.0883, lr=0.002]\n",
      "Steps:  18%|█▊        | 535/3000 [04:54<13:46,  2.98it/s, loss=0.215, lr=0.002] \n",
      "Steps:  18%|█▊        | 536/3000 [04:54<13:44,  2.99it/s, loss=0.223, lr=0.002]\n",
      "Steps:  18%|█▊        | 537/3000 [04:55<13:44,  2.99it/s, loss=0.0978, lr=0.002]\n",
      "Steps:  18%|█▊        | 538/3000 [04:55<13:45,  2.98it/s, loss=0.0749, lr=0.002]\n",
      "Steps:  18%|█▊        | 539/3000 [04:55<13:42,  2.99it/s, loss=0.0852, lr=0.002]\n",
      "Steps:  18%|█▊        | 540/3000 [04:56<13:49,  2.97it/s, loss=0.114, lr=0.002] \n",
      "Steps:  18%|█▊        | 541/3000 [04:56<13:44,  2.98it/s, loss=0.152, lr=0.002]\n",
      "Steps:  18%|█▊        | 542/3000 [04:56<13:48,  2.97it/s, loss=0.0634, lr=0.002]\n",
      "Steps:  18%|█▊        | 543/3000 [04:57<13:44,  2.98it/s, loss=0.185, lr=0.002] \n",
      "Steps:  18%|█▊        | 544/3000 [04:57<13:44,  2.98it/s, loss=0.0265, lr=0.002]\n",
      "Steps:  18%|█▊        | 545/3000 [04:57<13:43,  2.98it/s, loss=0.135, lr=0.002] \n",
      "Steps:  18%|█▊        | 546/3000 [04:58<13:44,  2.98it/s, loss=0.146, lr=0.002]\n",
      "Steps:  18%|█▊        | 547/3000 [04:58<13:44,  2.98it/s, loss=0.154, lr=0.002]\n",
      "Steps:  18%|█▊        | 548/3000 [04:58<13:45,  2.97it/s, loss=0.239, lr=0.002]\n",
      "Steps:  18%|█▊        | 549/3000 [04:59<13:43,  2.98it/s, loss=0.166, lr=0.002]\n",
      "Steps:  18%|█▊        | 550/3000 [04:59<13:39,  2.99it/s, loss=0.0979, lr=0.002]\n",
      "Steps:  18%|█▊        | 551/3000 [04:59<13:37,  3.00it/s, loss=0.178, lr=0.002] \n",
      "Steps:  18%|█▊        | 552/3000 [05:00<13:45,  2.97it/s, loss=0.0586, lr=0.002]\n",
      "Steps:  18%|█▊        | 553/3000 [05:00<13:49,  2.95it/s, loss=0.0789, lr=0.002]\n",
      "Steps:  18%|█▊        | 554/3000 [05:00<13:56,  2.92it/s, loss=0.107, lr=0.002] \n",
      "Steps:  18%|█▊        | 555/3000 [05:01<13:53,  2.93it/s, loss=0.178, lr=0.002]\n",
      "Steps:  19%|█▊        | 556/3000 [05:01<13:44,  2.96it/s, loss=0.139, lr=0.002]\n",
      "Steps:  19%|█▊        | 557/3000 [05:01<13:42,  2.97it/s, loss=0.102, lr=0.002]\n",
      "Steps:  19%|█▊        | 558/3000 [05:02<13:44,  2.96it/s, loss=0.0706, lr=0.002]\n",
      "Steps:  19%|█▊        | 559/3000 [05:02<13:46,  2.95it/s, loss=0.0665, lr=0.002]\n",
      "Steps:  19%|█▊        | 560/3000 [05:02<13:47,  2.95it/s, loss=0.122, lr=0.002] \n",
      "Steps:  19%|█▊        | 561/3000 [05:03<13:38,  2.98it/s, loss=0.115, lr=0.002]\n",
      "Steps:  19%|█▊        | 562/3000 [05:03<13:40,  2.97it/s, loss=0.257, lr=0.002]\n",
      "Steps:  19%|█▉        | 563/3000 [05:03<13:42,  2.96it/s, loss=0.237, lr=0.002]\n",
      "Steps:  19%|█▉        | 564/3000 [05:04<13:41,  2.97it/s, loss=0.17, lr=0.002] \n",
      "Steps:  19%|█▉        | 565/3000 [05:04<13:42,  2.96it/s, loss=0.0246, lr=0.002]\n",
      "Steps:  19%|█▉        | 566/3000 [05:04<13:40,  2.97it/s, loss=0.121, lr=0.002] \n",
      "Steps:  19%|█▉        | 567/3000 [05:05<13:34,  2.99it/s, loss=0.109, lr=0.002]\n",
      "Steps:  19%|█▉        | 568/3000 [05:05<13:33,  2.99it/s, loss=0.164, lr=0.002]\n",
      "Steps:  19%|█▉        | 569/3000 [05:05<13:34,  2.99it/s, loss=0.136, lr=0.002]\n",
      "Steps:  19%|█▉        | 570/3000 [05:06<15:26,  2.62it/s, loss=0.164, lr=0.002]\n",
      "Steps:  19%|█▉        | 571/3000 [05:06<15:28,  2.62it/s, loss=0.098, lr=0.002]\n",
      "Steps:  19%|█▉        | 572/3000 [05:07<14:51,  2.72it/s, loss=0.0795, lr=0.002]\n",
      "Steps:  19%|█▉        | 573/3000 [05:07<14:34,  2.78it/s, loss=0.016, lr=0.002] \n",
      "Steps:  19%|█▉        | 574/3000 [05:07<14:16,  2.83it/s, loss=0.14, lr=0.002] \n",
      "Steps:  19%|█▉        | 575/3000 [05:08<14:04,  2.87it/s, loss=0.0846, lr=0.002]\n",
      "Steps:  19%|█▉        | 576/3000 [05:08<13:53,  2.91it/s, loss=0.135, lr=0.002] \n",
      "Steps:  19%|█▉        | 577/3000 [05:08<13:47,  2.93it/s, loss=0.118, lr=0.002]\n",
      "Steps:  19%|█▉        | 578/3000 [05:09<13:29,  2.99it/s, loss=0.115, lr=0.002]\n",
      "Steps:  19%|█▉        | 579/3000 [05:09<13:36,  2.97it/s, loss=0.186, lr=0.002]\n",
      "Steps:  19%|█▉        | 580/3000 [05:09<13:30,  2.99it/s, loss=0.0543, lr=0.002]\n",
      "Steps:  19%|█▉        | 581/3000 [05:10<13:31,  2.98it/s, loss=0.0573, lr=0.002]\n",
      "Steps:  19%|█▉        | 582/3000 [05:10<13:35,  2.96it/s, loss=0.112, lr=0.002] \n",
      "Steps:  19%|█▉        | 583/3000 [05:10<13:31,  2.98it/s, loss=0.0615, lr=0.002]\n",
      "Steps:  19%|█▉        | 584/3000 [05:11<13:34,  2.96it/s, loss=0.176, lr=0.002] \n",
      "Steps:  20%|█▉        | 585/3000 [05:11<13:28,  2.99it/s, loss=0.104, lr=0.002]\n",
      "Steps:  20%|█▉        | 586/3000 [05:11<13:29,  2.98it/s, loss=0.216, lr=0.002]\n",
      "Steps:  20%|█▉        | 587/3000 [05:12<13:32,  2.97it/s, loss=0.128, lr=0.002]\n",
      "Steps:  20%|█▉        | 588/3000 [05:12<13:25,  2.99it/s, loss=0.11, lr=0.002] \n",
      "Steps:  20%|█▉        | 589/3000 [05:12<13:22,  3.00it/s, loss=0.056, lr=0.002]\n",
      "Steps:  20%|█▉        | 590/3000 [05:13<13:28,  2.98it/s, loss=0.128, lr=0.002]\n",
      "Steps:  20%|█▉        | 591/3000 [05:13<13:22,  3.00it/s, loss=0.128, lr=0.002]\n",
      "Steps:  20%|█▉        | 592/3000 [05:13<13:28,  2.98it/s, loss=0.315, lr=0.002]\n",
      "Steps:  20%|█▉        | 593/3000 [05:14<13:26,  2.99it/s, loss=0.0851, lr=0.002]\n",
      "Steps:  20%|█▉        | 594/3000 [05:14<13:17,  3.02it/s, loss=0.107, lr=0.002] \n",
      "Steps:  20%|█▉        | 595/3000 [05:14<13:13,  3.03it/s, loss=0.196, lr=0.002]\n",
      "Steps:  20%|█▉        | 596/3000 [05:15<13:26,  2.98it/s, loss=0.137, lr=0.002]\n",
      "Steps:  20%|█▉        | 597/3000 [05:15<13:47,  2.90it/s, loss=0.131, lr=0.002]\n",
      "Steps:  20%|█▉        | 598/3000 [05:15<13:45,  2.91it/s, loss=0.08, lr=0.002] \n",
      "Steps:  20%|█▉        | 599/3000 [05:16<13:46,  2.91it/s, loss=0.182, lr=0.002]\n",
      "Steps:  20%|██        | 600/3000 [05:16<12:24,  3.22it/s, loss=0.168, lr=0.002]\n",
      "Steps:  20%|██        | 601/3000 [05:16<13:53,  2.88it/s, loss=0.124, lr=0.002]\n",
      "Steps:  20%|██        | 602/3000 [05:17<13:46,  2.90it/s, loss=0.214, lr=0.002]\n",
      "Steps:  20%|██        | 603/3000 [05:17<13:46,  2.90it/s, loss=0.143, lr=0.002]\n",
      "Steps:  20%|██        | 604/3000 [05:17<13:38,  2.93it/s, loss=0.0349, lr=0.002]\n",
      "Steps:  20%|██        | 605/3000 [05:18<13:32,  2.95it/s, loss=0.0593, lr=0.002]\n",
      "Steps:  20%|██        | 606/3000 [05:18<13:30,  2.95it/s, loss=0.291, lr=0.002] \n",
      "Steps:  20%|██        | 607/3000 [05:18<13:29,  2.96it/s, loss=0.215, lr=0.002]\n",
      "Steps:  20%|██        | 608/3000 [05:19<13:27,  2.96it/s, loss=0.117, lr=0.002]\n",
      "Steps:  20%|██        | 609/3000 [05:19<13:25,  2.97it/s, loss=0.205, lr=0.002]\n",
      "Steps:  20%|██        | 610/3000 [05:19<13:23,  2.98it/s, loss=0.0564, lr=0.002]\n",
      "Steps:  20%|██        | 611/3000 [05:20<13:18,  2.99it/s, loss=0.11, lr=0.002]  \n",
      "Steps:  20%|██        | 612/3000 [05:20<13:24,  2.97it/s, loss=0.0869, lr=0.002]\n",
      "Steps:  20%|██        | 613/3000 [05:20<13:19,  2.99it/s, loss=0.177, lr=0.002] \n",
      "Steps:  20%|██        | 614/3000 [05:21<13:26,  2.96it/s, loss=0.0543, lr=0.002]\n",
      "Steps:  20%|██        | 615/3000 [05:21<13:22,  2.97it/s, loss=0.122, lr=0.002] \n",
      "Steps:  21%|██        | 616/3000 [05:21<13:20,  2.98it/s, loss=0.189, lr=0.002]\n",
      "Steps:  21%|██        | 617/3000 [05:22<13:08,  3.02it/s, loss=0.221, lr=0.002]\n",
      "Steps:  21%|██        | 618/3000 [05:22<13:13,  3.00it/s, loss=0.303, lr=0.002]\n",
      "Steps:  21%|██        | 619/3000 [05:22<13:03,  3.04it/s, loss=0.203, lr=0.002]\n",
      "Steps:  21%|██        | 620/3000 [05:23<13:09,  3.02it/s, loss=0.176, lr=0.002]\n",
      "Steps:  21%|██        | 621/3000 [05:23<13:12,  3.00it/s, loss=0.132, lr=0.002]\n",
      "Steps:  21%|██        | 622/3000 [05:23<13:16,  2.99it/s, loss=0.129, lr=0.002]\n",
      "Steps:  21%|██        | 623/3000 [05:24<13:50,  2.86it/s, loss=0.111, lr=0.002]\n",
      "Steps:  21%|██        | 624/3000 [05:24<13:48,  2.87it/s, loss=0.142, lr=0.002]\n",
      "Steps:  21%|██        | 625/3000 [05:24<13:37,  2.90it/s, loss=0.192, lr=0.002]\n",
      "Steps:  21%|██        | 626/3000 [05:25<13:31,  2.92it/s, loss=0.0445, lr=0.002]\n",
      "Steps:  21%|██        | 627/3000 [05:25<13:20,  2.96it/s, loss=0.162, lr=0.002] \n",
      "Steps:  21%|██        | 628/3000 [05:25<13:26,  2.94it/s, loss=0.133, lr=0.002]\n",
      "Steps:  21%|██        | 629/3000 [05:26<13:17,  2.97it/s, loss=0.0774, lr=0.002]\n",
      "Steps:  21%|██        | 630/3000 [05:26<13:28,  2.93it/s, loss=0.236, lr=0.002] \n",
      "Steps:  21%|██        | 631/3000 [05:26<13:29,  2.93it/s, loss=0.104, lr=0.002]\n",
      "Steps:  21%|██        | 632/3000 [05:27<13:24,  2.94it/s, loss=0.172, lr=0.002]\n",
      "Steps:  21%|██        | 633/3000 [05:27<13:22,  2.95it/s, loss=0.126, lr=0.002]\n",
      "Steps:  21%|██        | 634/3000 [05:27<13:25,  2.94it/s, loss=0.131, lr=0.002]\n",
      "Steps:  21%|██        | 635/3000 [05:28<13:10,  2.99it/s, loss=0.0199, lr=0.002]\n",
      "Steps:  21%|██        | 636/3000 [05:28<14:30,  2.72it/s, loss=0.178, lr=0.002] \n",
      "Steps:  21%|██        | 637/3000 [05:29<13:56,  2.83it/s, loss=0.0631, lr=0.002]\n",
      "Steps:  21%|██▏       | 638/3000 [05:29<13:43,  2.87it/s, loss=0.164, lr=0.002] \n",
      "Steps:  21%|██▏       | 639/3000 [05:29<13:34,  2.90it/s, loss=0.127, lr=0.002]\n",
      "Steps:  21%|██▏       | 640/3000 [05:30<13:40,  2.88it/s, loss=0.176, lr=0.002]\n",
      "Steps:  21%|██▏       | 641/3000 [05:30<13:36,  2.89it/s, loss=0.229, lr=0.002]\n",
      "Steps:  21%|██▏       | 642/3000 [05:30<13:26,  2.92it/s, loss=0.107, lr=0.002]\n",
      "Steps:  21%|██▏       | 643/3000 [05:31<13:23,  2.93it/s, loss=0.13, lr=0.002] \n",
      "Steps:  21%|██▏       | 644/3000 [05:31<13:18,  2.95it/s, loss=0.122, lr=0.002]\n",
      "Steps:  22%|██▏       | 645/3000 [05:31<13:21,  2.94it/s, loss=0.127, lr=0.002]\n",
      "Steps:  22%|██▏       | 646/3000 [05:32<13:21,  2.94it/s, loss=0.152, lr=0.002]\n",
      "Steps:  22%|██▏       | 647/3000 [05:32<13:22,  2.93it/s, loss=0.251, lr=0.002]\n",
      "Steps:  22%|██▏       | 648/3000 [05:32<13:19,  2.94it/s, loss=0.102, lr=0.002]\n",
      "Steps:  22%|██▏       | 649/3000 [05:33<13:13,  2.96it/s, loss=0.201, lr=0.002]\n",
      "Steps:  22%|██▏       | 650/3000 [05:33<13:14,  2.96it/s, loss=0.19, lr=0.002] \n",
      "Steps:  22%|██▏       | 651/3000 [05:33<13:11,  2.97it/s, loss=0.113, lr=0.002]\n",
      "Steps:  22%|██▏       | 652/3000 [05:34<13:06,  2.99it/s, loss=0.198, lr=0.002]\n",
      "Steps:  22%|██▏       | 653/3000 [05:34<13:09,  2.97it/s, loss=0.111, lr=0.002]\n",
      "Steps:  22%|██▏       | 654/3000 [05:34<13:04,  2.99it/s, loss=0.0835, lr=0.002]\n",
      "Steps:  22%|██▏       | 655/3000 [05:35<12:58,  3.01it/s, loss=0.14, lr=0.002]  \n",
      "Steps:  22%|██▏       | 656/3000 [05:35<12:58,  3.01it/s, loss=0.12, lr=0.002]\n",
      "Steps:  22%|██▏       | 657/3000 [05:35<13:08,  2.97it/s, loss=0.204, lr=0.002]\n",
      "Steps:  22%|██▏       | 658/3000 [05:36<13:07,  2.97it/s, loss=0.138, lr=0.002]\n",
      "Steps:  22%|██▏       | 659/3000 [05:36<13:03,  2.99it/s, loss=0.148, lr=0.002]\n",
      "Steps:  22%|██▏       | 660/3000 [05:36<13:03,  2.99it/s, loss=0.104, lr=0.002]\n",
      "Steps:  22%|██▏       | 661/3000 [05:37<13:05,  2.98it/s, loss=0.123, lr=0.002]\n",
      "Steps:  22%|██▏       | 662/3000 [05:37<13:07,  2.97it/s, loss=0.12, lr=0.002] \n",
      "Steps:  22%|██▏       | 663/3000 [05:37<13:02,  2.99it/s, loss=0.0918, lr=0.002]\n",
      "Steps:  22%|██▏       | 664/3000 [05:38<13:03,  2.98it/s, loss=0.102, lr=0.002] \n",
      "Steps:  22%|██▏       | 665/3000 [05:38<13:07,  2.97it/s, loss=0.287, lr=0.002]\n",
      "Steps:  22%|██▏       | 666/3000 [05:38<13:16,  2.93it/s, loss=0.178, lr=0.002]\n",
      "Steps:  22%|██▏       | 667/3000 [05:39<13:12,  2.94it/s, loss=0.122, lr=0.002]\n",
      "Steps:  22%|██▏       | 668/3000 [05:39<13:09,  2.95it/s, loss=0.0878, lr=0.002]\n",
      "Steps:  22%|██▏       | 669/3000 [05:39<13:11,  2.95it/s, loss=0.13, lr=0.002]  \n",
      "Steps:  22%|██▏       | 670/3000 [05:40<13:08,  2.96it/s, loss=0.214, lr=0.002]\n",
      "Steps:  22%|██▏       | 671/3000 [05:40<13:05,  2.96it/s, loss=0.162, lr=0.002]\n",
      "Steps:  22%|██▏       | 672/3000 [05:40<13:05,  2.96it/s, loss=0.121, lr=0.002]\n",
      "Steps:  22%|██▏       | 673/3000 [05:41<13:08,  2.95it/s, loss=0.131, lr=0.002]\n",
      "Steps:  22%|██▏       | 674/3000 [05:41<13:09,  2.95it/s, loss=0.0659, lr=0.002]\n",
      "Steps:  22%|██▎       | 675/3000 [05:41<13:09,  2.94it/s, loss=0.0671, lr=0.002]\n",
      "Steps:  23%|██▎       | 676/3000 [05:42<13:13,  2.93it/s, loss=0.159, lr=0.002] \n",
      "Steps:  23%|██▎       | 677/3000 [05:42<13:17,  2.91it/s, loss=0.168, lr=0.002]\n",
      "Steps:  23%|██▎       | 678/3000 [05:42<13:14,  2.92it/s, loss=0.235, lr=0.002]\n",
      "Steps:  23%|██▎       | 679/3000 [05:43<13:10,  2.94it/s, loss=0.152, lr=0.002]\n",
      "Steps:  23%|██▎       | 680/3000 [05:43<13:06,  2.95it/s, loss=0.126, lr=0.002]\n",
      "Steps:  23%|██▎       | 681/3000 [05:43<13:07,  2.95it/s, loss=0.0609, lr=0.002]\n",
      "Steps:  23%|██▎       | 682/3000 [05:44<13:01,  2.97it/s, loss=0.177, lr=0.002] \n",
      "Steps:  23%|██▎       | 683/3000 [05:44<12:57,  2.98it/s, loss=0.154, lr=0.002]\n",
      "Steps:  23%|██▎       | 684/3000 [05:44<13:02,  2.96it/s, loss=0.117, lr=0.002]\n",
      "Steps:  23%|██▎       | 685/3000 [05:45<12:52,  3.00it/s, loss=0.0871, lr=0.002]\n",
      "Steps:  23%|██▎       | 686/3000 [05:45<12:55,  2.98it/s, loss=0.11, lr=0.002]  \n",
      "Steps:  23%|██▎       | 687/3000 [05:45<12:56,  2.98it/s, loss=0.328, lr=0.002]\n",
      "Steps:  23%|██▎       | 688/3000 [05:46<12:50,  3.00it/s, loss=0.0224, lr=0.002]\n",
      "Steps:  23%|██▎       | 689/3000 [05:46<12:49,  3.00it/s, loss=0.118, lr=0.002] \n",
      "Steps:  23%|██▎       | 690/3000 [05:46<12:43,  3.02it/s, loss=0.0641, lr=0.002]\n",
      "Steps:  23%|██▎       | 691/3000 [05:47<12:49,  3.00it/s, loss=0.122, lr=0.002] \n",
      "Steps:  23%|██▎       | 692/3000 [05:47<13:18,  2.89it/s, loss=0.0563, lr=0.002]\n",
      "Steps:  23%|██▎       | 693/3000 [05:47<13:03,  2.94it/s, loss=0.0931, lr=0.002]\n",
      "Steps:  23%|██▎       | 694/3000 [05:48<14:13,  2.70it/s, loss=0.0686, lr=0.002]\n",
      "Steps:  23%|██▎       | 695/3000 [05:48<13:49,  2.78it/s, loss=0.17, lr=0.002]  \n",
      "Steps:  23%|██▎       | 696/3000 [05:49<13:31,  2.84it/s, loss=0.118, lr=0.002]\n",
      "Steps:  23%|██▎       | 697/3000 [05:49<13:20,  2.88it/s, loss=0.128, lr=0.002]\n",
      "Steps:  23%|██▎       | 698/3000 [05:49<13:19,  2.88it/s, loss=0.0698, lr=0.002]\n",
      "Steps:  23%|██▎       | 699/3000 [05:50<13:05,  2.93it/s, loss=0.153, lr=0.002] \n",
      "Steps:  23%|██▎       | 700/3000 [05:50<13:03,  2.94it/s, loss=0.101, lr=0.002]\n",
      "Steps:  23%|██▎       | 701/3000 [05:50<13:03,  2.94it/s, loss=0.0359, lr=0.002]\n",
      "Steps:  23%|██▎       | 702/3000 [05:51<13:08,  2.92it/s, loss=0.0629, lr=0.002]\n",
      "Steps:  23%|██▎       | 703/3000 [05:51<13:09,  2.91it/s, loss=0.166, lr=0.002] \n",
      "Steps:  23%|██▎       | 704/3000 [05:51<13:07,  2.92it/s, loss=0.157, lr=0.002]\n",
      "Steps:  24%|██▎       | 705/3000 [05:52<13:03,  2.93it/s, loss=0.167, lr=0.002]\n",
      "Steps:  24%|██▎       | 706/3000 [05:52<12:59,  2.94it/s, loss=0.194, lr=0.002]\n",
      "Steps:  24%|██▎       | 707/3000 [05:52<12:56,  2.95it/s, loss=0.204, lr=0.002]\n",
      "Steps:  24%|██▎       | 708/3000 [05:53<12:59,  2.94it/s, loss=0.144, lr=0.002]\n",
      "Steps:  24%|██▎       | 709/3000 [05:53<13:03,  2.92it/s, loss=0.156, lr=0.002]\n",
      "Steps:  24%|██▎       | 710/3000 [05:53<12:58,  2.94it/s, loss=0.291, lr=0.002]\n",
      "Steps:  24%|██▎       | 711/3000 [05:54<13:00,  2.93it/s, loss=0.22, lr=0.002] \n",
      "Steps:  24%|██▎       | 712/3000 [05:54<12:57,  2.94it/s, loss=0.126, lr=0.002]\n",
      "Steps:  24%|██▍       | 713/3000 [05:54<12:59,  2.93it/s, loss=0.108, lr=0.002]\n",
      "Steps:  24%|██▍       | 714/3000 [05:55<13:01,  2.93it/s, loss=0.269, lr=0.002]\n",
      "Steps:  24%|██▍       | 715/3000 [05:55<12:49,  2.97it/s, loss=0.127, lr=0.002]\n",
      "Steps:  24%|██▍       | 716/3000 [05:55<12:50,  2.96it/s, loss=0.113, lr=0.002]\n",
      "Steps:  24%|██▍       | 717/3000 [05:56<12:44,  2.99it/s, loss=0.145, lr=0.002]\n",
      "Steps:  24%|██▍       | 718/3000 [05:56<12:32,  3.03it/s, loss=0.13, lr=0.002] \n",
      "Steps:  24%|██▍       | 719/3000 [05:56<12:39,  3.00it/s, loss=0.208, lr=0.002]\n",
      "Steps:  24%|██▍       | 720/3000 [05:57<12:39,  3.00it/s, loss=0.174, lr=0.002]\n",
      "Steps:  24%|██▍       | 721/3000 [05:57<12:37,  3.01it/s, loss=0.17, lr=0.002] \n",
      "Steps:  24%|██▍       | 722/3000 [05:57<12:43,  2.99it/s, loss=0.127, lr=0.002]\n",
      "Steps:  24%|██▍       | 723/3000 [05:58<12:40,  2.99it/s, loss=0.123, lr=0.002]\n",
      "Steps:  24%|██▍       | 724/3000 [05:58<12:45,  2.97it/s, loss=0.15, lr=0.002] \n",
      "Steps:  24%|██▍       | 725/3000 [05:58<12:42,  2.98it/s, loss=0.203, lr=0.002]\n",
      "Steps:  24%|██▍       | 726/3000 [05:59<12:47,  2.96it/s, loss=0.249, lr=0.002]\n",
      "Steps:  24%|██▍       | 727/3000 [05:59<12:36,  3.00it/s, loss=0.292, lr=0.002]\n",
      "Steps:  24%|██▍       | 728/3000 [05:59<12:38,  2.99it/s, loss=0.114, lr=0.002]\n",
      "Steps:  24%|██▍       | 729/3000 [06:00<12:37,  3.00it/s, loss=0.0929, lr=0.002]\n",
      "Steps:  24%|██▍       | 730/3000 [06:00<12:36,  3.00it/s, loss=0.126, lr=0.002] \n",
      "Steps:  24%|██▍       | 731/3000 [06:00<12:45,  2.97it/s, loss=0.119, lr=0.002]\n",
      "Steps:  24%|██▍       | 732/3000 [06:01<12:47,  2.96it/s, loss=0.129, lr=0.002]\n",
      "Steps:  24%|██▍       | 733/3000 [06:01<12:47,  2.95it/s, loss=0.126, lr=0.002]\n",
      "Steps:  24%|██▍       | 734/3000 [06:01<12:48,  2.95it/s, loss=0.123, lr=0.002]\n",
      "Steps:  24%|██▍       | 735/3000 [06:02<13:04,  2.89it/s, loss=0.219, lr=0.002]\n",
      "Steps:  25%|██▍       | 736/3000 [06:02<12:57,  2.91it/s, loss=0.154, lr=0.002]\n",
      "Steps:  25%|██▍       | 737/3000 [06:02<12:50,  2.94it/s, loss=0.0496, lr=0.002]\n",
      "Steps:  25%|██▍       | 738/3000 [06:03<12:47,  2.95it/s, loss=0.021, lr=0.002] \n",
      "Steps:  25%|██▍       | 739/3000 [06:03<12:41,  2.97it/s, loss=0.15, lr=0.002] \n",
      "Steps:  25%|██▍       | 740/3000 [06:03<12:35,  2.99it/s, loss=0.138, lr=0.002]\n",
      "Steps:  25%|██▍       | 741/3000 [06:04<12:40,  2.97it/s, loss=0.269, lr=0.002]\n",
      "Steps:  25%|██▍       | 742/3000 [06:04<12:33,  3.00it/s, loss=0.124, lr=0.002]\n",
      "Steps:  25%|██▍       | 743/3000 [06:04<12:26,  3.02it/s, loss=0.117, lr=0.002]\n",
      "Steps:  25%|██▍       | 744/3000 [06:05<12:33,  2.99it/s, loss=0.0957, lr=0.002]\n",
      "Steps:  25%|██▍       | 745/3000 [06:05<12:31,  3.00it/s, loss=0.133, lr=0.002] \n",
      "Steps:  25%|██▍       | 746/3000 [06:05<12:19,  3.05it/s, loss=0.0893, lr=0.002]\n",
      "Steps:  25%|██▍       | 747/3000 [06:06<12:29,  3.01it/s, loss=0.206, lr=0.002] \n",
      "Steps:  25%|██▍       | 748/3000 [06:06<12:23,  3.03it/s, loss=0.148, lr=0.002]\n",
      "Steps:  25%|██▍       | 749/3000 [06:06<12:16,  3.05it/s, loss=0.115, lr=0.002]\n",
      "Steps:  25%|██▌       | 750/3000 [06:07<11:08,  3.36it/s, loss=0.202, lr=0.002]\n",
      "Steps:  25%|██▌       | 751/3000 [06:07<14:09,  2.65it/s, loss=0.0667, lr=0.002]\n",
      "Steps:  25%|██▌       | 752/3000 [06:07<13:34,  2.76it/s, loss=0.143, lr=0.002] \n",
      "Steps:  25%|██▌       | 753/3000 [06:08<13:15,  2.83it/s, loss=0.303, lr=0.002]\n",
      "Steps:  25%|██▌       | 754/3000 [06:08<13:00,  2.88it/s, loss=0.122, lr=0.002]\n",
      "Steps:  25%|██▌       | 755/3000 [06:08<12:51,  2.91it/s, loss=0.192, lr=0.002]\n",
      "Steps:  25%|██▌       | 756/3000 [06:09<12:46,  2.93it/s, loss=0.0665, lr=0.002]\n",
      "Steps:  25%|██▌       | 757/3000 [06:09<12:31,  2.98it/s, loss=0.066, lr=0.002] \n",
      "Steps:  25%|██▌       | 758/3000 [06:09<12:33,  2.98it/s, loss=0.251, lr=0.002]\n",
      "Steps:  25%|██▌       | 759/3000 [06:10<12:26,  3.00it/s, loss=0.0333, lr=0.002]\n",
      "Steps:  25%|██▌       | 760/3000 [06:10<12:20,  3.02it/s, loss=0.272, lr=0.002] \n",
      "Steps:  25%|██▌       | 761/3000 [06:10<12:35,  2.97it/s, loss=0.202, lr=0.002]\n",
      "Steps:  25%|██▌       | 762/3000 [06:11<12:33,  2.97it/s, loss=0.196, lr=0.002]\n",
      "Steps:  25%|██▌       | 763/3000 [06:11<12:32,  2.97it/s, loss=0.196, lr=0.002]\n",
      "Steps:  25%|██▌       | 764/3000 [06:11<12:33,  2.97it/s, loss=0.0903, lr=0.002]\n",
      "Steps:  26%|██▌       | 765/3000 [06:12<12:31,  2.98it/s, loss=0.0688, lr=0.002]\n",
      "Steps:  26%|██▌       | 766/3000 [06:12<12:35,  2.96it/s, loss=0.179, lr=0.002] \n",
      "Steps:  26%|██▌       | 767/3000 [06:12<12:30,  2.97it/s, loss=0.111, lr=0.002]\n",
      "Steps:  26%|██▌       | 768/3000 [06:13<12:30,  2.97it/s, loss=0.275, lr=0.002]\n",
      "Steps:  26%|██▌       | 769/3000 [06:13<12:23,  3.00it/s, loss=0.232, lr=0.002]\n",
      "Steps:  26%|██▌       | 770/3000 [06:13<12:24,  3.00it/s, loss=0.136, lr=0.002]\n",
      "Steps:  26%|██▌       | 771/3000 [06:14<12:32,  2.96it/s, loss=0.184, lr=0.002]\n",
      "Steps:  26%|██▌       | 772/3000 [06:14<12:29,  2.97it/s, loss=0.159, lr=0.002]\n",
      "Steps:  26%|██▌       | 773/3000 [06:14<12:22,  3.00it/s, loss=0.166, lr=0.002]\n",
      "Steps:  26%|██▌       | 774/3000 [06:15<12:19,  3.01it/s, loss=0.0589, lr=0.002]\n",
      "Steps:  26%|██▌       | 775/3000 [06:15<12:22,  3.00it/s, loss=0.114, lr=0.002] \n",
      "Steps:  26%|██▌       | 776/3000 [06:15<12:20,  3.00it/s, loss=0.168, lr=0.002]\n",
      "Steps:  26%|██▌       | 777/3000 [06:16<12:27,  2.97it/s, loss=0.0847, lr=0.002]\n",
      "Steps:  26%|██▌       | 778/3000 [06:16<12:27,  2.97it/s, loss=0.0713, lr=0.002]\n",
      "Steps:  26%|██▌       | 779/3000 [06:17<12:20,  3.00it/s, loss=0.123, lr=0.002] \n",
      "Steps:  26%|██▌       | 780/3000 [06:17<12:13,  3.03it/s, loss=0.0728, lr=0.002]\n",
      "Steps:  26%|██▌       | 781/3000 [06:17<12:19,  3.00it/s, loss=0.0591, lr=0.002]\n",
      "Steps:  26%|██▌       | 782/3000 [06:17<12:16,  3.01it/s, loss=0.198, lr=0.002] \n",
      "Steps:  26%|██▌       | 783/3000 [06:18<12:14,  3.02it/s, loss=0.197, lr=0.002]\n",
      "Steps:  26%|██▌       | 784/3000 [06:18<12:26,  2.97it/s, loss=0.145, lr=0.002]\n",
      "Steps:  26%|██▌       | 785/3000 [06:19<12:23,  2.98it/s, loss=0.105, lr=0.002]\n",
      "Steps:  26%|██▌       | 786/3000 [06:19<12:16,  3.01it/s, loss=0.175, lr=0.002]\n",
      "Steps:  26%|██▌       | 787/3000 [06:19<12:27,  2.96it/s, loss=0.115, lr=0.002]\n",
      "Steps:  26%|██▋       | 788/3000 [06:20<12:26,  2.96it/s, loss=0.205, lr=0.002]\n",
      "Steps:  26%|██▋       | 789/3000 [06:20<12:20,  2.99it/s, loss=0.331, lr=0.002]\n",
      "Steps:  26%|██▋       | 790/3000 [06:20<12:26,  2.96it/s, loss=0.025, lr=0.002]\n",
      "Steps:  26%|██▋       | 791/3000 [06:21<12:17,  3.00it/s, loss=0.154, lr=0.002]\n",
      "Steps:  26%|██▋       | 792/3000 [06:21<12:19,  2.99it/s, loss=0.192, lr=0.002]\n",
      "Steps:  26%|██▋       | 793/3000 [06:21<12:22,  2.97it/s, loss=0.277, lr=0.002]\n",
      "Steps:  26%|██▋       | 794/3000 [06:22<12:21,  2.97it/s, loss=0.155, lr=0.002]\n",
      "Steps:  26%|██▋       | 795/3000 [06:22<12:18,  2.99it/s, loss=0.224, lr=0.002]\n",
      "Steps:  27%|██▋       | 796/3000 [06:22<12:26,  2.95it/s, loss=0.118, lr=0.002]\n",
      "Steps:  27%|██▋       | 797/3000 [06:23<12:23,  2.96it/s, loss=0.259, lr=0.002]\n",
      "Steps:  27%|██▋       | 798/3000 [06:23<12:24,  2.96it/s, loss=0.239, lr=0.002]\n",
      "Steps:  27%|██▋       | 799/3000 [06:23<12:26,  2.95it/s, loss=0.238, lr=0.002]\n",
      "Steps:  27%|██▋       | 800/3000 [06:24<12:24,  2.95it/s, loss=0.127, lr=0.002]\n",
      "Steps:  27%|██▋       | 801/3000 [06:24<12:16,  2.99it/s, loss=0.0849, lr=0.002]\n",
      "Steps:  27%|██▋       | 802/3000 [06:24<12:14,  2.99it/s, loss=0.208, lr=0.002] \n",
      "Steps:  27%|██▋       | 803/3000 [06:25<12:14,  2.99it/s, loss=0.092, lr=0.002]\n",
      "Steps:  27%|██▋       | 804/3000 [06:25<12:11,  3.00it/s, loss=0.14, lr=0.002] \n",
      "Steps:  27%|██▋       | 805/3000 [06:25<12:14,  2.99it/s, loss=0.0879, lr=0.002]\n",
      "Steps:  27%|██▋       | 806/3000 [06:26<12:20,  2.96it/s, loss=0.133, lr=0.002] \n",
      "Steps:  27%|██▋       | 807/3000 [06:26<12:21,  2.96it/s, loss=0.0986, lr=0.002]\n",
      "Steps:  27%|██▋       | 808/3000 [06:26<13:33,  2.70it/s, loss=0.0274, lr=0.002]\n",
      "Steps:  27%|██▋       | 809/3000 [06:27<13:08,  2.78it/s, loss=0.0625, lr=0.002]\n",
      "Steps:  27%|██▋       | 810/3000 [06:27<12:53,  2.83it/s, loss=0.103, lr=0.002] \n",
      "Steps:  27%|██▋       | 811/3000 [06:27<12:37,  2.89it/s, loss=0.121, lr=0.002]\n",
      "Steps:  27%|██▋       | 812/3000 [06:28<12:26,  2.93it/s, loss=0.0538, lr=0.002]\n",
      "Steps:  27%|██▋       | 813/3000 [06:28<12:37,  2.89it/s, loss=0.0957, lr=0.002]\n",
      "Steps:  27%|██▋       | 814/3000 [06:28<12:27,  2.93it/s, loss=0.238, lr=0.002] \n",
      "Steps:  27%|██▋       | 815/3000 [06:29<12:25,  2.93it/s, loss=0.164, lr=0.002]\n",
      "Steps:  27%|██▋       | 816/3000 [06:29<12:29,  2.92it/s, loss=0.164, lr=0.002]\n",
      "Steps:  27%|██▋       | 817/3000 [06:29<12:25,  2.93it/s, loss=0.139, lr=0.002]\n",
      "Steps:  27%|██▋       | 818/3000 [06:30<12:18,  2.95it/s, loss=0.116, lr=0.002]\n",
      "Steps:  27%|██▋       | 819/3000 [06:30<12:13,  2.97it/s, loss=0.287, lr=0.002]\n",
      "Steps:  27%|██▋       | 820/3000 [06:30<12:20,  2.95it/s, loss=0.164, lr=0.002]\n",
      "Steps:  27%|██▋       | 821/3000 [06:31<12:15,  2.96it/s, loss=0.245, lr=0.002]\n",
      "Steps:  27%|██▋       | 822/3000 [06:31<12:16,  2.96it/s, loss=0.0969, lr=0.002]\n",
      "Steps:  27%|██▋       | 823/3000 [06:31<12:07,  2.99it/s, loss=0.0665, lr=0.002]\n",
      "Steps:  27%|██▋       | 824/3000 [06:32<12:12,  2.97it/s, loss=0.156, lr=0.002] \n",
      "Steps:  28%|██▊       | 825/3000 [06:32<12:07,  2.99it/s, loss=0.202, lr=0.002]\n",
      "Steps:  28%|██▊       | 826/3000 [06:32<12:10,  2.98it/s, loss=0.0771, lr=0.002]\n",
      "Steps:  28%|██▊       | 827/3000 [06:33<12:10,  2.97it/s, loss=0.19, lr=0.002]  \n",
      "Steps:  28%|██▊       | 828/3000 [06:33<12:11,  2.97it/s, loss=0.0919, lr=0.002]\n",
      "Steps:  28%|██▊       | 829/3000 [06:33<12:16,  2.95it/s, loss=0.144, lr=0.002] \n",
      "Steps:  28%|██▊       | 830/3000 [06:34<12:15,  2.95it/s, loss=0.101, lr=0.002]\n",
      "Steps:  28%|██▊       | 831/3000 [06:34<12:15,  2.95it/s, loss=0.125, lr=0.002]\n",
      "Steps:  28%|██▊       | 832/3000 [06:34<12:13,  2.95it/s, loss=0.0304, lr=0.002]\n",
      "Steps:  28%|██▊       | 833/3000 [06:35<12:08,  2.97it/s, loss=0.121, lr=0.002] \n",
      "Steps:  28%|██▊       | 834/3000 [06:35<12:03,  2.99it/s, loss=0.176, lr=0.002]\n",
      "Steps:  28%|██▊       | 835/3000 [06:35<12:06,  2.98it/s, loss=0.058, lr=0.002]\n",
      "Steps:  28%|██▊       | 836/3000 [06:36<12:09,  2.97it/s, loss=0.138, lr=0.002]\n",
      "Steps:  28%|██▊       | 837/3000 [06:36<12:09,  2.97it/s, loss=0.0852, lr=0.002]\n",
      "Steps:  28%|██▊       | 838/3000 [06:36<12:05,  2.98it/s, loss=0.0301, lr=0.002]\n",
      "Steps:  28%|██▊       | 839/3000 [06:37<12:05,  2.98it/s, loss=0.0676, lr=0.002]\n",
      "Steps:  28%|██▊       | 840/3000 [06:37<12:08,  2.96it/s, loss=0.0926, lr=0.002]\n",
      "Steps:  28%|██▊       | 841/3000 [06:37<12:04,  2.98it/s, loss=0.142, lr=0.002] \n",
      "Steps:  28%|██▊       | 842/3000 [06:38<12:05,  2.97it/s, loss=0.158, lr=0.002]\n",
      "Steps:  28%|██▊       | 843/3000 [06:38<12:05,  2.97it/s, loss=0.183, lr=0.002]\n",
      "Steps:  28%|██▊       | 844/3000 [06:38<12:08,  2.96it/s, loss=0.186, lr=0.002]\n",
      "Steps:  28%|██▊       | 845/3000 [06:39<12:00,  2.99it/s, loss=0.176, lr=0.002]\n",
      "Steps:  28%|██▊       | 846/3000 [06:39<12:04,  2.97it/s, loss=0.119, lr=0.002]\n",
      "Steps:  28%|██▊       | 847/3000 [06:39<12:00,  2.99it/s, loss=0.156, lr=0.002]\n",
      "Steps:  28%|██▊       | 848/3000 [06:40<12:03,  2.97it/s, loss=0.165, lr=0.002]\n",
      "Steps:  28%|██▊       | 849/3000 [06:40<11:49,  3.03it/s, loss=0.072, lr=0.002]\n",
      "Steps:  28%|██▊       | 850/3000 [06:40<11:48,  3.03it/s, loss=0.153, lr=0.002]\n",
      "Steps:  28%|██▊       | 851/3000 [06:41<11:53,  3.01it/s, loss=0.0745, lr=0.002]\n",
      "Steps:  28%|██▊       | 852/3000 [06:41<11:56,  3.00it/s, loss=0.164, lr=0.002] \n",
      "Steps:  28%|██▊       | 853/3000 [06:41<11:58,  2.99it/s, loss=0.112, lr=0.002]\n",
      "Steps:  28%|██▊       | 854/3000 [06:42<11:53,  3.01it/s, loss=0.0263, lr=0.002]\n",
      "Steps:  28%|██▊       | 855/3000 [06:42<11:48,  3.03it/s, loss=0.177, lr=0.002] \n",
      "Steps:  29%|██▊       | 856/3000 [06:42<11:51,  3.01it/s, loss=0.107, lr=0.002]\n",
      "Steps:  29%|██▊       | 857/3000 [06:43<11:47,  3.03it/s, loss=0.17, lr=0.002] \n",
      "Steps:  29%|██▊       | 858/3000 [06:43<11:49,  3.02it/s, loss=0.202, lr=0.002]\n",
      "Steps:  29%|██▊       | 859/3000 [06:43<11:49,  3.02it/s, loss=0.0843, lr=0.002]\n",
      "Steps:  29%|██▊       | 860/3000 [06:44<11:55,  2.99it/s, loss=0.172, lr=0.002] \n",
      "Steps:  29%|██▊       | 861/3000 [06:44<11:51,  3.01it/s, loss=0.249, lr=0.002]\n",
      "Steps:  29%|██▊       | 862/3000 [06:44<11:53,  3.00it/s, loss=0.124, lr=0.002]\n",
      "Steps:  29%|██▉       | 863/3000 [06:45<11:59,  2.97it/s, loss=0.0297, lr=0.002]\n",
      "Steps:  29%|██▉       | 864/3000 [06:45<11:57,  2.98it/s, loss=0.122, lr=0.002] \n",
      "Steps:  29%|██▉       | 865/3000 [06:46<13:03,  2.72it/s, loss=0.101, lr=0.002]\n",
      "Steps:  29%|██▉       | 866/3000 [06:46<12:50,  2.77it/s, loss=0.0838, lr=0.002]\n",
      "Steps:  29%|██▉       | 867/3000 [06:46<12:28,  2.85it/s, loss=0.197, lr=0.002] \n",
      "Steps:  29%|██▉       | 868/3000 [06:47<12:15,  2.90it/s, loss=0.0811, lr=0.002]\n",
      "Steps:  29%|██▉       | 869/3000 [06:47<12:06,  2.93it/s, loss=0.0728, lr=0.002]\n",
      "Steps:  29%|██▉       | 870/3000 [06:47<12:05,  2.93it/s, loss=0.127, lr=0.002] \n",
      "Steps:  29%|██▉       | 871/3000 [06:48<11:55,  2.97it/s, loss=0.137, lr=0.002]\n",
      "Steps:  29%|██▉       | 872/3000 [06:48<11:53,  2.98it/s, loss=0.155, lr=0.002]\n",
      "Steps:  29%|██▉       | 873/3000 [06:48<11:56,  2.97it/s, loss=0.135, lr=0.002]\n",
      "Steps:  29%|██▉       | 874/3000 [06:49<11:59,  2.95it/s, loss=0.228, lr=0.002]\n",
      "Steps:  29%|██▉       | 875/3000 [06:49<11:52,  2.98it/s, loss=0.0814, lr=0.002]\n",
      "Steps:  29%|██▉       | 876/3000 [06:49<11:47,  3.00it/s, loss=0.0931, lr=0.002]\n",
      "Steps:  29%|██▉       | 877/3000 [06:50<11:39,  3.04it/s, loss=0.146, lr=0.002] \n",
      "Steps:  29%|██▉       | 878/3000 [06:50<11:37,  3.04it/s, loss=0.0184, lr=0.002]\n",
      "Steps:  29%|██▉       | 879/3000 [06:50<11:40,  3.03it/s, loss=0.106, lr=0.002] \n",
      "Steps:  29%|██▉       | 880/3000 [06:51<11:46,  3.00it/s, loss=0.102, lr=0.002]\n",
      "Steps:  29%|██▉       | 881/3000 [06:51<11:48,  2.99it/s, loss=0.154, lr=0.002]\n",
      "Steps:  29%|██▉       | 882/3000 [06:51<11:49,  2.98it/s, loss=0.124, lr=0.002]\n",
      "Steps:  29%|██▉       | 883/3000 [06:52<11:47,  2.99it/s, loss=0.14, lr=0.002] \n",
      "Steps:  29%|██▉       | 884/3000 [06:52<11:47,  2.99it/s, loss=0.182, lr=0.002]\n",
      "Steps:  30%|██▉       | 885/3000 [06:52<11:49,  2.98it/s, loss=0.241, lr=0.002]\n",
      "Steps:  30%|██▉       | 886/3000 [06:53<11:52,  2.97it/s, loss=0.167, lr=0.002]\n",
      "Steps:  30%|██▉       | 887/3000 [06:53<11:51,  2.97it/s, loss=0.0684, lr=0.002]\n",
      "Steps:  30%|██▉       | 888/3000 [06:53<11:53,  2.96it/s, loss=0.119, lr=0.002] \n",
      "Steps:  30%|██▉       | 889/3000 [06:54<11:51,  2.97it/s, loss=0.125, lr=0.002]\n",
      "Steps:  30%|██▉       | 890/3000 [06:54<11:52,  2.96it/s, loss=0.122, lr=0.002]\n",
      "Steps:  30%|██▉       | 891/3000 [06:54<11:52,  2.96it/s, loss=0.102, lr=0.002]\n",
      "Steps:  30%|██▉       | 892/3000 [06:55<11:48,  2.98it/s, loss=0.0667, lr=0.002]\n",
      "Steps:  30%|██▉       | 893/3000 [06:55<11:51,  2.96it/s, loss=0.0316, lr=0.002]\n",
      "Steps:  30%|██▉       | 894/3000 [06:55<11:53,  2.95it/s, loss=0.169, lr=0.002] \n",
      "Steps:  30%|██▉       | 895/3000 [06:56<11:44,  2.99it/s, loss=0.119, lr=0.002]\n",
      "Steps:  30%|██▉       | 896/3000 [06:56<11:45,  2.98it/s, loss=0.13, lr=0.002] \n",
      "Steps:  30%|██▉       | 897/3000 [06:56<11:51,  2.96it/s, loss=0.0715, lr=0.002]\n",
      "Steps:  30%|██▉       | 898/3000 [06:57<11:51,  2.95it/s, loss=0.127, lr=0.002] \n",
      "Steps:  30%|██▉       | 899/3000 [06:57<11:51,  2.95it/s, loss=0.124, lr=0.002]\n",
      "Steps:  30%|███       | 900/3000 [06:57<10:41,  3.27it/s, loss=0.115, lr=0.002]\n",
      "Steps:  30%|███       | 901/3000 [06:58<11:59,  2.92it/s, loss=0.0838, lr=0.002]\n",
      "Steps:  30%|███       | 902/3000 [06:58<11:51,  2.95it/s, loss=0.104, lr=0.002] \n",
      "Steps:  30%|███       | 903/3000 [06:58<11:45,  2.97it/s, loss=0.0941, lr=0.002]\n",
      "Steps:  30%|███       | 904/3000 [06:59<11:39,  3.00it/s, loss=0.259, lr=0.002] \n",
      "Steps:  30%|███       | 905/3000 [06:59<11:41,  2.99it/s, loss=0.167, lr=0.002]\n",
      "Steps:  30%|███       | 906/3000 [06:59<11:39,  2.99it/s, loss=0.0869, lr=0.002]\n",
      "Steps:  30%|███       | 907/3000 [07:00<11:42,  2.98it/s, loss=0.124, lr=0.002] \n",
      "Steps:  30%|███       | 908/3000 [07:00<11:45,  2.96it/s, loss=0.0702, lr=0.002]\n",
      "Steps:  30%|███       | 909/3000 [07:00<11:46,  2.96it/s, loss=0.072, lr=0.002] \n",
      "Steps:  30%|███       | 910/3000 [07:01<11:47,  2.95it/s, loss=0.102, lr=0.002]\n",
      "Steps:  30%|███       | 911/3000 [07:01<11:39,  2.99it/s, loss=0.0956, lr=0.002]\n",
      "Steps:  30%|███       | 912/3000 [07:01<11:44,  2.96it/s, loss=0.146, lr=0.002] \n",
      "Steps:  30%|███       | 913/3000 [07:02<11:43,  2.97it/s, loss=0.122, lr=0.002]\n",
      "Steps:  30%|███       | 914/3000 [07:02<11:40,  2.98it/s, loss=0.133, lr=0.002]\n",
      "Steps:  30%|███       | 915/3000 [07:02<11:40,  2.97it/s, loss=0.0854, lr=0.002]\n",
      "Steps:  31%|███       | 916/3000 [07:03<11:28,  3.03it/s, loss=0.0635, lr=0.002]\n",
      "Steps:  31%|███       | 917/3000 [07:03<11:25,  3.04it/s, loss=0.203, lr=0.002] \n",
      "Steps:  31%|███       | 918/3000 [07:03<11:34,  3.00it/s, loss=0.117, lr=0.002]\n",
      "Steps:  31%|███       | 919/3000 [07:04<11:37,  2.98it/s, loss=0.263, lr=0.002]\n",
      "Steps:  31%|███       | 920/3000 [07:04<11:42,  2.96it/s, loss=0.116, lr=0.002]\n",
      "Steps:  31%|███       | 921/3000 [07:04<11:35,  2.99it/s, loss=0.0215, lr=0.002]\n",
      "Steps:  31%|███       | 922/3000 [07:05<12:42,  2.72it/s, loss=0.139, lr=0.002] \n",
      "Steps:  31%|███       | 923/3000 [07:05<12:17,  2.82it/s, loss=0.163, lr=0.002]\n",
      "Steps:  31%|███       | 924/3000 [07:05<12:01,  2.88it/s, loss=0.226, lr=0.002]\n",
      "Steps:  31%|███       | 925/3000 [07:06<11:48,  2.93it/s, loss=0.118, lr=0.002]\n",
      "Steps:  31%|███       | 926/3000 [07:06<11:59,  2.88it/s, loss=0.101, lr=0.002]\n",
      "Steps:  31%|███       | 927/3000 [07:06<11:52,  2.91it/s, loss=0.13, lr=0.002] \n",
      "Steps:  31%|███       | 928/3000 [07:07<11:44,  2.94it/s, loss=0.314, lr=0.002]\n",
      "Steps:  31%|███       | 929/3000 [07:07<11:48,  2.92it/s, loss=0.0769, lr=0.002]\n",
      "Steps:  31%|███       | 930/3000 [07:07<11:49,  2.92it/s, loss=0.262, lr=0.002] \n",
      "Steps:  31%|███       | 931/3000 [07:08<11:42,  2.95it/s, loss=0.0665, lr=0.002]\n",
      "Steps:  31%|███       | 932/3000 [07:08<11:42,  2.94it/s, loss=0.0714, lr=0.002]\n",
      "Steps:  31%|███       | 933/3000 [07:08<11:43,  2.94it/s, loss=0.0897, lr=0.002]\n",
      "Steps:  31%|███       | 934/3000 [07:09<11:39,  2.95it/s, loss=0.145, lr=0.002] \n",
      "Steps:  31%|███       | 935/3000 [07:09<11:35,  2.97it/s, loss=0.276, lr=0.002]\n",
      "Steps:  31%|███       | 936/3000 [07:10<11:32,  2.98it/s, loss=0.101, lr=0.002]\n",
      "Steps:  31%|███       | 937/3000 [07:10<11:31,  2.98it/s, loss=0.0991, lr=0.002]\n",
      "Steps:  31%|███▏      | 938/3000 [07:10<11:32,  2.98it/s, loss=0.0224, lr=0.002]\n",
      "Steps:  31%|███▏      | 939/3000 [07:11<11:34,  2.97it/s, loss=0.163, lr=0.002] \n",
      "Steps:  31%|███▏      | 940/3000 [07:11<11:36,  2.96it/s, loss=0.112, lr=0.002]\n",
      "Steps:  31%|███▏      | 941/3000 [07:11<11:45,  2.92it/s, loss=0.104, lr=0.002]\n",
      "Steps:  31%|███▏      | 942/3000 [07:12<11:45,  2.92it/s, loss=0.272, lr=0.002]\n",
      "Steps:  31%|███▏      | 943/3000 [07:12<11:41,  2.93it/s, loss=0.128, lr=0.002]\n",
      "Steps:  31%|███▏      | 944/3000 [07:12<11:36,  2.95it/s, loss=0.127, lr=0.002]\n",
      "Steps:  32%|███▏      | 945/3000 [07:13<11:36,  2.95it/s, loss=0.125, lr=0.002]\n",
      "Steps:  32%|███▏      | 946/3000 [07:13<11:28,  2.98it/s, loss=0.103, lr=0.002]\n",
      "Steps:  32%|███▏      | 947/3000 [07:13<11:22,  3.01it/s, loss=0.0643, lr=0.002]\n",
      "Steps:  32%|███▏      | 948/3000 [07:14<11:19,  3.02it/s, loss=0.212, lr=0.002] \n",
      "Steps:  32%|███▏      | 949/3000 [07:14<11:18,  3.02it/s, loss=0.0574, lr=0.002]\n",
      "Steps:  32%|███▏      | 950/3000 [07:14<11:24,  2.99it/s, loss=0.112, lr=0.002] \n",
      "Steps:  32%|███▏      | 951/3000 [07:15<11:29,  2.97it/s, loss=0.0666, lr=0.002]\n",
      "Steps:  32%|███▏      | 952/3000 [07:15<11:52,  2.87it/s, loss=0.121, lr=0.002] \n",
      "Steps:  32%|███▏      | 953/3000 [07:15<11:38,  2.93it/s, loss=0.114, lr=0.002]\n",
      "Steps:  32%|███▏      | 954/3000 [07:16<11:37,  2.93it/s, loss=0.136, lr=0.002]\n",
      "Steps:  32%|███▏      | 955/3000 [07:16<11:33,  2.95it/s, loss=0.116, lr=0.002]\n",
      "Steps:  32%|███▏      | 956/3000 [07:16<11:27,  2.97it/s, loss=0.0851, lr=0.002]\n",
      "Steps:  32%|███▏      | 957/3000 [07:17<11:21,  3.00it/s, loss=0.136, lr=0.002] \n",
      "Steps:  32%|███▏      | 958/3000 [07:17<11:18,  3.01it/s, loss=0.249, lr=0.002]\n",
      "Steps:  32%|███▏      | 959/3000 [07:17<11:20,  3.00it/s, loss=0.192, lr=0.002]\n",
      "Steps:  32%|███▏      | 960/3000 [07:18<11:29,  2.96it/s, loss=0.0833, lr=0.002]\n",
      "Steps:  32%|███▏      | 961/3000 [07:18<11:29,  2.96it/s, loss=0.0837, lr=0.002]\n",
      "Steps:  32%|███▏      | 962/3000 [07:18<11:25,  2.97it/s, loss=0.265, lr=0.002] \n",
      "Steps:  32%|███▏      | 963/3000 [07:19<11:22,  2.99it/s, loss=0.126, lr=0.002]\n",
      "Steps:  32%|███▏      | 964/3000 [07:19<11:19,  3.00it/s, loss=0.151, lr=0.002]\n",
      "Steps:  32%|███▏      | 965/3000 [07:19<11:22,  2.98it/s, loss=0.153, lr=0.002]\n",
      "Steps:  32%|███▏      | 966/3000 [07:20<11:20,  2.99it/s, loss=0.258, lr=0.002]\n",
      "Steps:  32%|███▏      | 967/3000 [07:20<11:15,  3.01it/s, loss=0.143, lr=0.002]\n",
      "Steps:  32%|███▏      | 968/3000 [07:20<11:13,  3.02it/s, loss=0.0226, lr=0.002]\n",
      "Steps:  32%|███▏      | 969/3000 [07:21<11:12,  3.02it/s, loss=0.0767, lr=0.002]\n",
      "Steps:  32%|███▏      | 970/3000 [07:21<11:16,  3.00it/s, loss=0.114, lr=0.002] \n",
      "Steps:  32%|███▏      | 971/3000 [07:21<11:18,  2.99it/s, loss=0.0341, lr=0.002]\n",
      "Steps:  32%|███▏      | 972/3000 [07:22<11:19,  2.98it/s, loss=0.0553, lr=0.002]\n",
      "Steps:  32%|███▏      | 973/3000 [07:22<11:20,  2.98it/s, loss=0.0774, lr=0.002]\n",
      "Steps:  32%|███▏      | 974/3000 [07:22<11:21,  2.97it/s, loss=0.113, lr=0.002] \n",
      "Steps:  32%|███▎      | 975/3000 [07:23<11:20,  2.98it/s, loss=0.108, lr=0.002]\n",
      "Steps:  33%|███▎      | 976/3000 [07:23<11:21,  2.97it/s, loss=0.105, lr=0.002]\n",
      "Steps:  33%|███▎      | 977/3000 [07:23<11:18,  2.98it/s, loss=0.132, lr=0.002]\n",
      "Steps:  33%|███▎      | 978/3000 [07:24<11:16,  2.99it/s, loss=0.162, lr=0.002]\n",
      "Steps:  33%|███▎      | 979/3000 [07:24<12:34,  2.68it/s, loss=0.109, lr=0.002]\n",
      "Steps:  33%|███▎      | 980/3000 [07:24<12:13,  2.75it/s, loss=0.21, lr=0.002] \n",
      "Steps:  33%|███▎      | 981/3000 [07:25<11:55,  2.82it/s, loss=0.0926, lr=0.002]\n",
      "Steps:  33%|███▎      | 982/3000 [07:25<11:45,  2.86it/s, loss=0.0958, lr=0.002]\n",
      "Steps:  33%|███▎      | 983/3000 [07:25<11:36,  2.90it/s, loss=0.166, lr=0.002] \n",
      "Steps:  33%|███▎      | 984/3000 [07:26<11:31,  2.92it/s, loss=0.286, lr=0.002]\n",
      "Steps:  33%|███▎      | 985/3000 [07:26<11:26,  2.93it/s, loss=0.236, lr=0.002]\n",
      "Steps:  33%|███▎      | 986/3000 [07:26<11:27,  2.93it/s, loss=0.0747, lr=0.002]\n",
      "Steps:  33%|███▎      | 987/3000 [07:27<11:19,  2.96it/s, loss=0.168, lr=0.002] \n",
      "Steps:  33%|███▎      | 988/3000 [07:27<11:10,  3.00it/s, loss=0.18, lr=0.002] \n",
      "Steps:  33%|███▎      | 989/3000 [07:27<11:08,  3.01it/s, loss=0.0952, lr=0.002]\n",
      "Steps:  33%|███▎      | 990/3000 [07:28<11:09,  3.00it/s, loss=0.113, lr=0.002] \n",
      "Steps:  33%|███▎      | 991/3000 [07:28<11:13,  2.98it/s, loss=0.155, lr=0.002]\n",
      "Steps:  33%|███▎      | 992/3000 [07:28<11:11,  2.99it/s, loss=0.207, lr=0.002]\n",
      "Steps:  33%|███▎      | 993/3000 [07:29<11:14,  2.98it/s, loss=0.0976, lr=0.002]\n",
      "Steps:  33%|███▎      | 994/3000 [07:29<11:14,  2.98it/s, loss=0.286, lr=0.002] \n",
      "Steps:  33%|███▎      | 995/3000 [07:29<11:10,  2.99it/s, loss=0.127, lr=0.002]\n",
      "Steps:  33%|███▎      | 996/3000 [07:30<11:08,  3.00it/s, loss=0.0806, lr=0.002]\n",
      "Steps:  33%|███▎      | 997/3000 [07:30<11:12,  2.98it/s, loss=0.0646, lr=0.002]\n",
      "Steps:  33%|███▎      | 998/3000 [07:30<11:14,  2.97it/s, loss=0.0883, lr=0.002]\n",
      "Steps:  33%|███▎      | 999/3000 [07:31<11:18,  2.95it/s, loss=0.191, lr=0.002] \n",
      "Steps:  33%|███▎      | 1000/3000 [07:31<11:18,  2.95it/s, loss=0.191, lr=0.002]05/09/2024 05:28:52 - INFO - __main__ - Saving embeddings\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:28:52 - INFO - accelerate.accelerator - Saving current state to /tmp/textual_inversion_cat/checkpoint-1000\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:28:53 - INFO - accelerate.checkpointing - Model weights saved in /tmp/textual_inversion_cat/checkpoint-1000/model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:28:53 - INFO - accelerate.checkpointing - Optimizer state saved in /tmp/textual_inversion_cat/checkpoint-1000/optimizer.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:28:53 - INFO - accelerate.checkpointing - Scheduler state saved in /tmp/textual_inversion_cat/checkpoint-1000/scheduler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:28:53 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /tmp/textual_inversion_cat/checkpoint-1000/sampler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:28:53 - INFO - accelerate.checkpointing - Random states saved in /tmp/textual_inversion_cat/checkpoint-1000/random_states_0.pkl\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:28:53 - INFO - __main__ - Saved state to /tmp/textual_inversion_cat/checkpoint-1000\n",
      "Steps:  33%|███▎      | 1000/3000 [07:32<11:18,  2.95it/s, loss=0.123, lr=0.002]\n",
      "Steps:  33%|███▎      | 1001/3000 [07:33<23:34,  1.41it/s, loss=0.125, lr=0.002]\n",
      "Steps:  33%|███▎      | 1002/3000 [07:33<19:46,  1.68it/s, loss=0.104, lr=0.002]\n",
      "Steps:  33%|███▎      | 1003/3000 [07:33<17:05,  1.95it/s, loss=0.224, lr=0.002]\n",
      "Steps:  33%|███▎      | 1004/3000 [07:34<15:15,  2.18it/s, loss=0.251, lr=0.002]\n",
      "Steps:  34%|███▎      | 1005/3000 [07:34<14:06,  2.36it/s, loss=0.1, lr=0.002]  \n",
      "Steps:  34%|███▎      | 1006/3000 [07:34<13:11,  2.52it/s, loss=0.0987, lr=0.002]\n",
      "Steps:  34%|███▎      | 1007/3000 [07:35<12:28,  2.66it/s, loss=0.149, lr=0.002] \n",
      "Steps:  34%|███▎      | 1008/3000 [07:35<12:09,  2.73it/s, loss=0.165, lr=0.002]\n",
      "Steps:  34%|███▎      | 1009/3000 [07:35<11:48,  2.81it/s, loss=0.315, lr=0.002]\n",
      "Steps:  34%|███▎      | 1010/3000 [07:36<11:24,  2.91it/s, loss=0.24, lr=0.002] \n",
      "Steps:  34%|███▎      | 1011/3000 [07:36<11:18,  2.93it/s, loss=0.117, lr=0.002]\n",
      "Steps:  34%|███▎      | 1012/3000 [07:36<11:10,  2.96it/s, loss=0.0272, lr=0.002]\n",
      "Steps:  34%|███▍      | 1013/3000 [07:37<11:03,  2.99it/s, loss=0.0972, lr=0.002]\n",
      "Steps:  34%|███▍      | 1014/3000 [07:37<11:08,  2.97it/s, loss=0.0846, lr=0.002]\n",
      "Steps:  34%|███▍      | 1015/3000 [07:37<11:08,  2.97it/s, loss=0.188, lr=0.002] \n",
      "Steps:  34%|███▍      | 1016/3000 [07:38<11:07,  2.97it/s, loss=0.0708, lr=0.002]\n",
      "Steps:  34%|███▍      | 1017/3000 [07:38<11:01,  3.00it/s, loss=0.098, lr=0.002] \n",
      "Steps:  34%|███▍      | 1018/3000 [07:38<11:26,  2.89it/s, loss=0.11, lr=0.002] \n",
      "Steps:  34%|███▍      | 1019/3000 [07:39<11:13,  2.94it/s, loss=0.309, lr=0.002]\n",
      "Steps:  34%|███▍      | 1020/3000 [07:39<11:08,  2.96it/s, loss=0.108, lr=0.002]\n",
      "Steps:  34%|███▍      | 1021/3000 [07:39<11:10,  2.95it/s, loss=0.174, lr=0.002]\n",
      "Steps:  34%|███▍      | 1022/3000 [07:40<11:18,  2.91it/s, loss=0.0651, lr=0.002]\n",
      "Steps:  34%|███▍      | 1023/3000 [07:40<11:15,  2.93it/s, loss=0.167, lr=0.002] \n",
      "Steps:  34%|███▍      | 1024/3000 [07:40<11:13,  2.93it/s, loss=0.0845, lr=0.002]\n",
      "Steps:  34%|███▍      | 1025/3000 [07:41<11:10,  2.95it/s, loss=0.0992, lr=0.002]\n",
      "Steps:  34%|███▍      | 1026/3000 [07:41<11:08,  2.95it/s, loss=0.11, lr=0.002]  \n",
      "Steps:  34%|███▍      | 1027/3000 [07:41<11:02,  2.98it/s, loss=0.167, lr=0.002]\n",
      "Steps:  34%|███▍      | 1028/3000 [07:42<11:01,  2.98it/s, loss=0.122, lr=0.002]\n",
      "Steps:  34%|███▍      | 1029/3000 [07:42<11:02,  2.97it/s, loss=0.178, lr=0.002]\n",
      "Steps:  34%|███▍      | 1030/3000 [07:42<10:55,  3.01it/s, loss=0.0805, lr=0.002]\n",
      "Steps:  34%|███▍      | 1031/3000 [07:43<10:56,  3.00it/s, loss=0.101, lr=0.002] \n",
      "Steps:  34%|███▍      | 1032/3000 [07:43<10:56,  3.00it/s, loss=0.235, lr=0.002]\n",
      "Steps:  34%|███▍      | 1033/3000 [07:43<10:53,  3.01it/s, loss=0.108, lr=0.002]\n",
      "Steps:  34%|███▍      | 1034/3000 [07:44<10:54,  3.00it/s, loss=0.203, lr=0.002]\n",
      "Steps:  34%|███▍      | 1035/3000 [07:44<10:56,  2.99it/s, loss=0.154, lr=0.002]\n",
      "Steps:  35%|███▍      | 1036/3000 [07:44<10:55,  3.00it/s, loss=0.194, lr=0.002]\n",
      "Steps:  35%|███▍      | 1037/3000 [07:45<10:51,  3.01it/s, loss=0.029, lr=0.002]\n",
      "Steps:  35%|███▍      | 1038/3000 [07:45<10:48,  3.03it/s, loss=0.151, lr=0.002]\n",
      "Steps:  35%|███▍      | 1039/3000 [07:45<10:51,  3.01it/s, loss=0.135, lr=0.002]\n",
      "Steps:  35%|███▍      | 1040/3000 [07:46<10:51,  3.01it/s, loss=0.247, lr=0.002]\n",
      "Steps:  35%|███▍      | 1041/3000 [07:46<10:56,  2.98it/s, loss=0.125, lr=0.002]\n",
      "Steps:  35%|███▍      | 1042/3000 [07:46<10:57,  2.98it/s, loss=0.0343, lr=0.002]\n",
      "Steps:  35%|███▍      | 1043/3000 [07:47<10:57,  2.98it/s, loss=0.117, lr=0.002] \n",
      "Steps:  35%|███▍      | 1044/3000 [07:47<10:59,  2.97it/s, loss=0.101, lr=0.002]\n",
      "Steps:  35%|███▍      | 1045/3000 [07:47<10:49,  3.01it/s, loss=0.224, lr=0.002]\n",
      "Steps:  35%|███▍      | 1046/3000 [07:48<10:43,  3.03it/s, loss=0.236, lr=0.002]\n",
      "Steps:  35%|███▍      | 1047/3000 [07:48<11:51,  2.75it/s, loss=0.0875, lr=0.002]\n",
      "Steps:  35%|███▍      | 1048/3000 [07:49<11:34,  2.81it/s, loss=0.127, lr=0.002] \n",
      "Steps:  35%|███▍      | 1049/3000 [07:49<11:22,  2.86it/s, loss=0.108, lr=0.002]\n",
      "Steps:  35%|███▌      | 1050/3000 [07:49<10:10,  3.20it/s, loss=0.113, lr=0.002]\n",
      "Steps:  35%|███▌      | 1051/3000 [07:50<11:17,  2.88it/s, loss=0.0662, lr=0.002]\n",
      "Steps:  35%|███▌      | 1052/3000 [07:50<11:14,  2.89it/s, loss=0.0247, lr=0.002]\n",
      "Steps:  35%|███▌      | 1053/3000 [07:50<11:09,  2.91it/s, loss=0.127, lr=0.002] \n",
      "Steps:  35%|███▌      | 1054/3000 [07:51<11:04,  2.93it/s, loss=0.0835, lr=0.002]\n",
      "Steps:  35%|███▌      | 1055/3000 [07:51<10:50,  2.99it/s, loss=0.11, lr=0.002]  \n",
      "Steps:  35%|███▌      | 1056/3000 [07:51<10:56,  2.96it/s, loss=0.231, lr=0.002]\n",
      "Steps:  35%|███▌      | 1057/3000 [07:52<10:51,  2.98it/s, loss=0.226, lr=0.002]\n",
      "Steps:  35%|███▌      | 1058/3000 [07:52<10:56,  2.96it/s, loss=0.0723, lr=0.002]\n",
      "Steps:  35%|███▌      | 1059/3000 [07:52<10:57,  2.95it/s, loss=0.0297, lr=0.002]\n",
      "Steps:  35%|███▌      | 1060/3000 [07:53<11:01,  2.93it/s, loss=0.151, lr=0.002] \n",
      "Steps:  35%|███▌      | 1061/3000 [07:53<11:07,  2.90it/s, loss=0.249, lr=0.002]\n",
      "Steps:  35%|███▌      | 1062/3000 [07:53<11:01,  2.93it/s, loss=0.142, lr=0.002]\n",
      "Steps:  35%|███▌      | 1063/3000 [07:54<11:00,  2.93it/s, loss=0.107, lr=0.002]\n",
      "Steps:  35%|███▌      | 1064/3000 [07:54<11:06,  2.90it/s, loss=0.129, lr=0.002]\n",
      "Steps:  36%|███▌      | 1065/3000 [07:54<11:00,  2.93it/s, loss=0.277, lr=0.002]\n",
      "Steps:  36%|███▌      | 1066/3000 [07:55<10:59,  2.93it/s, loss=0.19, lr=0.002] \n",
      "Steps:  36%|███▌      | 1067/3000 [07:55<11:01,  2.92it/s, loss=0.206, lr=0.002]\n",
      "Steps:  36%|███▌      | 1068/3000 [07:55<11:04,  2.91it/s, loss=0.16, lr=0.002] \n",
      "Steps:  36%|███▌      | 1069/3000 [07:56<11:02,  2.91it/s, loss=0.0347, lr=0.002]\n",
      "Steps:  36%|███▌      | 1070/3000 [07:56<11:23,  2.82it/s, loss=0.0682, lr=0.002]\n",
      "Steps:  36%|███▌      | 1071/3000 [07:56<11:13,  2.86it/s, loss=0.341, lr=0.002] \n",
      "Steps:  36%|███▌      | 1072/3000 [07:57<11:05,  2.90it/s, loss=0.102, lr=0.002]\n",
      "Steps:  36%|███▌      | 1073/3000 [07:57<11:06,  2.89it/s, loss=0.0907, lr=0.002]\n",
      "Steps:  36%|███▌      | 1074/3000 [07:57<11:03,  2.90it/s, loss=0.115, lr=0.002] \n",
      "Steps:  36%|███▌      | 1075/3000 [07:58<10:53,  2.95it/s, loss=0.196, lr=0.002]\n",
      "Steps:  36%|███▌      | 1076/3000 [07:58<10:55,  2.93it/s, loss=0.0662, lr=0.002]\n",
      "Steps:  36%|███▌      | 1077/3000 [07:58<10:52,  2.95it/s, loss=0.0841, lr=0.002]\n",
      "Steps:  36%|███▌      | 1078/3000 [07:59<10:56,  2.93it/s, loss=0.0718, lr=0.002]\n",
      "Steps:  36%|███▌      | 1079/3000 [07:59<10:56,  2.93it/s, loss=0.169, lr=0.002] \n",
      "Steps:  36%|███▌      | 1080/3000 [07:59<10:51,  2.95it/s, loss=0.186, lr=0.002]\n",
      "Steps:  36%|███▌      | 1081/3000 [08:00<10:53,  2.93it/s, loss=0.0725, lr=0.002]\n",
      "Steps:  36%|███▌      | 1082/3000 [08:00<10:51,  2.94it/s, loss=0.0678, lr=0.002]\n",
      "Steps:  36%|███▌      | 1083/3000 [08:00<10:54,  2.93it/s, loss=0.0691, lr=0.002]\n",
      "Steps:  36%|███▌      | 1084/3000 [08:01<10:48,  2.95it/s, loss=0.0841, lr=0.002]\n",
      "Steps:  36%|███▌      | 1085/3000 [08:01<10:48,  2.95it/s, loss=0.0722, lr=0.002]\n",
      "Steps:  36%|███▌      | 1086/3000 [08:01<10:54,  2.93it/s, loss=0.0722, lr=0.002]\n",
      "Steps:  36%|███▌      | 1086/3000 [08:01<10:54,  2.93it/s, loss=0.0863, lr=0.002]\n",
      "Steps:  36%|███▌      | 1087/3000 [08:02<11:06,  2.87it/s, loss=0.176, lr=0.002] \n",
      "Steps:  36%|███▋      | 1088/3000 [08:02<10:58,  2.90it/s, loss=0.0909, lr=0.002]\n",
      "Steps:  36%|███▋      | 1089/3000 [08:02<10:51,  2.93it/s, loss=0.19, lr=0.002]  \n",
      "Steps:  36%|███▋      | 1090/3000 [08:03<10:43,  2.97it/s, loss=0.0768, lr=0.002]\n",
      "Steps:  36%|███▋      | 1091/3000 [08:03<10:47,  2.95it/s, loss=0.116, lr=0.002] \n",
      "Steps:  36%|███▋      | 1092/3000 [08:04<10:44,  2.96it/s, loss=0.308, lr=0.002]\n",
      "Steps:  36%|███▋      | 1093/3000 [08:04<10:44,  2.96it/s, loss=0.0754, lr=0.002]\n",
      "Steps:  36%|███▋      | 1094/3000 [08:04<10:45,  2.95it/s, loss=0.0829, lr=0.002]\n",
      "Steps:  36%|███▋      | 1095/3000 [08:05<10:39,  2.98it/s, loss=0.295, lr=0.002] \n",
      "Steps:  37%|███▋      | 1096/3000 [08:05<10:47,  2.94it/s, loss=0.0698, lr=0.002]\n",
      "Steps:  37%|███▋      | 1097/3000 [08:05<10:51,  2.92it/s, loss=0.065, lr=0.002] \n",
      "Steps:  37%|███▋      | 1098/3000 [08:06<10:52,  2.91it/s, loss=0.102, lr=0.002]\n",
      "Steps:  37%|███▋      | 1099/3000 [08:06<10:48,  2.93it/s, loss=0.118, lr=0.002]\n",
      "Steps:  37%|███▋      | 1100/3000 [08:06<10:51,  2.92it/s, loss=0.127, lr=0.002]\n",
      "Steps:  37%|███▋      | 1101/3000 [08:07<10:49,  2.92it/s, loss=0.15, lr=0.002] \n",
      "Steps:  37%|███▋      | 1102/3000 [08:07<10:41,  2.96it/s, loss=0.102, lr=0.002]\n",
      "Steps:  37%|███▋      | 1103/3000 [08:07<10:40,  2.96it/s, loss=0.149, lr=0.002]\n",
      "Steps:  37%|███▋      | 1104/3000 [08:08<10:48,  2.92it/s, loss=0.117, lr=0.002]\n",
      "Steps:  37%|███▋      | 1105/3000 [08:08<10:41,  2.95it/s, loss=0.102, lr=0.002]\n",
      "Steps:  37%|███▋      | 1106/3000 [08:08<10:38,  2.97it/s, loss=0.0928, lr=0.002]\n",
      "Steps:  37%|███▋      | 1107/3000 [08:09<10:34,  2.98it/s, loss=0.131, lr=0.002] \n",
      "Steps:  37%|███▋      | 1108/3000 [08:09<10:31,  3.00it/s, loss=0.0659, lr=0.002]\n",
      "Steps:  37%|███▋      | 1109/3000 [08:09<10:38,  2.96it/s, loss=0.143, lr=0.002] \n",
      "Steps:  37%|███▋      | 1110/3000 [08:10<10:46,  2.93it/s, loss=0.112, lr=0.002]\n",
      "Steps:  37%|███▋      | 1111/3000 [08:10<10:43,  2.94it/s, loss=0.101, lr=0.002]\n",
      "Steps:  37%|███▋      | 1112/3000 [08:10<10:43,  2.93it/s, loss=0.0901, lr=0.002]\n",
      "Steps:  37%|███▋      | 1113/3000 [08:11<11:58,  2.63it/s, loss=0.0955, lr=0.002]\n",
      "Steps:  37%|███▋      | 1114/3000 [08:11<11:37,  2.71it/s, loss=0.112, lr=0.002] \n",
      "Steps:  37%|███▋      | 1115/3000 [08:11<11:23,  2.76it/s, loss=0.136, lr=0.002]\n",
      "Steps:  37%|███▋      | 1116/3000 [08:12<11:13,  2.80it/s, loss=0.212, lr=0.002]\n",
      "Steps:  37%|███▋      | 1117/3000 [08:12<11:01,  2.84it/s, loss=0.255, lr=0.002]\n",
      "Steps:  37%|███▋      | 1118/3000 [08:12<10:42,  2.93it/s, loss=0.116, lr=0.002]\n",
      "Steps:  37%|███▋      | 1119/3000 [08:13<10:43,  2.92it/s, loss=0.143, lr=0.002]\n",
      "Steps:  37%|███▋      | 1120/3000 [08:13<10:44,  2.92it/s, loss=0.228, lr=0.002]\n",
      "Steps:  37%|███▋      | 1121/3000 [08:13<10:46,  2.91it/s, loss=0.146, lr=0.002]\n",
      "Steps:  37%|███▋      | 1122/3000 [08:14<10:47,  2.90it/s, loss=0.0859, lr=0.002]\n",
      "Steps:  37%|███▋      | 1123/3000 [08:14<10:39,  2.93it/s, loss=0.0289, lr=0.002]\n",
      "Steps:  37%|███▋      | 1124/3000 [08:15<10:37,  2.94it/s, loss=0.262, lr=0.002] \n",
      "Steps:  38%|███▊      | 1125/3000 [08:15<10:35,  2.95it/s, loss=0.11, lr=0.002] \n",
      "Steps:  38%|███▊      | 1126/3000 [08:15<10:35,  2.95it/s, loss=0.136, lr=0.002]\n",
      "Steps:  38%|███▊      | 1127/3000 [08:16<10:32,  2.96it/s, loss=0.0351, lr=0.002]\n",
      "Steps:  38%|███▊      | 1128/3000 [08:16<10:30,  2.97it/s, loss=0.12, lr=0.002]  \n",
      "Steps:  38%|███▊      | 1129/3000 [08:16<10:33,  2.96it/s, loss=0.203, lr=0.002]\n",
      "Steps:  38%|███▊      | 1130/3000 [08:17<10:52,  2.87it/s, loss=0.251, lr=0.002]\n",
      "Steps:  38%|███▊      | 1131/3000 [08:17<10:47,  2.89it/s, loss=0.143, lr=0.002]\n",
      "Steps:  38%|███▊      | 1132/3000 [08:17<10:39,  2.92it/s, loss=0.167, lr=0.002]\n",
      "Steps:  38%|███▊      | 1133/3000 [08:18<10:34,  2.94it/s, loss=0.107, lr=0.002]\n",
      "Steps:  38%|███▊      | 1134/3000 [08:18<10:29,  2.96it/s, loss=0.11, lr=0.002] \n",
      "Steps:  38%|███▊      | 1135/3000 [08:18<10:30,  2.96it/s, loss=0.0756, lr=0.002]\n",
      "Steps:  38%|███▊      | 1136/3000 [08:19<10:30,  2.96it/s, loss=0.237, lr=0.002] \n",
      "Steps:  38%|███▊      | 1137/3000 [08:19<10:29,  2.96it/s, loss=0.145, lr=0.002]\n",
      "Steps:  38%|███▊      | 1138/3000 [08:19<10:26,  2.97it/s, loss=0.15, lr=0.002] \n",
      "Steps:  38%|███▊      | 1139/3000 [08:20<10:23,  2.98it/s, loss=0.161, lr=0.002]\n",
      "Steps:  38%|███▊      | 1140/3000 [08:20<10:25,  2.97it/s, loss=0.149, lr=0.002]\n",
      "Steps:  38%|███▊      | 1141/3000 [08:20<10:26,  2.97it/s, loss=0.144, lr=0.002]\n",
      "Steps:  38%|███▊      | 1142/3000 [08:21<10:27,  2.96it/s, loss=0.107, lr=0.002]\n",
      "Steps:  38%|███▊      | 1143/3000 [08:21<10:21,  2.99it/s, loss=0.115, lr=0.002]\n",
      "Steps:  38%|███▊      | 1144/3000 [08:21<10:24,  2.97it/s, loss=0.15, lr=0.002] \n",
      "Steps:  38%|███▊      | 1145/3000 [08:22<10:21,  2.98it/s, loss=0.175, lr=0.002]\n",
      "Steps:  38%|███▊      | 1146/3000 [08:22<10:22,  2.98it/s, loss=0.143, lr=0.002]\n",
      "Steps:  38%|███▊      | 1147/3000 [08:22<10:18,  3.00it/s, loss=0.229, lr=0.002]\n",
      "Steps:  38%|███▊      | 1148/3000 [08:23<10:18,  2.99it/s, loss=0.149, lr=0.002]\n",
      "Steps:  38%|███▊      | 1149/3000 [08:23<10:22,  2.97it/s, loss=0.11, lr=0.002] \n",
      "Steps:  38%|███▊      | 1150/3000 [08:23<10:23,  2.97it/s, loss=0.0863, lr=0.002]\n",
      "Steps:  38%|███▊      | 1151/3000 [08:24<10:27,  2.95it/s, loss=0.0905, lr=0.002]\n",
      "Steps:  38%|███▊      | 1152/3000 [08:24<10:30,  2.93it/s, loss=0.2, lr=0.002]   \n",
      "Steps:  38%|███▊      | 1153/3000 [08:24<10:17,  2.99it/s, loss=0.167, lr=0.002]\n",
      "Steps:  38%|███▊      | 1154/3000 [08:25<10:11,  3.02it/s, loss=0.287, lr=0.002]\n",
      "Steps:  38%|███▊      | 1155/3000 [08:25<10:16,  2.99it/s, loss=0.263, lr=0.002]\n",
      "Steps:  39%|███▊      | 1156/3000 [08:25<10:34,  2.91it/s, loss=0.127, lr=0.002]\n",
      "Steps:  39%|███▊      | 1157/3000 [08:26<10:28,  2.93it/s, loss=0.133, lr=0.002]\n",
      "Steps:  39%|███▊      | 1158/3000 [08:26<10:28,  2.93it/s, loss=0.209, lr=0.002]\n",
      "Steps:  39%|███▊      | 1159/3000 [08:26<10:28,  2.93it/s, loss=0.112, lr=0.002]\n",
      "Steps:  39%|███▊      | 1160/3000 [08:27<10:19,  2.97it/s, loss=0.234, lr=0.002]\n",
      "Steps:  39%|███▊      | 1161/3000 [08:27<10:26,  2.94it/s, loss=0.0968, lr=0.002]\n",
      "Steps:  39%|███▊      | 1162/3000 [08:27<10:22,  2.95it/s, loss=0.107, lr=0.002] \n",
      "Steps:  39%|███▉      | 1163/3000 [08:28<10:19,  2.96it/s, loss=0.214, lr=0.002]\n",
      "Steps:  39%|███▉      | 1164/3000 [08:28<10:20,  2.96it/s, loss=0.126, lr=0.002]\n",
      "Steps:  39%|███▉      | 1165/3000 [08:28<10:26,  2.93it/s, loss=0.19, lr=0.002] \n",
      "Steps:  39%|███▉      | 1166/3000 [08:29<10:27,  2.92it/s, loss=0.126, lr=0.002]\n",
      "Steps:  39%|███▉      | 1167/3000 [08:29<10:21,  2.95it/s, loss=0.306, lr=0.002]\n",
      "Steps:  39%|███▉      | 1168/3000 [08:29<10:22,  2.94it/s, loss=0.0557, lr=0.002]\n",
      "Steps:  39%|███▉      | 1169/3000 [08:30<10:16,  2.97it/s, loss=0.0664, lr=0.002]\n",
      "Steps:  39%|███▉      | 1170/3000 [08:30<10:19,  2.95it/s, loss=0.112, lr=0.002] \n",
      "Steps:  39%|███▉      | 1171/3000 [08:31<11:18,  2.69it/s, loss=0.124, lr=0.002]\n",
      "Steps:  39%|███▉      | 1172/3000 [08:31<11:02,  2.76it/s, loss=0.105, lr=0.002]\n",
      "Steps:  39%|███▉      | 1173/3000 [08:31<11:02,  2.76it/s, loss=0.176, lr=0.002]\n",
      "Steps:  39%|███▉      | 1174/3000 [08:32<10:51,  2.80it/s, loss=0.0183, lr=0.002]\n",
      "Steps:  39%|███▉      | 1175/3000 [08:32<10:40,  2.85it/s, loss=0.0881, lr=0.002]\n",
      "Steps:  39%|███▉      | 1176/3000 [08:32<10:36,  2.87it/s, loss=0.0853, lr=0.002]\n",
      "Steps:  39%|███▉      | 1177/3000 [08:33<10:32,  2.88it/s, loss=0.147, lr=0.002] \n",
      "Steps:  39%|███▉      | 1178/3000 [08:33<10:28,  2.90it/s, loss=0.221, lr=0.002]\n",
      "Steps:  39%|███▉      | 1179/3000 [08:33<10:20,  2.94it/s, loss=0.182, lr=0.002]\n",
      "Steps:  39%|███▉      | 1180/3000 [08:34<10:20,  2.93it/s, loss=0.103, lr=0.002]\n",
      "Steps:  39%|███▉      | 1181/3000 [08:34<10:23,  2.92it/s, loss=0.0984, lr=0.002]\n",
      "Steps:  39%|███▉      | 1182/3000 [08:34<10:20,  2.93it/s, loss=0.141, lr=0.002] \n",
      "Steps:  39%|███▉      | 1183/3000 [08:35<10:23,  2.91it/s, loss=0.128, lr=0.002]\n",
      "Steps:  39%|███▉      | 1184/3000 [08:35<10:21,  2.92it/s, loss=0.164, lr=0.002]\n",
      "Steps:  40%|███▉      | 1185/3000 [08:35<10:15,  2.95it/s, loss=0.131, lr=0.002]\n",
      "Steps:  40%|███▉      | 1186/3000 [08:36<10:15,  2.95it/s, loss=0.116, lr=0.002]\n",
      "Steps:  40%|███▉      | 1187/3000 [08:36<10:12,  2.96it/s, loss=0.0752, lr=0.002]\n",
      "Steps:  40%|███▉      | 1188/3000 [08:36<10:10,  2.97it/s, loss=0.235, lr=0.002] \n",
      "Steps:  40%|███▉      | 1189/3000 [08:37<10:08,  2.98it/s, loss=0.164, lr=0.002]\n",
      "Steps:  40%|███▉      | 1190/3000 [08:37<10:13,  2.95it/s, loss=0.167, lr=0.002]\n",
      "Steps:  40%|███▉      | 1191/3000 [08:37<10:16,  2.93it/s, loss=0.112, lr=0.002]\n",
      "Steps:  40%|███▉      | 1192/3000 [08:38<10:08,  2.97it/s, loss=0.27, lr=0.002] \n",
      "Steps:  40%|███▉      | 1193/3000 [08:38<10:12,  2.95it/s, loss=0.111, lr=0.002]\n",
      "Steps:  40%|███▉      | 1194/3000 [08:38<10:12,  2.95it/s, loss=0.024, lr=0.002]\n",
      "Steps:  40%|███▉      | 1195/3000 [08:39<10:14,  2.94it/s, loss=0.0806, lr=0.002]\n",
      "Steps:  40%|███▉      | 1196/3000 [08:39<10:16,  2.93it/s, loss=0.127, lr=0.002] \n",
      "Steps:  40%|███▉      | 1197/3000 [08:39<10:15,  2.93it/s, loss=0.106, lr=0.002]\n",
      "Steps:  40%|███▉      | 1198/3000 [08:40<10:09,  2.96it/s, loss=0.213, lr=0.002]\n",
      "Steps:  40%|███▉      | 1199/3000 [08:40<10:24,  2.89it/s, loss=0.08, lr=0.002] \n",
      "Steps:  40%|████      | 1200/3000 [08:40<09:24,  3.19it/s, loss=0.0894, lr=0.002]\n",
      "Steps:  40%|████      | 1201/3000 [08:41<10:30,  2.86it/s, loss=0.26, lr=0.002]  \n",
      "Steps:  40%|████      | 1202/3000 [08:41<10:27,  2.87it/s, loss=0.0972, lr=0.002]\n",
      "Steps:  40%|████      | 1203/3000 [08:41<10:17,  2.91it/s, loss=0.234, lr=0.002] \n",
      "Steps:  40%|████      | 1204/3000 [08:42<10:05,  2.97it/s, loss=0.0948, lr=0.002]\n",
      "Steps:  40%|████      | 1205/3000 [08:42<10:01,  2.99it/s, loss=0.111, lr=0.002] \n",
      "Steps:  40%|████      | 1206/3000 [08:42<10:00,  2.99it/s, loss=0.221, lr=0.002]\n",
      "Steps:  40%|████      | 1207/3000 [08:43<10:06,  2.96it/s, loss=0.0246, lr=0.002]\n",
      "Steps:  40%|████      | 1208/3000 [08:43<10:04,  2.96it/s, loss=0.143, lr=0.002] \n",
      "Steps:  40%|████      | 1209/3000 [08:43<10:01,  2.98it/s, loss=0.166, lr=0.002]\n",
      "Steps:  40%|████      | 1210/3000 [08:44<10:01,  2.98it/s, loss=0.15, lr=0.002] \n",
      "Steps:  40%|████      | 1211/3000 [08:44<09:56,  3.00it/s, loss=0.131, lr=0.002]\n",
      "Steps:  40%|████      | 1212/3000 [08:44<09:58,  2.99it/s, loss=0.277, lr=0.002]\n",
      "Steps:  40%|████      | 1213/3000 [08:45<09:56,  3.00it/s, loss=0.13, lr=0.002] \n",
      "Steps:  40%|████      | 1214/3000 [08:45<09:56,  2.99it/s, loss=0.0712, lr=0.002]\n",
      "Steps:  40%|████      | 1215/3000 [08:45<09:54,  3.00it/s, loss=0.264, lr=0.002] \n",
      "Steps:  41%|████      | 1216/3000 [08:46<09:58,  2.98it/s, loss=0.0262, lr=0.002]\n",
      "Steps:  41%|████      | 1217/3000 [08:46<10:01,  2.96it/s, loss=0.312, lr=0.002] \n",
      "Steps:  41%|████      | 1218/3000 [08:46<10:05,  2.94it/s, loss=0.158, lr=0.002]\n",
      "Steps:  41%|████      | 1219/3000 [08:47<10:01,  2.96it/s, loss=0.235, lr=0.002]\n",
      "Steps:  41%|████      | 1220/3000 [08:47<09:59,  2.97it/s, loss=0.108, lr=0.002]\n",
      "Steps:  41%|████      | 1221/3000 [08:47<10:01,  2.96it/s, loss=0.202, lr=0.002]\n",
      "Steps:  41%|████      | 1222/3000 [08:48<10:01,  2.95it/s, loss=0.165, lr=0.002]\n",
      "Steps:  41%|████      | 1223/3000 [08:48<09:56,  2.98it/s, loss=0.0942, lr=0.002]\n",
      "Steps:  41%|████      | 1224/3000 [08:48<09:47,  3.02it/s, loss=0.104, lr=0.002] \n",
      "Steps:  41%|████      | 1225/3000 [08:49<10:10,  2.91it/s, loss=0.126, lr=0.002]\n",
      "Steps:  41%|████      | 1226/3000 [08:49<10:02,  2.95it/s, loss=0.175, lr=0.002]\n",
      "Steps:  41%|████      | 1227/3000 [08:49<09:58,  2.96it/s, loss=0.131, lr=0.002]\n",
      "Steps:  41%|████      | 1228/3000 [08:50<11:09,  2.65it/s, loss=0.185, lr=0.002]\n",
      "Steps:  41%|████      | 1229/3000 [08:50<10:45,  2.74it/s, loss=0.156, lr=0.002]\n",
      "Steps:  41%|████      | 1230/3000 [08:51<10:28,  2.82it/s, loss=0.114, lr=0.002]\n",
      "Steps:  41%|████      | 1231/3000 [08:51<10:18,  2.86it/s, loss=0.0883, lr=0.002]\n",
      "Steps:  41%|████      | 1232/3000 [08:51<10:13,  2.88it/s, loss=0.28, lr=0.002]  \n",
      "Steps:  41%|████      | 1233/3000 [08:52<10:07,  2.91it/s, loss=0.0242, lr=0.002]\n",
      "Steps:  41%|████      | 1234/3000 [08:52<10:01,  2.94it/s, loss=0.216, lr=0.002] \n",
      "Steps:  41%|████      | 1235/3000 [08:52<09:54,  2.97it/s, loss=0.0749, lr=0.002]\n",
      "Steps:  41%|████      | 1236/3000 [08:53<09:58,  2.95it/s, loss=0.0241, lr=0.002]\n",
      "Steps:  41%|████      | 1237/3000 [08:53<09:53,  2.97it/s, loss=0.0337, lr=0.002]\n",
      "Steps:  41%|████▏     | 1238/3000 [08:53<09:47,  3.00it/s, loss=0.0602, lr=0.002]\n",
      "Steps:  41%|████▏     | 1239/3000 [08:54<09:42,  3.02it/s, loss=0.0648, lr=0.002]\n",
      "Steps:  41%|████▏     | 1240/3000 [08:54<09:47,  2.99it/s, loss=0.0217, lr=0.002]\n",
      "Steps:  41%|████▏     | 1241/3000 [08:54<09:46,  3.00it/s, loss=0.088, lr=0.002] \n",
      "Steps:  41%|████▏     | 1242/3000 [08:55<10:01,  2.92it/s, loss=0.177, lr=0.002]\n",
      "Steps:  41%|████▏     | 1243/3000 [08:55<09:56,  2.94it/s, loss=0.0622, lr=0.002]\n",
      "Steps:  41%|████▏     | 1244/3000 [08:55<09:46,  2.99it/s, loss=0.143, lr=0.002] \n",
      "Steps:  42%|████▏     | 1245/3000 [08:56<09:51,  2.97it/s, loss=0.205, lr=0.002]\n",
      "Steps:  42%|████▏     | 1246/3000 [08:56<09:53,  2.96it/s, loss=0.0696, lr=0.002]\n",
      "Steps:  42%|████▏     | 1247/3000 [08:56<09:44,  3.00it/s, loss=0.106, lr=0.002] \n",
      "Steps:  42%|████▏     | 1248/3000 [08:57<09:47,  2.98it/s, loss=0.111, lr=0.002]\n",
      "Steps:  42%|████▏     | 1249/3000 [08:57<09:47,  2.98it/s, loss=0.212, lr=0.002]\n",
      "Steps:  42%|████▏     | 1250/3000 [08:57<09:47,  2.98it/s, loss=0.0642, lr=0.002]\n",
      "Steps:  42%|████▏     | 1251/3000 [08:58<09:47,  2.98it/s, loss=0.388, lr=0.002] \n",
      "Steps:  42%|████▏     | 1252/3000 [08:58<09:49,  2.96it/s, loss=0.112, lr=0.002]\n",
      "Steps:  42%|████▏     | 1253/3000 [08:58<09:40,  3.01it/s, loss=0.347, lr=0.002]\n",
      "Steps:  42%|████▏     | 1254/3000 [08:59<09:38,  3.02it/s, loss=0.0233, lr=0.002]\n",
      "Steps:  42%|████▏     | 1255/3000 [08:59<09:41,  3.00it/s, loss=0.113, lr=0.002] \n",
      "Steps:  42%|████▏     | 1256/3000 [08:59<09:44,  2.99it/s, loss=0.12, lr=0.002] \n",
      "Steps:  42%|████▏     | 1257/3000 [09:00<09:42,  2.99it/s, loss=0.209, lr=0.002]\n",
      "Steps:  42%|████▏     | 1258/3000 [09:00<09:40,  3.00it/s, loss=0.0154, lr=0.002]\n",
      "Steps:  42%|████▏     | 1259/3000 [09:00<09:32,  3.04it/s, loss=0.0293, lr=0.002]\n",
      "Steps:  42%|████▏     | 1260/3000 [09:01<09:35,  3.03it/s, loss=0.144, lr=0.002] \n",
      "Steps:  42%|████▏     | 1261/3000 [09:01<09:38,  3.01it/s, loss=0.223, lr=0.002]\n",
      "Steps:  42%|████▏     | 1262/3000 [09:01<09:41,  2.99it/s, loss=0.139, lr=0.002]\n",
      "Steps:  42%|████▏     | 1263/3000 [09:02<09:40,  2.99it/s, loss=0.0379, lr=0.002]\n",
      "Steps:  42%|████▏     | 1264/3000 [09:02<09:42,  2.98it/s, loss=0.0733, lr=0.002]\n",
      "Steps:  42%|████▏     | 1265/3000 [09:02<09:43,  2.97it/s, loss=0.145, lr=0.002] \n",
      "Steps:  42%|████▏     | 1266/3000 [09:03<09:44,  2.97it/s, loss=0.211, lr=0.002]\n",
      "Steps:  42%|████▏     | 1267/3000 [09:03<09:41,  2.98it/s, loss=0.157, lr=0.002]\n",
      "Steps:  42%|████▏     | 1268/3000 [09:03<09:38,  2.99it/s, loss=0.053, lr=0.002]\n",
      "Steps:  42%|████▏     | 1269/3000 [09:04<09:38,  2.99it/s, loss=0.194, lr=0.002]\n",
      "Steps:  42%|████▏     | 1270/3000 [09:04<09:39,  2.98it/s, loss=0.14, lr=0.002] \n",
      "Steps:  42%|████▏     | 1271/3000 [09:04<09:42,  2.97it/s, loss=0.0221, lr=0.002]\n",
      "Steps:  42%|████▏     | 1272/3000 [09:05<09:40,  2.98it/s, loss=0.17, lr=0.002]  \n",
      "Steps:  42%|████▏     | 1273/3000 [09:05<09:36,  2.99it/s, loss=0.0968, lr=0.002]\n",
      "Steps:  42%|████▏     | 1274/3000 [09:05<09:32,  3.02it/s, loss=0.219, lr=0.002] \n",
      "Steps:  42%|████▎     | 1275/3000 [09:06<09:36,  2.99it/s, loss=0.125, lr=0.002]\n",
      "Steps:  43%|████▎     | 1276/3000 [09:06<09:37,  2.99it/s, loss=0.0972, lr=0.002]\n",
      "Steps:  43%|████▎     | 1277/3000 [09:06<09:49,  2.92it/s, loss=0.127, lr=0.002] \n",
      "Steps:  43%|████▎     | 1278/3000 [09:07<09:46,  2.94it/s, loss=0.0846, lr=0.002]\n",
      "Steps:  43%|████▎     | 1279/3000 [09:07<09:42,  2.95it/s, loss=0.0829, lr=0.002]\n",
      "Steps:  43%|████▎     | 1280/3000 [09:07<09:43,  2.95it/s, loss=0.124, lr=0.002] \n",
      "Steps:  43%|████▎     | 1281/3000 [09:08<09:40,  2.96it/s, loss=0.0289, lr=0.002]\n",
      "Steps:  43%|████▎     | 1282/3000 [09:08<09:43,  2.94it/s, loss=0.238, lr=0.002] \n",
      "Steps:  43%|████▎     | 1283/3000 [09:08<09:40,  2.96it/s, loss=0.119, lr=0.002]\n",
      "Steps:  43%|████▎     | 1284/3000 [09:09<09:42,  2.94it/s, loss=0.129, lr=0.002]\n",
      "Steps:  43%|████▎     | 1285/3000 [09:09<10:40,  2.68it/s, loss=0.0675, lr=0.002]\n",
      "Steps:  43%|████▎     | 1286/3000 [09:10<10:20,  2.76it/s, loss=0.236, lr=0.002] \n",
      "Steps:  43%|████▎     | 1287/3000 [09:10<10:09,  2.81it/s, loss=0.0839, lr=0.002]\n",
      "Steps:  43%|████▎     | 1288/3000 [09:10<09:57,  2.87it/s, loss=0.0327, lr=0.002]\n",
      "Steps:  43%|████▎     | 1289/3000 [09:11<09:46,  2.92it/s, loss=0.0359, lr=0.002]\n",
      "Steps:  43%|████▎     | 1290/3000 [09:11<09:42,  2.94it/s, loss=0.221, lr=0.002] \n",
      "Steps:  43%|████▎     | 1291/3000 [09:11<09:43,  2.93it/s, loss=0.104, lr=0.002]\n",
      "Steps:  43%|████▎     | 1292/3000 [09:12<09:42,  2.93it/s, loss=0.124, lr=0.002]\n",
      "Steps:  43%|████▎     | 1293/3000 [09:12<09:35,  2.96it/s, loss=0.118, lr=0.002]\n",
      "Steps:  43%|████▎     | 1294/3000 [09:12<09:51,  2.88it/s, loss=0.174, lr=0.002]\n",
      "Steps:  43%|████▎     | 1295/3000 [09:13<09:41,  2.93it/s, loss=0.283, lr=0.002]\n",
      "Steps:  43%|████▎     | 1296/3000 [09:13<09:36,  2.95it/s, loss=0.0237, lr=0.002]\n",
      "Steps:  43%|████▎     | 1297/3000 [09:13<09:40,  2.94it/s, loss=0.103, lr=0.002] \n",
      "Steps:  43%|████▎     | 1298/3000 [09:14<09:37,  2.95it/s, loss=0.152, lr=0.002]\n",
      "Steps:  43%|████▎     | 1299/3000 [09:14<09:34,  2.96it/s, loss=0.168, lr=0.002]\n",
      "Steps:  43%|████▎     | 1300/3000 [09:14<09:29,  2.98it/s, loss=0.0938, lr=0.002]\n",
      "Steps:  43%|████▎     | 1301/3000 [09:15<09:31,  2.97it/s, loss=0.256, lr=0.002] \n",
      "Steps:  43%|████▎     | 1302/3000 [09:15<09:36,  2.94it/s, loss=0.12, lr=0.002] \n",
      "Steps:  43%|████▎     | 1303/3000 [09:15<09:50,  2.87it/s, loss=0.195, lr=0.002]\n",
      "Steps:  43%|████▎     | 1304/3000 [09:16<09:44,  2.90it/s, loss=0.264, lr=0.002]\n",
      "Steps:  44%|████▎     | 1305/3000 [09:16<09:39,  2.92it/s, loss=0.3, lr=0.002]  \n",
      "Steps:  44%|████▎     | 1306/3000 [09:16<09:35,  2.94it/s, loss=0.159, lr=0.002]\n",
      "Steps:  44%|████▎     | 1307/3000 [09:17<09:26,  2.99it/s, loss=0.127, lr=0.002]\n",
      "Steps:  44%|████▎     | 1308/3000 [09:17<09:17,  3.03it/s, loss=0.0723, lr=0.002]\n",
      "Steps:  44%|████▎     | 1309/3000 [09:17<09:19,  3.02it/s, loss=0.0574, lr=0.002]\n",
      "Steps:  44%|████▎     | 1310/3000 [09:18<09:22,  3.00it/s, loss=0.0928, lr=0.002]\n",
      "Steps:  44%|████▎     | 1311/3000 [09:18<09:20,  3.01it/s, loss=0.138, lr=0.002] \n",
      "Steps:  44%|████▎     | 1312/3000 [09:18<09:20,  3.01it/s, loss=0.066, lr=0.002]\n",
      "Steps:  44%|████▍     | 1313/3000 [09:19<09:16,  3.03it/s, loss=0.277, lr=0.002]\n",
      "Steps:  44%|████▍     | 1314/3000 [09:19<09:18,  3.02it/s, loss=0.0679, lr=0.002]\n",
      "Steps:  44%|████▍     | 1315/3000 [09:19<09:19,  3.01it/s, loss=0.106, lr=0.002] \n",
      "Steps:  44%|████▍     | 1316/3000 [09:20<09:15,  3.03it/s, loss=0.149, lr=0.002]\n",
      "Steps:  44%|████▍     | 1317/3000 [09:20<09:20,  3.00it/s, loss=0.115, lr=0.002]\n",
      "Steps:  44%|████▍     | 1318/3000 [09:20<09:16,  3.02it/s, loss=0.24, lr=0.002] \n",
      "Steps:  44%|████▍     | 1319/3000 [09:21<09:13,  3.04it/s, loss=0.121, lr=0.002]\n",
      "Steps:  44%|████▍     | 1320/3000 [09:21<09:21,  2.99it/s, loss=0.118, lr=0.002]\n",
      "Steps:  44%|████▍     | 1321/3000 [09:21<09:19,  3.00it/s, loss=0.204, lr=0.002]\n",
      "Steps:  44%|████▍     | 1322/3000 [09:22<09:17,  3.01it/s, loss=0.132, lr=0.002]\n",
      "Steps:  44%|████▍     | 1323/3000 [09:22<09:22,  2.98it/s, loss=0.0966, lr=0.002]\n",
      "Steps:  44%|████▍     | 1324/3000 [09:22<09:25,  2.97it/s, loss=0.179, lr=0.002] \n",
      "Steps:  44%|████▍     | 1325/3000 [09:23<09:24,  2.97it/s, loss=0.142, lr=0.002]\n",
      "Steps:  44%|████▍     | 1326/3000 [09:23<09:23,  2.97it/s, loss=0.306, lr=0.002]\n",
      "Steps:  44%|████▍     | 1327/3000 [09:23<09:16,  3.01it/s, loss=0.236, lr=0.002]\n",
      "Steps:  44%|████▍     | 1328/3000 [09:24<09:14,  3.02it/s, loss=0.109, lr=0.002]\n",
      "Steps:  44%|████▍     | 1329/3000 [09:24<09:09,  3.04it/s, loss=0.123, lr=0.002]\n",
      "Steps:  44%|████▍     | 1330/3000 [09:24<09:15,  3.00it/s, loss=0.0204, lr=0.002]\n",
      "Steps:  44%|████▍     | 1331/3000 [09:25<09:11,  3.03it/s, loss=0.132, lr=0.002] \n",
      "Steps:  44%|████▍     | 1332/3000 [09:25<09:14,  3.01it/s, loss=0.113, lr=0.002]\n",
      "Steps:  44%|████▍     | 1333/3000 [09:25<09:16,  2.99it/s, loss=0.0268, lr=0.002]\n",
      "Steps:  44%|████▍     | 1334/3000 [09:26<09:21,  2.97it/s, loss=0.171, lr=0.002] \n",
      "Steps:  44%|████▍     | 1335/3000 [09:26<09:18,  2.98it/s, loss=0.128, lr=0.002]\n",
      "Steps:  45%|████▍     | 1336/3000 [09:26<09:11,  3.02it/s, loss=0.0917, lr=0.002]\n",
      "Steps:  45%|████▍     | 1337/3000 [09:27<09:16,  2.99it/s, loss=0.0772, lr=0.002]\n",
      "Steps:  45%|████▍     | 1338/3000 [09:27<09:32,  2.90it/s, loss=0.125, lr=0.002] \n",
      "Steps:  45%|████▍     | 1339/3000 [09:27<09:28,  2.92it/s, loss=0.08, lr=0.002] \n",
      "Steps:  45%|████▍     | 1340/3000 [09:28<09:24,  2.94it/s, loss=0.166, lr=0.002]\n",
      "Steps:  45%|████▍     | 1341/3000 [09:28<09:21,  2.95it/s, loss=0.109, lr=0.002]\n",
      "Steps:  45%|████▍     | 1342/3000 [09:28<10:09,  2.72it/s, loss=0.221, lr=0.002]\n",
      "Steps:  45%|████▍     | 1343/3000 [09:29<09:51,  2.80it/s, loss=0.419, lr=0.002]\n",
      "Steps:  45%|████▍     | 1344/3000 [09:29<09:46,  2.83it/s, loss=0.213, lr=0.002]\n",
      "Steps:  45%|████▍     | 1345/3000 [09:29<09:35,  2.88it/s, loss=0.099, lr=0.002]\n",
      "Steps:  45%|████▍     | 1346/3000 [09:30<09:32,  2.89it/s, loss=0.196, lr=0.002]\n",
      "Steps:  45%|████▍     | 1347/3000 [09:30<09:24,  2.93it/s, loss=0.179, lr=0.002]\n",
      "Steps:  45%|████▍     | 1348/3000 [09:30<09:16,  2.97it/s, loss=0.153, lr=0.002]\n",
      "Steps:  45%|████▍     | 1349/3000 [09:31<09:10,  3.00it/s, loss=0.0966, lr=0.002]\n",
      "Steps:  45%|████▌     | 1350/3000 [09:31<08:20,  3.30it/s, loss=0.13, lr=0.002]  \n",
      "Steps:  45%|████▌     | 1351/3000 [09:31<09:23,  2.92it/s, loss=0.0918, lr=0.002]\n",
      "Steps:  45%|████▌     | 1352/3000 [09:32<09:15,  2.96it/s, loss=0.187, lr=0.002] \n",
      "Steps:  45%|████▌     | 1353/3000 [09:32<09:16,  2.96it/s, loss=0.0946, lr=0.002]\n",
      "Steps:  45%|████▌     | 1354/3000 [09:32<09:09,  2.99it/s, loss=0.0966, lr=0.002]\n",
      "Steps:  45%|████▌     | 1355/3000 [09:33<09:09,  2.99it/s, loss=0.146, lr=0.002] \n",
      "Steps:  45%|████▌     | 1356/3000 [09:33<09:12,  2.98it/s, loss=0.182, lr=0.002]\n",
      "Steps:  45%|████▌     | 1357/3000 [09:33<09:09,  2.99it/s, loss=0.162, lr=0.002]\n",
      "Steps:  45%|████▌     | 1358/3000 [09:34<09:05,  3.01it/s, loss=0.149, lr=0.002]\n",
      "Steps:  45%|████▌     | 1359/3000 [09:34<09:08,  2.99it/s, loss=0.0985, lr=0.002]\n",
      "Steps:  45%|████▌     | 1360/3000 [09:34<09:08,  2.99it/s, loss=0.109, lr=0.002] \n",
      "Steps:  45%|████▌     | 1361/3000 [09:35<09:04,  3.01it/s, loss=0.146, lr=0.002]\n",
      "Steps:  45%|████▌     | 1362/3000 [09:35<09:04,  3.01it/s, loss=0.216, lr=0.002]\n",
      "Steps:  45%|████▌     | 1363/3000 [09:35<09:00,  3.03it/s, loss=0.0685, lr=0.002]\n",
      "Steps:  45%|████▌     | 1364/3000 [09:36<09:18,  2.93it/s, loss=0.0734, lr=0.002]\n",
      "Steps:  46%|████▌     | 1365/3000 [09:36<09:17,  2.93it/s, loss=0.235, lr=0.002] \n",
      "Steps:  46%|████▌     | 1366/3000 [09:36<09:16,  2.94it/s, loss=0.114, lr=0.002]\n",
      "Steps:  46%|████▌     | 1367/3000 [09:37<09:13,  2.95it/s, loss=0.0296, lr=0.002]\n",
      "Steps:  46%|████▌     | 1368/3000 [09:37<09:11,  2.96it/s, loss=0.129, lr=0.002] \n",
      "Steps:  46%|████▌     | 1369/3000 [09:37<09:09,  2.97it/s, loss=0.115, lr=0.002]\n",
      "Steps:  46%|████▌     | 1370/3000 [09:38<09:00,  3.02it/s, loss=0.134, lr=0.002]\n",
      "Steps:  46%|████▌     | 1371/3000 [09:38<09:01,  3.01it/s, loss=0.258, lr=0.002]\n",
      "Steps:  46%|████▌     | 1372/3000 [09:38<09:03,  3.00it/s, loss=0.0961, lr=0.002]\n",
      "Steps:  46%|████▌     | 1373/3000 [09:39<09:03,  3.00it/s, loss=0.115, lr=0.002] \n",
      "Steps:  46%|████▌     | 1374/3000 [09:39<08:58,  3.02it/s, loss=0.138, lr=0.002]\n",
      "Steps:  46%|████▌     | 1375/3000 [09:39<08:53,  3.04it/s, loss=0.092, lr=0.002]\n",
      "Steps:  46%|████▌     | 1376/3000 [09:40<08:58,  3.01it/s, loss=0.146, lr=0.002]\n",
      "Steps:  46%|████▌     | 1377/3000 [09:40<09:02,  2.99it/s, loss=0.195, lr=0.002]\n",
      "Steps:  46%|████▌     | 1378/3000 [09:40<08:56,  3.03it/s, loss=0.12, lr=0.002] \n",
      "Steps:  46%|████▌     | 1379/3000 [09:41<08:55,  3.03it/s, loss=0.116, lr=0.002]\n",
      "Steps:  46%|████▌     | 1380/3000 [09:41<09:02,  2.99it/s, loss=0.157, lr=0.002]\n",
      "Steps:  46%|████▌     | 1381/3000 [09:41<08:59,  3.00it/s, loss=0.292, lr=0.002]\n",
      "Steps:  46%|████▌     | 1382/3000 [09:42<08:53,  3.04it/s, loss=0.132, lr=0.002]\n",
      "Steps:  46%|████▌     | 1383/3000 [09:42<09:00,  2.99it/s, loss=0.047, lr=0.002]\n",
      "Steps:  46%|████▌     | 1384/3000 [09:42<08:59,  2.99it/s, loss=0.149, lr=0.002]\n",
      "Steps:  46%|████▌     | 1385/3000 [09:43<08:57,  3.00it/s, loss=0.117, lr=0.002]\n",
      "Steps:  46%|████▌     | 1386/3000 [09:43<09:02,  2.98it/s, loss=0.0588, lr=0.002]\n",
      "Steps:  46%|████▌     | 1387/3000 [09:43<08:58,  2.99it/s, loss=0.117, lr=0.002] \n",
      "Steps:  46%|████▋     | 1388/3000 [09:44<08:58,  3.00it/s, loss=0.189, lr=0.002]\n",
      "Steps:  46%|████▋     | 1389/3000 [09:44<08:55,  3.01it/s, loss=0.223, lr=0.002]\n",
      "Steps:  46%|████▋     | 1390/3000 [09:44<08:51,  3.03it/s, loss=0.173, lr=0.002]\n",
      "Steps:  46%|████▋     | 1391/3000 [09:45<08:51,  3.03it/s, loss=0.0976, lr=0.002]\n",
      "Steps:  46%|████▋     | 1392/3000 [09:45<08:50,  3.03it/s, loss=0.203, lr=0.002] \n",
      "Steps:  46%|████▋     | 1393/3000 [09:45<08:50,  3.03it/s, loss=0.0623, lr=0.002]\n",
      "Steps:  46%|████▋     | 1394/3000 [09:46<08:51,  3.02it/s, loss=0.0263, lr=0.002]\n",
      "Steps:  46%|████▋     | 1395/3000 [09:46<08:55,  3.00it/s, loss=0.187, lr=0.002] \n",
      "Steps:  47%|████▋     | 1396/3000 [09:46<08:51,  3.02it/s, loss=0.0535, lr=0.002]\n",
      "Steps:  47%|████▋     | 1397/3000 [09:47<08:53,  3.01it/s, loss=0.0656, lr=0.002]\n",
      "Steps:  47%|████▋     | 1398/3000 [09:47<08:52,  3.01it/s, loss=0.155, lr=0.002] \n",
      "Steps:  47%|████▋     | 1399/3000 [09:48<10:00,  2.67it/s, loss=0.185, lr=0.002]\n",
      "Steps:  47%|████▋     | 1400/3000 [09:48<09:38,  2.76it/s, loss=0.0882, lr=0.002]\n",
      "Steps:  47%|████▋     | 1401/3000 [09:48<09:25,  2.83it/s, loss=0.115, lr=0.002] \n",
      "Steps:  47%|████▋     | 1402/3000 [09:49<09:15,  2.88it/s, loss=0.123, lr=0.002]\n",
      "Steps:  47%|████▋     | 1403/3000 [09:49<09:11,  2.89it/s, loss=0.282, lr=0.002]\n",
      "Steps:  47%|████▋     | 1404/3000 [09:49<09:02,  2.94it/s, loss=0.0639, lr=0.002]\n",
      "Steps:  47%|████▋     | 1405/3000 [09:50<08:59,  2.96it/s, loss=0.153, lr=0.002] \n",
      "Steps:  47%|████▋     | 1406/3000 [09:50<08:57,  2.97it/s, loss=0.0879, lr=0.002]\n",
      "Steps:  47%|████▋     | 1407/3000 [09:50<08:57,  2.96it/s, loss=0.0276, lr=0.002]\n",
      "Steps:  47%|████▋     | 1408/3000 [09:51<08:59,  2.95it/s, loss=0.236, lr=0.002] \n",
      "Steps:  47%|████▋     | 1409/3000 [09:51<08:54,  2.98it/s, loss=0.106, lr=0.002]\n",
      "Steps:  47%|████▋     | 1410/3000 [09:51<08:55,  2.97it/s, loss=0.114, lr=0.002]\n",
      "Steps:  47%|████▋     | 1411/3000 [09:52<08:56,  2.96it/s, loss=0.022, lr=0.002]\n",
      "Steps:  47%|████▋     | 1412/3000 [09:52<08:53,  2.98it/s, loss=0.152, lr=0.002]\n",
      "Steps:  47%|████▋     | 1413/3000 [09:52<08:55,  2.96it/s, loss=0.0918, lr=0.002]\n",
      "Steps:  47%|████▋     | 1414/3000 [09:53<08:54,  2.97it/s, loss=0.098, lr=0.002] \n",
      "Steps:  47%|████▋     | 1415/3000 [09:53<08:57,  2.95it/s, loss=0.0928, lr=0.002]\n",
      "Steps:  47%|████▋     | 1416/3000 [09:53<09:10,  2.88it/s, loss=0.0327, lr=0.002]\n",
      "Steps:  47%|████▋     | 1417/3000 [09:54<09:01,  2.92it/s, loss=0.0999, lr=0.002]\n",
      "Steps:  47%|████▋     | 1418/3000 [09:54<08:56,  2.95it/s, loss=0.0527, lr=0.002]\n",
      "Steps:  47%|████▋     | 1419/3000 [09:54<08:58,  2.94it/s, loss=0.203, lr=0.002] \n",
      "Steps:  47%|████▋     | 1420/3000 [09:55<08:57,  2.94it/s, loss=0.073, lr=0.002]\n",
      "Steps:  47%|████▋     | 1421/3000 [09:55<08:52,  2.96it/s, loss=0.104, lr=0.002]\n",
      "Steps:  47%|████▋     | 1422/3000 [09:55<08:53,  2.96it/s, loss=0.0291, lr=0.002]\n",
      "Steps:  47%|████▋     | 1423/3000 [09:56<08:48,  2.98it/s, loss=0.241, lr=0.002] \n",
      "Steps:  47%|████▋     | 1424/3000 [09:56<08:46,  2.99it/s, loss=0.318, lr=0.002]\n",
      "Steps:  48%|████▊     | 1425/3000 [09:56<08:50,  2.97it/s, loss=0.0677, lr=0.002]\n",
      "Steps:  48%|████▊     | 1426/3000 [09:57<08:48,  2.98it/s, loss=0.109, lr=0.002] \n",
      "Steps:  48%|████▊     | 1427/3000 [09:57<08:47,  2.98it/s, loss=0.127, lr=0.002]\n",
      "Steps:  48%|████▊     | 1428/3000 [09:57<08:47,  2.98it/s, loss=0.169, lr=0.002]\n",
      "Steps:  48%|████▊     | 1429/3000 [09:58<08:46,  2.99it/s, loss=0.121, lr=0.002]\n",
      "Steps:  48%|████▊     | 1430/3000 [09:58<08:49,  2.96it/s, loss=0.0594, lr=0.002]\n",
      "Steps:  48%|████▊     | 1431/3000 [09:58<08:49,  2.96it/s, loss=0.174, lr=0.002] \n",
      "Steps:  48%|████▊     | 1432/3000 [09:59<08:39,  3.02it/s, loss=0.0702, lr=0.002]\n",
      "Steps:  48%|████▊     | 1433/3000 [09:59<08:44,  2.99it/s, loss=0.133, lr=0.002] \n",
      "Steps:  48%|████▊     | 1434/3000 [09:59<08:41,  3.01it/s, loss=0.0263, lr=0.002]\n",
      "Steps:  48%|████▊     | 1435/3000 [10:00<08:39,  3.01it/s, loss=0.0826, lr=0.002]\n",
      "Steps:  48%|████▊     | 1436/3000 [10:00<08:40,  3.01it/s, loss=0.0709, lr=0.002]\n",
      "Steps:  48%|████▊     | 1437/3000 [10:00<08:40,  3.00it/s, loss=0.0703, lr=0.002]\n",
      "Steps:  48%|████▊     | 1438/3000 [10:01<08:46,  2.97it/s, loss=0.2, lr=0.002]   \n",
      "Steps:  48%|████▊     | 1439/3000 [10:01<08:45,  2.97it/s, loss=0.0968, lr=0.002]\n",
      "Steps:  48%|████▊     | 1440/3000 [10:01<08:38,  3.01it/s, loss=0.0263, lr=0.002]\n",
      "Steps:  48%|████▊     | 1441/3000 [10:02<08:38,  3.01it/s, loss=0.137, lr=0.002] \n",
      "Steps:  48%|████▊     | 1442/3000 [10:02<08:38,  3.00it/s, loss=0.237, lr=0.002]\n",
      "Steps:  48%|████▊     | 1443/3000 [10:02<08:34,  3.03it/s, loss=0.0166, lr=0.002]\n",
      "Steps:  48%|████▊     | 1444/3000 [10:03<08:36,  3.01it/s, loss=0.18, lr=0.002]  \n",
      "Steps:  48%|████▊     | 1445/3000 [10:03<08:40,  2.99it/s, loss=0.0237, lr=0.002]\n",
      "Steps:  48%|████▊     | 1446/3000 [10:03<08:36,  3.01it/s, loss=0.0417, lr=0.002]\n",
      "Steps:  48%|████▊     | 1447/3000 [10:04<08:36,  3.01it/s, loss=0.149, lr=0.002] \n",
      "Steps:  48%|████▊     | 1448/3000 [10:04<08:40,  2.98it/s, loss=0.079, lr=0.002]\n",
      "Steps:  48%|████▊     | 1449/3000 [10:04<08:37,  2.99it/s, loss=0.185, lr=0.002]\n",
      "Steps:  48%|████▊     | 1450/3000 [10:05<08:40,  2.98it/s, loss=0.122, lr=0.002]\n",
      "Steps:  48%|████▊     | 1451/3000 [10:05<08:56,  2.89it/s, loss=0.194, lr=0.002]\n",
      "Steps:  48%|████▊     | 1452/3000 [10:05<08:47,  2.93it/s, loss=0.0337, lr=0.002]\n",
      "Steps:  48%|████▊     | 1453/3000 [10:06<08:41,  2.97it/s, loss=0.0737, lr=0.002]\n",
      "Steps:  48%|████▊     | 1454/3000 [10:06<08:38,  2.98it/s, loss=0.114, lr=0.002] \n",
      "Steps:  48%|████▊     | 1455/3000 [10:06<08:38,  2.98it/s, loss=0.0805, lr=0.002]\n",
      "Steps:  49%|████▊     | 1456/3000 [10:07<09:35,  2.68it/s, loss=0.0801, lr=0.002]\n",
      "Steps:  49%|████▊     | 1457/3000 [10:07<09:19,  2.76it/s, loss=0.299, lr=0.002] \n",
      "Steps:  49%|████▊     | 1458/3000 [10:08<09:08,  2.81it/s, loss=0.106, lr=0.002]\n",
      "Steps:  49%|████▊     | 1459/3000 [10:08<09:03,  2.84it/s, loss=0.142, lr=0.002]\n",
      "Steps:  49%|████▊     | 1460/3000 [10:08<08:52,  2.89it/s, loss=0.133, lr=0.002]\n",
      "Steps:  49%|████▊     | 1461/3000 [10:09<08:48,  2.91it/s, loss=0.106, lr=0.002]\n",
      "Steps:  49%|████▊     | 1462/3000 [10:09<08:35,  2.98it/s, loss=0.154, lr=0.002]\n",
      "Steps:  49%|████▉     | 1463/3000 [10:09<08:35,  2.98it/s, loss=0.159, lr=0.002]\n",
      "Steps:  49%|████▉     | 1464/3000 [10:10<08:37,  2.97it/s, loss=0.243, lr=0.002]\n",
      "Steps:  49%|████▉     | 1465/3000 [10:10<08:37,  2.97it/s, loss=0.125, lr=0.002]\n",
      "Steps:  49%|████▉     | 1466/3000 [10:10<08:36,  2.97it/s, loss=0.135, lr=0.002]\n",
      "Steps:  49%|████▉     | 1467/3000 [10:11<08:37,  2.96it/s, loss=0.039, lr=0.002]\n",
      "Steps:  49%|████▉     | 1468/3000 [10:11<08:44,  2.92it/s, loss=0.0801, lr=0.002]\n",
      "Steps:  49%|████▉     | 1469/3000 [10:11<08:40,  2.94it/s, loss=0.262, lr=0.002] \n",
      "Steps:  49%|████▉     | 1470/3000 [10:12<08:37,  2.96it/s, loss=0.165, lr=0.002]\n",
      "Steps:  49%|████▉     | 1471/3000 [10:12<08:36,  2.96it/s, loss=0.12, lr=0.002] \n",
      "Steps:  49%|████▉     | 1472/3000 [10:12<08:37,  2.95it/s, loss=0.238, lr=0.002]\n",
      "Steps:  49%|████▉     | 1473/3000 [10:13<08:31,  2.99it/s, loss=0.101, lr=0.002]\n",
      "Steps:  49%|████▉     | 1474/3000 [10:13<08:30,  2.99it/s, loss=0.19, lr=0.002] \n",
      "Steps:  49%|████▉     | 1475/3000 [10:13<08:34,  2.96it/s, loss=0.189, lr=0.002]\n",
      "Steps:  49%|████▉     | 1476/3000 [10:14<08:30,  2.98it/s, loss=0.0884, lr=0.002]\n",
      "Steps:  49%|████▉     | 1477/3000 [10:14<08:34,  2.96it/s, loss=0.105, lr=0.002] \n",
      "Steps:  49%|████▉     | 1478/3000 [10:14<08:30,  2.98it/s, loss=0.14, lr=0.002] \n",
      "Steps:  49%|████▉     | 1479/3000 [10:15<08:26,  3.00it/s, loss=0.0939, lr=0.002]\n",
      "Steps:  49%|████▉     | 1480/3000 [10:15<08:26,  3.00it/s, loss=0.167, lr=0.002] \n",
      "Steps:  49%|████▉     | 1481/3000 [10:15<08:25,  3.01it/s, loss=0.135, lr=0.002]\n",
      "Steps:  49%|████▉     | 1482/3000 [10:16<08:23,  3.02it/s, loss=0.13, lr=0.002] \n",
      "Steps:  49%|████▉     | 1483/3000 [10:16<08:19,  3.04it/s, loss=0.196, lr=0.002]\n",
      "Steps:  49%|████▉     | 1484/3000 [10:16<08:17,  3.05it/s, loss=0.164, lr=0.002]\n",
      "Steps:  50%|████▉     | 1485/3000 [10:17<08:21,  3.02it/s, loss=0.165, lr=0.002]\n",
      "Steps:  50%|████▉     | 1486/3000 [10:17<08:28,  2.98it/s, loss=0.0718, lr=0.002]\n",
      "Steps:  50%|████▉     | 1487/3000 [10:17<08:27,  2.98it/s, loss=0.239, lr=0.002] \n",
      "Steps:  50%|████▉     | 1488/3000 [10:18<08:24,  3.00it/s, loss=0.193, lr=0.002]\n",
      "Steps:  50%|████▉     | 1489/3000 [10:18<08:25,  2.99it/s, loss=0.116, lr=0.002]\n",
      "Steps:  50%|████▉     | 1490/3000 [10:18<08:31,  2.95it/s, loss=0.0928, lr=0.002]\n",
      "Steps:  50%|████▉     | 1491/3000 [10:19<08:25,  2.99it/s, loss=0.116, lr=0.002] \n",
      "Steps:  50%|████▉     | 1492/3000 [10:19<08:22,  3.00it/s, loss=0.253, lr=0.002]\n",
      "Steps:  50%|████▉     | 1493/3000 [10:19<08:23,  2.99it/s, loss=0.212, lr=0.002]\n",
      "Steps:  50%|████▉     | 1494/3000 [10:20<08:20,  3.01it/s, loss=0.1, lr=0.002]  \n",
      "Steps:  50%|████▉     | 1495/3000 [10:20<08:22,  3.00it/s, loss=0.133, lr=0.002]\n",
      "Steps:  50%|████▉     | 1496/3000 [10:20<08:25,  2.98it/s, loss=0.105, lr=0.002]\n",
      "Steps:  50%|████▉     | 1497/3000 [10:21<08:27,  2.96it/s, loss=0.0874, lr=0.002]\n",
      "Steps:  50%|████▉     | 1498/3000 [10:21<08:23,  2.98it/s, loss=0.169, lr=0.002] \n",
      "Steps:  50%|████▉     | 1499/3000 [10:21<08:24,  2.98it/s, loss=0.137, lr=0.002]\n",
      "Steps:  50%|█████     | 1500/3000 [10:21<07:35,  3.29it/s, loss=0.137, lr=0.002]05/09/2024 05:31:42 - INFO - __main__ - Saving embeddings\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:31:42 - INFO - accelerate.accelerator - Saving current state to /tmp/textual_inversion_cat/checkpoint-1500\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:31:43 - INFO - accelerate.checkpointing - Model weights saved in /tmp/textual_inversion_cat/checkpoint-1500/model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:31:44 - INFO - accelerate.checkpointing - Optimizer state saved in /tmp/textual_inversion_cat/checkpoint-1500/optimizer.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:31:44 - INFO - accelerate.checkpointing - Scheduler state saved in /tmp/textual_inversion_cat/checkpoint-1500/scheduler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:31:44 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /tmp/textual_inversion_cat/checkpoint-1500/sampler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:31:44 - INFO - accelerate.checkpointing - Random states saved in /tmp/textual_inversion_cat/checkpoint-1500/random_states_0.pkl\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:31:44 - INFO - __main__ - Saved state to /tmp/textual_inversion_cat/checkpoint-1500\n",
      "Steps:  50%|█████     | 1500/3000 [10:23<07:35,  3.29it/s, loss=0.0734, lr=0.002]\n",
      "Steps:  50%|█████     | 1501/3000 [10:23<18:19,  1.36it/s, loss=0.209, lr=0.002] \n",
      "Steps:  50%|█████     | 1502/3000 [10:24<15:18,  1.63it/s, loss=0.0891, lr=0.002]\n",
      "Steps:  50%|█████     | 1503/3000 [10:24<13:12,  1.89it/s, loss=0.0858, lr=0.002]\n",
      "Steps:  50%|█████     | 1504/3000 [10:24<11:46,  2.12it/s, loss=0.19, lr=0.002]  \n",
      "Steps:  50%|█████     | 1505/3000 [10:25<10:46,  2.31it/s, loss=0.293, lr=0.002]\n",
      "Steps:  50%|█████     | 1506/3000 [10:25<10:04,  2.47it/s, loss=0.293, lr=0.002]\n",
      "Steps:  50%|█████     | 1506/3000 [10:25<10:04,  2.47it/s, loss=0.322, lr=0.002]\n",
      "Steps:  50%|█████     | 1507/3000 [10:25<09:28,  2.62it/s, loss=0.112, lr=0.002]\n",
      "Steps:  50%|█████     | 1508/3000 [10:26<09:16,  2.68it/s, loss=0.13, lr=0.002] \n",
      "Steps:  50%|█████     | 1509/3000 [10:26<09:00,  2.76it/s, loss=0.155, lr=0.002]\n",
      "Steps:  50%|█████     | 1510/3000 [10:26<08:43,  2.85it/s, loss=0.142, lr=0.002]\n",
      "Steps:  50%|█████     | 1511/3000 [10:27<08:33,  2.90it/s, loss=0.108, lr=0.002]\n",
      "Steps:  50%|█████     | 1512/3000 [10:27<08:28,  2.93it/s, loss=0.102, lr=0.002]\n",
      "Steps:  50%|█████     | 1513/3000 [10:27<08:25,  2.94it/s, loss=0.117, lr=0.002]\n",
      "Steps:  50%|█████     | 1514/3000 [10:28<08:18,  2.98it/s, loss=0.152, lr=0.002]\n",
      "Steps:  50%|█████     | 1515/3000 [10:28<09:05,  2.72it/s, loss=0.0879, lr=0.002]\n",
      "Steps:  51%|█████     | 1516/3000 [10:28<08:48,  2.81it/s, loss=0.115, lr=0.002] \n",
      "Steps:  51%|█████     | 1517/3000 [10:29<08:28,  2.92it/s, loss=0.236, lr=0.002]\n",
      "Steps:  51%|█████     | 1518/3000 [10:29<08:27,  2.92it/s, loss=0.242, lr=0.002]\n",
      "Steps:  51%|█████     | 1519/3000 [10:29<08:25,  2.93it/s, loss=0.0671, lr=0.002]\n",
      "Steps:  51%|█████     | 1520/3000 [10:30<08:18,  2.97it/s, loss=0.115, lr=0.002] \n",
      "Steps:  51%|█████     | 1521/3000 [10:30<08:20,  2.96it/s, loss=0.12, lr=0.002] \n",
      "Steps:  51%|█████     | 1522/3000 [10:30<08:15,  2.98it/s, loss=0.179, lr=0.002]\n",
      "Steps:  51%|█████     | 1523/3000 [10:31<08:13,  2.99it/s, loss=0.0564, lr=0.002]\n",
      "Steps:  51%|█████     | 1524/3000 [10:31<08:08,  3.02it/s, loss=0.182, lr=0.002] \n",
      "Steps:  51%|█████     | 1525/3000 [10:31<08:09,  3.01it/s, loss=0.0233, lr=0.002]\n",
      "Steps:  51%|█████     | 1526/3000 [10:32<08:10,  3.01it/s, loss=0.178, lr=0.002] \n",
      "Steps:  51%|█████     | 1527/3000 [10:32<08:13,  2.99it/s, loss=0.0606, lr=0.002]\n",
      "Steps:  51%|█████     | 1528/3000 [10:32<08:10,  3.00it/s, loss=0.14, lr=0.002]  \n",
      "Steps:  51%|█████     | 1529/3000 [10:33<08:09,  3.00it/s, loss=0.152, lr=0.002]\n",
      "Steps:  51%|█████     | 1530/3000 [10:33<08:12,  2.98it/s, loss=0.135, lr=0.002]\n",
      "Steps:  51%|█████     | 1531/3000 [10:33<08:08,  3.01it/s, loss=0.0951, lr=0.002]\n",
      "Steps:  51%|█████     | 1532/3000 [10:34<08:04,  3.03it/s, loss=0.0779, lr=0.002]\n",
      "Steps:  51%|█████     | 1533/3000 [10:34<08:01,  3.05it/s, loss=0.121, lr=0.002] \n",
      "Steps:  51%|█████     | 1534/3000 [10:34<08:09,  3.00it/s, loss=0.0203, lr=0.002]\n",
      "Steps:  51%|█████     | 1535/3000 [10:35<08:05,  3.02it/s, loss=0.0671, lr=0.002]\n",
      "Steps:  51%|█████     | 1536/3000 [10:35<08:06,  3.01it/s, loss=0.169, lr=0.002] \n",
      "Steps:  51%|█████     | 1537/3000 [10:35<08:04,  3.02it/s, loss=0.143, lr=0.002]\n",
      "Steps:  51%|█████▏    | 1538/3000 [10:36<08:09,  2.99it/s, loss=0.161, lr=0.002]\n",
      "Steps:  51%|█████▏    | 1539/3000 [10:36<08:13,  2.96it/s, loss=0.246, lr=0.002]\n",
      "Steps:  51%|█████▏    | 1540/3000 [10:36<08:13,  2.96it/s, loss=0.0733, lr=0.002]\n",
      "Steps:  51%|█████▏    | 1541/3000 [10:37<08:08,  2.99it/s, loss=0.165, lr=0.002] \n",
      "Steps:  51%|█████▏    | 1542/3000 [10:37<08:12,  2.96it/s, loss=0.0773, lr=0.002]\n",
      "Steps:  51%|█████▏    | 1543/3000 [10:37<08:15,  2.94it/s, loss=0.175, lr=0.002] \n",
      "Steps:  51%|█████▏    | 1544/3000 [10:38<08:16,  2.93it/s, loss=0.1, lr=0.002]  \n",
      "Steps:  52%|█████▏    | 1545/3000 [10:38<08:14,  2.94it/s, loss=0.17, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1546/3000 [10:38<08:14,  2.94it/s, loss=0.0928, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1547/3000 [10:39<08:08,  2.97it/s, loss=0.097, lr=0.002] \n",
      "Steps:  52%|█████▏    | 1548/3000 [10:39<08:07,  2.98it/s, loss=0.0261, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1549/3000 [10:39<08:07,  2.98it/s, loss=0.162, lr=0.002] \n",
      "Steps:  52%|█████▏    | 1550/3000 [10:40<08:05,  2.98it/s, loss=0.13, lr=0.002] \n",
      "Steps:  52%|█████▏    | 1551/3000 [10:40<08:06,  2.98it/s, loss=0.13, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1552/3000 [10:40<08:10,  2.95it/s, loss=0.149, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1553/3000 [10:41<08:09,  2.96it/s, loss=0.187, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1554/3000 [10:41<08:10,  2.95it/s, loss=0.174, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1555/3000 [10:41<08:13,  2.93it/s, loss=0.113, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1556/3000 [10:42<08:04,  2.98it/s, loss=0.226, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1557/3000 [10:42<08:09,  2.95it/s, loss=0.0892, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1558/3000 [10:42<08:06,  2.97it/s, loss=0.221, lr=0.002] \n",
      "Steps:  52%|█████▏    | 1559/3000 [10:43<08:08,  2.95it/s, loss=0.214, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1560/3000 [10:43<08:12,  2.93it/s, loss=0.0599, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1561/3000 [10:43<08:12,  2.92it/s, loss=0.0913, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1562/3000 [10:44<08:05,  2.96it/s, loss=0.105, lr=0.002] \n",
      "Steps:  52%|█████▏    | 1563/3000 [10:44<08:00,  2.99it/s, loss=0.0955, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1564/3000 [10:44<08:00,  2.99it/s, loss=0.0703, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1565/3000 [10:45<08:00,  2.98it/s, loss=0.12, lr=0.002]  \n",
      "Steps:  52%|█████▏    | 1566/3000 [10:45<07:53,  3.03it/s, loss=0.0204, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1567/3000 [10:45<07:58,  3.00it/s, loss=0.131, lr=0.002] \n",
      "Steps:  52%|█████▏    | 1568/3000 [10:46<07:58,  2.99it/s, loss=0.232, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1569/3000 [10:46<08:03,  2.96it/s, loss=0.104, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1570/3000 [10:46<07:59,  2.98it/s, loss=0.162, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1571/3000 [10:47<07:56,  3.00it/s, loss=0.214, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1572/3000 [10:47<07:59,  2.98it/s, loss=0.233, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1573/3000 [10:48<09:02,  2.63it/s, loss=0.083, lr=0.002]\n",
      "Steps:  52%|█████▏    | 1574/3000 [10:48<08:38,  2.75it/s, loss=0.0663, lr=0.002]\n",
      "Steps:  52%|█████▎    | 1575/3000 [10:48<08:26,  2.81it/s, loss=0.105, lr=0.002] \n",
      "Steps:  53%|█████▎    | 1576/3000 [10:49<08:14,  2.88it/s, loss=0.215, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1577/3000 [10:49<08:20,  2.84it/s, loss=0.0535, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1578/3000 [10:49<08:10,  2.90it/s, loss=0.241, lr=0.002] \n",
      "Steps:  53%|█████▎    | 1579/3000 [10:50<08:05,  2.93it/s, loss=0.116, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1580/3000 [10:50<07:59,  2.96it/s, loss=0.195, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1581/3000 [10:50<08:00,  2.95it/s, loss=0.0655, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1582/3000 [10:51<07:59,  2.96it/s, loss=0.0655, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1582/3000 [10:51<07:59,  2.96it/s, loss=0.117, lr=0.002] \n",
      "Steps:  53%|█████▎    | 1583/3000 [10:51<08:01,  2.94it/s, loss=0.282, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1584/3000 [10:51<08:00,  2.95it/s, loss=0.137, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1585/3000 [10:52<07:59,  2.95it/s, loss=0.154, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1586/3000 [10:52<07:56,  2.97it/s, loss=0.0782, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1587/3000 [10:52<07:54,  2.98it/s, loss=0.292, lr=0.002] \n",
      "Steps:  53%|█████▎    | 1588/3000 [10:53<07:49,  3.01it/s, loss=0.163, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1589/3000 [10:53<07:49,  3.00it/s, loss=0.138, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1590/3000 [10:53<07:49,  3.00it/s, loss=0.0743, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1591/3000 [10:54<07:52,  2.99it/s, loss=0.165, lr=0.002] \n",
      "Steps:  53%|█████▎    | 1592/3000 [10:54<07:54,  2.97it/s, loss=0.103, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1593/3000 [10:54<07:51,  2.98it/s, loss=0.148, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1594/3000 [10:55<07:52,  2.98it/s, loss=0.167, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1595/3000 [10:55<07:49,  2.99it/s, loss=0.128, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1596/3000 [10:55<07:51,  2.98it/s, loss=0.0864, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1597/3000 [10:56<07:48,  3.00it/s, loss=0.0848, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1598/3000 [10:56<07:49,  2.98it/s, loss=0.107, lr=0.002] \n",
      "Steps:  53%|█████▎    | 1599/3000 [10:56<07:49,  2.98it/s, loss=0.144, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1600/3000 [10:57<07:43,  3.02it/s, loss=0.0762, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1601/3000 [10:57<07:45,  3.01it/s, loss=0.091, lr=0.002] \n",
      "Steps:  53%|█████▎    | 1602/3000 [10:57<07:37,  3.05it/s, loss=0.0325, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1603/3000 [10:58<07:39,  3.04it/s, loss=0.0216, lr=0.002]\n",
      "Steps:  53%|█████▎    | 1604/3000 [10:58<07:41,  3.02it/s, loss=0.324, lr=0.002] \n",
      "Steps:  54%|█████▎    | 1605/3000 [10:58<07:43,  3.01it/s, loss=0.231, lr=0.002]\n",
      "Steps:  54%|█████▎    | 1606/3000 [10:59<07:44,  3.00it/s, loss=0.0223, lr=0.002]\n",
      "Steps:  54%|█████▎    | 1607/3000 [10:59<07:43,  3.00it/s, loss=0.102, lr=0.002] \n",
      "Steps:  54%|█████▎    | 1608/3000 [10:59<07:42,  3.01it/s, loss=0.122, lr=0.002]\n",
      "Steps:  54%|█████▎    | 1609/3000 [11:00<07:36,  3.05it/s, loss=0.13, lr=0.002] \n",
      "Steps:  54%|█████▎    | 1610/3000 [11:00<07:39,  3.02it/s, loss=0.0655, lr=0.002]\n",
      "Steps:  54%|█████▎    | 1611/3000 [11:00<07:44,  2.99it/s, loss=0.0784, lr=0.002]\n",
      "Steps:  54%|█████▎    | 1612/3000 [11:01<07:56,  2.92it/s, loss=0.0329, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1613/3000 [11:01<07:48,  2.96it/s, loss=0.0355, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1614/3000 [11:01<07:49,  2.95it/s, loss=0.118, lr=0.002] \n",
      "Steps:  54%|█████▍    | 1615/3000 [11:02<07:44,  2.98it/s, loss=0.212, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1616/3000 [11:02<07:42,  2.99it/s, loss=0.072, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1617/3000 [11:02<07:43,  2.99it/s, loss=0.118, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1618/3000 [11:03<07:39,  3.01it/s, loss=0.143, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1619/3000 [11:03<07:37,  3.02it/s, loss=0.132, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1620/3000 [11:03<07:40,  3.00it/s, loss=0.148, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1621/3000 [11:04<07:40,  2.99it/s, loss=0.023, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1622/3000 [11:04<07:40,  2.99it/s, loss=0.259, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1623/3000 [11:04<07:40,  2.99it/s, loss=0.0732, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1624/3000 [11:05<07:38,  3.00it/s, loss=0.201, lr=0.002] \n",
      "Steps:  54%|█████▍    | 1625/3000 [11:05<07:34,  3.03it/s, loss=0.106, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1626/3000 [11:05<07:38,  2.99it/s, loss=0.0977, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1627/3000 [11:06<07:36,  3.01it/s, loss=0.0907, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1628/3000 [11:06<07:38,  2.99it/s, loss=0.144, lr=0.002] \n",
      "Steps:  54%|█████▍    | 1629/3000 [11:06<07:38,  2.99it/s, loss=0.111, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1630/3000 [11:07<08:26,  2.71it/s, loss=0.122, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1631/3000 [11:07<08:13,  2.77it/s, loss=0.15, lr=0.002] \n",
      "Steps:  54%|█████▍    | 1632/3000 [11:07<07:57,  2.86it/s, loss=0.0293, lr=0.002]\n",
      "Steps:  54%|█████▍    | 1633/3000 [11:08<07:52,  2.89it/s, loss=0.123, lr=0.002] \n",
      "Steps:  54%|█████▍    | 1634/3000 [11:08<07:46,  2.93it/s, loss=0.0877, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1635/3000 [11:08<07:42,  2.95it/s, loss=0.144, lr=0.002] \n",
      "Steps:  55%|█████▍    | 1636/3000 [11:09<07:36,  2.99it/s, loss=0.132, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1637/3000 [11:09<07:35,  2.99it/s, loss=0.206, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1638/3000 [11:09<07:38,  2.97it/s, loss=0.252, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1639/3000 [11:10<07:35,  2.99it/s, loss=0.133, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1640/3000 [11:10<07:34,  2.99it/s, loss=0.0617, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1641/3000 [11:10<07:31,  3.01it/s, loss=0.171, lr=0.002] \n",
      "Steps:  55%|█████▍    | 1642/3000 [11:11<07:31,  3.01it/s, loss=0.129, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1643/3000 [11:11<07:33,  2.99it/s, loss=0.069, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1644/3000 [11:11<07:29,  3.02it/s, loss=0.0663, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1645/3000 [11:12<07:32,  3.00it/s, loss=0.281, lr=0.002] \n",
      "Steps:  55%|█████▍    | 1646/3000 [11:12<07:35,  2.97it/s, loss=0.108, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1647/3000 [11:12<07:33,  2.98it/s, loss=0.0844, lr=0.002]\n",
      "Steps:  55%|█████▍    | 1648/3000 [11:13<07:37,  2.96it/s, loss=0.24, lr=0.002]  \n",
      "Steps:  55%|█████▍    | 1649/3000 [11:13<07:32,  2.98it/s, loss=0.121, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1650/3000 [11:13<06:49,  3.29it/s, loss=0.156, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1651/3000 [11:14<07:46,  2.89it/s, loss=0.134, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1652/3000 [11:14<07:43,  2.91it/s, loss=0.117, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1653/3000 [11:14<07:39,  2.93it/s, loss=0.0792, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1654/3000 [11:15<07:39,  2.93it/s, loss=0.0541, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1655/3000 [11:15<07:32,  2.97it/s, loss=0.192, lr=0.002] \n",
      "Steps:  55%|█████▌    | 1656/3000 [11:15<07:28,  2.99it/s, loss=0.136, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1657/3000 [11:16<07:30,  2.98it/s, loss=0.0582, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1658/3000 [11:16<07:30,  2.98it/s, loss=0.133, lr=0.002] \n",
      "Steps:  55%|█████▌    | 1659/3000 [11:16<07:29,  2.99it/s, loss=0.115, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1660/3000 [11:17<07:30,  2.97it/s, loss=0.232, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1661/3000 [11:17<07:28,  2.99it/s, loss=0.024, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1662/3000 [11:17<07:31,  2.96it/s, loss=0.103, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1663/3000 [11:18<07:28,  2.98it/s, loss=0.164, lr=0.002]\n",
      "Steps:  55%|█████▌    | 1664/3000 [11:18<07:34,  2.94it/s, loss=0.0888, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1665/3000 [11:18<07:31,  2.96it/s, loss=0.0714, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1666/3000 [11:19<07:30,  2.96it/s, loss=0.2, lr=0.002]   \n",
      "Steps:  56%|█████▌    | 1667/3000 [11:19<07:26,  2.99it/s, loss=0.0859, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1668/3000 [11:19<07:25,  2.99it/s, loss=0.0966, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1669/3000 [11:20<07:28,  2.97it/s, loss=0.232, lr=0.002] \n",
      "Steps:  56%|█████▌    | 1670/3000 [11:20<07:27,  2.97it/s, loss=0.206, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1671/3000 [11:20<07:27,  2.97it/s, loss=0.14, lr=0.002] \n",
      "Steps:  56%|█████▌    | 1672/3000 [11:21<07:27,  2.97it/s, loss=0.156, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1673/3000 [11:21<07:29,  2.95it/s, loss=0.209, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1674/3000 [11:22<07:29,  2.95it/s, loss=0.197, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1675/3000 [11:22<07:27,  2.96it/s, loss=0.107, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1676/3000 [11:22<07:31,  2.94it/s, loss=0.211, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1677/3000 [11:23<07:26,  2.96it/s, loss=0.109, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1678/3000 [11:23<07:24,  2.98it/s, loss=0.0688, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1679/3000 [11:23<07:23,  2.98it/s, loss=0.161, lr=0.002] \n",
      "Steps:  56%|█████▌    | 1680/3000 [11:24<07:22,  2.99it/s, loss=0.178, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1681/3000 [11:24<07:20,  2.99it/s, loss=0.057, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1682/3000 [11:24<07:17,  3.01it/s, loss=0.266, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1683/3000 [11:25<07:20,  2.99it/s, loss=0.123, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1684/3000 [11:25<07:19,  2.99it/s, loss=0.134, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1685/3000 [11:25<07:22,  2.97it/s, loss=0.0334, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1686/3000 [11:26<07:20,  2.98it/s, loss=0.0334, lr=0.002]\n",
      "Steps:  56%|█████▌    | 1686/3000 [11:26<07:20,  2.98it/s, loss=0.102, lr=0.002] \n",
      "Steps:  56%|█████▌    | 1687/3000 [11:26<08:08,  2.69it/s, loss=0.294, lr=0.002]\n",
      "Steps:  56%|█████▋    | 1688/3000 [11:26<07:50,  2.79it/s, loss=0.183, lr=0.002]\n",
      "Steps:  56%|█████▋    | 1689/3000 [11:27<07:42,  2.84it/s, loss=0.328, lr=0.002]\n",
      "Steps:  56%|█████▋    | 1690/3000 [11:27<07:41,  2.84it/s, loss=0.128, lr=0.002]\n",
      "Steps:  56%|█████▋    | 1691/3000 [11:27<07:34,  2.88it/s, loss=0.163, lr=0.002]\n",
      "Steps:  56%|█████▋    | 1692/3000 [11:28<07:30,  2.91it/s, loss=0.18, lr=0.002] \n",
      "Steps:  56%|█████▋    | 1693/3000 [11:28<07:25,  2.93it/s, loss=0.129, lr=0.002]\n",
      "Steps:  56%|█████▋    | 1694/3000 [11:28<07:19,  2.97it/s, loss=0.0732, lr=0.002]\n",
      "Steps:  56%|█████▋    | 1695/3000 [11:29<07:14,  3.00it/s, loss=0.221, lr=0.002] \n",
      "Steps:  57%|█████▋    | 1696/3000 [11:29<07:14,  3.00it/s, loss=0.122, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1697/3000 [11:29<07:12,  3.01it/s, loss=0.115, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1698/3000 [11:30<07:10,  3.02it/s, loss=0.0507, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1699/3000 [11:30<07:09,  3.03it/s, loss=0.0186, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1700/3000 [11:30<07:11,  3.02it/s, loss=0.173, lr=0.002] \n",
      "Steps:  57%|█████▋    | 1701/3000 [11:31<07:15,  2.98it/s, loss=0.141, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1702/3000 [11:31<07:14,  2.99it/s, loss=0.0637, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1703/3000 [11:31<07:13,  2.99it/s, loss=0.133, lr=0.002] \n",
      "Steps:  57%|█████▋    | 1704/3000 [11:32<07:12,  3.00it/s, loss=0.137, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1705/3000 [11:32<07:12,  2.99it/s, loss=0.082, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1706/3000 [11:32<07:11,  3.00it/s, loss=0.0283, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1707/3000 [11:33<07:13,  2.98it/s, loss=0.194, lr=0.002] \n",
      "Steps:  57%|█████▋    | 1708/3000 [11:33<07:13,  2.98it/s, loss=0.131, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1709/3000 [11:33<07:13,  2.98it/s, loss=0.0884, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1710/3000 [11:34<07:09,  3.00it/s, loss=0.032, lr=0.002] \n",
      "Steps:  57%|█████▋    | 1711/3000 [11:34<07:10,  3.00it/s, loss=0.298, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1712/3000 [11:34<07:13,  2.97it/s, loss=0.203, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1713/3000 [11:35<07:12,  2.97it/s, loss=0.138, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1714/3000 [11:35<07:08,  3.00it/s, loss=0.183, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1715/3000 [11:35<07:10,  2.98it/s, loss=0.127, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1716/3000 [11:36<07:16,  2.94it/s, loss=0.0788, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1717/3000 [11:36<07:13,  2.96it/s, loss=0.0958, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1718/3000 [11:36<07:06,  3.00it/s, loss=0.136, lr=0.002] \n",
      "Steps:  57%|█████▋    | 1719/3000 [11:37<07:01,  3.04it/s, loss=0.195, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1720/3000 [11:37<07:04,  3.01it/s, loss=0.0589, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1721/3000 [11:37<07:02,  3.02it/s, loss=0.0563, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1722/3000 [11:38<07:04,  3.01it/s, loss=0.0812, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1723/3000 [11:38<07:02,  3.02it/s, loss=0.0914, lr=0.002]\n",
      "Steps:  57%|█████▋    | 1724/3000 [11:38<06:57,  3.05it/s, loss=0.192, lr=0.002] \n",
      "Steps:  57%|█████▊    | 1725/3000 [11:39<07:06,  2.99it/s, loss=0.0993, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1726/3000 [11:39<07:04,  3.00it/s, loss=0.0614, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1727/3000 [11:39<06:58,  3.04it/s, loss=0.118, lr=0.002] \n",
      "Steps:  58%|█████▊    | 1728/3000 [11:40<07:00,  3.02it/s, loss=0.114, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1729/3000 [11:40<07:04,  2.99it/s, loss=0.161, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1730/3000 [11:40<07:06,  2.98it/s, loss=0.0486, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1731/3000 [11:41<07:05,  2.98it/s, loss=0.101, lr=0.002] \n",
      "Steps:  58%|█████▊    | 1732/3000 [11:41<07:06,  2.98it/s, loss=0.182, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1733/3000 [11:41<07:02,  3.00it/s, loss=0.114, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1734/3000 [11:42<07:03,  2.99it/s, loss=0.0675, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1735/3000 [11:42<07:08,  2.95it/s, loss=0.104, lr=0.002] \n",
      "Steps:  58%|█████▊    | 1736/3000 [11:42<07:05,  2.97it/s, loss=0.133, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1737/3000 [11:43<06:59,  3.01it/s, loss=0.292, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1738/3000 [11:43<07:00,  3.00it/s, loss=0.0992, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1739/3000 [11:43<07:01,  2.99it/s, loss=0.229, lr=0.002] \n",
      "Steps:  58%|█████▊    | 1740/3000 [11:44<06:58,  3.01it/s, loss=0.167, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1741/3000 [11:44<07:03,  2.97it/s, loss=0.202, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1742/3000 [11:44<07:02,  2.97it/s, loss=0.0736, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1743/3000 [11:45<07:00,  2.99it/s, loss=0.199, lr=0.002] \n",
      "Steps:  58%|█████▊    | 1744/3000 [11:45<07:40,  2.73it/s, loss=0.178, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1745/3000 [11:45<07:29,  2.79it/s, loss=0.148, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1746/3000 [11:46<07:23,  2.83it/s, loss=0.105, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1747/3000 [11:46<07:16,  2.87it/s, loss=0.142, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1748/3000 [11:46<07:13,  2.89it/s, loss=0.113, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1749/3000 [11:47<07:11,  2.90it/s, loss=0.0939, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1750/3000 [11:47<07:03,  2.95it/s, loss=0.0789, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1751/3000 [11:47<07:02,  2.96it/s, loss=0.162, lr=0.002] \n",
      "Steps:  58%|█████▊    | 1752/3000 [11:48<07:00,  2.97it/s, loss=0.227, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1753/3000 [11:48<06:59,  2.97it/s, loss=0.141, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1754/3000 [11:48<06:58,  2.98it/s, loss=0.0214, lr=0.002]\n",
      "Steps:  58%|█████▊    | 1755/3000 [11:49<06:56,  2.99it/s, loss=0.21, lr=0.002]  \n",
      "Steps:  59%|█████▊    | 1756/3000 [11:49<06:53,  3.01it/s, loss=0.162, lr=0.002]\n",
      "Steps:  59%|█████▊    | 1757/3000 [11:49<06:50,  3.03it/s, loss=0.0475, lr=0.002]\n",
      "Steps:  59%|█████▊    | 1758/3000 [11:50<06:51,  3.02it/s, loss=0.193, lr=0.002] \n",
      "Steps:  59%|█████▊    | 1759/3000 [11:50<06:56,  2.98it/s, loss=0.12, lr=0.002] \n",
      "Steps:  59%|█████▊    | 1760/3000 [11:51<06:59,  2.96it/s, loss=0.132, lr=0.002]\n",
      "Steps:  59%|█████▊    | 1761/3000 [11:51<06:57,  2.97it/s, loss=0.179, lr=0.002]\n",
      "Steps:  59%|█████▊    | 1762/3000 [11:51<06:55,  2.98it/s, loss=0.047, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1763/3000 [11:52<06:53,  2.99it/s, loss=0.0157, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1764/3000 [11:52<06:52,  3.00it/s, loss=0.0841, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1765/3000 [11:52<06:54,  2.98it/s, loss=0.16, lr=0.002]  \n",
      "Steps:  59%|█████▉    | 1766/3000 [11:52<06:46,  3.03it/s, loss=0.0988, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1767/3000 [11:53<06:45,  3.04it/s, loss=0.137, lr=0.002] \n",
      "Steps:  59%|█████▉    | 1768/3000 [11:53<06:46,  3.03it/s, loss=0.286, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1769/3000 [11:53<06:49,  3.01it/s, loss=0.132, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1770/3000 [11:54<06:51,  2.99it/s, loss=0.171, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1771/3000 [11:54<06:56,  2.95it/s, loss=0.103, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1772/3000 [11:55<06:55,  2.95it/s, loss=0.269, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1773/3000 [11:55<06:54,  2.96it/s, loss=0.14, lr=0.002] \n",
      "Steps:  59%|█████▉    | 1774/3000 [11:55<06:52,  2.97it/s, loss=0.0777, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1775/3000 [11:56<06:52,  2.97it/s, loss=0.129, lr=0.002] \n",
      "Steps:  59%|█████▉    | 1776/3000 [11:56<06:52,  2.97it/s, loss=0.256, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1777/3000 [11:56<07:01,  2.90it/s, loss=0.142, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1778/3000 [11:57<06:58,  2.92it/s, loss=0.132, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1779/3000 [11:57<06:55,  2.94it/s, loss=0.156, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1780/3000 [11:57<06:52,  2.96it/s, loss=0.148, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1781/3000 [11:58<06:51,  2.97it/s, loss=0.13, lr=0.002] \n",
      "Steps:  59%|█████▉    | 1782/3000 [11:58<06:50,  2.97it/s, loss=0.205, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1783/3000 [11:58<06:47,  2.99it/s, loss=0.0809, lr=0.002]\n",
      "Steps:  59%|█████▉    | 1784/3000 [11:59<06:47,  2.99it/s, loss=0.204, lr=0.002] \n",
      "Steps:  60%|█████▉    | 1785/3000 [11:59<06:48,  2.98it/s, loss=0.117, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1786/3000 [11:59<06:46,  2.98it/s, loss=0.137, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1787/3000 [12:00<06:51,  2.95it/s, loss=0.124, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1788/3000 [12:00<06:49,  2.96it/s, loss=0.143, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1789/3000 [12:00<06:50,  2.95it/s, loss=0.247, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1790/3000 [12:01<06:48,  2.96it/s, loss=0.11, lr=0.002] \n",
      "Steps:  60%|█████▉    | 1791/3000 [12:01<06:48,  2.96it/s, loss=0.391, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1792/3000 [12:01<06:41,  3.01it/s, loss=0.222, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1793/3000 [12:02<06:45,  2.98it/s, loss=0.0759, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1794/3000 [12:02<06:39,  3.02it/s, loss=0.123, lr=0.002] \n",
      "Steps:  60%|█████▉    | 1795/3000 [12:02<06:41,  3.00it/s, loss=0.0664, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1796/3000 [12:03<06:40,  3.01it/s, loss=0.111, lr=0.002] \n",
      "Steps:  60%|█████▉    | 1797/3000 [12:03<06:41,  3.00it/s, loss=0.2, lr=0.002]  \n",
      "Steps:  60%|█████▉    | 1798/3000 [12:03<06:42,  2.98it/s, loss=0.0682, lr=0.002]\n",
      "Steps:  60%|█████▉    | 1799/3000 [12:04<06:35,  3.04it/s, loss=0.139, lr=0.002] \n",
      "Steps:  60%|██████    | 1800/3000 [12:04<05:58,  3.35it/s, loss=0.106, lr=0.002]\n",
      "Steps:  60%|██████    | 1801/3000 [12:04<07:24,  2.69it/s, loss=0.122, lr=0.002]\n",
      "Steps:  60%|██████    | 1802/3000 [12:05<07:11,  2.78it/s, loss=0.0734, lr=0.002]\n",
      "Steps:  60%|██████    | 1803/3000 [12:05<06:58,  2.86it/s, loss=0.0923, lr=0.002]\n",
      "Steps:  60%|██████    | 1804/3000 [12:05<06:54,  2.89it/s, loss=0.0995, lr=0.002]\n",
      "Steps:  60%|██████    | 1805/3000 [12:06<06:51,  2.90it/s, loss=0.184, lr=0.002] \n",
      "Steps:  60%|██████    | 1806/3000 [12:06<06:52,  2.89it/s, loss=0.0612, lr=0.002]\n",
      "Steps:  60%|██████    | 1807/3000 [12:06<06:47,  2.93it/s, loss=0.117, lr=0.002] \n",
      "Steps:  60%|██████    | 1808/3000 [12:07<06:43,  2.96it/s, loss=0.134, lr=0.002]\n",
      "Steps:  60%|██████    | 1809/3000 [12:07<06:39,  2.98it/s, loss=0.134, lr=0.002]\n",
      "Steps:  60%|██████    | 1810/3000 [12:07<06:39,  2.98it/s, loss=0.0896, lr=0.002]\n",
      "Steps:  60%|██████    | 1811/3000 [12:08<06:33,  3.02it/s, loss=0.123, lr=0.002] \n",
      "Steps:  60%|██████    | 1812/3000 [12:08<06:38,  2.98it/s, loss=0.157, lr=0.002]\n",
      "Steps:  60%|██████    | 1813/3000 [12:08<06:37,  2.98it/s, loss=0.125, lr=0.002]\n",
      "Steps:  60%|██████    | 1814/3000 [12:09<06:37,  2.98it/s, loss=0.133, lr=0.002]\n",
      "Steps:  60%|██████    | 1815/3000 [12:09<06:37,  2.98it/s, loss=0.199, lr=0.002]\n",
      "Steps:  61%|██████    | 1816/3000 [12:09<06:36,  2.99it/s, loss=0.0304, lr=0.002]\n",
      "Steps:  61%|██████    | 1817/3000 [12:10<06:39,  2.96it/s, loss=0.237, lr=0.002] \n",
      "Steps:  61%|██████    | 1818/3000 [12:10<06:37,  2.98it/s, loss=0.101, lr=0.002]\n",
      "Steps:  61%|██████    | 1819/3000 [12:10<06:34,  2.99it/s, loss=0.104, lr=0.002]\n",
      "Steps:  61%|██████    | 1820/3000 [12:11<06:34,  2.99it/s, loss=0.165, lr=0.002]\n",
      "Steps:  61%|██████    | 1821/3000 [12:11<06:33,  3.00it/s, loss=0.117, lr=0.002]\n",
      "Steps:  61%|██████    | 1822/3000 [12:11<06:31,  3.01it/s, loss=0.241, lr=0.002]\n",
      "Steps:  61%|██████    | 1823/3000 [12:12<06:33,  2.99it/s, loss=0.113, lr=0.002]\n",
      "Steps:  61%|██████    | 1824/3000 [12:12<06:30,  3.01it/s, loss=0.0602, lr=0.002]\n",
      "Steps:  61%|██████    | 1825/3000 [12:12<06:32,  2.99it/s, loss=0.203, lr=0.002] \n",
      "Steps:  61%|██████    | 1826/3000 [12:13<06:32,  2.99it/s, loss=0.0635, lr=0.002]\n",
      "Steps:  61%|██████    | 1827/3000 [12:13<06:36,  2.96it/s, loss=0.0614, lr=0.002]\n",
      "Steps:  61%|██████    | 1828/3000 [12:13<06:36,  2.96it/s, loss=0.279, lr=0.002] \n",
      "Steps:  61%|██████    | 1829/3000 [12:14<06:51,  2.85it/s, loss=0.095, lr=0.002]\n",
      "Steps:  61%|██████    | 1830/3000 [12:14<06:42,  2.90it/s, loss=0.102, lr=0.002]\n",
      "Steps:  61%|██████    | 1831/3000 [12:14<06:38,  2.93it/s, loss=0.0851, lr=0.002]\n",
      "Steps:  61%|██████    | 1832/3000 [12:15<06:37,  2.94it/s, loss=0.0935, lr=0.002]\n",
      "Steps:  61%|██████    | 1833/3000 [12:15<06:32,  2.97it/s, loss=0.126, lr=0.002] \n",
      "Steps:  61%|██████    | 1834/3000 [12:15<06:29,  2.99it/s, loss=0.091, lr=0.002]\n",
      "Steps:  61%|██████    | 1835/3000 [12:16<06:32,  2.97it/s, loss=0.0571, lr=0.002]\n",
      "Steps:  61%|██████    | 1836/3000 [12:16<06:32,  2.97it/s, loss=0.122, lr=0.002] \n",
      "Steps:  61%|██████    | 1837/3000 [12:16<06:29,  2.98it/s, loss=0.107, lr=0.002]\n",
      "Steps:  61%|██████▏   | 1838/3000 [12:17<06:28,  2.99it/s, loss=0.0589, lr=0.002]\n",
      "Steps:  61%|██████▏   | 1839/3000 [12:17<06:27,  3.00it/s, loss=0.189, lr=0.002] \n",
      "Steps:  61%|██████▏   | 1840/3000 [12:17<06:30,  2.97it/s, loss=0.16, lr=0.002] \n",
      "Steps:  61%|██████▏   | 1841/3000 [12:18<06:24,  3.01it/s, loss=0.12, lr=0.002]\n",
      "Steps:  61%|██████▏   | 1842/3000 [12:18<06:26,  2.99it/s, loss=0.0797, lr=0.002]\n",
      "Steps:  61%|██████▏   | 1843/3000 [12:18<06:26,  2.99it/s, loss=0.143, lr=0.002] \n",
      "Steps:  61%|██████▏   | 1844/3000 [12:19<06:27,  2.99it/s, loss=0.0643, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1845/3000 [12:19<06:27,  2.98it/s, loss=0.158, lr=0.002] \n",
      "Steps:  62%|██████▏   | 1846/3000 [12:19<06:31,  2.95it/s, loss=0.134, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1847/3000 [12:20<06:27,  2.98it/s, loss=0.113, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1848/3000 [12:20<06:27,  2.97it/s, loss=0.12, lr=0.002] \n",
      "Steps:  62%|██████▏   | 1849/3000 [12:20<06:30,  2.95it/s, loss=0.224, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1850/3000 [12:21<06:31,  2.94it/s, loss=0.145, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1851/3000 [12:21<06:30,  2.94it/s, loss=0.428, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1852/3000 [12:22<06:31,  2.93it/s, loss=0.106, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1853/3000 [12:22<06:26,  2.96it/s, loss=0.163, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1854/3000 [12:22<06:26,  2.97it/s, loss=0.193, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1855/3000 [12:23<06:26,  2.96it/s, loss=0.247, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1856/3000 [12:23<06:22,  2.99it/s, loss=0.205, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1857/3000 [12:23<06:22,  2.99it/s, loss=0.123, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1858/3000 [12:24<07:07,  2.67it/s, loss=0.109, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1859/3000 [12:24<06:55,  2.75it/s, loss=0.286, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1860/3000 [12:24<06:46,  2.80it/s, loss=0.113, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1861/3000 [12:25<06:37,  2.87it/s, loss=0.142, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1862/3000 [12:25<06:32,  2.90it/s, loss=0.105, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1863/3000 [12:25<06:21,  2.98it/s, loss=0.0736, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1864/3000 [12:26<06:19,  2.99it/s, loss=0.098, lr=0.002] \n",
      "Steps:  62%|██████▏   | 1865/3000 [12:26<06:15,  3.02it/s, loss=0.214, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1866/3000 [12:26<06:19,  2.99it/s, loss=0.122, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1867/3000 [12:27<06:16,  3.01it/s, loss=0.125, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1868/3000 [12:27<06:14,  3.02it/s, loss=0.142, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1869/3000 [12:27<06:15,  3.01it/s, loss=0.111, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1870/3000 [12:28<06:15,  3.01it/s, loss=0.0861, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1871/3000 [12:28<06:17,  2.99it/s, loss=0.155, lr=0.002] \n",
      "Steps:  62%|██████▏   | 1872/3000 [12:28<06:24,  2.93it/s, loss=0.141, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1873/3000 [12:29<06:21,  2.95it/s, loss=0.192, lr=0.002]\n",
      "Steps:  62%|██████▏   | 1874/3000 [12:29<06:18,  2.98it/s, loss=0.216, lr=0.002]\n",
      "Steps:  62%|██████▎   | 1875/3000 [12:29<06:18,  2.97it/s, loss=0.18, lr=0.002] \n",
      "Steps:  63%|██████▎   | 1876/3000 [12:30<06:16,  2.99it/s, loss=0.207, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1877/3000 [12:30<06:13,  3.00it/s, loss=0.0226, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1878/3000 [12:30<06:12,  3.01it/s, loss=0.0211, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1879/3000 [12:31<06:12,  3.01it/s, loss=0.121, lr=0.002] \n",
      "Steps:  63%|██████▎   | 1880/3000 [12:31<06:15,  2.99it/s, loss=0.0169, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1881/3000 [12:31<06:14,  2.99it/s, loss=0.11, lr=0.002]  \n",
      "Steps:  63%|██████▎   | 1882/3000 [12:32<06:13,  2.99it/s, loss=0.13, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1883/3000 [12:32<06:11,  3.01it/s, loss=0.241, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1884/3000 [12:32<06:12,  3.00it/s, loss=0.0899, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1885/3000 [12:33<06:12,  2.99it/s, loss=0.218, lr=0.002] \n",
      "Steps:  63%|██████▎   | 1886/3000 [12:33<06:08,  3.02it/s, loss=0.105, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1887/3000 [12:33<06:06,  3.03it/s, loss=0.108, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1888/3000 [12:34<06:08,  3.02it/s, loss=0.125, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1889/3000 [12:34<06:08,  3.01it/s, loss=0.142, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1890/3000 [12:34<06:09,  3.00it/s, loss=0.0986, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1891/3000 [12:35<06:09,  3.00it/s, loss=0.102, lr=0.002] \n",
      "Steps:  63%|██████▎   | 1892/3000 [12:35<06:02,  3.05it/s, loss=0.221, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1893/3000 [12:35<06:01,  3.06it/s, loss=0.0973, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1894/3000 [12:36<06:06,  3.02it/s, loss=0.077, lr=0.002] \n",
      "Steps:  63%|██████▎   | 1895/3000 [12:36<06:05,  3.03it/s, loss=0.195, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1896/3000 [12:36<06:07,  3.00it/s, loss=0.105, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1897/3000 [12:37<06:08,  2.99it/s, loss=0.0852, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1898/3000 [12:37<06:05,  3.01it/s, loss=0.0303, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1899/3000 [12:37<06:03,  3.03it/s, loss=0.211, lr=0.002] \n",
      "Steps:  63%|██████▎   | 1900/3000 [12:38<06:03,  3.02it/s, loss=0.0502, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1901/3000 [12:38<06:02,  3.03it/s, loss=0.219, lr=0.002] \n",
      "Steps:  63%|██████▎   | 1902/3000 [12:38<06:04,  3.01it/s, loss=0.0912, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1903/3000 [12:39<06:06,  2.99it/s, loss=0.0786, lr=0.002]\n",
      "Steps:  63%|██████▎   | 1904/3000 [12:39<05:58,  3.06it/s, loss=0.179, lr=0.002] \n",
      "Steps:  64%|██████▎   | 1905/3000 [12:39<06:02,  3.02it/s, loss=0.124, lr=0.002]\n",
      "Steps:  64%|██████▎   | 1906/3000 [12:40<06:05,  3.00it/s, loss=0.277, lr=0.002]\n",
      "Steps:  64%|██████▎   | 1907/3000 [12:40<06:03,  3.01it/s, loss=0.12, lr=0.002] \n",
      "Steps:  64%|██████▎   | 1908/3000 [12:40<06:06,  2.98it/s, loss=0.129, lr=0.002]\n",
      "Steps:  64%|██████▎   | 1909/3000 [12:41<06:07,  2.97it/s, loss=0.171, lr=0.002]\n",
      "Steps:  64%|██████▎   | 1910/3000 [12:41<06:09,  2.95it/s, loss=0.145, lr=0.002]\n",
      "Steps:  64%|██████▎   | 1911/3000 [12:41<06:10,  2.94it/s, loss=0.0167, lr=0.002]\n",
      "Steps:  64%|██████▎   | 1912/3000 [12:42<06:06,  2.97it/s, loss=0.284, lr=0.002] \n",
      "Steps:  64%|██████▍   | 1913/3000 [12:42<06:06,  2.97it/s, loss=0.148, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1914/3000 [12:42<06:02,  2.99it/s, loss=0.147, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1915/3000 [12:43<06:44,  2.68it/s, loss=0.148, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1916/3000 [12:43<06:33,  2.75it/s, loss=0.126, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1917/3000 [12:43<06:20,  2.84it/s, loss=0.274, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1918/3000 [12:44<06:10,  2.92it/s, loss=0.132, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1919/3000 [12:44<06:06,  2.95it/s, loss=0.127, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1920/3000 [12:44<06:01,  2.99it/s, loss=0.105, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1921/3000 [12:45<06:04,  2.96it/s, loss=0.101, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1922/3000 [12:45<06:03,  2.96it/s, loss=0.0282, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1923/3000 [12:45<05:59,  2.99it/s, loss=0.109, lr=0.002] \n",
      "Steps:  64%|██████▍   | 1924/3000 [12:46<05:59,  2.99it/s, loss=0.0958, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1925/3000 [12:46<06:00,  2.98it/s, loss=0.286, lr=0.002] \n",
      "Steps:  64%|██████▍   | 1926/3000 [12:46<06:01,  2.97it/s, loss=0.0956, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1927/3000 [12:47<06:01,  2.97it/s, loss=0.183, lr=0.002] \n",
      "Steps:  64%|██████▍   | 1928/3000 [12:47<06:02,  2.96it/s, loss=0.16, lr=0.002] \n",
      "Steps:  64%|██████▍   | 1929/3000 [12:47<05:58,  2.99it/s, loss=0.209, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1930/3000 [12:48<06:00,  2.97it/s, loss=0.16, lr=0.002] \n",
      "Steps:  64%|██████▍   | 1931/3000 [12:48<06:00,  2.97it/s, loss=0.0886, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1932/3000 [12:48<05:52,  3.03it/s, loss=0.0164, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1933/3000 [12:49<06:02,  2.94it/s, loss=0.105, lr=0.002] \n",
      "Steps:  64%|██████▍   | 1934/3000 [12:49<06:00,  2.96it/s, loss=0.0698, lr=0.002]\n",
      "Steps:  64%|██████▍   | 1935/3000 [12:49<05:55,  3.00it/s, loss=0.0524, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1936/3000 [12:50<05:55,  2.99it/s, loss=0.0548, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1937/3000 [12:50<05:56,  2.98it/s, loss=0.0878, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1938/3000 [12:50<05:57,  2.97it/s, loss=0.107, lr=0.002] \n",
      "Steps:  65%|██████▍   | 1939/3000 [12:51<05:53,  3.01it/s, loss=0.0962, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1940/3000 [12:51<05:51,  3.01it/s, loss=0.113, lr=0.002] \n",
      "Steps:  65%|██████▍   | 1941/3000 [12:51<05:48,  3.04it/s, loss=0.238, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1942/3000 [12:52<05:49,  3.02it/s, loss=0.0562, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1943/3000 [12:52<05:50,  3.01it/s, loss=0.172, lr=0.002] \n",
      "Steps:  65%|██████▍   | 1944/3000 [12:52<05:52,  3.00it/s, loss=0.104, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1945/3000 [12:53<05:50,  3.01it/s, loss=0.199, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1946/3000 [12:53<05:52,  2.99it/s, loss=0.117, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1947/3000 [12:53<05:53,  2.98it/s, loss=0.206, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1948/3000 [12:54<05:49,  3.01it/s, loss=0.0306, lr=0.002]\n",
      "Steps:  65%|██████▍   | 1949/3000 [12:54<05:52,  2.98it/s, loss=0.0902, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1950/3000 [12:54<05:18,  3.30it/s, loss=0.0878, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1951/3000 [12:55<06:04,  2.88it/s, loss=0.165, lr=0.002] \n",
      "Steps:  65%|██████▌   | 1952/3000 [12:55<06:00,  2.90it/s, loss=0.0215, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1953/3000 [12:55<05:58,  2.92it/s, loss=0.14, lr=0.002]  \n",
      "Steps:  65%|██████▌   | 1954/3000 [12:56<05:58,  2.92it/s, loss=0.131, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1955/3000 [12:56<05:55,  2.94it/s, loss=0.123, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1956/3000 [12:56<05:52,  2.96it/s, loss=0.266, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1957/3000 [12:57<05:54,  2.94it/s, loss=0.0683, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1958/3000 [12:57<05:53,  2.95it/s, loss=0.0624, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1959/3000 [12:58<06:00,  2.89it/s, loss=0.374, lr=0.002] \n",
      "Steps:  65%|██████▌   | 1960/3000 [12:58<05:59,  2.89it/s, loss=0.132, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1961/3000 [12:58<05:55,  2.92it/s, loss=0.196, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1962/3000 [12:59<05:54,  2.93it/s, loss=0.144, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1963/3000 [12:59<05:52,  2.94it/s, loss=0.224, lr=0.002]\n",
      "Steps:  65%|██████▌   | 1964/3000 [12:59<05:48,  2.97it/s, loss=0.102, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1965/3000 [13:00<05:45,  3.00it/s, loss=0.231, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1966/3000 [13:00<05:41,  3.03it/s, loss=0.0693, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1967/3000 [13:00<05:42,  3.02it/s, loss=0.109, lr=0.002] \n",
      "Steps:  66%|██████▌   | 1968/3000 [13:01<05:45,  2.99it/s, loss=0.302, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1969/3000 [13:01<05:43,  3.00it/s, loss=0.0857, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1970/3000 [13:01<05:45,  2.98it/s, loss=0.0717, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1971/3000 [13:02<05:45,  2.98it/s, loss=0.15, lr=0.002]  \n",
      "Steps:  66%|██████▌   | 1972/3000 [13:02<06:22,  2.69it/s, loss=0.143, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1973/3000 [13:02<06:10,  2.77it/s, loss=0.137, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1974/3000 [13:03<06:04,  2.82it/s, loss=0.198, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1975/3000 [13:03<05:58,  2.86it/s, loss=0.056, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1976/3000 [13:03<06:00,  2.84it/s, loss=0.268, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1977/3000 [13:04<05:51,  2.91it/s, loss=0.114, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1978/3000 [13:04<05:50,  2.92it/s, loss=0.114, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1978/3000 [13:04<05:50,  2.92it/s, loss=0.0727, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1979/3000 [13:04<05:45,  2.96it/s, loss=0.211, lr=0.002] \n",
      "Steps:  66%|██████▌   | 1980/3000 [13:05<05:42,  2.97it/s, loss=0.101, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1981/3000 [13:05<05:42,  2.97it/s, loss=0.165, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1982/3000 [13:05<05:41,  2.98it/s, loss=0.122, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1983/3000 [13:06<05:42,  2.97it/s, loss=0.115, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1984/3000 [13:06<05:44,  2.95it/s, loss=0.115, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1984/3000 [13:06<05:44,  2.95it/s, loss=0.176, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1985/3000 [13:06<05:47,  2.92it/s, loss=0.221, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1986/3000 [13:07<05:44,  2.94it/s, loss=0.101, lr=0.002]\n",
      "Steps:  66%|██████▌   | 1987/3000 [13:07<05:45,  2.94it/s, loss=0.0635, lr=0.002]\n",
      "Steps:  66%|██████▋   | 1988/3000 [13:07<05:40,  2.97it/s, loss=0.0753, lr=0.002]\n",
      "Steps:  66%|██████▋   | 1989/3000 [13:08<05:37,  3.00it/s, loss=0.142, lr=0.002] \n",
      "Steps:  66%|██████▋   | 1990/3000 [13:08<05:36,  3.00it/s, loss=0.0588, lr=0.002]\n",
      "Steps:  66%|██████▋   | 1991/3000 [13:08<05:36,  3.00it/s, loss=0.141, lr=0.002] \n",
      "Steps:  66%|██████▋   | 1992/3000 [13:09<05:36,  3.00it/s, loss=0.092, lr=0.002]\n",
      "Steps:  66%|██████▋   | 1993/3000 [13:09<05:39,  2.97it/s, loss=0.243, lr=0.002]\n",
      "Steps:  66%|██████▋   | 1994/3000 [13:09<05:39,  2.96it/s, loss=0.207, lr=0.002]\n",
      "Steps:  66%|██████▋   | 1995/3000 [13:10<05:39,  2.96it/s, loss=0.278, lr=0.002]\n",
      "Steps:  67%|██████▋   | 1996/3000 [13:10<05:37,  2.97it/s, loss=0.109, lr=0.002]\n",
      "Steps:  67%|██████▋   | 1997/3000 [13:10<05:35,  2.99it/s, loss=0.108, lr=0.002]\n",
      "Steps:  67%|██████▋   | 1998/3000 [13:11<05:32,  3.01it/s, loss=0.258, lr=0.002]\n",
      "Steps:  67%|██████▋   | 1999/3000 [13:11<05:34,  2.99it/s, loss=0.148, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2000/3000 [13:11<05:33,  3.00it/s, loss=0.148, lr=0.002]05/09/2024 05:34:32 - INFO - __main__ - Saving embeddings\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:34:32 - INFO - accelerate.accelerator - Saving current state to /tmp/textual_inversion_cat/checkpoint-2000\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:34:33 - INFO - accelerate.checkpointing - Model weights saved in /tmp/textual_inversion_cat/checkpoint-2000/model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:34:34 - INFO - accelerate.checkpointing - Optimizer state saved in /tmp/textual_inversion_cat/checkpoint-2000/optimizer.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:34:34 - INFO - accelerate.checkpointing - Scheduler state saved in /tmp/textual_inversion_cat/checkpoint-2000/scheduler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:34:34 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /tmp/textual_inversion_cat/checkpoint-2000/sampler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:34:34 - INFO - accelerate.checkpointing - Random states saved in /tmp/textual_inversion_cat/checkpoint-2000/random_states_0.pkl\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:34:34 - INFO - __main__ - Saved state to /tmp/textual_inversion_cat/checkpoint-2000\n",
      "Steps:  67%|██████▋   | 2000/3000 [13:13<05:33,  3.00it/s, loss=0.093, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2001/3000 [13:13<12:57,  1.29it/s, loss=0.128, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2002/3000 [13:14<10:47,  1.54it/s, loss=0.0938, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2003/3000 [13:14<09:12,  1.80it/s, loss=0.307, lr=0.002] \n",
      "Steps:  67%|██████▋   | 2004/3000 [13:14<08:07,  2.04it/s, loss=0.0648, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2005/3000 [13:15<07:19,  2.26it/s, loss=0.181, lr=0.002] \n",
      "Steps:  67%|██████▋   | 2006/3000 [13:15<06:48,  2.43it/s, loss=0.103, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2007/3000 [13:15<06:24,  2.59it/s, loss=0.0182, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2008/3000 [13:16<06:08,  2.69it/s, loss=0.152, lr=0.002] \n",
      "Steps:  67%|██████▋   | 2009/3000 [13:16<05:58,  2.77it/s, loss=0.257, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2010/3000 [13:16<05:45,  2.87it/s, loss=0.149, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2011/3000 [13:17<05:41,  2.89it/s, loss=0.0704, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2012/3000 [13:17<05:38,  2.92it/s, loss=0.221, lr=0.002] \n",
      "Steps:  67%|██████▋   | 2013/3000 [13:17<05:34,  2.95it/s, loss=0.087, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2014/3000 [13:18<05:32,  2.97it/s, loss=0.106, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2015/3000 [13:18<05:32,  2.96it/s, loss=0.368, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2016/3000 [13:18<05:34,  2.94it/s, loss=0.0966, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2017/3000 [13:19<05:30,  2.98it/s, loss=0.175, lr=0.002] \n",
      "Steps:  67%|██████▋   | 2018/3000 [13:19<05:28,  2.99it/s, loss=0.0908, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2019/3000 [13:19<05:25,  3.01it/s, loss=0.134, lr=0.002] \n",
      "Steps:  67%|██████▋   | 2020/3000 [13:20<05:27,  3.00it/s, loss=0.203, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2021/3000 [13:20<05:27,  2.99it/s, loss=0.113, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2022/3000 [13:20<05:28,  2.97it/s, loss=0.171, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2023/3000 [13:21<05:29,  2.96it/s, loss=0.141, lr=0.002]\n",
      "Steps:  67%|██████▋   | 2024/3000 [13:21<05:33,  2.93it/s, loss=0.0304, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2025/3000 [13:21<05:30,  2.95it/s, loss=0.126, lr=0.002] \n",
      "Steps:  68%|██████▊   | 2026/3000 [13:22<05:28,  2.97it/s, loss=0.274, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2027/3000 [13:22<05:30,  2.94it/s, loss=0.0904, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2028/3000 [13:22<05:31,  2.93it/s, loss=0.0943, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2029/3000 [13:23<05:26,  2.97it/s, loss=0.115, lr=0.002] \n",
      "Steps:  68%|██████▊   | 2030/3000 [13:23<05:28,  2.95it/s, loss=0.151, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2031/3000 [13:23<05:26,  2.97it/s, loss=0.261, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2032/3000 [13:24<05:26,  2.97it/s, loss=0.142, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2033/3000 [13:24<05:28,  2.94it/s, loss=0.178, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2034/3000 [13:24<06:03,  2.66it/s, loss=0.134, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2035/3000 [13:25<05:50,  2.75it/s, loss=0.139, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2036/3000 [13:25<05:42,  2.81it/s, loss=0.0447, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2037/3000 [13:25<05:38,  2.85it/s, loss=0.0546, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2038/3000 [13:26<05:32,  2.89it/s, loss=0.202, lr=0.002] \n",
      "Steps:  68%|██████▊   | 2039/3000 [13:26<05:32,  2.89it/s, loss=0.151, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2040/3000 [13:26<05:26,  2.94it/s, loss=0.121, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2041/3000 [13:27<05:25,  2.94it/s, loss=0.046, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2042/3000 [13:27<05:24,  2.95it/s, loss=0.094, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2043/3000 [13:27<05:24,  2.95it/s, loss=0.126, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2044/3000 [13:28<05:27,  2.92it/s, loss=0.118, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2045/3000 [13:28<05:24,  2.95it/s, loss=0.17, lr=0.002] \n",
      "Steps:  68%|██████▊   | 2046/3000 [13:28<05:21,  2.97it/s, loss=0.16, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2047/3000 [13:29<05:19,  2.98it/s, loss=0.195, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2048/3000 [13:29<05:17,  2.99it/s, loss=0.184, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2049/3000 [13:29<05:19,  2.98it/s, loss=0.179, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2050/3000 [13:30<05:18,  2.98it/s, loss=0.189, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2051/3000 [13:30<05:14,  3.02it/s, loss=0.126, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2052/3000 [13:30<05:17,  2.98it/s, loss=0.0615, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2053/3000 [13:31<05:21,  2.95it/s, loss=0.19, lr=0.002]  \n",
      "Steps:  68%|██████▊   | 2054/3000 [13:31<05:23,  2.93it/s, loss=0.0972, lr=0.002]\n",
      "Steps:  68%|██████▊   | 2055/3000 [13:32<05:19,  2.96it/s, loss=0.276, lr=0.002] \n",
      "Steps:  69%|██████▊   | 2056/3000 [13:32<05:17,  2.97it/s, loss=0.22, lr=0.002] \n",
      "Steps:  69%|██████▊   | 2057/3000 [13:32<05:15,  2.99it/s, loss=0.119, lr=0.002]\n",
      "Steps:  69%|██████▊   | 2058/3000 [13:33<05:13,  3.00it/s, loss=0.234, lr=0.002]\n",
      "Steps:  69%|██████▊   | 2059/3000 [13:33<05:16,  2.98it/s, loss=0.133, lr=0.002]\n",
      "Steps:  69%|██████▊   | 2060/3000 [13:33<05:19,  2.94it/s, loss=0.252, lr=0.002]\n",
      "Steps:  69%|██████▊   | 2061/3000 [13:34<05:15,  2.98it/s, loss=0.0328, lr=0.002]\n",
      "Steps:  69%|██████▊   | 2062/3000 [13:34<05:15,  2.97it/s, loss=0.116, lr=0.002] \n",
      "Steps:  69%|██████▉   | 2063/3000 [13:34<05:14,  2.98it/s, loss=0.197, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2064/3000 [13:35<05:13,  2.98it/s, loss=0.0246, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2065/3000 [13:35<05:11,  3.01it/s, loss=0.105, lr=0.002] \n",
      "Steps:  69%|██████▉   | 2066/3000 [13:35<05:13,  2.98it/s, loss=0.121, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2067/3000 [13:36<05:20,  2.91it/s, loss=0.204, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2068/3000 [13:36<05:16,  2.95it/s, loss=0.156, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2069/3000 [13:36<05:14,  2.96it/s, loss=0.128, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2070/3000 [13:37<05:16,  2.94it/s, loss=0.101, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2071/3000 [13:37<05:12,  2.97it/s, loss=0.0588, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2072/3000 [13:37<05:13,  2.96it/s, loss=0.0785, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2073/3000 [13:38<05:09,  2.99it/s, loss=0.0318, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2074/3000 [13:38<05:09,  2.99it/s, loss=0.149, lr=0.002] \n",
      "Steps:  69%|██████▉   | 2075/3000 [13:38<05:05,  3.03it/s, loss=0.282, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2076/3000 [13:39<05:07,  3.01it/s, loss=0.0266, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2077/3000 [13:39<05:05,  3.02it/s, loss=0.12, lr=0.002]  \n",
      "Steps:  69%|██████▉   | 2078/3000 [13:39<05:08,  2.99it/s, loss=0.122, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2079/3000 [13:40<05:07,  2.99it/s, loss=0.129, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2080/3000 [13:40<05:07,  2.99it/s, loss=0.108, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2081/3000 [13:40<05:08,  2.98it/s, loss=0.126, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2082/3000 [13:41<05:11,  2.95it/s, loss=0.274, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2083/3000 [13:41<05:12,  2.94it/s, loss=0.0916, lr=0.002]\n",
      "Steps:  69%|██████▉   | 2084/3000 [13:41<05:09,  2.96it/s, loss=0.177, lr=0.002] \n",
      "Steps:  70%|██████▉   | 2085/3000 [13:42<05:09,  2.95it/s, loss=0.411, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2086/3000 [13:42<05:11,  2.93it/s, loss=0.116, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2087/3000 [13:42<05:08,  2.96it/s, loss=0.244, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2088/3000 [13:43<05:04,  2.99it/s, loss=0.163, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2089/3000 [13:43<05:05,  2.98it/s, loss=0.0536, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2090/3000 [13:43<05:02,  3.01it/s, loss=0.254, lr=0.002] \n",
      "Steps:  70%|██████▉   | 2091/3000 [13:44<04:59,  3.03it/s, loss=0.111, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2092/3000 [13:44<05:32,  2.73it/s, loss=0.179, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2093/3000 [13:44<05:24,  2.79it/s, loss=0.111, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2094/3000 [13:45<05:18,  2.85it/s, loss=0.121, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2095/3000 [13:45<05:14,  2.88it/s, loss=0.0963, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2096/3000 [13:45<05:10,  2.91it/s, loss=0.0612, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2097/3000 [13:46<05:07,  2.94it/s, loss=0.177, lr=0.002] \n",
      "Steps:  70%|██████▉   | 2098/3000 [13:46<05:06,  2.95it/s, loss=0.0938, lr=0.002]\n",
      "Steps:  70%|██████▉   | 2099/3000 [13:46<05:00,  2.99it/s, loss=0.104, lr=0.002] \n",
      "Steps:  70%|███████   | 2100/3000 [13:47<04:31,  3.31it/s, loss=0.228, lr=0.002]\n",
      "Steps:  70%|███████   | 2101/3000 [13:47<05:11,  2.88it/s, loss=0.156, lr=0.002]\n",
      "Steps:  70%|███████   | 2102/3000 [13:47<05:09,  2.90it/s, loss=0.162, lr=0.002]\n",
      "Steps:  70%|███████   | 2103/3000 [13:48<05:07,  2.92it/s, loss=0.0786, lr=0.002]\n",
      "Steps:  70%|███████   | 2104/3000 [13:48<05:07,  2.91it/s, loss=0.163, lr=0.002] \n",
      "Steps:  70%|███████   | 2105/3000 [13:48<05:03,  2.95it/s, loss=0.0787, lr=0.002]\n",
      "Steps:  70%|███████   | 2106/3000 [13:49<05:01,  2.96it/s, loss=0.0363, lr=0.002]\n",
      "Steps:  70%|███████   | 2107/3000 [13:49<04:59,  2.98it/s, loss=0.195, lr=0.002] \n",
      "Steps:  70%|███████   | 2108/3000 [13:49<04:59,  2.97it/s, loss=0.298, lr=0.002]\n",
      "Steps:  70%|███████   | 2109/3000 [13:50<05:01,  2.95it/s, loss=0.201, lr=0.002]\n",
      "Steps:  70%|███████   | 2110/3000 [13:50<05:05,  2.91it/s, loss=0.188, lr=0.002]\n",
      "Steps:  70%|███████   | 2111/3000 [13:50<05:01,  2.95it/s, loss=0.241, lr=0.002]\n",
      "Steps:  70%|███████   | 2112/3000 [13:51<04:58,  2.97it/s, loss=0.121, lr=0.002]\n",
      "Steps:  70%|███████   | 2113/3000 [13:51<04:58,  2.97it/s, loss=0.0771, lr=0.002]\n",
      "Steps:  70%|███████   | 2114/3000 [13:51<04:59,  2.96it/s, loss=0.164, lr=0.002] \n",
      "Steps:  70%|███████   | 2115/3000 [13:52<04:58,  2.97it/s, loss=0.108, lr=0.002]\n",
      "Steps:  71%|███████   | 2116/3000 [13:52<04:59,  2.95it/s, loss=0.114, lr=0.002]\n",
      "Steps:  71%|███████   | 2117/3000 [13:52<04:56,  2.98it/s, loss=0.197, lr=0.002]\n",
      "Steps:  71%|███████   | 2118/3000 [13:53<04:54,  3.00it/s, loss=0.144, lr=0.002]\n",
      "Steps:  71%|███████   | 2119/3000 [13:53<04:50,  3.03it/s, loss=0.105, lr=0.002]\n",
      "Steps:  71%|███████   | 2120/3000 [13:53<04:48,  3.05it/s, loss=0.193, lr=0.002]\n",
      "Steps:  71%|███████   | 2121/3000 [13:54<04:47,  3.06it/s, loss=0.0282, lr=0.002]\n",
      "Steps:  71%|███████   | 2122/3000 [13:54<04:48,  3.05it/s, loss=0.168, lr=0.002] \n",
      "Steps:  71%|███████   | 2123/3000 [13:54<04:50,  3.02it/s, loss=0.156, lr=0.002]\n",
      "Steps:  71%|███████   | 2124/3000 [13:55<04:49,  3.03it/s, loss=0.105, lr=0.002]\n",
      "Steps:  71%|███████   | 2125/3000 [13:55<04:49,  3.02it/s, loss=0.172, lr=0.002]\n",
      "Steps:  71%|███████   | 2126/3000 [13:55<04:48,  3.03it/s, loss=0.144, lr=0.002]\n",
      "Steps:  71%|███████   | 2127/3000 [13:56<04:47,  3.04it/s, loss=0.115, lr=0.002]\n",
      "Steps:  71%|███████   | 2128/3000 [13:56<04:47,  3.03it/s, loss=0.238, lr=0.002]\n",
      "Steps:  71%|███████   | 2129/3000 [13:56<04:48,  3.02it/s, loss=0.0536, lr=0.002]\n",
      "Steps:  71%|███████   | 2130/3000 [13:57<04:46,  3.04it/s, loss=0.116, lr=0.002] \n",
      "Steps:  71%|███████   | 2131/3000 [13:57<04:48,  3.01it/s, loss=0.138, lr=0.002]\n",
      "Steps:  71%|███████   | 2132/3000 [13:57<04:49,  3.00it/s, loss=0.192, lr=0.002]\n",
      "Steps:  71%|███████   | 2133/3000 [13:58<04:49,  3.00it/s, loss=0.192, lr=0.002]\n",
      "Steps:  71%|███████   | 2133/3000 [13:58<04:49,  3.00it/s, loss=0.212, lr=0.002]\n",
      "Steps:  71%|███████   | 2134/3000 [13:58<04:51,  2.97it/s, loss=0.19, lr=0.002] \n",
      "Steps:  71%|███████   | 2135/3000 [13:58<04:54,  2.94it/s, loss=0.138, lr=0.002]\n",
      "Steps:  71%|███████   | 2136/3000 [13:59<04:51,  2.97it/s, loss=0.0874, lr=0.002]\n",
      "Steps:  71%|███████   | 2137/3000 [13:59<04:51,  2.97it/s, loss=0.0206, lr=0.002]\n",
      "Steps:  71%|███████▏  | 2138/3000 [13:59<04:50,  2.97it/s, loss=0.295, lr=0.002] \n",
      "Steps:  71%|███████▏  | 2139/3000 [14:00<04:51,  2.95it/s, loss=0.157, lr=0.002]\n",
      "Steps:  71%|███████▏  | 2140/3000 [14:00<04:48,  2.98it/s, loss=0.172, lr=0.002]\n",
      "Steps:  71%|███████▏  | 2141/3000 [14:00<04:50,  2.96it/s, loss=0.148, lr=0.002]\n",
      "Steps:  71%|███████▏  | 2142/3000 [14:01<04:48,  2.97it/s, loss=0.087, lr=0.002]\n",
      "Steps:  71%|███████▏  | 2143/3000 [14:01<04:47,  2.98it/s, loss=0.107, lr=0.002]\n",
      "Steps:  71%|███████▏  | 2144/3000 [14:01<04:47,  2.98it/s, loss=0.0782, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2145/3000 [14:02<04:53,  2.92it/s, loss=0.0644, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2146/3000 [14:02<04:46,  2.98it/s, loss=0.125, lr=0.002] \n",
      "Steps:  72%|███████▏  | 2147/3000 [14:02<04:45,  2.99it/s, loss=0.0753, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2148/3000 [14:03<04:44,  2.99it/s, loss=0.204, lr=0.002] \n",
      "Steps:  72%|███████▏  | 2149/3000 [14:03<05:14,  2.70it/s, loss=0.128, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2150/3000 [14:04<05:04,  2.79it/s, loss=0.0364, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2151/3000 [14:04<05:00,  2.83it/s, loss=0.0996, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2152/3000 [14:04<04:56,  2.86it/s, loss=0.166, lr=0.002] \n",
      "Steps:  72%|███████▏  | 2153/3000 [14:05<04:51,  2.91it/s, loss=0.187, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2154/3000 [14:05<04:49,  2.93it/s, loss=0.161, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2155/3000 [14:05<04:48,  2.93it/s, loss=0.0823, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2156/3000 [14:06<04:45,  2.96it/s, loss=0.104, lr=0.002] \n",
      "Steps:  72%|███████▏  | 2157/3000 [14:06<04:43,  2.97it/s, loss=0.111, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2158/3000 [14:06<04:44,  2.96it/s, loss=0.152, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2159/3000 [14:07<04:44,  2.96it/s, loss=0.0573, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2160/3000 [14:07<04:44,  2.95it/s, loss=0.0909, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2161/3000 [14:07<04:44,  2.95it/s, loss=0.177, lr=0.002] \n",
      "Steps:  72%|███████▏  | 2162/3000 [14:08<04:47,  2.92it/s, loss=0.062, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2163/3000 [14:08<04:45,  2.93it/s, loss=0.118, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2164/3000 [14:08<04:43,  2.95it/s, loss=0.0939, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2165/3000 [14:09<04:42,  2.95it/s, loss=0.0717, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2166/3000 [14:09<04:41,  2.96it/s, loss=0.109, lr=0.002] \n",
      "Steps:  72%|███████▏  | 2167/3000 [14:09<04:39,  2.98it/s, loss=0.0808, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2168/3000 [14:10<04:38,  2.99it/s, loss=0.135, lr=0.002] \n",
      "Steps:  72%|███████▏  | 2169/3000 [14:10<04:39,  2.97it/s, loss=0.266, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2170/3000 [14:10<04:36,  3.00it/s, loss=0.0734, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2171/3000 [14:11<04:39,  2.97it/s, loss=0.15, lr=0.002]  \n",
      "Steps:  72%|███████▏  | 2172/3000 [14:11<04:38,  2.98it/s, loss=0.177, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2173/3000 [14:11<04:38,  2.97it/s, loss=0.194, lr=0.002]\n",
      "Steps:  72%|███████▏  | 2174/3000 [14:12<04:36,  2.99it/s, loss=0.114, lr=0.002]\n",
      "Steps:  72%|███████▎  | 2175/3000 [14:12<04:38,  2.96it/s, loss=0.123, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2176/3000 [14:12<04:38,  2.96it/s, loss=0.199, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2177/3000 [14:13<04:35,  2.99it/s, loss=0.184, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2178/3000 [14:13<04:34,  3.00it/s, loss=0.139, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2179/3000 [14:13<04:33,  3.00it/s, loss=0.114, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2180/3000 [14:14<04:33,  3.00it/s, loss=0.0582, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2181/3000 [14:14<04:34,  2.98it/s, loss=0.123, lr=0.002] \n",
      "Steps:  73%|███████▎  | 2182/3000 [14:14<04:33,  2.99it/s, loss=0.239, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2183/3000 [14:15<04:30,  3.02it/s, loss=0.327, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2184/3000 [14:15<04:30,  3.02it/s, loss=0.126, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2185/3000 [14:15<04:32,  2.99it/s, loss=0.028, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2186/3000 [14:16<04:33,  2.97it/s, loss=0.271, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2187/3000 [14:16<04:33,  2.97it/s, loss=0.0701, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2188/3000 [14:16<04:45,  2.85it/s, loss=0.111, lr=0.002] \n",
      "Steps:  73%|███████▎  | 2189/3000 [14:17<04:40,  2.89it/s, loss=0.127, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2190/3000 [14:17<04:38,  2.91it/s, loss=0.0926, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2191/3000 [14:17<04:34,  2.94it/s, loss=0.141, lr=0.002] \n",
      "Steps:  73%|███████▎  | 2192/3000 [14:18<04:32,  2.97it/s, loss=0.102, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2193/3000 [14:18<04:31,  2.97it/s, loss=0.0989, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2194/3000 [14:18<04:31,  2.96it/s, loss=0.0612, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2195/3000 [14:19<04:30,  2.98it/s, loss=0.123, lr=0.002] \n",
      "Steps:  73%|███████▎  | 2196/3000 [14:19<04:29,  2.98it/s, loss=0.138, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2197/3000 [14:19<04:29,  2.98it/s, loss=0.18, lr=0.002] \n",
      "Steps:  73%|███████▎  | 2198/3000 [14:20<04:28,  2.98it/s, loss=0.288, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2199/3000 [14:20<04:28,  2.99it/s, loss=0.0249, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2200/3000 [14:20<04:29,  2.97it/s, loss=0.133, lr=0.002] \n",
      "Steps:  73%|███████▎  | 2201/3000 [14:21<04:26,  3.00it/s, loss=0.31, lr=0.002] \n",
      "Steps:  73%|███████▎  | 2202/3000 [14:21<04:25,  3.00it/s, loss=0.133, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2203/3000 [14:21<04:23,  3.02it/s, loss=0.0831, lr=0.002]\n",
      "Steps:  73%|███████▎  | 2204/3000 [14:22<04:22,  3.03it/s, loss=0.0619, lr=0.002]\n",
      "Steps:  74%|███████▎  | 2205/3000 [14:22<04:23,  3.01it/s, loss=0.105, lr=0.002] \n",
      "Steps:  74%|███████▎  | 2206/3000 [14:23<04:55,  2.69it/s, loss=0.194, lr=0.002]\n",
      "Steps:  74%|███████▎  | 2207/3000 [14:23<04:46,  2.77it/s, loss=0.238, lr=0.002]\n",
      "Steps:  74%|███████▎  | 2208/3000 [14:23<04:38,  2.84it/s, loss=0.12, lr=0.002] \n",
      "Steps:  74%|███████▎  | 2209/3000 [14:24<04:31,  2.92it/s, loss=0.199, lr=0.002]\n",
      "Steps:  74%|███████▎  | 2210/3000 [14:24<04:27,  2.95it/s, loss=0.022, lr=0.002]\n",
      "Steps:  74%|███████▎  | 2211/3000 [14:24<04:23,  3.00it/s, loss=0.103, lr=0.002]\n",
      "Steps:  74%|███████▎  | 2212/3000 [14:25<04:22,  3.00it/s, loss=0.187, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2213/3000 [14:25<04:23,  2.99it/s, loss=0.211, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2214/3000 [14:25<04:22,  2.99it/s, loss=0.169, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2215/3000 [14:26<04:22,  2.99it/s, loss=0.111, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2216/3000 [14:26<04:21,  3.00it/s, loss=0.0582, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2217/3000 [14:26<04:21,  2.99it/s, loss=0.0946, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2218/3000 [14:27<04:21,  2.99it/s, loss=0.143, lr=0.002] \n",
      "Steps:  74%|███████▍  | 2219/3000 [14:27<04:19,  3.01it/s, loss=0.147, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2220/3000 [14:27<04:19,  3.01it/s, loss=0.078, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2221/3000 [14:28<04:18,  3.02it/s, loss=0.204, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2222/3000 [14:28<04:17,  3.02it/s, loss=0.198, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2223/3000 [14:28<04:14,  3.06it/s, loss=0.171, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2224/3000 [14:28<04:15,  3.04it/s, loss=0.154, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2225/3000 [14:29<04:14,  3.04it/s, loss=0.189, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2226/3000 [14:29<04:14,  3.04it/s, loss=0.12, lr=0.002] \n",
      "Steps:  74%|███████▍  | 2227/3000 [14:29<04:13,  3.05it/s, loss=0.242, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2228/3000 [14:30<04:13,  3.04it/s, loss=0.111, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2229/3000 [14:30<04:13,  3.04it/s, loss=0.219, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2230/3000 [14:30<04:14,  3.02it/s, loss=0.14, lr=0.002] \n",
      "Steps:  74%|███████▍  | 2231/3000 [14:31<04:14,  3.02it/s, loss=0.117, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2232/3000 [14:31<04:11,  3.06it/s, loss=0.202, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2233/3000 [14:31<04:12,  3.04it/s, loss=0.112, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2234/3000 [14:32<04:13,  3.02it/s, loss=0.136, lr=0.002]\n",
      "Steps:  74%|███████▍  | 2235/3000 [14:32<04:15,  2.99it/s, loss=0.289, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2236/3000 [14:32<04:15,  2.99it/s, loss=0.241, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2237/3000 [14:33<04:16,  2.97it/s, loss=0.137, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2238/3000 [14:33<04:15,  2.98it/s, loss=0.122, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2239/3000 [14:33<04:14,  2.99it/s, loss=0.0256, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2240/3000 [14:34<04:15,  2.98it/s, loss=0.0991, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2241/3000 [14:34<04:13,  3.00it/s, loss=0.0601, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2242/3000 [14:34<04:10,  3.03it/s, loss=0.0645, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2243/3000 [14:35<04:12,  3.00it/s, loss=0.19, lr=0.002]  \n",
      "Steps:  75%|███████▍  | 2244/3000 [14:35<04:15,  2.96it/s, loss=0.0441, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2245/3000 [14:36<04:19,  2.91it/s, loss=0.19, lr=0.002]  \n",
      "Steps:  75%|███████▍  | 2246/3000 [14:36<04:20,  2.89it/s, loss=0.131, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2247/3000 [14:36<04:17,  2.93it/s, loss=0.247, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2248/3000 [14:37<04:21,  2.88it/s, loss=0.108, lr=0.002]\n",
      "Steps:  75%|███████▍  | 2249/3000 [14:37<04:24,  2.83it/s, loss=0.238, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2250/3000 [14:37<04:00,  3.12it/s, loss=0.09, lr=0.002] \n",
      "Steps:  75%|███████▌  | 2251/3000 [14:38<04:32,  2.75it/s, loss=0.111, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2252/3000 [14:38<04:28,  2.79it/s, loss=0.209, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2253/3000 [14:38<04:23,  2.84it/s, loss=0.137, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2254/3000 [14:39<04:24,  2.82it/s, loss=0.118, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2255/3000 [14:39<04:24,  2.82it/s, loss=0.151, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2256/3000 [14:39<04:22,  2.83it/s, loss=0.0713, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2257/3000 [14:40<04:27,  2.78it/s, loss=0.183, lr=0.002] \n",
      "Steps:  75%|███████▌  | 2258/3000 [14:40<04:26,  2.79it/s, loss=0.0683, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2259/3000 [14:40<04:25,  2.79it/s, loss=0.249, lr=0.002] \n",
      "Steps:  75%|███████▌  | 2260/3000 [14:41<04:23,  2.81it/s, loss=0.205, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2261/3000 [14:41<04:22,  2.82it/s, loss=0.2, lr=0.002]  \n",
      "Steps:  75%|███████▌  | 2262/3000 [14:42<04:22,  2.82it/s, loss=0.0504, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2263/3000 [14:42<04:57,  2.47it/s, loss=0.0361, lr=0.002]\n",
      "Steps:  75%|███████▌  | 2264/3000 [14:42<04:44,  2.59it/s, loss=0.148, lr=0.002] \n",
      "Steps:  76%|███████▌  | 2265/3000 [14:43<04:36,  2.66it/s, loss=0.0844, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2266/3000 [14:43<04:32,  2.69it/s, loss=0.255, lr=0.002] \n",
      "Steps:  76%|███████▌  | 2267/3000 [14:43<04:25,  2.76it/s, loss=0.199, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2268/3000 [14:44<04:23,  2.78it/s, loss=0.0643, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2269/3000 [14:44<04:22,  2.79it/s, loss=0.154, lr=0.002] \n",
      "Steps:  76%|███████▌  | 2270/3000 [14:44<04:16,  2.85it/s, loss=0.307, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2271/3000 [14:45<04:17,  2.83it/s, loss=0.12, lr=0.002] \n",
      "Steps:  76%|███████▌  | 2272/3000 [14:45<04:19,  2.81it/s, loss=0.093, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2273/3000 [14:46<04:21,  2.78it/s, loss=0.146, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2274/3000 [14:46<04:20,  2.79it/s, loss=0.155, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2275/3000 [14:46<04:16,  2.83it/s, loss=0.196, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2276/3000 [14:47<04:15,  2.84it/s, loss=0.102, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2277/3000 [14:47<04:15,  2.82it/s, loss=0.0646, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2278/3000 [14:47<04:15,  2.83it/s, loss=0.171, lr=0.002] \n",
      "Steps:  76%|███████▌  | 2279/3000 [14:48<04:12,  2.86it/s, loss=0.179, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2280/3000 [14:48<04:12,  2.85it/s, loss=0.124, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2281/3000 [14:48<04:13,  2.84it/s, loss=0.218, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2282/3000 [14:49<04:13,  2.83it/s, loss=0.156, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2283/3000 [14:49<04:14,  2.81it/s, loss=0.032, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2284/3000 [14:49<04:15,  2.80it/s, loss=0.212, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2285/3000 [14:50<04:15,  2.80it/s, loss=0.155, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2286/3000 [14:50<04:13,  2.81it/s, loss=0.168, lr=0.002]\n",
      "Steps:  76%|███████▌  | 2287/3000 [14:51<04:14,  2.81it/s, loss=0.0523, lr=0.002]\n",
      "Steps:  76%|███████▋  | 2288/3000 [14:51<04:15,  2.79it/s, loss=0.209, lr=0.002] \n",
      "Steps:  76%|███████▋  | 2289/3000 [14:51<04:18,  2.75it/s, loss=0.0893, lr=0.002]\n",
      "Steps:  76%|███████▋  | 2290/3000 [14:52<04:14,  2.79it/s, loss=0.233, lr=0.002] \n",
      "Steps:  76%|███████▋  | 2291/3000 [14:52<04:12,  2.81it/s, loss=0.304, lr=0.002]\n",
      "Steps:  76%|███████▋  | 2292/3000 [14:52<04:09,  2.84it/s, loss=0.136, lr=0.002]\n",
      "Steps:  76%|███████▋  | 2293/3000 [14:53<04:09,  2.84it/s, loss=0.0828, lr=0.002]\n",
      "Steps:  76%|███████▋  | 2294/3000 [14:53<04:06,  2.87it/s, loss=0.12, lr=0.002]  \n",
      "Steps:  76%|███████▋  | 2295/3000 [14:53<04:05,  2.87it/s, loss=0.141, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2296/3000 [14:54<04:07,  2.84it/s, loss=0.0742, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2297/3000 [14:54<04:07,  2.84it/s, loss=0.278, lr=0.002] \n",
      "Steps:  77%|███████▋  | 2298/3000 [14:54<04:08,  2.83it/s, loss=0.117, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2299/3000 [14:55<04:07,  2.83it/s, loss=0.0947, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2300/3000 [14:55<04:07,  2.83it/s, loss=0.152, lr=0.002] \n",
      "Steps:  77%|███████▋  | 2301/3000 [14:55<04:04,  2.86it/s, loss=0.0919, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2302/3000 [14:56<04:06,  2.83it/s, loss=0.107, lr=0.002] \n",
      "Steps:  77%|███████▋  | 2303/3000 [14:56<04:06,  2.82it/s, loss=0.234, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2304/3000 [14:57<04:04,  2.85it/s, loss=0.0827, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2305/3000 [14:57<04:03,  2.85it/s, loss=0.1, lr=0.002]   \n",
      "Steps:  77%|███████▋  | 2306/3000 [14:57<04:05,  2.83it/s, loss=0.0876, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2307/3000 [14:58<04:05,  2.82it/s, loss=0.0385, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2308/3000 [14:58<04:04,  2.83it/s, loss=0.197, lr=0.002] \n",
      "Steps:  77%|███████▋  | 2309/3000 [14:58<04:06,  2.80it/s, loss=0.0686, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2310/3000 [14:59<04:06,  2.80it/s, loss=0.19, lr=0.002]  \n",
      "Steps:  77%|███████▋  | 2311/3000 [14:59<04:06,  2.79it/s, loss=0.205, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2312/3000 [14:59<04:04,  2.81it/s, loss=0.117, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2313/3000 [15:00<04:02,  2.83it/s, loss=0.263, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2314/3000 [15:00<04:02,  2.83it/s, loss=0.129, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2315/3000 [15:00<04:03,  2.81it/s, loss=0.196, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2316/3000 [15:01<04:01,  2.84it/s, loss=0.12, lr=0.002] \n",
      "Steps:  77%|███████▋  | 2317/3000 [15:01<03:59,  2.85it/s, loss=0.139, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2318/3000 [15:01<03:59,  2.85it/s, loss=0.125, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2319/3000 [15:02<04:00,  2.84it/s, loss=0.157, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2320/3000 [15:02<04:36,  2.46it/s, loss=0.101, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2321/3000 [15:03<04:23,  2.57it/s, loss=0.0686, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2322/3000 [15:03<04:16,  2.65it/s, loss=0.105, lr=0.002] \n",
      "Steps:  77%|███████▋  | 2323/3000 [15:03<04:11,  2.69it/s, loss=0.143, lr=0.002]\n",
      "Steps:  77%|███████▋  | 2324/3000 [15:04<04:03,  2.78it/s, loss=0.123, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2325/3000 [15:04<04:00,  2.81it/s, loss=0.105, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2326/3000 [15:04<03:58,  2.82it/s, loss=0.238, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2327/3000 [15:05<03:55,  2.85it/s, loss=0.0771, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2328/3000 [15:05<03:54,  2.86it/s, loss=0.156, lr=0.002] \n",
      "Steps:  78%|███████▊  | 2329/3000 [15:05<03:54,  2.86it/s, loss=0.118, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2330/3000 [15:06<03:55,  2.85it/s, loss=0.281, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2331/3000 [15:06<03:56,  2.83it/s, loss=0.0798, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2332/3000 [15:07<03:57,  2.82it/s, loss=0.258, lr=0.002] \n",
      "Steps:  78%|███████▊  | 2333/3000 [15:07<03:58,  2.80it/s, loss=0.139, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2334/3000 [15:07<03:54,  2.84it/s, loss=0.107, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2335/3000 [15:08<03:54,  2.83it/s, loss=0.143, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2336/3000 [15:08<03:53,  2.84it/s, loss=0.115, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2337/3000 [15:08<03:52,  2.85it/s, loss=0.109, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2338/3000 [15:09<03:51,  2.86it/s, loss=0.106, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2339/3000 [15:09<03:55,  2.81it/s, loss=0.104, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2340/3000 [15:09<03:49,  2.88it/s, loss=0.105, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2341/3000 [15:10<03:48,  2.88it/s, loss=0.0263, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2342/3000 [15:10<03:49,  2.86it/s, loss=0.16, lr=0.002]  \n",
      "Steps:  78%|███████▊  | 2343/3000 [15:10<03:49,  2.87it/s, loss=0.144, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2344/3000 [15:11<03:48,  2.87it/s, loss=0.134, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2345/3000 [15:11<03:46,  2.89it/s, loss=0.165, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2346/3000 [15:11<03:48,  2.86it/s, loss=0.0788, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2347/3000 [15:12<03:48,  2.86it/s, loss=0.117, lr=0.002] \n",
      "Steps:  78%|███████▊  | 2348/3000 [15:12<03:47,  2.86it/s, loss=0.304, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2349/3000 [15:13<03:46,  2.87it/s, loss=0.0849, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2350/3000 [15:13<03:46,  2.86it/s, loss=0.151, lr=0.002] \n",
      "Steps:  78%|███████▊  | 2351/3000 [15:13<03:48,  2.84it/s, loss=0.371, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2352/3000 [15:14<03:48,  2.84it/s, loss=0.106, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2353/3000 [15:14<03:47,  2.84it/s, loss=0.111, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2354/3000 [15:14<03:45,  2.86it/s, loss=0.108, lr=0.002]\n",
      "Steps:  78%|███████▊  | 2355/3000 [15:15<03:44,  2.88it/s, loss=0.219, lr=0.002]\n",
      "Steps:  79%|███████▊  | 2356/3000 [15:15<03:44,  2.86it/s, loss=0.122, lr=0.002]\n",
      "Steps:  79%|███████▊  | 2357/3000 [15:15<03:42,  2.89it/s, loss=0.0203, lr=0.002]\n",
      "Steps:  79%|███████▊  | 2358/3000 [15:16<03:42,  2.89it/s, loss=0.0851, lr=0.002]\n",
      "Steps:  79%|███████▊  | 2359/3000 [15:16<03:41,  2.89it/s, loss=0.133, lr=0.002] \n",
      "Steps:  79%|███████▊  | 2360/3000 [15:16<03:41,  2.90it/s, loss=0.191, lr=0.002]\n",
      "Steps:  79%|███████▊  | 2361/3000 [15:17<03:43,  2.85it/s, loss=0.101, lr=0.002]\n",
      "Steps:  79%|███████▊  | 2362/3000 [15:17<03:42,  2.86it/s, loss=0.176, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2363/3000 [15:17<03:43,  2.85it/s, loss=0.103, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2364/3000 [15:18<03:52,  2.73it/s, loss=0.116, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2365/3000 [15:18<03:48,  2.78it/s, loss=0.165, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2366/3000 [15:19<03:48,  2.78it/s, loss=0.0973, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2367/3000 [15:19<03:45,  2.81it/s, loss=0.127, lr=0.002] \n",
      "Steps:  79%|███████▉  | 2368/3000 [15:19<03:41,  2.86it/s, loss=0.117, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2369/3000 [15:20<03:38,  2.89it/s, loss=0.218, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2370/3000 [15:20<03:39,  2.87it/s, loss=0.274, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2371/3000 [15:20<03:39,  2.87it/s, loss=0.0609, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2372/3000 [15:21<03:40,  2.85it/s, loss=0.136, lr=0.002] \n",
      "Steps:  79%|███████▉  | 2373/3000 [15:21<03:41,  2.83it/s, loss=0.123, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2374/3000 [15:21<03:43,  2.80it/s, loss=0.117, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2375/3000 [15:22<03:44,  2.79it/s, loss=0.131, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2376/3000 [15:22<03:45,  2.77it/s, loss=0.181, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2377/3000 [15:23<04:11,  2.48it/s, loss=0.105, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2378/3000 [15:23<04:03,  2.55it/s, loss=0.171, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2379/3000 [15:23<03:57,  2.62it/s, loss=0.192, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2380/3000 [15:24<03:54,  2.65it/s, loss=0.126, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2381/3000 [15:24<03:51,  2.68it/s, loss=0.102, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2382/3000 [15:24<03:48,  2.70it/s, loss=0.244, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2383/3000 [15:25<03:45,  2.74it/s, loss=0.108, lr=0.002]\n",
      "Steps:  79%|███████▉  | 2384/3000 [15:25<03:44,  2.75it/s, loss=0.0739, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2385/3000 [15:25<03:42,  2.76it/s, loss=0.142, lr=0.002] \n",
      "Steps:  80%|███████▉  | 2386/3000 [15:26<03:40,  2.78it/s, loss=0.156, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2387/3000 [15:26<03:38,  2.80it/s, loss=0.13, lr=0.002] \n",
      "Steps:  80%|███████▉  | 2388/3000 [15:27<03:41,  2.76it/s, loss=0.0932, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2389/3000 [15:27<03:42,  2.75it/s, loss=0.163, lr=0.002] \n",
      "Steps:  80%|███████▉  | 2390/3000 [15:27<03:38,  2.79it/s, loss=0.0323, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2391/3000 [15:28<03:37,  2.80it/s, loss=0.109, lr=0.002] \n",
      "Steps:  80%|███████▉  | 2392/3000 [15:28<03:37,  2.79it/s, loss=0.207, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2393/3000 [15:28<03:37,  2.80it/s, loss=0.217, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2394/3000 [15:29<03:37,  2.79it/s, loss=0.186, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2395/3000 [15:29<03:38,  2.77it/s, loss=0.143, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2396/3000 [15:29<03:37,  2.78it/s, loss=0.126, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2397/3000 [15:30<03:34,  2.81it/s, loss=0.143, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2398/3000 [15:30<03:32,  2.84it/s, loss=0.106, lr=0.002]\n",
      "Steps:  80%|███████▉  | 2399/3000 [15:30<03:33,  2.81it/s, loss=0.0906, lr=0.002]\n",
      "Steps:  80%|████████  | 2400/3000 [15:31<03:12,  3.11it/s, loss=0.177, lr=0.002] \n",
      "Steps:  80%|████████  | 2401/3000 [15:31<03:37,  2.75it/s, loss=0.112, lr=0.002]\n",
      "Steps:  80%|████████  | 2402/3000 [15:31<03:34,  2.79it/s, loss=0.143, lr=0.002]\n",
      "Steps:  80%|████████  | 2403/3000 [15:32<03:32,  2.81it/s, loss=0.0968, lr=0.002]\n",
      "Steps:  80%|████████  | 2404/3000 [15:32<03:31,  2.82it/s, loss=0.111, lr=0.002] \n",
      "Steps:  80%|████████  | 2405/3000 [15:33<03:32,  2.80it/s, loss=0.103, lr=0.002]\n",
      "Steps:  80%|████████  | 2406/3000 [15:33<03:33,  2.78it/s, loss=0.0575, lr=0.002]\n",
      "Steps:  80%|████████  | 2407/3000 [15:33<03:34,  2.77it/s, loss=0.127, lr=0.002] \n",
      "Steps:  80%|████████  | 2408/3000 [15:34<03:32,  2.79it/s, loss=0.138, lr=0.002]\n",
      "Steps:  80%|████████  | 2409/3000 [15:34<03:30,  2.81it/s, loss=0.136, lr=0.002]\n",
      "Steps:  80%|████████  | 2410/3000 [15:34<03:31,  2.79it/s, loss=0.0254, lr=0.002]\n",
      "Steps:  80%|████████  | 2411/3000 [15:35<03:30,  2.80it/s, loss=0.116, lr=0.002] \n",
      "Steps:  80%|████████  | 2412/3000 [15:35<03:30,  2.79it/s, loss=0.133, lr=0.002]\n",
      "Steps:  80%|████████  | 2413/3000 [15:35<03:28,  2.81it/s, loss=0.171, lr=0.002]\n",
      "Steps:  80%|████████  | 2414/3000 [15:36<03:27,  2.83it/s, loss=0.161, lr=0.002]\n",
      "Steps:  80%|████████  | 2415/3000 [15:36<03:27,  2.82it/s, loss=0.0695, lr=0.002]\n",
      "Steps:  81%|████████  | 2416/3000 [15:36<03:27,  2.82it/s, loss=0.127, lr=0.002] \n",
      "Steps:  81%|████████  | 2417/3000 [15:37<03:26,  2.82it/s, loss=0.182, lr=0.002]\n",
      "Steps:  81%|████████  | 2418/3000 [15:37<03:25,  2.83it/s, loss=0.182, lr=0.002]\n",
      "Steps:  81%|████████  | 2418/3000 [15:37<03:25,  2.83it/s, loss=0.133, lr=0.002]\n",
      "Steps:  81%|████████  | 2419/3000 [15:38<03:26,  2.81it/s, loss=0.0337, lr=0.002]\n",
      "Steps:  81%|████████  | 2420/3000 [15:38<03:28,  2.79it/s, loss=0.0682, lr=0.002]\n",
      "Steps:  81%|████████  | 2421/3000 [15:38<03:27,  2.80it/s, loss=0.153, lr=0.002] \n",
      "Steps:  81%|████████  | 2422/3000 [15:39<03:26,  2.79it/s, loss=0.191, lr=0.002]\n",
      "Steps:  81%|████████  | 2423/3000 [15:39<03:25,  2.80it/s, loss=0.138, lr=0.002]\n",
      "Steps:  81%|████████  | 2424/3000 [15:39<03:23,  2.83it/s, loss=0.0309, lr=0.002]\n",
      "Steps:  81%|████████  | 2425/3000 [15:40<03:22,  2.85it/s, loss=0.125, lr=0.002] \n",
      "Steps:  81%|████████  | 2426/3000 [15:40<03:23,  2.82it/s, loss=0.167, lr=0.002]\n",
      "Steps:  81%|████████  | 2427/3000 [15:40<03:24,  2.80it/s, loss=0.108, lr=0.002]\n",
      "Steps:  81%|████████  | 2428/3000 [15:41<03:22,  2.82it/s, loss=0.155, lr=0.002]\n",
      "Steps:  81%|████████  | 2429/3000 [15:41<03:26,  2.77it/s, loss=0.119, lr=0.002]\n",
      "Steps:  81%|████████  | 2430/3000 [15:41<03:24,  2.79it/s, loss=0.0861, lr=0.002]\n",
      "Steps:  81%|████████  | 2431/3000 [15:42<03:24,  2.78it/s, loss=0.0893, lr=0.002]\n",
      "Steps:  81%|████████  | 2432/3000 [15:42<03:22,  2.80it/s, loss=0.099, lr=0.002] \n",
      "Steps:  81%|████████  | 2433/3000 [15:43<03:22,  2.80it/s, loss=0.193, lr=0.002]\n",
      "Steps:  81%|████████  | 2434/3000 [15:43<03:49,  2.47it/s, loss=0.158, lr=0.002]\n",
      "Steps:  81%|████████  | 2435/3000 [15:43<03:40,  2.56it/s, loss=0.0721, lr=0.002]\n",
      "Steps:  81%|████████  | 2436/3000 [15:44<03:32,  2.65it/s, loss=0.186, lr=0.002] \n",
      "Steps:  81%|████████  | 2437/3000 [15:44<03:29,  2.69it/s, loss=0.115, lr=0.002]\n",
      "Steps:  81%|████████▏ | 2438/3000 [15:44<03:26,  2.72it/s, loss=0.0958, lr=0.002]\n",
      "Steps:  81%|████████▏ | 2439/3000 [15:45<03:22,  2.77it/s, loss=0.0931, lr=0.002]\n",
      "Steps:  81%|████████▏ | 2440/3000 [15:45<03:21,  2.78it/s, loss=0.126, lr=0.002] \n",
      "Steps:  81%|████████▏ | 2441/3000 [15:46<03:18,  2.81it/s, loss=0.152, lr=0.002]\n",
      "Steps:  81%|████████▏ | 2442/3000 [15:46<03:18,  2.81it/s, loss=0.0216, lr=0.002]\n",
      "Steps:  81%|████████▏ | 2443/3000 [15:46<03:17,  2.81it/s, loss=0.0792, lr=0.002]\n",
      "Steps:  81%|████████▏ | 2444/3000 [15:47<03:16,  2.83it/s, loss=0.141, lr=0.002] \n",
      "Steps:  82%|████████▏ | 2445/3000 [15:47<03:13,  2.87it/s, loss=0.104, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2446/3000 [15:47<03:13,  2.86it/s, loss=0.054, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2447/3000 [15:48<03:11,  2.88it/s, loss=0.0909, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2448/3000 [15:48<03:12,  2.86it/s, loss=0.191, lr=0.002] \n",
      "Steps:  82%|████████▏ | 2449/3000 [15:48<03:12,  2.86it/s, loss=0.115, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2450/3000 [15:49<03:12,  2.85it/s, loss=0.106, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2451/3000 [15:49<03:13,  2.84it/s, loss=0.149, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2452/3000 [15:49<03:13,  2.83it/s, loss=0.156, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2453/3000 [15:50<03:15,  2.80it/s, loss=0.0889, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2454/3000 [15:50<03:13,  2.82it/s, loss=0.123, lr=0.002] \n",
      "Steps:  82%|████████▏ | 2455/3000 [15:50<03:11,  2.84it/s, loss=0.1, lr=0.002]  \n",
      "Steps:  82%|████████▏ | 2456/3000 [15:51<03:11,  2.85it/s, loss=0.145, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2457/3000 [15:51<03:09,  2.87it/s, loss=0.0819, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2458/3000 [15:51<03:08,  2.87it/s, loss=0.0735, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2459/3000 [15:52<03:08,  2.87it/s, loss=0.092, lr=0.002] \n",
      "Steps:  82%|████████▏ | 2460/3000 [15:52<03:07,  2.88it/s, loss=0.106, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2461/3000 [15:53<03:07,  2.87it/s, loss=0.0237, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2462/3000 [15:53<03:09,  2.85it/s, loss=0.168, lr=0.002] \n",
      "Steps:  82%|████████▏ | 2463/3000 [15:53<03:09,  2.83it/s, loss=0.135, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2464/3000 [15:54<03:07,  2.86it/s, loss=0.165, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2465/3000 [15:54<03:05,  2.88it/s, loss=0.11, lr=0.002] \n",
      "Steps:  82%|████████▏ | 2466/3000 [15:54<03:05,  2.87it/s, loss=0.166, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2467/3000 [15:55<03:05,  2.87it/s, loss=0.136, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2468/3000 [15:55<03:06,  2.86it/s, loss=0.225, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2469/3000 [15:55<03:06,  2.85it/s, loss=0.067, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2470/3000 [15:56<03:05,  2.85it/s, loss=0.103, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2471/3000 [15:56<03:05,  2.85it/s, loss=0.071, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2472/3000 [15:56<03:04,  2.87it/s, loss=0.112, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2473/3000 [15:57<03:05,  2.84it/s, loss=0.201, lr=0.002]\n",
      "Steps:  82%|████████▏ | 2474/3000 [15:57<03:04,  2.86it/s, loss=0.0676, lr=0.002]\n",
      "Steps:  82%|████████▎ | 2475/3000 [15:57<03:03,  2.86it/s, loss=0.109, lr=0.002] \n",
      "Steps:  83%|████████▎ | 2476/3000 [15:58<03:02,  2.88it/s, loss=0.162, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2477/3000 [15:58<03:03,  2.86it/s, loss=0.0641, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2478/3000 [15:58<03:03,  2.85it/s, loss=0.0302, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2479/3000 [15:59<03:02,  2.85it/s, loss=0.0999, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2480/3000 [15:59<03:01,  2.86it/s, loss=0.176, lr=0.002] \n",
      "Steps:  83%|████████▎ | 2481/3000 [16:00<03:00,  2.88it/s, loss=0.178, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2482/3000 [16:00<03:01,  2.85it/s, loss=0.0784, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2483/3000 [16:00<03:01,  2.85it/s, loss=0.0256, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2484/3000 [16:01<03:00,  2.87it/s, loss=0.155, lr=0.002] \n",
      "Steps:  83%|████████▎ | 2485/3000 [16:01<02:59,  2.86it/s, loss=0.222, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2486/3000 [16:01<02:58,  2.88it/s, loss=0.167, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2487/3000 [16:02<02:59,  2.86it/s, loss=0.0479, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2488/3000 [16:02<02:59,  2.86it/s, loss=0.0246, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2489/3000 [16:02<02:59,  2.85it/s, loss=0.0675, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2490/3000 [16:03<02:56,  2.90it/s, loss=0.15, lr=0.002]  \n",
      "Steps:  83%|████████▎ | 2491/3000 [16:03<03:17,  2.58it/s, loss=0.12, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2492/3000 [16:03<03:09,  2.68it/s, loss=0.103, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2493/3000 [16:04<03:05,  2.73it/s, loss=0.111, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2494/3000 [16:04<03:03,  2.76it/s, loss=0.232, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2495/3000 [16:05<03:02,  2.76it/s, loss=0.0807, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2496/3000 [16:05<02:59,  2.81it/s, loss=0.0835, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2497/3000 [16:05<02:57,  2.83it/s, loss=0.124, lr=0.002] \n",
      "Steps:  83%|████████▎ | 2498/3000 [16:06<02:56,  2.84it/s, loss=0.122, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2499/3000 [16:06<02:56,  2.85it/s, loss=0.115, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2500/3000 [16:06<02:55,  2.85it/s, loss=0.115, lr=0.002]05/09/2024 05:37:27 - INFO - __main__ - Saving embeddings\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:37:27 - INFO - accelerate.accelerator - Saving current state to /tmp/textual_inversion_cat/checkpoint-2500\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:37:28 - INFO - accelerate.checkpointing - Model weights saved in /tmp/textual_inversion_cat/checkpoint-2500/model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:37:29 - INFO - accelerate.checkpointing - Optimizer state saved in /tmp/textual_inversion_cat/checkpoint-2500/optimizer.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:37:29 - INFO - accelerate.checkpointing - Scheduler state saved in /tmp/textual_inversion_cat/checkpoint-2500/scheduler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:37:29 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /tmp/textual_inversion_cat/checkpoint-2500/sampler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:37:29 - INFO - accelerate.checkpointing - Random states saved in /tmp/textual_inversion_cat/checkpoint-2500/random_states_0.pkl\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:37:29 - INFO - __main__ - Saved state to /tmp/textual_inversion_cat/checkpoint-2500\n",
      "Steps:  83%|████████▎ | 2500/3000 [16:08<02:55,  2.85it/s, loss=0.232, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2501/3000 [16:08<07:07,  1.17it/s, loss=0.155, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2502/3000 [16:09<05:48,  1.43it/s, loss=0.11, lr=0.002] \n",
      "Steps:  83%|████████▎ | 2503/3000 [16:09<04:54,  1.69it/s, loss=0.16, lr=0.002]\n",
      "Steps:  83%|████████▎ | 2504/3000 [16:09<04:18,  1.92it/s, loss=0.11, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2505/3000 [16:10<03:52,  2.13it/s, loss=0.183, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2506/3000 [16:10<03:34,  2.30it/s, loss=0.208, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2507/3000 [16:10<03:21,  2.45it/s, loss=0.171, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2508/3000 [16:11<03:10,  2.59it/s, loss=0.151, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2509/3000 [16:11<03:04,  2.67it/s, loss=0.146, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2510/3000 [16:11<02:58,  2.74it/s, loss=0.134, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2511/3000 [16:12<02:57,  2.76it/s, loss=0.203, lr=0.002]\n",
      "Steps:  84%|████████▎ | 2512/3000 [16:12<02:55,  2.79it/s, loss=0.151, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2513/3000 [16:12<02:53,  2.80it/s, loss=0.159, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2514/3000 [16:13<02:53,  2.80it/s, loss=0.12, lr=0.002] \n",
      "Steps:  84%|████████▍ | 2515/3000 [16:13<02:52,  2.82it/s, loss=0.111, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2516/3000 [16:14<02:49,  2.85it/s, loss=0.0281, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2517/3000 [16:14<02:48,  2.87it/s, loss=0.176, lr=0.002] \n",
      "Steps:  84%|████████▍ | 2518/3000 [16:14<02:45,  2.91it/s, loss=0.12, lr=0.002] \n",
      "Steps:  84%|████████▍ | 2519/3000 [16:15<02:45,  2.90it/s, loss=0.26, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2520/3000 [16:15<02:45,  2.90it/s, loss=0.125, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2521/3000 [16:15<02:43,  2.93it/s, loss=0.125, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2521/3000 [16:15<02:43,  2.93it/s, loss=0.0553, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2522/3000 [16:16<02:44,  2.90it/s, loss=0.131, lr=0.002] \n",
      "Steps:  84%|████████▍ | 2523/3000 [16:16<02:42,  2.93it/s, loss=0.196, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2524/3000 [16:16<02:43,  2.92it/s, loss=0.174, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2525/3000 [16:17<02:43,  2.90it/s, loss=0.148, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2526/3000 [16:17<02:43,  2.90it/s, loss=0.117, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2527/3000 [16:17<02:43,  2.90it/s, loss=0.111, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2528/3000 [16:18<02:42,  2.91it/s, loss=0.104, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2529/3000 [16:18<02:40,  2.93it/s, loss=0.138, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2530/3000 [16:18<02:41,  2.91it/s, loss=0.0848, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2531/3000 [16:19<02:40,  2.92it/s, loss=0.0706, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2532/3000 [16:19<02:41,  2.90it/s, loss=0.182, lr=0.002] \n",
      "Steps:  84%|████████▍ | 2533/3000 [16:19<02:41,  2.88it/s, loss=0.243, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2534/3000 [16:20<02:41,  2.88it/s, loss=0.0751, lr=0.002]\n",
      "Steps:  84%|████████▍ | 2535/3000 [16:20<02:39,  2.91it/s, loss=0.0599, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2536/3000 [16:20<02:37,  2.94it/s, loss=0.117, lr=0.002] \n",
      "Steps:  85%|████████▍ | 2537/3000 [16:21<02:38,  2.92it/s, loss=0.0607, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2538/3000 [16:21<02:40,  2.88it/s, loss=0.163, lr=0.002] \n",
      "Steps:  85%|████████▍ | 2539/3000 [16:21<02:39,  2.89it/s, loss=0.137, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2540/3000 [16:22<02:37,  2.92it/s, loss=0.125, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2541/3000 [16:22<02:38,  2.90it/s, loss=0.146, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2542/3000 [16:22<02:37,  2.91it/s, loss=0.11, lr=0.002] \n",
      "Steps:  85%|████████▍ | 2543/3000 [16:23<02:37,  2.90it/s, loss=0.0753, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2544/3000 [16:23<02:38,  2.88it/s, loss=0.127, lr=0.002] \n",
      "Steps:  85%|████████▍ | 2545/3000 [16:23<02:35,  2.92it/s, loss=0.14, lr=0.002] \n",
      "Steps:  85%|████████▍ | 2546/3000 [16:24<02:36,  2.90it/s, loss=0.194, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2547/3000 [16:24<02:34,  2.94it/s, loss=0.113, lr=0.002]\n",
      "Steps:  85%|████████▍ | 2548/3000 [16:25<02:34,  2.93it/s, loss=0.19, lr=0.002] \n",
      "Steps:  85%|████████▍ | 2549/3000 [16:25<02:36,  2.88it/s, loss=0.173, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2550/3000 [16:25<02:22,  3.16it/s, loss=0.0625, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2551/3000 [16:26<02:38,  2.83it/s, loss=0.0901, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2552/3000 [16:26<02:37,  2.85it/s, loss=0.0689, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2553/3000 [16:26<02:35,  2.88it/s, loss=0.155, lr=0.002] \n",
      "Steps:  85%|████████▌ | 2554/3000 [16:27<02:35,  2.87it/s, loss=0.11, lr=0.002] \n",
      "Steps:  85%|████████▌ | 2555/3000 [16:27<02:33,  2.90it/s, loss=0.0671, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2556/3000 [16:27<02:34,  2.88it/s, loss=0.246, lr=0.002] \n",
      "Steps:  85%|████████▌ | 2557/3000 [16:28<02:34,  2.87it/s, loss=0.12, lr=0.002] \n",
      "Steps:  85%|████████▌ | 2558/3000 [16:28<02:33,  2.88it/s, loss=0.0668, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2559/3000 [16:28<02:31,  2.91it/s, loss=0.0587, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2560/3000 [16:29<02:31,  2.90it/s, loss=0.127, lr=0.002] \n",
      "Steps:  85%|████████▌ | 2561/3000 [16:29<02:31,  2.90it/s, loss=0.188, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2562/3000 [16:30<02:54,  2.51it/s, loss=0.109, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2563/3000 [16:30<02:47,  2.61it/s, loss=0.217, lr=0.002]\n",
      "Steps:  85%|████████▌ | 2564/3000 [16:30<02:40,  2.71it/s, loss=0.135, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2565/3000 [16:31<02:38,  2.75it/s, loss=0.254, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2566/3000 [16:31<02:34,  2.80it/s, loss=0.0764, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2567/3000 [16:31<02:32,  2.84it/s, loss=0.129, lr=0.002] \n",
      "Steps:  86%|████████▌ | 2568/3000 [16:32<02:30,  2.87it/s, loss=0.0567, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2569/3000 [16:32<02:31,  2.85it/s, loss=0.0292, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2570/3000 [16:32<02:30,  2.87it/s, loss=0.15, lr=0.002]  \n",
      "Steps:  86%|████████▌ | 2571/3000 [16:33<02:29,  2.87it/s, loss=0.158, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2572/3000 [16:33<02:29,  2.86it/s, loss=0.226, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2573/3000 [16:33<02:28,  2.87it/s, loss=0.029, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2574/3000 [16:34<02:30,  2.82it/s, loss=0.0304, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2575/3000 [16:34<02:30,  2.83it/s, loss=0.147, lr=0.002] \n",
      "Steps:  86%|████████▌ | 2576/3000 [16:34<02:28,  2.85it/s, loss=0.0742, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2577/3000 [16:35<02:26,  2.89it/s, loss=0.0769, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2578/3000 [16:35<02:27,  2.87it/s, loss=0.0996, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2579/3000 [16:35<02:27,  2.86it/s, loss=0.172, lr=0.002] \n",
      "Steps:  86%|████████▌ | 2580/3000 [16:36<02:26,  2.86it/s, loss=0.123, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2581/3000 [16:36<02:26,  2.85it/s, loss=0.0765, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2582/3000 [16:36<02:26,  2.85it/s, loss=0.038, lr=0.002] \n",
      "Steps:  86%|████████▌ | 2583/3000 [16:37<02:26,  2.86it/s, loss=0.109, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2584/3000 [16:37<02:25,  2.87it/s, loss=0.139, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2585/3000 [16:38<02:26,  2.84it/s, loss=0.124, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2586/3000 [16:38<02:25,  2.84it/s, loss=0.179, lr=0.002]\n",
      "Steps:  86%|████████▌ | 2587/3000 [16:38<02:24,  2.86it/s, loss=0.121, lr=0.002]\n",
      "Steps:  86%|████████▋ | 2588/3000 [16:39<02:24,  2.84it/s, loss=0.245, lr=0.002]\n",
      "Steps:  86%|████████▋ | 2589/3000 [16:39<02:24,  2.84it/s, loss=0.0872, lr=0.002]\n",
      "Steps:  86%|████████▋ | 2590/3000 [16:39<02:24,  2.85it/s, loss=0.0674, lr=0.002]\n",
      "Steps:  86%|████████▋ | 2591/3000 [16:40<02:23,  2.86it/s, loss=0.0586, lr=0.002]\n",
      "Steps:  86%|████████▋ | 2592/3000 [16:40<02:23,  2.84it/s, loss=0.132, lr=0.002] \n",
      "Steps:  86%|████████▋ | 2593/3000 [16:40<02:22,  2.85it/s, loss=0.336, lr=0.002]\n",
      "Steps:  86%|████████▋ | 2594/3000 [16:41<02:21,  2.86it/s, loss=0.252, lr=0.002]\n",
      "Steps:  86%|████████▋ | 2595/3000 [16:41<02:21,  2.87it/s, loss=0.111, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2596/3000 [16:41<02:19,  2.90it/s, loss=0.21, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2597/3000 [16:42<02:19,  2.89it/s, loss=0.156, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2598/3000 [16:42<02:21,  2.85it/s, loss=0.276, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2599/3000 [16:42<02:22,  2.82it/s, loss=0.214, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2600/3000 [16:43<02:22,  2.82it/s, loss=0.125, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2601/3000 [16:43<02:20,  2.83it/s, loss=0.169, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2602/3000 [16:43<02:19,  2.86it/s, loss=0.0567, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2603/3000 [16:44<02:18,  2.86it/s, loss=0.118, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2604/3000 [16:44<02:17,  2.88it/s, loss=0.204, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2605/3000 [16:45<02:17,  2.87it/s, loss=0.0286, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2606/3000 [16:45<02:17,  2.86it/s, loss=0.13, lr=0.002]  \n",
      "Steps:  87%|████████▋ | 2607/3000 [16:45<02:16,  2.87it/s, loss=0.22, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2608/3000 [16:46<02:17,  2.85it/s, loss=0.0537, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2609/3000 [16:46<02:16,  2.86it/s, loss=0.177, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2610/3000 [16:46<02:15,  2.87it/s, loss=0.0971, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2611/3000 [16:47<02:14,  2.89it/s, loss=0.153, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2612/3000 [16:47<02:14,  2.88it/s, loss=0.218, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2613/3000 [16:47<02:14,  2.88it/s, loss=0.0203, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2614/3000 [16:48<02:14,  2.87it/s, loss=0.213, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2615/3000 [16:48<02:13,  2.88it/s, loss=0.0244, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2616/3000 [16:48<02:13,  2.87it/s, loss=0.0575, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2617/3000 [16:49<02:13,  2.88it/s, loss=0.257, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2618/3000 [16:49<02:13,  2.86it/s, loss=0.142, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2619/3000 [16:49<02:14,  2.83it/s, loss=0.0152, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2620/3000 [16:50<02:14,  2.82it/s, loss=0.126, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2621/3000 [16:50<02:13,  2.85it/s, loss=0.106, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2622/3000 [16:50<02:12,  2.86it/s, loss=0.343, lr=0.002]\n",
      "Steps:  87%|████████▋ | 2623/3000 [16:51<02:11,  2.88it/s, loss=0.15, lr=0.002] \n",
      "Steps:  87%|████████▋ | 2624/3000 [16:51<02:11,  2.85it/s, loss=0.103, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2625/3000 [16:52<02:11,  2.86it/s, loss=0.105, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2626/3000 [16:52<02:10,  2.87it/s, loss=0.116, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2627/3000 [16:52<02:10,  2.86it/s, loss=0.0929, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2628/3000 [16:53<02:26,  2.55it/s, loss=0.143, lr=0.002] \n",
      "Steps:  88%|████████▊ | 2629/3000 [16:53<02:19,  2.65it/s, loss=0.0894, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2630/3000 [16:53<02:15,  2.73it/s, loss=0.155, lr=0.002] \n",
      "Steps:  88%|████████▊ | 2631/3000 [16:54<02:12,  2.78it/s, loss=0.127, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2632/3000 [16:54<02:12,  2.77it/s, loss=0.168, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2633/3000 [16:54<02:10,  2.81it/s, loss=0.0918, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2634/3000 [16:55<02:09,  2.84it/s, loss=0.0911, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2635/3000 [16:55<02:07,  2.86it/s, loss=0.0427, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2636/3000 [16:55<02:07,  2.86it/s, loss=0.119, lr=0.002] \n",
      "Steps:  88%|████████▊ | 2637/3000 [16:56<02:07,  2.86it/s, loss=0.158, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2638/3000 [16:56<02:06,  2.86it/s, loss=0.119, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2639/3000 [16:57<02:04,  2.91it/s, loss=0.183, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2640/3000 [16:57<02:04,  2.90it/s, loss=0.111, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2641/3000 [16:57<02:04,  2.89it/s, loss=0.101, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2642/3000 [16:58<02:04,  2.89it/s, loss=0.128, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2643/3000 [16:58<02:02,  2.91it/s, loss=0.109, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2644/3000 [16:58<02:03,  2.89it/s, loss=0.0998, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2645/3000 [16:59<02:02,  2.90it/s, loss=0.0754, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2646/3000 [16:59<02:01,  2.91it/s, loss=0.245, lr=0.002] \n",
      "Steps:  88%|████████▊ | 2647/3000 [16:59<02:01,  2.91it/s, loss=0.127, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2648/3000 [17:00<02:01,  2.89it/s, loss=0.214, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2649/3000 [17:00<02:05,  2.80it/s, loss=0.0911, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2650/3000 [17:00<02:03,  2.83it/s, loss=0.117, lr=0.002] \n",
      "Steps:  88%|████████▊ | 2651/3000 [17:01<02:02,  2.84it/s, loss=0.19, lr=0.002] \n",
      "Steps:  88%|████████▊ | 2652/3000 [17:01<02:02,  2.85it/s, loss=0.0222, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2653/3000 [17:01<02:01,  2.86it/s, loss=0.124, lr=0.002] \n",
      "Steps:  88%|████████▊ | 2654/3000 [17:02<01:59,  2.89it/s, loss=0.124, lr=0.002]\n",
      "Steps:  88%|████████▊ | 2655/3000 [17:02<02:00,  2.87it/s, loss=0.134, lr=0.002]\n",
      "Steps:  89%|████████▊ | 2656/3000 [17:02<01:59,  2.87it/s, loss=0.125, lr=0.002]\n",
      "Steps:  89%|████████▊ | 2657/3000 [17:03<01:58,  2.90it/s, loss=0.0678, lr=0.002]\n",
      "Steps:  89%|████████▊ | 2658/3000 [17:03<01:58,  2.88it/s, loss=0.209, lr=0.002] \n",
      "Steps:  89%|████████▊ | 2659/3000 [17:03<01:58,  2.89it/s, loss=0.184, lr=0.002]\n",
      "Steps:  89%|████████▊ | 2660/3000 [17:04<01:57,  2.89it/s, loss=0.149, lr=0.002]\n",
      "Steps:  89%|████████▊ | 2661/3000 [17:04<01:57,  2.89it/s, loss=0.233, lr=0.002]\n",
      "Steps:  89%|████████▊ | 2662/3000 [17:05<01:56,  2.90it/s, loss=0.0674, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2663/3000 [17:05<01:56,  2.88it/s, loss=0.133, lr=0.002] \n",
      "Steps:  89%|████████▉ | 2664/3000 [17:05<01:55,  2.91it/s, loss=0.0952, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2665/3000 [17:06<01:56,  2.89it/s, loss=0.119, lr=0.002] \n",
      "Steps:  89%|████████▉ | 2666/3000 [17:06<01:58,  2.81it/s, loss=0.211, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2667/3000 [17:06<01:58,  2.81it/s, loss=0.242, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2668/3000 [17:07<01:57,  2.83it/s, loss=0.102, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2669/3000 [17:07<01:55,  2.86it/s, loss=0.176, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2670/3000 [17:07<01:54,  2.88it/s, loss=0.256, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2671/3000 [17:08<01:52,  2.91it/s, loss=0.186, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2672/3000 [17:08<01:52,  2.92it/s, loss=0.22, lr=0.002] \n",
      "Steps:  89%|████████▉ | 2673/3000 [17:08<01:51,  2.92it/s, loss=0.128, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2674/3000 [17:09<01:52,  2.91it/s, loss=0.13, lr=0.002] \n",
      "Steps:  89%|████████▉ | 2675/3000 [17:09<01:51,  2.92it/s, loss=0.245, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2676/3000 [17:09<01:50,  2.93it/s, loss=0.103, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2677/3000 [17:10<01:50,  2.93it/s, loss=0.0746, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2678/3000 [17:10<01:50,  2.90it/s, loss=0.097, lr=0.002] \n",
      "Steps:  89%|████████▉ | 2679/3000 [17:10<01:50,  2.90it/s, loss=0.183, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2680/3000 [17:11<01:50,  2.90it/s, loss=0.295, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2681/3000 [17:11<01:49,  2.92it/s, loss=0.0852, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2682/3000 [17:11<01:49,  2.91it/s, loss=0.179, lr=0.002] \n",
      "Steps:  89%|████████▉ | 2683/3000 [17:12<01:49,  2.89it/s, loss=0.137, lr=0.002]\n",
      "Steps:  89%|████████▉ | 2684/3000 [17:12<01:50,  2.87it/s, loss=0.136, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2685/3000 [17:12<01:48,  2.89it/s, loss=0.137, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2686/3000 [17:13<02:05,  2.51it/s, loss=0.325, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2687/3000 [17:13<02:00,  2.61it/s, loss=0.0705, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2688/3000 [17:14<01:55,  2.69it/s, loss=0.196, lr=0.002] \n",
      "Steps:  90%|████████▉ | 2689/3000 [17:14<01:53,  2.74it/s, loss=0.142, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2690/3000 [17:14<01:52,  2.76it/s, loss=0.118, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2691/3000 [17:15<01:51,  2.78it/s, loss=0.0633, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2692/3000 [17:15<01:48,  2.83it/s, loss=0.106, lr=0.002] \n",
      "Steps:  90%|████████▉ | 2693/3000 [17:15<01:48,  2.83it/s, loss=0.0682, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2694/3000 [17:16<01:48,  2.82it/s, loss=0.264, lr=0.002] \n",
      "Steps:  90%|████████▉ | 2695/3000 [17:16<01:47,  2.85it/s, loss=0.103, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2696/3000 [17:16<01:46,  2.85it/s, loss=0.107, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2697/3000 [17:17<01:44,  2.89it/s, loss=0.155, lr=0.002]\n",
      "Steps:  90%|████████▉ | 2698/3000 [17:17<01:45,  2.86it/s, loss=0.23, lr=0.002] \n",
      "Steps:  90%|████████▉ | 2699/3000 [17:18<01:47,  2.79it/s, loss=0.228, lr=0.002]\n",
      "Steps:  90%|█████████ | 2700/3000 [17:18<01:37,  3.09it/s, loss=0.0505, lr=0.002]\n",
      "Steps:  90%|█████████ | 2701/3000 [17:18<01:48,  2.75it/s, loss=0.0798, lr=0.002]\n",
      "Steps:  90%|█████████ | 2702/3000 [17:19<01:46,  2.79it/s, loss=0.113, lr=0.002] \n",
      "Steps:  90%|█████████ | 2703/3000 [17:19<01:44,  2.84it/s, loss=0.307, lr=0.002]\n",
      "Steps:  90%|█████████ | 2704/3000 [17:19<01:44,  2.85it/s, loss=0.13, lr=0.002] \n",
      "Steps:  90%|█████████ | 2705/3000 [17:20<01:43,  2.85it/s, loss=0.0913, lr=0.002]\n",
      "Steps:  90%|█████████ | 2706/3000 [17:20<01:43,  2.84it/s, loss=0.148, lr=0.002] \n",
      "Steps:  90%|█████████ | 2707/3000 [17:20<01:42,  2.85it/s, loss=0.05, lr=0.002] \n",
      "Steps:  90%|█████████ | 2708/3000 [17:21<01:42,  2.85it/s, loss=0.108, lr=0.002]\n",
      "Steps:  90%|█████████ | 2709/3000 [17:21<01:42,  2.84it/s, loss=0.203, lr=0.002]\n",
      "Steps:  90%|█████████ | 2710/3000 [17:21<01:41,  2.85it/s, loss=0.134, lr=0.002]\n",
      "Steps:  90%|█████████ | 2711/3000 [17:22<01:41,  2.84it/s, loss=0.0887, lr=0.002]\n",
      "Steps:  90%|█████████ | 2712/3000 [17:22<01:42,  2.82it/s, loss=0.0903, lr=0.002]\n",
      "Steps:  90%|█████████ | 2713/3000 [17:22<01:41,  2.83it/s, loss=0.191, lr=0.002] \n",
      "Steps:  90%|█████████ | 2714/3000 [17:23<01:39,  2.87it/s, loss=0.131, lr=0.002]\n",
      "Steps:  90%|█████████ | 2715/3000 [17:23<01:39,  2.86it/s, loss=0.104, lr=0.002]\n",
      "Steps:  91%|█████████ | 2716/3000 [17:23<01:39,  2.87it/s, loss=0.123, lr=0.002]\n",
      "Steps:  91%|█████████ | 2717/3000 [17:24<01:37,  2.89it/s, loss=0.246, lr=0.002]\n",
      "Steps:  91%|█████████ | 2718/3000 [17:24<01:36,  2.91it/s, loss=0.138, lr=0.002]\n",
      "Steps:  91%|█████████ | 2719/3000 [17:25<01:37,  2.89it/s, loss=0.14, lr=0.002] \n",
      "Steps:  91%|█████████ | 2720/3000 [17:25<01:37,  2.86it/s, loss=0.127, lr=0.002]\n",
      "Steps:  91%|█████████ | 2721/3000 [17:25<01:37,  2.87it/s, loss=0.113, lr=0.002]\n",
      "Steps:  91%|█████████ | 2722/3000 [17:26<01:36,  2.87it/s, loss=0.112, lr=0.002]\n",
      "Steps:  91%|█████████ | 2723/3000 [17:26<01:37,  2.85it/s, loss=0.104, lr=0.002]\n",
      "Steps:  91%|█████████ | 2724/3000 [17:26<01:39,  2.76it/s, loss=0.0817, lr=0.002]\n",
      "Steps:  91%|█████████ | 2725/3000 [17:27<01:38,  2.80it/s, loss=0.164, lr=0.002] \n",
      "Steps:  91%|█████████ | 2726/3000 [17:27<01:37,  2.81it/s, loss=0.0205, lr=0.002]\n",
      "Steps:  91%|█████████ | 2727/3000 [17:27<01:35,  2.85it/s, loss=0.0322, lr=0.002]\n",
      "Steps:  91%|█████████ | 2728/3000 [17:28<01:35,  2.86it/s, loss=0.138, lr=0.002] \n",
      "Steps:  91%|█████████ | 2729/3000 [17:28<01:35,  2.85it/s, loss=0.019, lr=0.002]\n",
      "Steps:  91%|█████████ | 2730/3000 [17:28<01:33,  2.90it/s, loss=0.184, lr=0.002]\n",
      "Steps:  91%|█████████ | 2731/3000 [17:29<01:32,  2.90it/s, loss=0.185, lr=0.002]\n",
      "Steps:  91%|█████████ | 2732/3000 [17:29<01:32,  2.89it/s, loss=0.158, lr=0.002]\n",
      "Steps:  91%|█████████ | 2733/3000 [17:29<01:32,  2.89it/s, loss=0.154, lr=0.002]\n",
      "Steps:  91%|█████████ | 2734/3000 [17:30<01:31,  2.89it/s, loss=0.0907, lr=0.002]\n",
      "Steps:  91%|█████████ | 2735/3000 [17:30<01:32,  2.86it/s, loss=0.155, lr=0.002] \n",
      "Steps:  91%|█████████ | 2736/3000 [17:30<01:31,  2.87it/s, loss=0.0905, lr=0.002]\n",
      "Steps:  91%|█████████ | 2737/3000 [17:31<01:31,  2.88it/s, loss=0.228, lr=0.002] \n",
      "Steps:  91%|█████████▏| 2738/3000 [17:31<01:30,  2.88it/s, loss=0.181, lr=0.002]\n",
      "Steps:  91%|█████████▏| 2739/3000 [17:32<01:29,  2.91it/s, loss=0.0809, lr=0.002]\n",
      "Steps:  91%|█████████▏| 2740/3000 [17:32<01:29,  2.91it/s, loss=0.124, lr=0.002] \n",
      "Steps:  91%|█████████▏| 2741/3000 [17:32<01:31,  2.83it/s, loss=0.18, lr=0.002] \n",
      "Steps:  91%|█████████▏| 2742/3000 [17:33<01:31,  2.83it/s, loss=0.14, lr=0.002]\n",
      "Steps:  91%|█████████▏| 2743/3000 [17:33<01:41,  2.53it/s, loss=0.248, lr=0.002]\n",
      "Steps:  91%|█████████▏| 2744/3000 [17:33<01:36,  2.64it/s, loss=0.166, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2745/3000 [17:34<01:33,  2.74it/s, loss=0.274, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2746/3000 [17:34<01:31,  2.79it/s, loss=0.101, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2747/3000 [17:34<01:30,  2.80it/s, loss=0.0767, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2748/3000 [17:35<01:28,  2.85it/s, loss=0.0815, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2749/3000 [17:35<01:28,  2.83it/s, loss=0.0224, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2750/3000 [17:35<01:27,  2.85it/s, loss=0.144, lr=0.002] \n",
      "Steps:  92%|█████████▏| 2751/3000 [17:36<01:27,  2.86it/s, loss=0.219, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2752/3000 [17:36<01:27,  2.85it/s, loss=0.0554, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2753/3000 [17:37<01:25,  2.89it/s, loss=0.0695, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2754/3000 [17:37<01:25,  2.87it/s, loss=0.0975, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2755/3000 [17:37<01:24,  2.89it/s, loss=0.121, lr=0.002] \n",
      "Steps:  92%|█████████▏| 2756/3000 [17:38<01:24,  2.90it/s, loss=0.117, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2757/3000 [17:38<01:24,  2.87it/s, loss=0.156, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2758/3000 [17:38<01:24,  2.88it/s, loss=0.26, lr=0.002] \n",
      "Steps:  92%|█████████▏| 2759/3000 [17:39<01:22,  2.91it/s, loss=0.132, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2760/3000 [17:39<01:22,  2.91it/s, loss=0.0296, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2761/3000 [17:39<01:21,  2.93it/s, loss=0.175, lr=0.002] \n",
      "Steps:  92%|█████████▏| 2762/3000 [17:40<01:20,  2.96it/s, loss=0.0964, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2763/3000 [17:40<01:20,  2.94it/s, loss=0.056, lr=0.002] \n",
      "Steps:  92%|█████████▏| 2764/3000 [17:40<01:21,  2.91it/s, loss=0.0617, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2765/3000 [17:41<01:20,  2.91it/s, loss=0.0703, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2766/3000 [17:41<01:21,  2.88it/s, loss=0.227, lr=0.002] \n",
      "Steps:  92%|█████████▏| 2767/3000 [17:41<01:20,  2.90it/s, loss=0.109, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2768/3000 [17:42<01:19,  2.90it/s, loss=0.164, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2769/3000 [17:42<01:19,  2.92it/s, loss=0.117, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2770/3000 [17:42<01:19,  2.91it/s, loss=0.117, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2771/3000 [17:43<01:19,  2.90it/s, loss=0.202, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2772/3000 [17:43<01:18,  2.91it/s, loss=0.167, lr=0.002]\n",
      "Steps:  92%|█████████▏| 2773/3000 [17:43<01:17,  2.93it/s, loss=0.22, lr=0.002] \n",
      "Steps:  92%|█████████▏| 2774/3000 [17:44<01:18,  2.89it/s, loss=0.144, lr=0.002]\n",
      "Steps:  92%|█████████▎| 2775/3000 [17:44<01:18,  2.88it/s, loss=0.233, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2776/3000 [17:44<01:17,  2.88it/s, loss=0.081, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2777/3000 [17:45<01:17,  2.87it/s, loss=0.139, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2778/3000 [17:45<01:17,  2.88it/s, loss=0.0856, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2779/3000 [17:45<01:16,  2.89it/s, loss=0.0945, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2780/3000 [17:46<01:15,  2.91it/s, loss=0.346, lr=0.002] \n",
      "Steps:  93%|█████████▎| 2781/3000 [17:46<01:15,  2.91it/s, loss=0.143, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2782/3000 [17:47<01:16,  2.86it/s, loss=0.029, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2783/3000 [17:47<01:16,  2.85it/s, loss=0.18, lr=0.002] \n",
      "Steps:  93%|█████████▎| 2784/3000 [17:47<01:15,  2.85it/s, loss=0.129, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2785/3000 [17:48<01:14,  2.87it/s, loss=0.158, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2786/3000 [17:48<01:15,  2.85it/s, loss=0.0573, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2787/3000 [17:48<01:14,  2.85it/s, loss=0.186, lr=0.002] \n",
      "Steps:  93%|█████████▎| 2788/3000 [17:49<01:14,  2.86it/s, loss=0.0923, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2789/3000 [17:49<01:13,  2.87it/s, loss=0.109, lr=0.002] \n",
      "Steps:  93%|█████████▎| 2790/3000 [17:49<01:12,  2.90it/s, loss=0.135, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2791/3000 [17:50<01:13,  2.85it/s, loss=0.105, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2792/3000 [17:50<01:12,  2.86it/s, loss=0.165, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2793/3000 [17:50<01:11,  2.90it/s, loss=0.118, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2794/3000 [17:51<01:11,  2.87it/s, loss=0.12, lr=0.002] \n",
      "Steps:  93%|█████████▎| 2795/3000 [17:51<01:11,  2.89it/s, loss=0.095, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2796/3000 [17:51<01:10,  2.89it/s, loss=0.0434, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2797/3000 [17:52<01:09,  2.91it/s, loss=0.071, lr=0.002] \n",
      "Steps:  93%|█████████▎| 2798/3000 [17:52<01:09,  2.89it/s, loss=0.0561, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2799/3000 [17:52<01:08,  2.92it/s, loss=0.26, lr=0.002]  \n",
      "Steps:  93%|█████████▎| 2800/3000 [17:53<01:17,  2.57it/s, loss=0.0739, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2801/3000 [17:53<01:14,  2.68it/s, loss=0.105, lr=0.002] \n",
      "Steps:  93%|█████████▎| 2802/3000 [17:54<01:11,  2.76it/s, loss=0.115, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2803/3000 [17:54<01:10,  2.80it/s, loss=0.119, lr=0.002]\n",
      "Steps:  93%|█████████▎| 2804/3000 [17:54<01:09,  2.81it/s, loss=0.213, lr=0.002]\n",
      "Steps:  94%|█████████▎| 2805/3000 [17:55<01:08,  2.84it/s, loss=0.109, lr=0.002]\n",
      "Steps:  94%|█████████▎| 2806/3000 [17:55<01:07,  2.86it/s, loss=0.202, lr=0.002]\n",
      "Steps:  94%|█████████▎| 2807/3000 [17:55<01:07,  2.84it/s, loss=0.0385, lr=0.002]\n",
      "Steps:  94%|█████████▎| 2808/3000 [17:56<01:07,  2.86it/s, loss=0.236, lr=0.002] \n",
      "Steps:  94%|█████████▎| 2809/3000 [17:56<01:06,  2.86it/s, loss=0.135, lr=0.002]\n",
      "Steps:  94%|█████████▎| 2810/3000 [17:56<01:06,  2.85it/s, loss=0.0662, lr=0.002]\n",
      "Steps:  94%|█████████▎| 2811/3000 [17:57<01:06,  2.85it/s, loss=0.131, lr=0.002] \n",
      "Steps:  94%|█████████▎| 2812/3000 [17:57<01:06,  2.83it/s, loss=0.159, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2813/3000 [17:57<01:05,  2.86it/s, loss=0.186, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2814/3000 [17:58<01:04,  2.88it/s, loss=0.12, lr=0.002] \n",
      "Steps:  94%|█████████▍| 2815/3000 [17:58<01:04,  2.87it/s, loss=0.251, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2816/3000 [17:59<01:04,  2.84it/s, loss=0.0846, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2817/3000 [17:59<01:04,  2.86it/s, loss=0.103, lr=0.002] \n",
      "Steps:  94%|█████████▍| 2818/3000 [17:59<01:02,  2.89it/s, loss=0.109, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2819/3000 [18:00<01:02,  2.91it/s, loss=0.191, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2820/3000 [18:00<01:02,  2.90it/s, loss=0.172, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2821/3000 [18:00<01:01,  2.91it/s, loss=0.104, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2822/3000 [18:01<01:00,  2.96it/s, loss=0.115, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2823/3000 [18:01<01:00,  2.94it/s, loss=0.143, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2824/3000 [18:01<01:00,  2.89it/s, loss=0.13, lr=0.002] \n",
      "Steps:  94%|█████████▍| 2825/3000 [18:02<00:59,  2.93it/s, loss=0.105, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2826/3000 [18:02<01:00,  2.89it/s, loss=0.0806, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2827/3000 [18:02<00:59,  2.89it/s, loss=0.128, lr=0.002] \n",
      "Steps:  94%|█████████▍| 2828/3000 [18:03<00:59,  2.87it/s, loss=0.0861, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2829/3000 [18:03<00:59,  2.89it/s, loss=0.151, lr=0.002] \n",
      "Steps:  94%|█████████▍| 2830/3000 [18:03<00:58,  2.91it/s, loss=0.107, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2831/3000 [18:04<00:58,  2.91it/s, loss=0.135, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2832/3000 [18:04<00:58,  2.87it/s, loss=0.261, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2833/3000 [18:04<00:59,  2.82it/s, loss=0.0898, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2834/3000 [18:05<00:58,  2.85it/s, loss=0.0861, lr=0.002]\n",
      "Steps:  94%|█████████▍| 2835/3000 [18:05<00:57,  2.87it/s, loss=0.264, lr=0.002] \n",
      "Steps:  95%|█████████▍| 2836/3000 [18:05<00:57,  2.86it/s, loss=0.174, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2837/3000 [18:06<00:56,  2.88it/s, loss=0.0968, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2838/3000 [18:06<00:56,  2.87it/s, loss=0.206, lr=0.002] \n",
      "Steps:  95%|█████████▍| 2839/3000 [18:06<00:55,  2.90it/s, loss=0.151, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2840/3000 [18:07<00:54,  2.91it/s, loss=0.106, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2841/3000 [18:07<00:54,  2.90it/s, loss=0.0597, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2842/3000 [18:07<00:54,  2.89it/s, loss=0.136, lr=0.002] \n",
      "Steps:  95%|█████████▍| 2843/3000 [18:08<00:54,  2.89it/s, loss=0.141, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2844/3000 [18:08<00:53,  2.89it/s, loss=0.044, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2845/3000 [18:09<00:53,  2.89it/s, loss=0.0726, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2846/3000 [18:09<00:52,  2.96it/s, loss=0.173, lr=0.002] \n",
      "Steps:  95%|█████████▍| 2847/3000 [18:09<00:51,  2.96it/s, loss=0.118, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2848/3000 [18:10<00:51,  2.94it/s, loss=0.119, lr=0.002]\n",
      "Steps:  95%|█████████▍| 2849/3000 [18:10<00:51,  2.94it/s, loss=0.0618, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2850/3000 [18:10<00:46,  3.22it/s, loss=0.0991, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2851/3000 [18:11<00:52,  2.86it/s, loss=0.11, lr=0.002]  \n",
      "Steps:  95%|█████████▌| 2852/3000 [18:11<00:51,  2.89it/s, loss=0.0165, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2853/3000 [18:11<00:51,  2.88it/s, loss=0.0683, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2854/3000 [18:12<00:50,  2.89it/s, loss=0.13, lr=0.002]  \n",
      "Steps:  95%|█████████▌| 2855/3000 [18:12<00:49,  2.92it/s, loss=0.133, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2856/3000 [18:12<00:49,  2.92it/s, loss=0.122, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2857/3000 [18:13<00:54,  2.61it/s, loss=0.0801, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2858/3000 [18:13<00:53,  2.65it/s, loss=0.157, lr=0.002] \n",
      "Steps:  95%|█████████▌| 2859/3000 [18:13<00:51,  2.72it/s, loss=0.0246, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2860/3000 [18:14<00:50,  2.78it/s, loss=0.116, lr=0.002] \n",
      "Steps:  95%|█████████▌| 2861/3000 [18:14<00:49,  2.83it/s, loss=0.0705, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2862/3000 [18:14<00:47,  2.88it/s, loss=0.212, lr=0.002] \n",
      "Steps:  95%|█████████▌| 2863/3000 [18:15<00:47,  2.91it/s, loss=0.105, lr=0.002]\n",
      "Steps:  95%|█████████▌| 2864/3000 [18:15<00:46,  2.91it/s, loss=0.0758, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2865/3000 [18:15<00:46,  2.92it/s, loss=0.051, lr=0.002] \n",
      "Steps:  96%|█████████▌| 2866/3000 [18:16<00:45,  2.93it/s, loss=0.0765, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2867/3000 [18:16<00:45,  2.92it/s, loss=0.139, lr=0.002] \n",
      "Steps:  96%|█████████▌| 2868/3000 [18:16<00:45,  2.92it/s, loss=0.0268, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2869/3000 [18:17<00:44,  2.95it/s, loss=0.0813, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2870/3000 [18:17<00:44,  2.92it/s, loss=0.125, lr=0.002] \n",
      "Steps:  96%|█████████▌| 2871/3000 [18:18<00:44,  2.91it/s, loss=0.0685, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2872/3000 [18:18<00:43,  2.91it/s, loss=0.193, lr=0.002] \n",
      "Steps:  96%|█████████▌| 2873/3000 [18:18<00:43,  2.92it/s, loss=0.111, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2874/3000 [18:19<00:43,  2.92it/s, loss=0.11, lr=0.002] \n",
      "Steps:  96%|█████████▌| 2875/3000 [18:19<00:43,  2.86it/s, loss=0.0844, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2876/3000 [18:19<00:43,  2.87it/s, loss=0.105, lr=0.002] \n",
      "Steps:  96%|█████████▌| 2877/3000 [18:20<00:42,  2.91it/s, loss=0.255, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2878/3000 [18:20<00:41,  2.92it/s, loss=0.149, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2879/3000 [18:20<00:41,  2.92it/s, loss=0.171, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2880/3000 [18:21<00:40,  2.94it/s, loss=0.0883, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2881/3000 [18:21<00:40,  2.93it/s, loss=0.136, lr=0.002] \n",
      "Steps:  96%|█████████▌| 2882/3000 [18:21<00:40,  2.94it/s, loss=0.122, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2883/3000 [18:22<00:40,  2.92it/s, loss=0.104, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2884/3000 [18:22<00:39,  2.93it/s, loss=0.128, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2885/3000 [18:22<00:39,  2.91it/s, loss=0.115, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2886/3000 [18:23<00:39,  2.88it/s, loss=0.169, lr=0.002]\n",
      "Steps:  96%|█████████▌| 2887/3000 [18:23<00:39,  2.88it/s, loss=0.163, lr=0.002]\n",
      "Steps:  96%|█████████▋| 2888/3000 [18:23<00:38,  2.89it/s, loss=0.141, lr=0.002]\n",
      "Steps:  96%|█████████▋| 2889/3000 [18:24<00:38,  2.90it/s, loss=0.187, lr=0.002]\n",
      "Steps:  96%|█████████▋| 2890/3000 [18:24<00:38,  2.89it/s, loss=0.0812, lr=0.002]\n",
      "Steps:  96%|█████████▋| 2891/3000 [18:24<00:37,  2.93it/s, loss=0.127, lr=0.002] \n",
      "Steps:  96%|█████████▋| 2892/3000 [18:25<00:36,  2.95it/s, loss=0.0619, lr=0.002]\n",
      "Steps:  96%|█████████▋| 2893/3000 [18:25<00:36,  2.93it/s, loss=0.128, lr=0.002] \n",
      "Steps:  96%|█████████▋| 2894/3000 [18:25<00:36,  2.90it/s, loss=0.0842, lr=0.002]\n",
      "Steps:  96%|█████████▋| 2895/3000 [18:26<00:36,  2.89it/s, loss=0.254, lr=0.002] \n",
      "Steps:  97%|█████████▋| 2896/3000 [18:26<00:35,  2.92it/s, loss=0.183, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2897/3000 [18:26<00:35,  2.92it/s, loss=0.161, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2898/3000 [18:27<00:34,  2.94it/s, loss=0.127, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2899/3000 [18:27<00:34,  2.93it/s, loss=0.0601, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2900/3000 [18:27<00:34,  2.91it/s, loss=0.063, lr=0.002] \n",
      "Steps:  97%|█████████▋| 2901/3000 [18:28<00:34,  2.88it/s, loss=0.134, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2902/3000 [18:28<00:33,  2.91it/s, loss=0.0237, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2903/3000 [18:29<00:33,  2.92it/s, loss=0.12, lr=0.002]  \n",
      "Steps:  97%|█████████▋| 2904/3000 [18:29<00:32,  2.92it/s, loss=0.078, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2905/3000 [18:29<00:32,  2.90it/s, loss=0.241, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2906/3000 [18:30<00:32,  2.90it/s, loss=0.224, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2907/3000 [18:30<00:31,  2.94it/s, loss=0.0867, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2908/3000 [18:30<00:31,  2.90it/s, loss=0.0973, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2909/3000 [18:31<00:32,  2.84it/s, loss=0.125, lr=0.002] \n",
      "Steps:  97%|█████████▋| 2910/3000 [18:31<00:31,  2.86it/s, loss=0.228, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2911/3000 [18:31<00:31,  2.87it/s, loss=0.0694, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2912/3000 [18:32<00:30,  2.89it/s, loss=0.214, lr=0.002] \n",
      "Steps:  97%|█████████▋| 2913/3000 [18:32<00:29,  2.90it/s, loss=0.0848, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2914/3000 [18:33<00:34,  2.47it/s, loss=0.097, lr=0.002] \n",
      "Steps:  97%|█████████▋| 2915/3000 [18:33<00:33,  2.57it/s, loss=0.222, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2916/3000 [18:33<00:31,  2.64it/s, loss=0.0961, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2917/3000 [18:34<00:31,  2.66it/s, loss=0.228, lr=0.002] \n",
      "Steps:  97%|█████████▋| 2918/3000 [18:34<00:30,  2.71it/s, loss=0.161, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2919/3000 [18:34<00:29,  2.76it/s, loss=0.125, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2920/3000 [18:35<00:28,  2.78it/s, loss=0.0947, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2921/3000 [18:35<00:28,  2.80it/s, loss=0.138, lr=0.002] \n",
      "Steps:  97%|█████████▋| 2922/3000 [18:35<00:27,  2.84it/s, loss=0.128, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2923/3000 [18:36<00:27,  2.84it/s, loss=0.197, lr=0.002]\n",
      "Steps:  97%|█████████▋| 2924/3000 [18:36<00:26,  2.86it/s, loss=0.164, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2925/3000 [18:36<00:26,  2.87it/s, loss=0.0672, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2926/3000 [18:37<00:25,  2.89it/s, loss=0.0804, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2927/3000 [18:37<00:25,  2.86it/s, loss=0.144, lr=0.002] \n",
      "Steps:  98%|█████████▊| 2928/3000 [18:37<00:25,  2.88it/s, loss=0.0226, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2929/3000 [18:38<00:24,  2.89it/s, loss=0.137, lr=0.002] \n",
      "Steps:  98%|█████████▊| 2930/3000 [18:38<00:24,  2.87it/s, loss=0.165, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2931/3000 [18:38<00:23,  2.88it/s, loss=0.189, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2932/3000 [18:39<00:23,  2.89it/s, loss=0.122, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2933/3000 [18:39<00:23,  2.89it/s, loss=0.118, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2934/3000 [18:39<00:22,  2.93it/s, loss=0.0975, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2935/3000 [18:40<00:22,  2.92it/s, loss=0.275, lr=0.002] \n",
      "Steps:  98%|█████████▊| 2936/3000 [18:40<00:21,  2.92it/s, loss=0.125, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2937/3000 [18:41<00:21,  2.92it/s, loss=0.0617, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2938/3000 [18:41<00:21,  2.93it/s, loss=0.146, lr=0.002] \n",
      "Steps:  98%|█████████▊| 2939/3000 [18:41<00:20,  2.93it/s, loss=0.14, lr=0.002] \n",
      "Steps:  98%|█████████▊| 2940/3000 [18:42<00:20,  2.91it/s, loss=0.121, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2941/3000 [18:42<00:20,  2.90it/s, loss=0.134, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2942/3000 [18:42<00:20,  2.89it/s, loss=0.086, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2943/3000 [18:43<00:19,  2.89it/s, loss=0.139, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2944/3000 [18:43<00:19,  2.90it/s, loss=0.248, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2945/3000 [18:43<00:19,  2.89it/s, loss=0.0351, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2946/3000 [18:44<00:18,  2.90it/s, loss=0.353, lr=0.002] \n",
      "Steps:  98%|█████████▊| 2947/3000 [18:44<00:18,  2.89it/s, loss=0.226, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2948/3000 [18:44<00:17,  2.91it/s, loss=0.152, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2949/3000 [18:45<00:17,  2.88it/s, loss=0.219, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2950/3000 [18:45<00:17,  2.86it/s, loss=0.101, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2951/3000 [18:45<00:17,  2.86it/s, loss=0.0961, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2952/3000 [18:46<00:16,  2.86it/s, loss=0.0467, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2953/3000 [18:46<00:16,  2.83it/s, loss=0.0252, lr=0.002]\n",
      "Steps:  98%|█████████▊| 2954/3000 [18:46<00:15,  2.88it/s, loss=0.117, lr=0.002] \n",
      "Steps:  98%|█████████▊| 2955/3000 [18:47<00:15,  2.89it/s, loss=0.279, lr=0.002]\n",
      "Steps:  99%|█████████▊| 2956/3000 [18:47<00:15,  2.87it/s, loss=0.126, lr=0.002]\n",
      "Steps:  99%|█████████▊| 2957/3000 [18:47<00:14,  2.88it/s, loss=0.111, lr=0.002]\n",
      "Steps:  99%|█████████▊| 2958/3000 [18:48<00:14,  2.86it/s, loss=0.101, lr=0.002]\n",
      "Steps:  99%|█████████▊| 2959/3000 [18:48<00:14,  2.80it/s, loss=0.16, lr=0.002] \n",
      "Steps:  99%|█████████▊| 2960/3000 [18:49<00:13,  2.86it/s, loss=0.165, lr=0.002]\n",
      "Steps:  99%|█████████▊| 2961/3000 [18:49<00:13,  2.89it/s, loss=0.122, lr=0.002]\n",
      "Steps:  99%|█████████▊| 2962/3000 [18:49<00:13,  2.88it/s, loss=0.225, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2963/3000 [18:50<00:12,  2.91it/s, loss=0.107, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2964/3000 [18:50<00:12,  2.92it/s, loss=0.0953, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2965/3000 [18:50<00:12,  2.90it/s, loss=0.207, lr=0.002] \n",
      "Steps:  99%|█████████▉| 2966/3000 [18:51<00:11,  2.90it/s, loss=0.136, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2967/3000 [18:51<00:11,  2.88it/s, loss=0.113, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2968/3000 [18:51<00:11,  2.85it/s, loss=0.106, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2969/3000 [18:52<00:10,  2.85it/s, loss=0.144, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2970/3000 [18:52<00:10,  2.87it/s, loss=0.0987, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2971/3000 [18:52<00:11,  2.56it/s, loss=0.0691, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2972/3000 [18:53<00:10,  2.64it/s, loss=0.105, lr=0.002] \n",
      "Steps:  99%|█████████▉| 2973/3000 [18:53<00:10,  2.69it/s, loss=0.213, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2974/3000 [18:54<00:09,  2.76it/s, loss=0.117, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2975/3000 [18:54<00:08,  2.81it/s, loss=0.13, lr=0.002] \n",
      "Steps:  99%|█████████▉| 2976/3000 [18:54<00:08,  2.85it/s, loss=0.0981, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2977/3000 [18:55<00:08,  2.85it/s, loss=0.127, lr=0.002] \n",
      "Steps:  99%|█████████▉| 2978/3000 [18:55<00:07,  2.84it/s, loss=0.173, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2979/3000 [18:55<00:07,  2.84it/s, loss=0.0348, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2980/3000 [18:56<00:06,  2.88it/s, loss=0.151, lr=0.002] \n",
      "Steps:  99%|█████████▉| 2981/3000 [18:56<00:06,  2.89it/s, loss=0.0981, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2982/3000 [18:56<00:06,  2.89it/s, loss=0.192, lr=0.002] \n",
      "Steps:  99%|█████████▉| 2983/3000 [18:57<00:05,  2.92it/s, loss=0.115, lr=0.002]\n",
      "Steps:  99%|█████████▉| 2984/3000 [18:57<00:05,  2.87it/s, loss=0.132, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2985/3000 [18:57<00:05,  2.87it/s, loss=0.0697, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2986/3000 [18:58<00:04,  2.92it/s, loss=0.116, lr=0.002] \n",
      "Steps: 100%|█████████▉| 2987/3000 [18:58<00:04,  2.88it/s, loss=0.116, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2988/3000 [18:58<00:04,  2.87it/s, loss=0.176, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2989/3000 [18:59<00:03,  2.88it/s, loss=0.111, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2990/3000 [18:59<00:03,  2.86it/s, loss=0.101, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2991/3000 [18:59<00:03,  2.87it/s, loss=0.0828, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2992/3000 [19:00<00:02,  2.90it/s, loss=0.221, lr=0.002] \n",
      "Steps: 100%|█████████▉| 2993/3000 [19:00<00:02,  2.88it/s, loss=0.0504, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2994/3000 [19:00<00:02,  2.90it/s, loss=0.21, lr=0.002]  \n",
      "Steps: 100%|█████████▉| 2995/3000 [19:01<00:01,  2.93it/s, loss=0.11, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2996/3000 [19:01<00:01,  2.91it/s, loss=0.131, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2997/3000 [19:01<00:01,  2.92it/s, loss=0.11, lr=0.002] \n",
      "Steps: 100%|█████████▉| 2998/3000 [19:02<00:00,  2.93it/s, loss=0.0912, lr=0.002]\n",
      "Steps: 100%|█████████▉| 2999/3000 [19:02<00:00,  2.92it/s, loss=0.0274, lr=0.002]\n",
      "Steps: 100%|██████████| 3000/3000 [19:02<00:00,  3.20it/s, loss=0.0274, lr=0.002]05/09/2024 05:40:23 - INFO - __main__ - Saving embeddings\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:23 - INFO - accelerate.accelerator - Saving current state to /tmp/textual_inversion_cat/checkpoint-3000\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:24 - INFO - accelerate.checkpointing - Model weights saved in /tmp/textual_inversion_cat/checkpoint-3000/model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:25 - INFO - accelerate.checkpointing - Optimizer state saved in /tmp/textual_inversion_cat/checkpoint-3000/optimizer.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:25 - INFO - accelerate.checkpointing - Scheduler state saved in /tmp/textual_inversion_cat/checkpoint-3000/scheduler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /tmp/textual_inversion_cat/checkpoint-3000/sampler.bin\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:25 - INFO - accelerate.checkpointing - Random states saved in /tmp/textual_inversion_cat/checkpoint-3000/random_states_0.pkl\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:25 - INFO - __main__ - Saved state to /tmp/textual_inversion_cat/checkpoint-3000\n",
      "Steps: 100%|██████████| 3000/3000 [19:04<00:00,  3.20it/s, loss=0.0261, lr=0.002]05/09/2024 05:40:25 - INFO - __main__ - Throughput = 11.083350060523712 samples/s\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:25 - INFO - __main__ - Train runtime = 1081.622427743976 seconds\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m /usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m {'use_habana', 'requires_safety_checker', 'image_encoder', 'use_hpu_graphs', 'gaudi_config', 'bf16_full_eval'} was not found in config. Values will be initialized to default values.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m \n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m \n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 26.90it/s]\u001b[A\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m [INFO|pipeline_utils.py:193] 2024-05-09 05:40:25,683 >> Running on CPU.\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Configuration saved in /tmp/textual_inversion_cat/vae/config.json\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Model weights saved in /tmp/textual_inversion_cat/vae/diffusion_pytorch_model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Configuration saved in /tmp/textual_inversion_cat/unet/config.json\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Model weights saved in /tmp/textual_inversion_cat/unet/diffusion_pytorch_model.safetensors\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Configuration saved in /tmp/textual_inversion_cat/scheduler/scheduler_config.json\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m Configuration saved in /tmp/textual_inversion_cat/model_index.json\n",
      "\u001b[36m(RayTrainWorker pid=15683)\u001b[0m 05/09/2024 05:40:31 - INFO - __main__ - Saving embeddings\n",
      "Steps: 100%|██████████| 3000/3000 [19:10<00:00,  2.61it/s, loss=0.0261, lr=0.002]\n",
      "\n",
      "Training completed after 0 iterations at 2024-05-09 05:40:33. Total running time: 19min 30s\n",
      "2024-05-09 05:40:33,116\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/TorchTrainer_2024-05-09_05-21-02' in 0.0022s.\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python ~/optimum-habana/examples/stable-diffusion/training/textual_inversion.py \\\n",
    "  --pretrained_model_name_or_path runwayml/stable-diffusion-v1-5 \\\n",
    "  --train_data_dir \"/root/cat\" \\\n",
    "  --learnable_property object \\\n",
    "  --placeholder_token \"<cat-toy>\" \\\n",
    "  --initializer_token toy \\\n",
    "  --resolution 512 \\\n",
    "  --train_batch_size 4 \\\n",
    "  --max_train_steps 3000 \\\n",
    "  --learning_rate 5.0e-04 \\\n",
    "  --scale_lr \\\n",
    "  --lr_scheduler constant \\\n",
    "  --lr_warmup_steps 0 \\\n",
    "  --output_dir /tmp/textual_inversion_cat \\\n",
    "  --save_as_full_pipeline \\\n",
    "  --gaudi_config_name Habana/stable-diffusion \\\n",
    "  --throughput_warmup_steps 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of Ray is that it scales easily. In this example, we can easily scale the training to multiple workers by changing `num_workers` in `ScalingConfig`. Torch distributed environment will be automatically initialized in Ray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve the fine-tuned model on Ray\n",
    "Now that we have fine-tuned a Stable Diffusion model, we can serve it for image generation. The code below loads the fine-tuned model and generates an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from optimum.habana.diffusers import GaudiStableDiffusionPipeline\n",
    "model_id = \"/tmp/textual_inversion_cat/\"\n",
    "pipe = GaudiStableDiffusionPipeline.from_pretrained(\n",
    "  model_id,\n",
    "  torch_dtype=torch.bfloat16,\n",
    "  use_habana=True,\n",
    "  use_hpu_graphs=True,\n",
    "  gaudi_config=\"Habana/stable-diffusion\",\n",
    ")\n",
    "prompt = \"A <cat-toy> backpack\"\n",
    "image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "image.save(\"cat-backpack.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily use Ray Serve to deploy it as an HTTP service. The code below is modified from this [example](https://docs.ray.io/en/master/serve/tutorials/stable-diffusion.html). Save it to `gaudi_sd_deploy.py`, and use `serve run gaudi_sd_deploy:entrypoint` to start the Serve application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from optimum.habana.diffusers import GaudiStableDiffusionPipeline\n",
    "from io import BytesIO\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import Response\n",
    "\n",
    "from ray import serve\n",
    "from ray.serve.handle import DeploymentHandle\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "@serve.deployment(num_replicas=1)\n",
    "@serve.ingress(app)\n",
    "class APIIngress:\n",
    "    def __init__(self, diffusion_model_handle: DeploymentHandle) -> None:\n",
    "        self.handle = diffusion_model_handle\n",
    "\n",
    "    @app.get(\n",
    "        \"/imagine\",\n",
    "        responses={200: {\"content\": {\"image/png\": {}}}},\n",
    "        response_class=Response,\n",
    "    )\n",
    "    async def generate(self, prompt: str, img_size: int = 512):\n",
    "        assert len(prompt), \"prompt parameter cannot be empty\"\n",
    "\n",
    "        image = await self.handle.generate.remote(prompt, img_size=img_size)\n",
    "        file_stream = BytesIO()\n",
    "        image.save(file_stream, \"PNG\")\n",
    "        return Response(content=file_stream.getvalue(), media_type=\"image/png\")\n",
    "\n",
    "\n",
    "@serve.deployment(\n",
    "    ray_actor_options={\"resources\": {\"HPU\": 1}}\n",
    ")\n",
    "class GaudiStableDiffusion:\n",
    "    def __init__(self, model_id):\n",
    "        self.pipe = GaudiStableDiffusionPipeline.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            use_habana=True,\n",
    "            use_hpu_graphs=True,\n",
    "            gaudi_config=\"Habana/stable-diffusion\",\n",
    "        )\n",
    "\n",
    "    def generate(self, prompt: str, img_size: int = 512):\n",
    "        assert len(prompt), \"prompt parameter cannot be empty\"\n",
    "\n",
    "        image = self.pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "\t\treturn image\n",
    "\n",
    "\n",
    "entrypoint = APIIngress.bind(GaudiStableDiffusion.bind(\"/tmp/textual_inversion_cat/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you successfully deployed this Serve application, run the code below to generate an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "prompt = \"a <cat-toy> is dancing on the grass.\"\n",
    "input = \"%20\".join(prompt.split(\" \"))\n",
    "resp = requests.get(f\"http://127.0.0.1:8000/imagine?prompt={input}\")\n",
    "with open(\"output.png\", 'wb') as f:\n",
    "    f.write(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example image: ![output](link to image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
