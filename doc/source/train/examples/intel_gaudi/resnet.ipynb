{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(hpu_resnet_training)=\n",
    "# ResNet Model Training with Intel Gaudi\n",
    "\n",
    "<a id=\"try-anyscale-quickstart-intel_gaudi-resnet\" href=\"https://console.anyscale.com/register/ha?render_flow=ray&utm_source=ray_docs&utm_medium=docs&utm_campaign=intel_gaudi-resnet\">\n",
    "    <img src=\"../../../_static/img/run-on-anyscale.svg\" alt=\"try-anyscale-quickstart\">\n",
    "</a>\n",
    "<br></br>\n",
    "\n",
    "In this Jupyter notebook, we will train a ResNet-50 model to classify images of ants and bees using HPU. We will use PyTorch for model training and Ray for distributed training. The dataset will be downloaded and processed using torchvision's datasets and transforms.\n",
    "\n",
    "[Intel Gaudi AI Processors (HPUs)](https://habana.ai) are AI hardware accelerators designed by Intel Habana Labs. For more information, see [Gaudi Architecture](https://docs.habana.ai/en/latest/Gaudi_Overview/index.html) and [Gaudi Developer Docs](https://developer.habana.ai/).\n",
    "\n",
    "## Configuration\n",
    "\n",
    "A node with Gaudi/Gaudi2 installed is required to run this example. Both Gaudi and Gaudi2 have 8 HPUs. We will use 2 workers to train the model, each using 1 HPU.\n",
    "\n",
    "We recommend using a prebuilt container to run these examples. To run a container, you need Docker. See [Install Docker Engine](https://docs.docker.com/engine/install/) for installation instructions.\n",
    "\n",
    "Next, follow [Run Using Containers](https://docs.habana.ai/en/latest/Installation_Guide/Bare_Metal_Fresh_OS.html?highlight=installer#run-using-containers) to install the Gaudi drivers and container runtime.\n",
    "\n",
    "Next, start the Gaudi container:\n",
    "```bash\n",
    "docker pull vault.habana.ai/gaudi-docker/1.22.1/ubuntu24.04/habanalabs/pytorch-installer-2.7.1:latest\n",
    "docker run -it --runtime=habana -e HABANA_VISIBLE_DEVICES=all -e OMPI_MCA_btl_vader_single_copy_mechanism=none --cap-add=sys_nice --net=host --ipc=host vault.habana.ai/gaudi-docker/1.22.1/ubuntu24.04/habanalabs/pytorch-installer-2.7.1:latest\n",
    "```\n",
    "\n",
    "Inside the container, install Ray and Jupyter to run this notebook.\n",
    "```bash\n",
    "pip install ray[train] notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import torch\n",
    "from filelock import FileLock\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ray\n",
    "import ray.train as train\n",
    "from ray.train import ScalingConfig, Checkpoint\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train.torch import TorchConfig\n",
    "from ray.runtime_env import RuntimeEnv\n",
    "\n",
    "import habana_frameworks.torch.core as htcore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Transforms\n",
    "\n",
    "We will set up the data transforms for preprocessing images for training and validation. This includes random cropping, flipping, and normalization for the training set, and resizing and normalization for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download Function\n",
    "\n",
    "We will define a function to download the Hymenoptera dataset. This dataset contains images of ants and bees for a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_datasets():\n",
    "    os.system(\"wget https://download.pytorch.org/tutorial/hymenoptera_data.zip >/dev/null 2>&1\")\n",
    "    os.system(\"unzip hymenoptera_data.zip >/dev/null 2>&1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation Function\n",
    "\n",
    "After downloading the dataset, we need to build PyTorch datasets for training and validation. The `build_datasets` function will apply the previously defined transforms and create the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets():\n",
    "    torch_datasets = {}\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        torch_datasets[split] = datasets.ImageFolder(\n",
    "            os.path.join(\"./hymenoptera_data\", split), data_transforms[split]\n",
    "        )\n",
    "    return torch_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization Functions\n",
    "\n",
    "We will define two functions to initialize our model. The `initialize_model` function will load a pre-trained ResNet-50 model and replace the final classification layer for our binary classification task. The `initialize_model_from_checkpoint` function will load a model from a saved checkpoint if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    # Load pretrained model params\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Replace the original classifier with a new Linear layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "    # Ensure all params get updated during finetuning\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function\n",
    "\n",
    "To assess the performance of our model during training, we define an `evaluate` function. This function computes the number of correct predictions by comparing the predicted labels with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(logits, labels):\n",
    "    _, preds = torch.max(logits, 1)\n",
    "    corrects = torch.sum(preds == labels).item()\n",
    "    return corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop Function\n",
    "\n",
    "This function defines the training loop that will be executed by each worker. It includes downloading the dataset, preparing data loaders, initializing the model, and running the training and validation phases. Compared to a training function for GPU, no changes are needed to port to HPU. Internally, Ray Train does these things:\n",
    "\n",
    "* Detect HPU and set the device.\n",
    "\n",
    "* Initializes the habana PyTorch backend.\n",
    "\n",
    "* Initializes the habana distributed backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_per_worker(configs):\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Calculate the batch size for a single worker\n",
    "    worker_batch_size = configs[\"batch_size\"] // train.get_context().get_world_size()\n",
    "\n",
    "    # Download dataset once on local rank 0 worker\n",
    "    if train.get_context().get_local_rank() == 0:\n",
    "        download_datasets()\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "    # Build datasets on each worker\n",
    "    torch_datasets = build_datasets()\n",
    "\n",
    "    # Prepare dataloader for each worker\n",
    "    dataloaders = dict()\n",
    "    dataloaders[\"train\"] = DataLoader(\n",
    "        torch_datasets[\"train\"], batch_size=worker_batch_size, shuffle=True\n",
    "    )\n",
    "    dataloaders[\"val\"] = DataLoader(\n",
    "        torch_datasets[\"val\"], batch_size=worker_batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Distribute\n",
    "    dataloaders[\"train\"] = train.torch.prepare_data_loader(dataloaders[\"train\"])\n",
    "    dataloaders[\"val\"] = train.torch.prepare_data_loader(dataloaders[\"val\"])\n",
    "\n",
    "    # Obtain HPU device automatically\n",
    "    device = train.torch.get_device()\n",
    "\n",
    "    # Prepare DDP Model, optimizer, and loss function\n",
    "    model = initialize_model()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=configs[\"lr\"], momentum=configs[\"momentum\"]\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Start training loops\n",
    "    for epoch in range(configs[\"num_epochs\"]):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # calculate statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += evaluate(outputs, labels)\n",
    "\n",
    "            size = len(torch_datasets[phase]) // train.get_context().get_world_size()\n",
    "            epoch_loss = running_loss / size\n",
    "            epoch_acc = running_corrects / size\n",
    "\n",
    "            if train.get_context().get_world_rank() == 0:\n",
    "                print(\n",
    "                    \"Epoch {}-{} Loss: {:.4f} Acc: {:.4f}\".format(\n",
    "                        epoch, phase, epoch_loss, epoch_acc\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Report metrics and checkpoint every epoch\n",
    "            if phase == \"val\":\n",
    "                train.report(\n",
    "                    metrics={\"loss\": epoch_loss, \"acc\": epoch_acc},\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Function\n",
    "\n",
    "The `train_resnet` function sets up the distributed training environment using Ray and starts the training process. It specifies the batch size, number of epochs, learning rate, and momentum for the SGD optimizer. To enable training using HPU, we only need to make the following changes:\n",
    "* Require an HPU for each worker in ScalingConfig\n",
    "* Set backend to \"hccl\" in TorchConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(num_workers=2):\n",
    "    global_batch_size = 16\n",
    "\n",
    "    train_loop_config = {\n",
    "        \"input_size\": 224,  # Input image size (224 x 224)\n",
    "        \"batch_size\": 32,  # Batch size for training\n",
    "        \"num_epochs\": 10,  # Number of epochs to train for\n",
    "        \"lr\": 0.001,  # Learning Rate\n",
    "        \"momentum\": 0.9,  # SGD optimizer momentum\n",
    "    }\n",
    "    # Configure computation resources\n",
    "    # In ScalingConfig, require an HPU for each worker\n",
    "    scaling_config = ScalingConfig(num_workers=num_workers, resources_per_worker={\"CPU\": 1, \"HPU\": 1})\n",
    "    # Set backend to hccl in TorchConfig\n",
    "    torch_config = TorchConfig(backend = \"hccl\")\n",
    "    \n",
    "    # Workaround https://github.com/ray-project/ray/issues/45302 by explictly setting HPU resource\n",
    "    ray.init(resources={\"HPU\": 8})\n",
    "    \n",
    "    # Initialize a Ray TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_loop_per_worker,\n",
    "        train_loop_config=train_loop_config,\n",
    "        torch_config=torch_config,\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "\n",
    "    result = trainer.fit()\n",
    "    print(f\"Training result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "Finally, we call the `train_resnet` function to start the training process. You can adjust the number of workers to use. Before running this cell, ensure that Ray is properly set up in your environment to handle distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%env PT_HPU_LAZY_MODE=1\n",
    "train_resnet(num_workers=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible outputs\n",
    "\n",
    "``` text\n",
    "env: PT_HPU_LAZY_MODE=1\n",
    "2025-11-19 23:26:40,364\tINFO worker.py:2012 -- Started a local Ray instance.\n",
    "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
    "  warnings.warn(\n",
    "(TrainController pid=10012) Attempting to start training worker group of size 2 with the following resources: [{'CPU': 1, 'HPU': 1}] * 2\n",
    "(RayTrainWorker pid=10466) Setting up process group for: env:// [rank=0, world_size=2]\n",
    "(TrainController pid=10012) Started training worker group of size 2: \n",
    "(TrainController pid=10012) - (ip=100.83.67.100, pid=10466) world_rank=0, local_rank=0, node_rank=0\n",
    "(TrainController pid=10012) - (ip=100.83.67.100, pid=10465) world_rank=1, local_rank=1, node_rank=0\n",
    "(RayTrainWorker pid=10466) ============================= HPU PT BRIDGE CONFIGURATION ON RANK = 0 ============= \n",
    "(RayTrainWorker pid=10466)  PT_HPU_LAZY_MODE = 1\n",
    "(RayTrainWorker pid=10466)  PT_HPU_RECIPE_CACHE_CONFIG = ,false,1024,false\n",
    "(RayTrainWorker pid=10466)  PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
    "(RayTrainWorker pid=10466)  PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
    "(RayTrainWorker pid=10466)  PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
    "(RayTrainWorker pid=10466)  PT_HPU_EAGER_PIPELINE_ENABLE = 1\n",
    "(RayTrainWorker pid=10466)  PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1\n",
    "(RayTrainWorker pid=10466)  PT_HPU_ENABLE_LAZY_COLLECTIVES = 0\n",
    "(RayTrainWorker pid=10466) ---------------------------: System Configuration :---------------------------\n",
    "(RayTrainWorker pid=10466) Num CPU Cores : 160\n",
    "(RayTrainWorker pid=10466) CPU RAM       : 1007 GB\n",
    "(RayTrainWorker pid=10466) ------------------------------------------------------------------------------\n",
    "  0%|          | 0.00/97.8M [00:00<?, ?B/s]\n",
    " 13%|█▎        | 12.5M/97.8M [00:00<00:00, 126MB/s]\n",
    "(RayTrainWorker pid=10465) Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
    "100%|██████████| 97.8M/97.8M [00:00<00:00, 251MB/s]\n",
    "100%|██████████| 97.8M/97.8M [00:00<00:00, 247MB/s]\n",
    "(pid=gcs_server) [2025-11-19 23:27:08,208 E 135 135] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(raylet) [2025-11-19 23:27:10,279 E 436 436] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(pid=571) [2025-11-19 23:27:14,208 E 571 1215] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "  0%|          | 0.00/97.8M [00:00<?, ?B/s]\n",
    " 55%|█████▌    | 53.9M/97.8M [00:00<00:00, 222MB/s]  [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\n",
    "[2025-11-19 23:27:15,493 E 52 563] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(RayTrainWorker pid=10466) Epoch 0-train Loss: 0.6561 Acc: 0.6230\n",
    "(RayTrainWorker pid=10466) Epoch 0-val Loss: 0.5295 Acc: 0.6447\n",
    "(RayTrainWorker pid=10465) Reporting training result 1: TrainingReport(checkpoint=None, metrics={'loss': 0.6530329294894871, 'acc': 0.5394736842105263}, validation_spec=None)\n",
    "(RayTrainWorker pid=10466) Epoch 1-train Loss: 0.5024 Acc: 0.7459\n",
    "(RayTrainWorker pid=10466) Epoch 1-val Loss: 0.3141 Acc: 0.9474\n",
    "(RayTrainWorker pid=10466) Epoch 2-train Loss: 0.3223 Acc: 0.9344\n",
    "(TrainController pid=10012) [2025-11-19 23:27:18,259 E 10012 10052] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14 [repeated 157x across cluster]\n",
    "(RayTrainWorker pid=10466) Epoch 2-val Loss: 0.2315 Acc: 0.9474\n",
    "(RayTrainWorker pid=10466) Epoch 3-train Loss: 0.2607 Acc: 0.9426\n",
    "(RayTrainWorker pid=10466) Epoch 3-val Loss: 0.1912 Acc: 0.9605\n",
    "(RayTrainWorker pid=10466) Epoch 4-train Loss: 0.1582 Acc: 0.9672\n",
    "(RayTrainWorker pid=10466) Reporting training result 4: TrainingReport(checkpoint=None, metrics={'loss': 0.19123821666366175, 'acc': 0.9605263157894737}, validation_spec=None) [repeated 7x across cluster]\n",
    "(RayTrainWorker pid=10466) Epoch 4-val Loss: 0.1681 Acc: 0.9474\n",
    "(bundle_reservation_check_func pid=10281) [2025-11-19 23:27:24,784 E 10281 10400] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(RayTrainWorker pid=10466) Epoch 5-train Loss: 0.1454 Acc: 0.9590\n",
    "(RayTrainWorker pid=10466) Epoch 5-val Loss: 0.1510 Acc: 0.9737\n",
    "(RayTrainWorker pid=10466) Epoch 6-train Loss: 0.1103 Acc: 0.9836\n",
    "(RayTrainWorker pid=10466) Epoch 6-val Loss: 0.1436 Acc: 0.9605\n",
    "(RayTrainWorker pid=10465) [2025-11-19 23:27:27,666 E 10465 10664] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(RayTrainWorker pid=10466) Epoch 7-train Loss: 0.1021 Acc: 0.9836\n",
    "(RayTrainWorker pid=10466) Reporting training result 7: TrainingReport(checkpoint=None, metrics={'loss': 0.14356592101486107, 'acc': 0.9605263157894737}, validation_spec=None) [repeated 6x across cluster]\n",
    "(RayTrainWorker pid=10466) Epoch 7-val Loss: 0.1382 Acc: 0.9605\n",
    "(RayTrainWorker pid=10466) Epoch 8-train Loss: 0.0715 Acc: 0.9918\n",
    "(RayTrainWorker pid=10466) Epoch 8-val Loss: 0.1396 Acc: 0.9737\n",
    "(RayTrainWorker pid=10466) Epoch 9-train Loss: 0.0874 Acc: 0.9672\n",
    "(RayTrainWorker pid=10466) [2025-11-19 23:27:27,646 E 10466 10580] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14 [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=10466) Epoch 9-val Loss: 0.1374 Acc: 0.9737\n",
    "Training result: Result(metrics=None, checkpoint=None, error=None, path='/root/ray_results/ray_train_run-2025-11-19_23-26-45', metrics_dataframe=None, best_checkpoints=[], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x7f6e6e587c70>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orphan": true,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
