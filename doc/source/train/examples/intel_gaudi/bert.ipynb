{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(hpu_bert_training)=\n",
    "# BERT Model Training with Intel Gaudi\n",
    "\n",
    "<a id=\"try-anyscale-quickstart-intel_gaudi-bert\" href=\"https://console.anyscale.com/register/ha?render_flow=ray&utm_source=ray_docs&utm_medium=docs&utm_campaign=intel_gaudi-bert\">\n",
    "    <img src=\"../../../_static/img/run-on-anyscale.svg\" alt=\"try-anyscale-quickstart\">\n",
    "</a>\n",
    "<br></br>\n",
    "\n",
    "In this notebook, we will train a BERT model for sequence classification using the Yelp review full dataset. We will use the `transformers` and `datasets` libraries from Hugging Face, along with `ray.train` for distributed training.\n",
    "\n",
    "[Intel Gaudi AI Processors (HPUs)](https://habana.ai) are AI hardware accelerators designed by Intel Habana Labs. For more information, see [Gaudi Architecture](https://docs.habana.ai/en/latest/Gaudi_Overview/index.html) and [Gaudi Developer Docs](https://developer.habana.ai/).\n",
    "\n",
    "## Configuration\n",
    "\n",
    "A node with Gaudi/Gaudi2 installed is required to run this example. Both Gaudi and Gaudi2 have 8 HPUs. We will use 2 workers to train the model, each using 1 HPU.\n",
    "\n",
    "We recommend using a prebuilt container to run these examples. To run a container, you need Docker. See [Install Docker Engine](https://docs.docker.com/engine/install/) for installation instructions.\n",
    "\n",
    "Next, follow [Run Using Containers](https://docs.habana.ai/en/latest/Installation_Guide/Bare_Metal_Fresh_OS.html?highlight=installer#run-using-containers) to install the Gaudi drivers and container runtime.\n",
    "\n",
    "Next, start the Gaudi container:\n",
    "```bash\n",
    "docker pull vault.habana.ai/gaudi-docker/1.22.1/ubuntu24.04/habanalabs/pytorch-installer-2.7.1:latest\n",
    "docker run -it --runtime=habana -e HABANA_VISIBLE_DEVICES=all -e OMPI_MCA_btl_vader_single_copy_mechanism=none --cap-add=sys_nice --net=host --ipc=host vault.habana.ai/gaudi-docker/1.22.1/ubuntu24.04/habanalabs/pytorch-installer-2.7.1:latest\n",
    "```\n",
    "\n",
    "Inside the container, install the following dependencies to run this notebook.\n",
    "```bash\n",
    "pip install ray[train] notebook transformers datasets evaluate scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "import ray.train\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train.torch import TorchConfig\n",
    "from ray.runtime_env import RuntimeEnv\n",
    "\n",
    "import habana_frameworks.torch.core as htcore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Setup\n",
    "\n",
    "We will use accuracy as our evaluation metric. The `compute_metrics` function will calculate the accuracy of our model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "This function will be executed by each worker during training. It handles data loading, tokenization, model initialization, and the training loop. Compared to a training function for GPU, no changes are needed to port to HPU. Internally, Ray Train does these things:\n",
    "\n",
    "* Detect HPU and set the device.\n",
    "\n",
    "* Initializes the habana PyTorch backend.\n",
    "\n",
    "* Initializes the habana distributed backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func_per_worker(config: Dict):\n",
    "    \n",
    "    # Datasets\n",
    "    dataset = load_dataset(\"yelp_review_full\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    batch_size = config[\"batch_size_per_worker\"]\n",
    "\n",
    "    train_dataset = dataset[\"train\"].select(range(1000)).map(tokenize_function, batched=True)\n",
    "    eval_dataset = dataset[\"test\"].select(range(1000)).map(tokenize_function, batched=True)\n",
    "\n",
    "    # Prepare dataloader for each worker\n",
    "    dataloaders = {}\n",
    "    dataloaders[\"train\"] = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        shuffle=True, \n",
    "        collate_fn=transformers.default_data_collator, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    dataloaders[\"test\"] = torch.utils.data.DataLoader(\n",
    "        eval_dataset, \n",
    "        shuffle=True, \n",
    "        collate_fn=transformers.default_data_collator, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Obtain HPU device automatically\n",
    "    device = ray.train.torch.get_device()\n",
    "\n",
    "    # Prepare model and optimizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-cased\", num_labels=5\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    # Start training loops\n",
    "    for epoch in range(epochs):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            # breakpoint()\n",
    "            for batch  in dataloaders[phase]:\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    \n",
    "                    outputs = model(**batch)\n",
    "                    loss = outputs.loss\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        print(f\"train epoch:[{epoch}]\\tloss:{loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Function\n",
    "\n",
    "The `train_bert` function sets up the distributed training environment using Ray and starts the training process. To enable training using HPU, we only need to make the following changes:\n",
    "* Require an HPU for each worker in ScalingConfig\n",
    "* Set backend to \"hccl\" in TorchConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(num_workers=2):\n",
    "    global_batch_size = 8\n",
    "\n",
    "    train_config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size_per_worker\": global_batch_size // num_workers,\n",
    "    }\n",
    "\n",
    "    # Configure computation resources\n",
    "    # In ScalingConfig, require an HPU for each worker\n",
    "    scaling_config = ScalingConfig(num_workers=num_workers, resources_per_worker={\"CPU\": 1, \"HPU\": 1})\n",
    "    # Set backend to hccl in TorchConfig\n",
    "    torch_config = TorchConfig(backend = \"hccl\")\n",
    "    \n",
    "    # Start your ray cluster\n",
    "    # Workaround https://github.com/ray-project/ray/issues/45302 by explictly setting HPU resource\n",
    "    ray.init(resources={\"HPU\": 8})\n",
    "    \n",
    "    # Initialize a Ray TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_func_per_worker,\n",
    "        train_loop_config=train_config,\n",
    "        torch_config=torch_config,\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "\n",
    "    result = trainer.fit()\n",
    "    print(f\"Training result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "Finally, we call the `train_bert` function to start the training process. You can adjust the number of workers to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert(num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible outputs\n",
    "\n",
    "``` text\n",
    "2025-11-17 22:15:24,256\tINFO worker.py:2012 -- Started a local Ray instance.\n",
    "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
    "  warnings.warn(\n",
    "(TrainController pid=87725) Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(TrainController pid=87725) Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(TrainController pid=87725) Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(TrainController pid=87725) Attempting to start training worker group of size 2 with the following resources: [{'CPU': 1, 'HPU': 1}] * 2\n",
    "(RayTrainWorker pid=88179) Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(RayTrainWorker pid=88179) Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(RayTrainWorker pid=88179) Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(RayTrainWorker pid=88178) Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(RayTrainWorker pid=88178) Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(RayTrainWorker pid=88178) Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
    "(RayTrainWorker pid=88178) Setting up process group for: env:// [rank=0, world_size=2]\n",
    "(TrainController pid=87725) Started training worker group of size 2: \n",
    "(TrainController pid=87725) - (ip=100.83.67.100, pid=88178) world_rank=0, local_rank=0, node_rank=0\n",
    "(TrainController pid=87725) - (ip=100.83.67.100, pid=88179) world_rank=1, local_rank=1, node_rank=0\n",
    "(RayTrainWorker pid=88179)               0 COPY_FREE_VARS           1\n",
    "(RayTrainWorker pid=88179) \n",
    "(RayTrainWorker pid=88179)   7           2 RESUME                   0\n",
    "(RayTrainWorker pid=88179) \n",
    "(RayTrainWorker pid=88179)   8           4 PUSH_NULL\n",
    "(RayTrainWorker pid=88179)               6 LOAD_DEREF               1 (tokenizer)\n",
    "(RayTrainWorker pid=88179)               8 LOAD_FAST                0 (examples)\n",
    "(RayTrainWorker pid=88179)              10 LOAD_CONST               1 ('text')\n",
    "(RayTrainWorker pid=88179)              12 BINARY_SUBSCR\n",
    "(RayTrainWorker pid=88179)              16 LOAD_CONST               2 ('max_length')\n",
    "(RayTrainWorker pid=88179)              18 LOAD_CONST               3 (True)\n",
    "(RayTrainWorker pid=88179)              20 KW_NAMES                 4 (('padding', 'truncation'))\n",
    "(RayTrainWorker pid=88179)              22 CALL                     3\n",
    "(RayTrainWorker pid=88179)              30 RETURN_VALUE\n",
    "(RayTrainWorker pid=88179)               0 COPY_FREE_VARS           1\n",
    "(RayTrainWorker pid=88179) \n",
    "(RayTrainWorker pid=88179)   7           2 RESUME                   0\n",
    "(RayTrainWorker pid=88179) \n",
    "(RayTrainWorker pid=88179)   8           4 PUSH_NULL\n",
    "(RayTrainWorker pid=88179)               6 LOAD_DEREF               1 (tokenizer)\n",
    "(RayTrainWorker pid=88179)               8 LOAD_FAST                0 (examples)\n",
    "(RayTrainWorker pid=88179)              10 LOAD_CONST               1 ('text')\n",
    "(RayTrainWorker pid=88179)              12 BINARY_SUBSCR\n",
    "(RayTrainWorker pid=88179)              16 LOAD_CONST               2 ('max_length')\n",
    "(RayTrainWorker pid=88179)              18 LOAD_CONST               3 (True)\n",
    "(RayTrainWorker pid=88179)              20 KW_NAMES                 4 (('padding', 'truncation'))\n",
    "(RayTrainWorker pid=88179)              22 CALL                     3\n",
    "(RayTrainWorker pid=88179)              30 RETURN_VALUE\n",
    "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]\n",
    "(RayTrainWorker pid=88178) \n",
    "(RayTrainWorker pid=88178) \n",
    "(RayTrainWorker pid=88178) \n",
    "(RayTrainWorker pid=88178) \n",
    "Map: 100%|██████████| 1000/1000 [00:00<00:00, 4032.52 examples/s]\n",
    "(RayTrainWorker pid=88179) Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
    "(RayTrainWorker pid=88179) You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "(pid=gcs_server) [2025-11-17 22:15:52,392 E 77855 77855] (gcs_server) gcs_server.cc:302: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(RayTrainWorker pid=88178) ============================= HPU PT BRIDGE CONFIGURATION ON RANK = 0 ============= \n",
    "(RayTrainWorker pid=88178)  PT_HPU_LAZY_MODE = 0\n",
    "(RayTrainWorker pid=88178)  PT_HPU_RECIPE_CACHE_CONFIG = ,false,1024,false\n",
    "(RayTrainWorker pid=88178)  PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
    "(RayTrainWorker pid=88178)  PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
    "(RayTrainWorker pid=88178)  PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
    "(RayTrainWorker pid=88178)  PT_HPU_EAGER_PIPELINE_ENABLE = 1\n",
    "(RayTrainWorker pid=88178)  PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1\n",
    "(RayTrainWorker pid=88178)  PT_HPU_ENABLE_LAZY_COLLECTIVES = 0\n",
    "(RayTrainWorker pid=88178) ---------------------------: System Configuration :---------------------------\n",
    "(RayTrainWorker pid=88178) Num CPU Cores : 160\n",
    "(RayTrainWorker pid=88178) CPU RAM       : 1007 GB\n",
    "(RayTrainWorker pid=88178) ------------------------------------------------------------------------------\n",
    "(RayTrainWorker pid=88179) train epoch:[0]\tloss:2.253497\n",
    "(RayTrainWorker pid=88179) train epoch:[0]\tloss:1.718906\n",
    "(raylet) [2025-11-17 22:15:54,166 E 78148 78148] (raylet) main.cc:975: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(RayTrainWorker pid=88178)               0 COPY_FREE_VARS           1 [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\n",
    "(RayTrainWorker pid=88178)   7           2 RESUME                   0 [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)   8           4 PUSH_NULL [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)               6 LOAD_DEREF               1 (tokenizer) [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)               8 LOAD_FAST                0 (examples) [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)              10 LOAD_CONST               1 ('text') [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)              12 BINARY_SUBSCR [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)              16 LOAD_CONST               2 ('max_length') [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)              18 LOAD_CONST               3 (True) [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)              20 KW_NAMES                 4 (('padding', 'truncation')) [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)              22 CALL                     3 [repeated 2x across cluster]\n",
    "(RayTrainWorker pid=88178)              30 RETURN_VALUE [repeated 2x across cluster]\n",
    "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]\n",
    "Map: 100%|██████████| 1000/1000 [00:00<00:00, 4351.62 examples/s]\n",
    "(RayTrainWorker pid=88178) Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
    "(RayTrainWorker pid=88178) You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "(pid=78279) [2025-11-17 22:15:58,103 E 78279 78722] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(RayTrainWorker pid=88179) train epoch:[0]\tloss:1.546598 [repeated 146x across cluster]\n",
    "[2025-11-17 22:15:59,457 E 77711 78275] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(TrainController pid=87725) [2025-11-17 22:16:02,243 E 87725 87764] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14 [repeated 157x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[0]\tloss:1.599180 [repeated 151x across cluster]\n",
    "(bundle_reservation_check_func pid=87994) [2025-11-17 22:16:08,707 E 87994 88113] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
    "(RayTrainWorker pid=88179) train epoch:[0]\tloss:1.554767 [repeated 145x across cluster]\n",
    "(RayTrainWorker pid=88178) [2025-11-17 22:16:11,577 E 88178 88342] core_worker_process.cc:825: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14 [repeated 3x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[1]\tloss:1.579086 [repeated 58x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[1]\tloss:1.228644 [repeated 136x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[1]\tloss:1.458077 [repeated 158x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[1]\tloss:1.093389 [repeated 155x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[2]\tloss:1.557385 [repeated 75x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[2]\tloss:1.406001 [repeated 111x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[2]\tloss:1.225072 [repeated 146x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[2]\tloss:1.274225 [repeated 147x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[3]\tloss:1.091613 [repeated 93x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[3]\tloss:1.352153 [repeated 100x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[3]\tloss:1.706026 [repeated 156x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[3]\tloss:2.390724 [repeated 149x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[4]\tloss:0.666302 [repeated 106x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[4]\tloss:1.550435 [repeated 100x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[4]\tloss:0.650674 [repeated 162x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[4]\tloss:2.413051 [repeated 116x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[5]\tloss:1.099013 [repeated 140x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[5]\tloss:1.775257 [repeated 103x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[5]\tloss:0.800103 [repeated 159x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[6]\tloss:0.799364 [repeated 103x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[6]\tloss:0.831640 [repeated 160x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[6]\tloss:0.791100 [repeated 101x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[6]\tloss:1.881995 [repeated 152x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[7]\tloss:0.614887 [repeated 102x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[7]\tloss:0.568946 [repeated 145x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[7]\tloss:1.241300 [repeated 108x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[7]\tloss:1.521225 [repeated 126x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[8]\tloss:1.929299 [repeated 110x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[8]\tloss:0.744064 [repeated 162x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[8]\tloss:0.533718 [repeated 114x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[8]\tloss:1.589755 [repeated 118x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[9]\tloss:1.681320 [repeated 123x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[9]\tloss:0.482950 [repeated 151x across cluster]\n",
    "(RayTrainWorker pid=88179) train epoch:[9]\tloss:0.122691 [repeated 125x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[9]\tloss:1.464374 [repeated 101x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[9]\tloss:1.761037 [repeated 80x across cluster]\n",
    "(RayTrainWorker pid=88178) train epoch:[9]\tloss:1.560819 [repeated 77x across cluster]\n",
    "Training result: Result(metrics=None, checkpoint=None, error=None, path='/root/ray_results/ray_train_run-2025-11-17_22-15-29', metrics_dataframe=None, best_checkpoints=[], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x7f792c895330>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orphan": true,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
