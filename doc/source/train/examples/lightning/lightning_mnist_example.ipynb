{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning a Pytorch Lightning Image Classifier\n",
    "\n",
    "This example introduces how to train a Pytorch Lightning Module with Ray AIR. We will demonstrate how to train a basic neural network on the MNIST dataset with distributed data parallelism using AIR LightningTrainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import trainer\n",
    "from pytorch_lightning.core import datamodule\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "\n",
    "from ray.air.config import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.lightning import LightningTrainer, LightningConfigBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOKE_TEST = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset and Module\n",
    "\n",
    "The Pytorch Lightning Trainer takes either `torch.utils.data.DataLoader` or `pl.LightningDataModule` as data inputs. You can keep using them without any changes for the Ray AIR LightningTrainer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=100):\n",
    "        super().__init__()\n",
    "        self.data_dir = os.getcwd()\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # split data into train and val sets\n",
    "        mnist = MNIST(\n",
    "            self.data_dir, train=True, download=True, transform=self.transform\n",
    "        )\n",
    "        self.mnist_train, self.mnist_val = random_split(mnist, [55000, 5000])\n",
    "\n",
    "        self.mnist_test = MNIST(\n",
    "            self.data_dir, train=False, download=True, transform=self.transform\n",
    "        )\n",
    "        \n",
    "        if SMOKE_TEST:\n",
    "            self.mnist_train = Subset(self.mnist_train, range(5000))\n",
    "            self.mnist_val = Subset(self.mnist_val, range(1000))\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "datamodule = MNISTDataModule(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a simple multi-layer perception as the subclass of `pl.LightningModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self, lr, feature_dim):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, feature_dim)\n",
    "        self.fc2 = torch.nn.Linear(feature_dim, 10)\n",
    "        self.lr = lr\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        logits = self.forward(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        acc = self.accuracy(logits, y)\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"val_accuracy\"] for x in outputs]).mean()\n",
    "        self.log(\"val_loss\", avg_loss, sync_dist=True)\n",
    "        self.log(\"val_accuracy\", avg_acc, sync_dist=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Cofigurations for AIR LightningTrainer\n",
    "\n",
    "The {meth}`LightningConfigBuilder <ray.train.lightning.LightningConfigBuilder>` class stores all the parameters involved in training a PyTorch Lightning module. It takes the same parameter lists as those in PyTorch Lightning.\n",
    "\n",
    "- The `.module()` method takes a PyTorch Lightning module class and its initialization parameters.\n",
    "- The `.trainer()` method takes the initialization parameters of `ptl.Trainer`. You can specify training configurations, loggers, and callbacks here.\n",
    "- The `.fit_params()` method stores all the parameters that will be passed into `ptl.Trainer.fit()`, including train/val dataloaders, datamodules, and checkpoint paths.\n",
    "- The `.checkpointing()` method saves the configurations for a `ModelCheckpoint` callback. Note that the `LightningTrainer` reports the latest metrics to the AIR session when a new checkpoint is saved.\n",
    "- The `.build()` method converts the configurations into a dictionary that is readable for `LightningTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_config = (\n",
    "    LightningConfigBuilder()\n",
    "    .module(\n",
    "        MNISTClassifier, feature_dim=128, lr=0.001\n",
    "    )\n",
    "    .trainer(max_epochs=7, accelerator=\"cpu\", log_every_n_steps=100, logger=CSVLogger(\"logs\"))\n",
    "    .fit_params(datamodule=datamodule)\n",
    "    .checkpointing(monitor=\"val_accuracy\", mode=\"max\", save_top_k=3)\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_config = ScalingConfig(\n",
    "    num_workers=2, use_gpu=True, resources_per_worker={\"CPU\": 1, \"GPU\": 1}\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    name=\"ptl-mnist-example\",\n",
    "    local_dir=\"/tmp/ray_results\",\n",
    "    checkpoint_config=CheckpointConfig(num_to_keep=3, checkpoint_score_attribute=\"val_accuracy\", checkpoint_score_order=\"max\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SMOKE_TEST:\n",
    "    scaling_config = ScalingConfig(\n",
    "        num_workers=2, use_gpu=False, resources_per_worker={\"CPU\": 1}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LightningTrainer(\n",
    "    lightning_config=lightning_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.fit()\n",
    "print(result)\n",
    "print(result.metrics[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8c1140d108077f4faeb76b2438f85e4ed675f93d004359552883616a1acd54c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
