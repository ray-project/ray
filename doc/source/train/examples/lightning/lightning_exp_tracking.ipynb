{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using W&B, CometML, and MLFlow Logger in LightningTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cluster_storage/pypi/lib/python3.9/site-packages/neptune/common/warnings.py:62: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "from pytorch_lightning.loggers.comet import CometLogger\n",
    "from pytorch_lightning.loggers.mlflow import MLFlowLogger\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create dummy data\n",
    "X = torch.randn(128, 3)  # 128 samples, 3 features\n",
    "y = torch.randint(0, 2, (128,))  # 128 binary labels\n",
    "\n",
    "# create a TensorDataset to wrap the data\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# create a DataLoader to iterate over the dataset\n",
    "batch_size = 8\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = torch.nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat.flatten(), y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        self.log_dict({\"batch_idx\": batch_idx, \"random_metric\": 123})\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in offline mode\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.rank_zero import rank_zero_only\n",
    "\n",
    "\n",
    "class WandbLoginCallback(pl.Callback):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def setup(self, trainer, pl_module, stage) -> None:\n",
    "        if self.key:\n",
    "            wandb.login(key=self.key)\n",
    "\n",
    "\n",
    "def create_loggers(name, project_name, save_dir=\"./logs\", offline=False):\n",
    "    # Set the global rank to None to avoid creating\n",
    "    # a new experiment run on the driver.\n",
    "    rank_zero_only.rank = None\n",
    "\n",
    "    # Wandb\n",
    "    wandb_logger = WandbLogger(\n",
    "        name=name,\n",
    "        project=project_name,\n",
    "        save_dir=f\"{save_dir}/wandb\",\n",
    "        offline=offline\n",
    "    )\n",
    "    callbacks = [] if offline else [WandbLoginCallback(key=os.environ.get(\"WANDB_API_KEY\", None))]\n",
    "\n",
    "    # CometML\n",
    "    comet_logger = CometLogger(\n",
    "        api_key=os.environ.get(\"COMET_API_KEY\", None),\n",
    "        experiment_name=name,\n",
    "        project_name=project_name,\n",
    "        save_dir=f\"{save_dir}/comet\",\n",
    "        offline=offline,\n",
    "    )\n",
    "\n",
    "    # MLFlow\n",
    "    mlflow_logger = MLFlowLogger(\n",
    "        run_name=name,\n",
    "        experiment_name=project_name,\n",
    "        save_dir=f\"{save_dir}/mlflow\"\n",
    "    )\n",
    "\n",
    "    # Tensorboard\n",
    "    tensorboard_logger = TensorBoardLogger(\n",
    "        name=name,\n",
    "        save_dir=f\"{save_dir}/tensorboard\"\n",
    "    )\n",
    "\n",
    "    return [wandb_logger, comet_logger, mlflow_logger, tensorboard_logger], callbacks\n",
    "\n",
    "\n",
    "loggers, callbacks = create_loggers(\n",
    "    name=\"demo-run\", project_name=\"demo-project\", offline=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR SMOKE TEST\n",
    "loggers, callbacks = create_loggers(\n",
    "    name=\"demo-run\", project_name=\"demo-project\", offline=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.lightning import LightningConfigBuilder, LightningTrainer\n",
    "\n",
    "builder = LightningConfigBuilder()\n",
    "builder.module(cls=DummyModel)\n",
    "builder.trainer(max_epochs=5, accelerator=\"cpu\", logger=loggers, callbacks=callbacks)\n",
    "builder.fit_params(train_dataloaders=dataloader)\n",
    "lightning_config = builder.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import RunConfig, ScalingConfig\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=4, use_gpu=False)\n",
    "\n",
    "run_config = RunConfig(\n",
    "    name=\"ptl-exp-tracking\",\n",
    "    storage_path=\"/tmp/ray_results\",\n",
    ")\n",
    "\n",
    "trainer = LightningTrainer(\n",
    "    lightning_config=lightning_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "trainer.fit()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
