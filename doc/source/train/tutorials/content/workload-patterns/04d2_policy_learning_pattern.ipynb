{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion policy pattern\n",
    "\n",
    "<div align=\"left\">\n",
    "<a target=\"_blank\" href=\"https://console.anyscale.com/template-preview/ray_train_workloads?file=%252Ffiles%252Fworkload-patterns%252F04d2_policy_learning_pattern.ipynb\"><img src=\"https://img.shields.io/badge/üöÄ Run_on-Anyscale-9hf\"></a>&nbsp;\n",
    "<a href=\"https://github.com/ray-project/ray/tree/master/doc/source/train/tutorials/content/workload-patterns/04d2_policy_learning_pattern.ipynb\" role=\"button\"><img src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
    "</div>\n",
    "\n",
    "This notebook builds a **mini diffusion-policy pipeline** on a **real Pendulum-v1 offline dataset** and runs it end-to-end on an Anyscale cluster with **Ray Train**.\n",
    "\n",
    "## Learning objectives  \n",
    "* How to use **Ray Data** to stream and preprocess Gymnasium rollouts in parallel across CPU workers.  \n",
    "* How to scale training across **multiple A10G GPUs** using `TorchTrainer` with a minimal `LightningModule`.  \n",
    "* How to **checkpoint every epoch** for robust fault tolerance and auto-resume.  \n",
    "* How to log and visualize metrics using **Ray's built-in results and observability tooling**.  \n",
    "* How to generate actions from a trained policy directly in-notebook, with **no need to repackage or redeploy**.  \n",
    "* How to run the full pipeline on **Anyscale Workspaces** with no infrastructure setup or cluster config required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What problem are you solving? (Inverted Pendulum, Diffusion-Style)\n",
    "\n",
    "You‚Äôre training a policy to **swing up and balance an inverted pendulum** ‚Äî a classic control problem.  \n",
    "In the Gym `Pendulum-v1` environment, the agent sees the current state of the pendulum and must decide what **torque** to apply at the pivot.\n",
    "\n",
    "---\n",
    "\n",
    "## What's a policy?\n",
    "\n",
    "A **policy** is a function that maps the current state to an action:\n",
    "\n",
    "$$\n",
    "\\pi_\\theta(s_{k}) \\;\\longrightarrow\\; u_{k}\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- The **state** $s_k$ describes where the pendulum is and how fast it‚Äôs moving  \n",
    "- The **action** $u_k$ is the torque you apply to influence future motion  \n",
    "- The **goal** is to learn a policy that keeps the pendulum upright by generating the right torque at every step\n",
    "\n",
    "---\n",
    "\n",
    "## Environment state and action\n",
    "\n",
    "At each timestep:\n",
    "\n",
    "| Symbol        | Dim    | Meaning                           |\n",
    "|---------------|--------|-----------------------------------|\n",
    "| $\\theta_{k}$    | scalar | Angle of the pendulum             |\n",
    "| $\\dot\\theta_{k}$| scalar | Angular velocity                  |\n",
    "| $u_{k}$         | scalar | Torque applied to the base        |\n",
    "\n",
    "The pendulum starts hanging down and must swing up and maintain balance.\n",
    "\n",
    "Encode the state as:\n",
    "\n",
    "$$\n",
    "s_{k} = [\\cos\\theta_{k},\\ \\sin\\theta_{k},\\ \\dot\\theta_{k}] \\in \\mathbb{R}^3\n",
    "$$\n",
    "\n",
    "This avoids angle discontinuities (no $\\pm\\pi$ jumps) and keeps values in $[-1, 1]$.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dataset tuples\n",
    "\n",
    "Train on a **log of actions** from a random policy, then inject artificial noise to simulate the diffusion process:\n",
    "\n",
    "$$\n",
    "\\varepsilon_{k} \\sim \\mathcal{N}(0, 1), \\quad t_{k} \\sim \\text{Uniform}\\{0,\\dots,T{-}1\\}\n",
    "$$\n",
    "\n",
    "and construct a noisy action:\n",
    "\n",
    "$$\n",
    "\\tilde{u}_k = u_{k} + \\varepsilon_{k}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Training objective\n",
    "\n",
    "Train a model $f_\\theta$ to predict the injected noise, given the state, the noisy action, and the timestep:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathbb{E}_{s_{k},\\varepsilon_k,t_{k}}\\ \\big\\|f_\\theta(s_k, \\tilde{u}_k, t_{k}) - \\varepsilon_k\\big\\|_2^2\n",
    "$$\n",
    "\n",
    "Minimizing this loss teaches the model to **de-noise** $\\tilde{u}_{k}$ back toward the expert action $u_k$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Reverse diffusion (sampling)\n",
    "\n",
    "At inference time, start from noise $x_T \\sim \\mathcal{N}(0, 1)$ and de-noise step by step:\n",
    "\n",
    "$$\n",
    "x_{t} \\;\\leftarrow\\; x_{t} - \\eta \\cdot f_\\theta(s, x_{t}, t), \\quad t = T{-}1, \\dots, 0\n",
    "$$\n",
    "\n",
    "After $T$ steps:\n",
    "\n",
    "$$\n",
    "x_0 \\approx u^\\star\n",
    "$$\n",
    "\n",
    "is a valid torque for the current state ‚Äî a sample from your learned diffusion policy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to scale this policy learning workload using Ray on Anyscale\n",
    "\n",
    "This tutorial shows how to take a **local PyTorch + Gymnasium workflow** and migrate it to a fully **distributed, fault-tolerant Ray pipeline running on Anyscale** with minimal code changes.\n",
    "\n",
    "Here's how the transition works:\n",
    "\n",
    "1. **Gym rollouts ‚Üí Ray Dataset**  \n",
    "   Generate simulation rollouts from `Pendulum-v1` and stream them directly into a **Ray Dataset**, enabling distributed preprocessing (For example, normalization) and automatic partitioning across workers.\n",
    "\n",
    "2. **Local Training ‚Üí Cluster-scale Distributed Training**  \n",
    "   Wrap a minimal `LightningModule` in a Ray Train `train_loop`, then launch training with **TorchTrainer** across eight A10G GPUs. Ray handles data sharding, worker setup, and device placement without boilerplate.\n",
    "\n",
    "3. **Manual State Saving ‚Üí Lightning-Integrated Checkpointing & Auto-Resume**  \n",
    "   Checkpointing and metric tracking are handled automatically by **PyTorch Lightning** and **Ray Train V2**.  \n",
    "   The `RayTrainReportCallback()` forwards Lightning's `checkpoint.ckpt` files and logged metrics to Ray,  \n",
    "   enabling **structured, fault-tolerant training** with seamless resume support. No manual save or report logic required.\n",
    "\n",
    "4. **Ad-hoc Coordination ‚Üí Declarative Orchestration**  \n",
    "   Replace manual logging, retry logic, and resource management with **Ray-native configs** (`ScalingConfig`, `CheckpointConfig`, `FailureConfig`), letting Ray + Anyscale own the orchestration.\n",
    "\n",
    "5. **Notebook-only Inference ‚Üí Cluster-aware Evaluation**  \n",
    "   After training, perform **reverse diffusion sampling** in-notebook using the latest checkpoint‚Äîbut this can easily scale using **Ray Data**.\n",
    "\n",
    "This flow upgrades a local notebook into a **multi-node, resilient training + inference pipeline**, using Ray's native abstractions and running seamlessly inside an Anyscale Workspace, without sacrificing dev agility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and setup\n",
    "\n",
    "Standard scientific-Python stack, plus **Ray** for distributed data/training\n",
    "and **Lightning** for ergonomic model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00. Runtime setup \n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Non-secret env var \n",
    "os.environ[\"RAY_TRAIN_V2_ENABLED\"] = \"1\"\n",
    "\n",
    "# Install Python dependencies \n",
    "!pip install --no-cache-dir lightning==2.5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Imports\n",
    "\n",
    "# Standard Python packages for math, plotting, and data handling\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "import uuid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "\n",
    "# Ray libraries for distributed data and training\n",
    "import ray\n",
    "import ray.data\n",
    "from ray.train.lightning import RayLightningEnvironment  \n",
    "from ray.train import ScalingConfig, RunConfig, FailureConfig, CheckpointConfig, get_context, get_checkpoint, report, Checkpoint\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "# PyTorch Lightning and base PyTorch for model definition and training\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate a real pendulum dataset\n",
    "\n",
    "Roll out a random policy for **10,000 steps**, logging:\n",
    "\n",
    "| field | shape | description |\n",
    "|-------|-------|-------------|\n",
    "| `obs`          | `(3,)`  | `[cos Œ∏, sin Œ∏, Œ∏Ãá]` |\n",
    "| `noisy_action` | `(1,)`  | ground-truth action + Gaussian noise |\n",
    "| `noise`        | `(1,)`  | the injected noise (supervision target) |\n",
    "| `timestep`     | `()`    | random diffusion step ‚àà [0, 999] |\n",
    "\n",
    "You wrap the list of dicts in a **Ray Dataset** for automatic sharding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. Generate Pendulum offline dataset \n",
    "\n",
    "def make_pendulum_dataset(n_steps: int = 10_000):\n",
    "    \"\"\"\n",
    "    Roll out a random policy in Pendulum-v1 and log (obs, noisy_action, noise, timestep).\n",
    "    Returns a Ray Dataset ready for sharding.\n",
    "    \"\"\"\n",
    "    env = gym.make(\"Pendulum-v1\")\n",
    "    obs, _ = env.reset(seed=0)\n",
    "    data = []\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        action = env.action_space.sample().astype(np.float32)      # shape (1,)\n",
    "        noise   = np.random.randn(*action.shape).astype(np.float32)\n",
    "        noisy_action = action + noise                              # add Gaussian noise\n",
    "        timestep = np.random.randint(0, 1000, dtype=np.int64)\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"obs\":        obs.astype(np.float32),              # shape (3,)\n",
    "                \"noisy_action\": noisy_action,                      # shape (1,)\n",
    "                \"noise\":        noise,                             # shape (1,)\n",
    "                \"timestep\":     timestep,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Step environment\n",
    "        obs, _, terminated, truncated, _ = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "    return ray.data.from_items(data)\n",
    "\n",
    "ds = make_pendulum_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize and split\n",
    "\n",
    "Pendulum states lie roughly in **[‚ÄìœÄ, œÄ]**.  \n",
    "Scale to **[‚Äì1, 1]**, then **shuffle** and split 80 / 20 into train and val shards.\n",
    "All transformations execute in parallel across the Ray cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. Normalize and split (vector obs ‚àà [-œÄ, œÄ])\n",
    "\n",
    "# Normalize pixel values from [0, 1] to [-1, 1] for training\n",
    "def normalize(batch):\n",
    "    # Pendulum observations are roughly in [-œÄ, œÄ] ‚Üí scale to [-1, 1]\n",
    "    batch[\"obs\"] = batch[\"obs\"] / np.pi\n",
    "    return batch\n",
    "\n",
    "# Apply normalization in parallel using Ray Data\n",
    "ds = ds.map_batches(normalize, batch_format=\"numpy\")\n",
    "\n",
    "# Count total number of items (triggers actual execution)\n",
    "total = ds.count()\n",
    "print(\"Total dataset size:\", total)\n",
    "\n",
    "# Shuffle and split dataset into 80% training and 20% validation\n",
    "split_idx = int(total * 0.8)\n",
    "ds = ds.random_shuffle()\n",
    "train_ds, val_ds = ds.split_at_indices([split_idx])\n",
    "\n",
    "print(\"Train size:\", train_ds.count())\n",
    "print(\"Val size:\", val_ds.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DiffusionPolicy LightningModule\n",
    "\n",
    "A tiny MLP that predicts the injected noise œµ given:\n",
    "\n",
    "- 3D normalized state  \n",
    "- 1D *noisy* action  \n",
    "- scalar timestep (normalized by `max_t`)\n",
    "\n",
    "It logs per-epoch losses so you can plot later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. DiffusionPolicy for low-dim observation (3D) and action (1D)\n",
    "\n",
    "class DiffusionPolicy(pl.LightningModule):\n",
    "    \"\"\"Tiny MLP that predicts injected noise œµ given (obs, noisy_action, timestep).\"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim: int = 3, act_dim: int = 1, max_t: int = 1000):\n",
    "        super().__init__()\n",
    "        self.max_t = max_t\n",
    "\n",
    "        # 3D obs + 1D action + 1 timestep ‚Üí 1D noise\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim + act_dim + 1, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, act_dim),\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    # ---------- forward ----------\n",
    "    def forward(self, obs, noisy_action, timestep):\n",
    "        t = timestep.view(-1, 1).float() / self.max_t\n",
    "        x = torch.cat([obs, noisy_action, t], dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "    # ---------- shared loss ----------\n",
    "    def _shared_step(self, batch):\n",
    "        pred = self.forward(\n",
    "            batch[\"obs\"].float(),\n",
    "            batch[\"noisy_action\"],\n",
    "            batch[\"timestep\"],\n",
    "        )\n",
    "        return self.loss_fn(pred, batch[\"noise\"])\n",
    "\n",
    "    # ---------- training / validation ----------\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=False, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=False, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distributed Train loop with checkpointing \n",
    "\n",
    "This per-worker function demonstrates:\n",
    "\n",
    "* **Ray Data to PyTorch**: `iter_torch_batches()` each epoch  \n",
    "* **Lightning-on-Ray**: single-GPU trainer per worker  \n",
    "* **Fault tolerance**: resume from the latest Ray Train checkpoint  \n",
    "* **checkpoint**: saves the metadata and metrics every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05. Ray Train Lightning-native training loop\n",
    "\n",
    "def train_loop(config):\n",
    "    import os, tempfile, torch, warnings\n",
    "    import lightning.pytorch as pl\n",
    "    from ray.train import get_checkpoint, get_context\n",
    "    from ray.train.lightning import (\n",
    "        RayLightningEnvironment,\n",
    "        RayDDPStrategy,\n",
    "        RayTrainReportCallback,\n",
    "        prepare_trainer,\n",
    "    )\n",
    "\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\", message=\"barrier.*using the device under current context\"\n",
    "    )\n",
    "\n",
    "    # ---- Ray Dataset shards ‚Üí iterable torch batches ----\n",
    "    train_ds = ray.train.get_dataset_shard(\"train\")\n",
    "    val_ds   = ray.train.get_dataset_shard(\"val\")\n",
    "    train_loader = train_ds.iter_torch_batches(batch_size=config.get(\"batch_size\", 32))\n",
    "    val_loader   = val_ds.iter_torch_batches(batch_size=config.get(\"batch_size\", 32))\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = DiffusionPolicy()\n",
    "\n",
    "    # ---- Local scratch for PL checkpoints (Ray will persist to storage_path) ----\n",
    "    CKPT_ROOT = os.path.join(tempfile.gettempdir(), \"ray_pl_ckpts\")\n",
    "    os.makedirs(CKPT_ROOT, exist_ok=True)\n",
    "\n",
    "    # ---- Lightning Trainer configured for Ray ----\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.get(\"epochs\", 10),\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"auto\",\n",
    "        strategy=RayDDPStrategy(),\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        callbacks=[\n",
    "            RayTrainReportCallback(),       # forwards metrics + ckpt to Ray\n",
    "            pl.callbacks.ModelCheckpoint(   # local PL checkpoints each epoch\n",
    "                dirpath=CKPT_ROOT,\n",
    "                filename=\"epoch-{epoch:03d}\",\n",
    "                every_n_epochs=1,\n",
    "                save_top_k=-1,\n",
    "                save_last=True,\n",
    "            ),\n",
    "        ],\n",
    "        default_root_dir=CKPT_ROOT,\n",
    "        enable_progress_bar=False,\n",
    "        check_val_every_n_epoch=1,\n",
    "    )\n",
    "\n",
    "    # ---- Prepare trainer for Ray environment ----\n",
    "    trainer = prepare_trainer(trainer)\n",
    "\n",
    "    # ---- Resume from Ray checkpoint if available ----\n",
    "    ckpt_path = None\n",
    "    ckpt = get_checkpoint()\n",
    "    if ckpt:\n",
    "        with ckpt.as_directory() as d:\n",
    "            candidate = os.path.join(d, \"checkpoint.ckpt\")\n",
    "            if os.path.exists(candidate):\n",
    "                ckpt_path = candidate\n",
    "                if get_context().get_world_rank() == 0:\n",
    "                    print(f\"‚úÖ Resuming from Lightning checkpoint: {ckpt_path}\")\n",
    "\n",
    "    # ---- Run training (Lightning owns the loop) ----\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader, ckpt_path=ckpt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launch Ray TorchTrainer\n",
    "\n",
    "Eight A10G workers train in parallel.  \n",
    "`RunConfig` keeps the **five most recent checkpoints** and automatically restarts\n",
    "up to **three** times on failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. Launch distributed training with Ray TorchTrainer\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop,\n",
    "    scaling_config=ScalingConfig(num_workers=8, use_gpu=True),\n",
    "    datasets={\"train\": train_ds, \"val\": val_ds},\n",
    "    run_config=RunConfig(\n",
    "        name=\"pendulum_diffusion_ft\",\n",
    "        storage_path=\"/mnt/cluster_storage/pendulum_diffusion/pendulum_diffusion_results\",\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=5,\n",
    "            checkpoint_score_attribute=\"epoch\",\n",
    "            checkpoint_score_order=\"max\",\n",
    "        ),\n",
    "        failure_config=FailureConfig(max_failures=3),\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "print(\"Training complete ‚Üí\", result.metrics)\n",
    "best_ckpt = result.checkpoint  # latest Ray-managed Lightning checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot train / val loss  \n",
    "\n",
    "Visualize convergence using Ray‚Äôs built-in metrics.  \n",
    "`result.metrics_dataframe` automatically collects the losses logged by Lightning each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07. Plot training and validation loss (Ray + Lightning integration)\n",
    "\n",
    "df = result.metrics_dataframe\n",
    "print(df.head())  # optional sanity check\n",
    "\n",
    "if \"train_loss\" not in df.columns or \"val_loss\" not in df.columns:\n",
    "    raise ValueError(\"train_loss / val_loss missing. Did you log them via self.log()?\")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(df[\"epoch\"], df[\"train_loss\"], marker=\"o\", label=\"Train\")\n",
    "plt.plot(df[\"epoch\"], df[\"val_loss\"], marker=\"o\", label=\"Val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Pendulum Diffusion - Loss per Epoch (Ray Train + Lightning)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reverse diffusion helper\n",
    "\n",
    "Iteratively de-noise a random action vector **50 steps** back to a feasible Pendulum command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Reverse diffusion sampling for 1-D action\n",
    "\n",
    "# Function to simulate reverse diffusion process\n",
    "def sample_action(model, obs, n_steps=50, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Runs reverse diffusion starting from noise to generate a Pendulum action.\n",
    "    obs: torch.Tensor of shape (3,)\n",
    "    returns: torch.Tensor of shape (1,)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        obs = obs.unsqueeze(0).to(device)      # [1, 3]\n",
    "        obs = obs / np.pi                      # Same normalization used in training\n",
    "\n",
    "        x = torch.randn(1, 1).to(device)       # Start from noise in action space\n",
    "\n",
    "        for step in reversed(range(n_steps)):\n",
    "            t = torch.tensor([step], device=device)\n",
    "            pred_noise = model(obs, x, t)\n",
    "            x = x - pred_noise * 0.1\n",
    "\n",
    "        return x.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sample an action from the trained policy\n",
    "\n",
    "Finally, load the **latest epoch checkpoint**, supply a sample state  \n",
    "`[cos Œ∏ = 1, sin Œ∏ = 0, Œ∏Ãá = 0]`, and generate a 1-D torque command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. In-notebook sampling from trained model (Ray Lightning checkpoint)\n",
    "\n",
    "# A plausible pendulum state: [cos(theta), sin(theta), theta_dot]\n",
    "obs_sample = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32)   # shape (3,)\n",
    "\n",
    "assert best_ckpt is not None, \"No checkpoint found ‚Äî did training complete successfully?\"\n",
    "\n",
    "# Load the trained model from Ray's latest Lightning checkpoint\n",
    "model = DiffusionPolicy(obs_dim=3, act_dim=1)\n",
    "\n",
    "with best_ckpt.as_directory() as ckpt_dir:\n",
    "    # RayTrainReportCallback saves a file named \"checkpoint.ckpt\"\n",
    "    ckpt_file = os.path.join(ckpt_dir, \"checkpoint.ckpt\")\n",
    "    if not os.path.exists(ckpt_file):\n",
    "        # Fallback: search any .ckpt file if name differs\n",
    "        candidates = glob.glob(os.path.join(ckpt_dir, \"*.ckpt\"))\n",
    "        ckpt_file = candidates[0] if candidates else None\n",
    "\n",
    "    assert ckpt_file is not None, f\"No Lightning checkpoint found in {ckpt_dir}\"\n",
    "    state = torch.load(ckpt_file, map_location=\"cpu\")\n",
    "    model.load_state_dict(state.get(\"state_dict\", state), strict=False)\n",
    "\n",
    "# Move to device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Run reverse diffusion sampling\n",
    "action = sample_action(model, obs_sample, n_steps=50, device=device)\n",
    "print(\"Sampled action:\", action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Clean up\n",
    "\n",
    "When you're finished, release Ray resources and clear any temporary files.  \n",
    "This ensures the cluster is ready for other jobs and avoids unnecessary storage costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Cleanup -- delete checkpoints and metrics from model training\n",
    "\n",
    "TARGET_PATH = \"/mnt/cluster_storage/pendulum_diffusion\"\n",
    "\n",
    "if os.path.exists(TARGET_PATH):\n",
    "    shutil.rmtree(TARGET_PATH)\n",
    "    print(f\"‚úÖ Deleted everything under {TARGET_PATH}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Path does not exist: {TARGET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up and next steps  \n",
    "\n",
    "You transformed a synthetic control demo into a **Ray-native, real-data pipeline**, training a diffusion policy across multiple GPUs, surviving worker restarts, and sampling feasible actions, all within a distributed Ray environment.\n",
    "\n",
    "This tutorial demonstrates:\n",
    "\n",
    "* Logging continuous-control trajectories directly into a **Ray Dataset** for scalable preprocessing.  \n",
    "* Streaming data into a **Ray Train** workload using Ray Data and Lightning with minimal integration overhead.  \n",
    "* Saving structured checkpoints automatically through **Lightning + Ray Train callbacks**, ensuring seamless **fault-tolerant recovery**.  \n",
    "* Running reverse diffusion sampling directly in-notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "The following are a few directions you can explore to extend or adapt this workload:\n",
    "\n",
    "1. **Evaluate in the environment**  \n",
    "   * Load the best checkpoint, deploy the policy in Gym's `Pendulum-v1`, and log episode returns.  \n",
    "   * Compare against baseline behavior cloning or TD3/TD3+BC.\n",
    "\n",
    "2. **Larger and richer datasets**  \n",
    "   * Generate 100 k+ steps with a scripted controller or collect data from a learned agent.  \n",
    "   * Swap in other classic-control tasks like `CartPole` or `MountainCar`.\n",
    "\n",
    "3. **Model and loss upgrades**  \n",
    "   * Add timestep embeddings or a small transformer for better temporal reasoning.  \n",
    "   * Experiment with different noise schedules or auxiliary consistency losses.\n",
    "\n",
    "4. **Hyperparameter sweeps**  \n",
    "   * Wrap the training loop in **Ray Tune** and grid-search learning rate, hidden size, or diffusion steps.  \n",
    "   * Use Tune's automatic checkpoint pruning to keep only the top-N runs.\n",
    "\n",
    "5. **Mixed precision and performance**  \n",
    "   * Enable `torch.set_float32_matmul_precision('high')` to leverage A10G Tensor Cores.  \n",
    "   * Profile GPU utilization across workers and tune batch size accordingly.\n",
    "\n",
    "6. **Real robotics logs**  \n",
    "   * Replace Pendulum with logs from a real robotic apparatus stored in Parquet; Ray Data shards them the same way.\n",
    "\n",
    "7. **Serving the policy**  \n",
    "   * Export the trained MLP to TorchScript and deploy with **Ray Serve** for low-latency inference.  \n",
    "   * Hook it to a real-time simulator or a web dashboard.\n",
    "\n",
    "8. **End-to-end MLOps**  \n",
    "   * Track checkpoints and metrics with MLflow or Weights & Biases.  \n",
    "   * Schedule nightly Ray jobs on Anyscale to retrain as new data arrives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
