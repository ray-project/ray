{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation system pattern\n",
    "\n",
    "<div align=\"left\">\n",
    "<a target=\"_blank\" href=\"https://console.anyscale.com/template-preview/ray_train_workloads?file=%252Ffiles%252Fworkload-patterns%252F04e_rec_sys_workload_pattern.ipynb\"><img src=\"https://img.shields.io/badge/üöÄ Run_on-Anyscale-9hf\"></a>&nbsp;\n",
    "<a href=\"https://github.com/ray-project/ray/tree/master/doc/source/train/tutorials/content/workload-patterns/04e_rec_sys_workload_pattern.ipynb\" role=\"button\"><img src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
    "</div>\n",
    "\n",
    "This notebook builds a **scalable matrix factorization recommendation system** using the **MovieLens 100K** dataset, fully distributed on an Anyscale cluster with **Ray Train** and **Ray Data**. For larger scale recommendation use-cases we additionally have an integration with TorchRec. An example can be found [here](https://github.com/ray-project/ray/tree/d84d0fd0e88f116302c3fa22ed80fbc3d358c4a3/release/train_tests/benchmark/recsys).\n",
    "\n",
    "## Learning objectives  \n",
    "* How to use **Ray Data** to load, encode, and shard tabular datasets across many workers.  \n",
    "* How to **stream training data** directly into PyTorch using `iter_torch_batches()`.  \n",
    "* How to build a **custom training loop with validation and checkpointing** using `ray.train.report()`.  \n",
    "* How to use **Ray Train's fault-tolerant trainer** to resume training from the latest checkpoint with no extra logic.  \n",
    "* How to separate **training, evaluation, and inference** while keeping all code modular and distributed-ready.  \n",
    "* How to run real-world recommendation workloads with **no changes to your model code**, using Ray's orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What problem are you solving? (matrix factorization for recommendations)\n",
    "\n",
    "Build a **collaborative filtering recommendation system** that predicts how much a user likes an item  \n",
    "based on **historical interaction data**‚Äîin this case, user ratings from the MovieLens 100K dataset.\n",
    "\n",
    "Use **matrix factorization**, a classic yet scalable approach where you embed each user and item in a latent space.  \n",
    "The model learns to represent users and items as vectors and predicts ratings by computing their dot product.\n",
    "\n",
    "---\n",
    "\n",
    "## Input: user‚Äìitem‚Äìrating triples\n",
    "\n",
    "Each row in the dataset represents a user‚Äôs explicit rating of a movie:\n",
    "\n",
    "$$\n",
    "(u, {i}, r) \\in \\{\\text{users}\\} \\times \\{\\text{items}\\} \\times \\{1, 2, 3, 4, 5\\}\n",
    "$$\n",
    "\n",
    "Encode these using contiguous integer indices (`user_idx`, `item_idx`)  \n",
    "and normalize them for efficient embedding lookup and training.\n",
    "\n",
    "---\n",
    "\n",
    "## Model: embedding-based matrix factorization\n",
    "\n",
    "Learn an embedding vector for each user and each item:\n",
    "\n",
    "$$\n",
    "U_{u} \\in \\mathbb{R}^d, \\quad V_{i} \\in \\mathbb{R}^d\n",
    "$$\n",
    "\n",
    "The predicted rating is the dot product of these vectors:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,{i}} = U_{u}^\\top V_{i}\n",
    "$$\n",
    "\n",
    "The embedding dimension $d$ controls model capacity.\n",
    "\n",
    "---\n",
    "\n",
    "## Training objective\n",
    "\n",
    "Minimize **Mean Squared Error (MSE)** between predicted and actual ratings:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathbb{E}_{(u, {i}, r)}\\ \\big(\\hat{r}_{u,{i}} - r\\big)^2\n",
    "$$\n",
    "\n",
    "This encourages the model to assign higher scores to user‚Äìitem pairs that historically received high ratings.\n",
    "\n",
    "---\n",
    "\n",
    "## Inference: ranking items per user\n",
    "\n",
    "Once the model trains, you can recommend items by computing predicted scores for a target user  \n",
    "against **all items in the catalog** (approximate methods can later be applied at scale):\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u, *} = U_{u}^\\top V^\\top\n",
    "$$\n",
    "\n",
    "Sort these scores and return the top-N items as personalized recommendations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to migrate this recommendation system workload to a distributed setup using Ray on Anyscale\n",
    "\n",
    "This tutorial **migrates a local matrix factorization pipeline for recommendation into a distributed, fault-tolerant training loop using Ray Train and Ray Data on Anyscale**.\n",
    "\n",
    "Approach the transition with the following steps:\n",
    "\n",
    "1. **Convert parquet files to sharded Ray Dataset**  \n",
    "   Load MovieLens 100K to parquet, encode the IDs to create a **multi-block Ray Dataset**. Each block is a training shard that Ray can distribute across workers.\n",
    "\n",
    "2. **Stream Torch data loaders**  \n",
    "   Instead of manually writing PyTorch `Dataset` logic, use `iter_torch_batches()` from **Ray Data** to stream batches directly into each worker. Ray handles all the parallelism and sharding behind the scenes.\n",
    "\n",
    "3. **Convert a single-node PyTorch process to a multi-GPU distributed training**  \n",
    "   Write a minimal `train_loop_per_worker` that runs on each Ray worker. Using `TorchTrainer` and `prepare_model()`, scale this loop across eight GPU workers automatically, where each works on its own data shard.\n",
    "\n",
    "4. **Configure structured epoch logging and checkpoints**  \n",
    "   Each epoch logs `train_loss` and `val_loss` and report checkpoints with `ray.train.report(checkpoint=...)`. This enables **automatic recovery and metric tracking** without any additional code.\n",
    "\n",
    "5. **Declaratively configure tolerance, checkpointing and scaling**  \n",
    "   Configure fault tolerance, checkpointing, and scaling using `ScalingConfig`, `CheckpointConfig`, and `FailureConfig`. This lets Ray and Anyscale handle retries, recovery, and GPU orchestration.\n",
    "\n",
    "6. **Write lightweight Python functions for post-training inference**  \n",
    "   After training, load the latest checkpoint and generate top-N recommendations for any user with a simple forward pass. No retraining, no re-initialization, just pure PyTorch inference.\n",
    "\n",
    "With just a few changes to your core code, scale a traditional recommendation pipeline across a Ray cluster with **distributed data loading, checkpointing, fault tolerance, and parallel training**, all fully managed by Anyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports  \n",
    "Start by importing all the libraries you need for the rest of the notebook. These include standard utilities like `os`, `json`, and `pandas`, as well as deep learning libraries like PyTorch and visualization tools like `matplotlib`.\n",
    "\n",
    "Also, import everything needed for **distributed training and data processing with Ray**:\n",
    "- `ray` and `ray.data` provide the high-level distributed data API.\n",
    "- `ray.train` gives you `TorchTrainer`, `ScalingConfig`, checkpointing, and metrics reporting.\n",
    "- `prepare_model` wraps your PyTorch model for multi-worker training with Distributed Data Parallel (DDP).\n",
    "\n",
    "A few extra helpers like `tqdm` and `train_test_split` round out the list for progress bars and quick offline preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00. Runtime setup\n",
    "import os, sys, subprocess\n",
    "\n",
    "# Non-secret env var \n",
    "os.environ[\"RAY_TRAIN_V2_ENABLED\"] = \"1\"\n",
    "\n",
    "# Install Python dependencies \n",
    "!pip install --no-cache-dir torch==2.8.0 pandas==2.3.3 matplotlib==3.7.4 tqdm==4.67.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Imports\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ray\n",
    "import ray\n",
    "import ray.data\n",
    "from ray.train import ScalingConfig, RunConfig, CheckpointConfig, FailureConfig, Checkpoint, get_checkpoint, get_context,  get_dataset_shard, report\n",
    "from ray.train.torch import TorchTrainer, prepare_model\n",
    "\n",
    "# Other\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MovieLens 100K dataset\n",
    "\n",
    "Download and extract the [MovieLens 100K](https://grouplens.org/datasets/movielens/100k/) dataset, then persist a cleaned copy under `/mnt/cluster_storage/rec_sys_tutorial/raw/` in **two formats**:\n",
    "\n",
    "- **CSV:** `ratings.csv` (kept for later inference cells).  \n",
    "- **Parquet dataset:** `ratings_parquet/` as multiple shards (production-style blob store layout) so Ray Data can **stream** reads in parallel without materializing the full dataset.\n",
    "\n",
    "The output has four columns: `user_id`, `item_id`, `rating`, and `timestamp`.\n",
    "\n",
    "The MovieLens 100K dataset contains **100,000 ratings** across **943 users** and **1,682 movies** ‚Äî small enough for quick iteration, yet realistic for demonstrating distributed streaming and training with **Ray Data + Ray Train**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. Load MovieLens 100K Dataset and store in /mnt/cluster_storage/ as CSV + Parquet\n",
    "\n",
    "# Define clean working paths\n",
    "DATA_URL = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "LOCAL_ZIP = \"/mnt/cluster_storage/rec_sys_tutorial/ml-100k.zip\"\n",
    "EXTRACT_DIR = \"/mnt/cluster_storage/rec_sys_tutorial/ml-100k\"\n",
    "OUTPUT_CSV = \"/mnt/cluster_storage/rec_sys_tutorial/raw/ratings.csv\"\n",
    "PARQUET_DIR = \"/mnt/cluster_storage/rec_sys_tutorial/raw/ratings_parquet\"\n",
    "\n",
    "# Ensure target directories exist\n",
    "os.makedirs(\"/mnt/cluster_storage/rec_sys_tutorial/raw\", exist_ok=True)\n",
    "\n",
    "# Download only if not already done\n",
    "if not os.path.exists(LOCAL_ZIP):\n",
    "    !curl -sSL $DATA_URL -o $LOCAL_ZIP\n",
    "\n",
    "# Extract cleanly\n",
    "if not os.path.exists(EXTRACT_DIR):\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(LOCAL_ZIP, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"/mnt/cluster_storage/rec_sys_tutorial\")\n",
    "\n",
    "# Load raw file\n",
    "raw_path = os.path.join(EXTRACT_DIR, \"u.data\")\n",
    "df = pd.read_csv(raw_path, sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "\n",
    "# Persist CSV (kept for later inference cell that expects CSV)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# Persist a Parquet *dataset* (multiple files) to simulate blob storage layout\n",
    "if os.path.exists(PARQUET_DIR):\n",
    "    shutil.rmtree(PARQUET_DIR)\n",
    "os.makedirs(PARQUET_DIR, exist_ok=True)\n",
    "\n",
    "NUM_PARQUET_SHARDS = 8\n",
    "for i, shard in enumerate(np.array_split(df, NUM_PARQUET_SHARDS)):\n",
    "    shard.to_parquet(os.path.join(PARQUET_DIR, f\"part-{i:02d}.parquet\"), index=False)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df):,} ratings ‚Üí CSV: {OUTPUT_CSV}\")\n",
    "print(f\"‚úÖ Wrote Parquet dataset with {NUM_PARQUET_SHARDS} shards ‚Üí {PARQUET_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Point to Parquet dataset URI\n",
    "\n",
    "Instead of creating a Ray Dataset from in-memory pandas objects, this tutorial now reads data directly from a **Parquet dataset** stored in persistent cluster storage.\n",
    "\n",
    "This URI is used by Ray Data to **stream** Parquet shards efficiently across workers without loading the full dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. Point to Parquet dataset URI \n",
    "DATASET_URI = os.environ.get(\n",
    "    \"RATINGS_PARQUET_URI\",\n",
    "    \"/mnt/cluster_storage/rec_sys_tutorial/raw/ratings_parquet\",\n",
    ")\n",
    "\n",
    "print(\"Parquet dataset URI:\", DATASET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize dataset: ratings, users, and items\n",
    "\n",
    "Before training, visualize the distribution of ratings, user activity, and item popularity.  \n",
    "These plots serve as a quick sanity check to confirm the dataset loaded correctly and to highlight patterns in user‚Äìitem interactions:\n",
    "\n",
    "- **Rating distribution:** shows how often each rating (1‚Äì5 stars) occurs, typically skewed toward higher scores.  \n",
    "- **Ratings per user:** reveals the long-tail behavior where a few users rate many items, while most rate only a few.  \n",
    "- **Ratings per item:** similarly shows that a handful of popular items receive most of the ratings.\n",
    "\n",
    "This visualization works with either raw IDs (`user_id`, `item_id`) or encoded indices (`user_idx`, `item_idx`), depending on what‚Äôs available in the current DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. Visualize dataset: ratings, user and item activity\n",
    "\n",
    "# Use encoded indices if present; otherwise fall back to raw IDs\n",
    "user_col = \"user_idx\" if \"user_idx\" in df.columns else \"user_id\"\n",
    "item_col = \"item_idx\" if \"item_idx\" in df.columns else \"item_id\"\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Rating distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "df[\"rating\"].hist(bins=[0.5,1.5,2.5,3.5,4.5,5.5], edgecolor='black')\n",
    "plt.title(\"Rating Distribution\")\n",
    "plt.xlabel(\"Rating\"); plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Number of ratings per user\n",
    "plt.subplot(1, 3, 2)\n",
    "df[user_col].value_counts().hist(bins=30, edgecolor='black')\n",
    "plt.title(\"Ratings per User\")\n",
    "plt.xlabel(\"# Ratings\"); plt.ylabel(\"Users\")\n",
    "\n",
    "# Number of ratings per item\n",
    "plt.subplot(1, 3, 3)\n",
    "df[item_col].value_counts().hist(bins=30, edgecolor='black')\n",
    "plt.title(\"Ratings per Item\")\n",
    "plt.xlabel(\"# Ratings\"); plt.ylabel(\"Items\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Ray Dataset from Parquet and encode IDs\n",
    "\n",
    "Read the MovieLens ratings directly from the **Parquet dataset** using `ray.data.read_parquet()`. This keeps data in a **streaming, non-materialized** form suitable for large-scale distributed processing.\n",
    "\n",
    "Next, build lightweight **global ID mappings** for users and items on the driver to convert raw `user_id` and `item_id` values into contiguous integer indices (`user_idx`, `item_idx`) required for embedding layers.  \n",
    "This mapping step materializes only the distinct IDs (a small subset of the data) while keeping the main dataset lazy and scalable.\n",
    "\n",
    "Finally, apply a `map_batches()` transformation to encode each batch of rows in parallel across the cluster.  \n",
    "The resulting **Ray Dataset** remains distributed and ready for streaming batches directly into the Ray Train workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05. Create Ray Dataset by reading Parquet, then encode IDs via Ray\n",
    "\n",
    "# Read Parquet dataset directly\n",
    "ratings_ds = ray.data.read_parquet(DATASET_URI)\n",
    "print(\"‚úÖ Parquet dataset loaded (streaming, non-materialized)\")\n",
    "ratings_ds.show(3)\n",
    "\n",
    "# ---- Build global ID mappings on the driver ----\n",
    "user_ids = sorted([r[\"user_id\"] for r in ratings_ds.groupby(\"user_id\").count().take_all()])\n",
    "item_ids = sorted([r[\"item_id\"] for r in ratings_ds.groupby(\"item_id\").count().take_all()])\n",
    "\n",
    "user2idx = {uid: j for j, uid in enumerate(user_ids)}\n",
    "item2idx = {iid: j for j, iid in enumerate(item_ids)}\n",
    "\n",
    "NUM_USERS = len(user2idx)\n",
    "NUM_ITEMS = len(item2idx)\n",
    "print(f\"Users: {NUM_USERS:,} | Items: {NUM_ITEMS:,}\")\n",
    "\n",
    "# ---- Encode to contiguous indices within Ray (keeps everything distributed) ----\n",
    "def encode_batch(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    pdf[\"user_idx\"] = pdf[\"user_id\"].map(user2idx).astype(\"int64\")\n",
    "    pdf[\"item_idx\"] = pdf[\"item_id\"].map(item2idx).astype(\"int64\")\n",
    "    return pdf[[\"user_idx\", \"item_idx\", \"rating\", \"timestamp\"]]\n",
    "\n",
    "ratings_ds = ratings_ds.map_batches(encode_batch, batch_format=\"pandas\")\n",
    "print(\"‚úÖ Encoded Ray Dataset schema:\", ratings_ds.schema())\n",
    "ratings_ds.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/validation split using Ray Data  \n",
    "Next, split the dataset into training and validation sets. First, shuffle the entire Ray Dataset to ensure randomization, then split by row index, using 80% for training and 20% for validation.\n",
    "\n",
    "This approach is simple and scalable: Ray handles the shuffling and slicing in parallel across blocks. Also, set a fixed seed to ensure the split is reproducible. After you split it, each dataset remains a fully distributed Ray Dataset, ready to stream into workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. Train/val split using Ray Data (lazy, avoids materialization)\n",
    "\n",
    "TRAIN_FRAC = 0.8\n",
    "SEED = 42  # for reproducibility\n",
    "\n",
    "# Block-level shuffle + proportional split (approximate by block, lazy)\n",
    "train_ds, val_ds = (\n",
    "    ratings_ds\n",
    "    .randomize_block_order(seed=SEED)   # lightweight; no row-level materialization\n",
    "    .split_proportionately([TRAIN_FRAC])  # returns [train, remainder]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Train/Val Split:\")\n",
    "print(f\"  Train ‚Üí {train_ds.count():,} rows\")\n",
    "print(f\"  Val   ‚Üí {val_ds.count():,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define matrix factorization model  \n",
    "Define a simple but effective matrix factorization model using PyTorch. A learned embedding vector represents each user and item. The model predicts a rating by taking the dot product of the corresponding user and item embeddings.\n",
    "\n",
    "This architecture is commonly used in collaborative filtering and serves as a strong baseline for recommendation tasks. It's also well-suited for scaling with Ray Train and DistributedDataParallel (DDP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07. Define matrix factorization model\n",
    "\n",
    "class MatrixFactorizationModel(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embedding_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        user_vecs = self.user_embedding(user_idx)\n",
    "        item_vecs = self.item_embedding(item_idx)\n",
    "        dot_product = (user_vecs * item_vecs).sum(dim=1)\n",
    "        return dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define Ray Train loop (with validation, checkpointing, and Ray-managed metrics)\n",
    "\n",
    "Define the `train_loop_per_worker`, the core function executed by each Ray Train worker.  \n",
    "This loop handles distributed training, validation, and checkpointing with Ray-managed metrics.\n",
    "\n",
    "Each worker receives its own shard of the training and validation datasets using `get_dataset_shard()`.  \n",
    "Batches are streamed directly into PyTorch via `iter_torch_batches()`, ensuring efficient, fully distributed data loading.\n",
    "\n",
    "During each epoch:\n",
    "- Compute average **training** and **validation** MSE losses.  \n",
    "- On **rank 0** only, save a temporary checkpoint (model weights + epoch metadata) using `tempfile.TemporaryDirectory()`.  \n",
    "- Call `ray.train.report()` to report metrics and attach the checkpoint; other workers report metrics only.\n",
    "\n",
    "All metrics are automatically captured by Ray and made available in `result.metrics_dataframe`, enabling progress tracking and fault-tolerant recovery without extra logging logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Define Ray Train loop (with val loss, checkpointing, and Ray-managed metrics)\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    import tempfile\n",
    "    # ---------------- Dataset shards -> PyTorch-style iterators ---------------- #\n",
    "    train_ds = get_dataset_shard(\"train\")\n",
    "    val_ds   = get_dataset_shard(\"val\")\n",
    "    train_loader = train_ds.iter_torch_batches(batch_size=512, dtypes=torch.float32)\n",
    "    val_loader   = val_ds.iter_torch_batches(batch_size=512, dtypes=torch.float32)\n",
    "\n",
    "    # ---------------- Model / Optimizer ---------------- #\n",
    "    model = MatrixFactorizationModel(\n",
    "        num_users=config[\"num_users\"],\n",
    "        num_items=config[\"num_items\"],\n",
    "        embedding_dim=config.get(\"embedding_dim\", 64),\n",
    "    )\n",
    "    model = prepare_model(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"lr\", 1e-3))\n",
    "\n",
    "    # ---------------- Checkpointing setup ---------------- #\n",
    "    rank = get_context().get_world_rank()\n",
    "    start_epoch = 0\n",
    "\n",
    "    # If a checkpoint exists (auto-resume), load it\n",
    "    ckpt = get_checkpoint()\n",
    "    if ckpt:\n",
    "        with ckpt.as_directory() as ckpt_dir:\n",
    "            model.load_state_dict(\n",
    "                torch.load(os.path.join(ckpt_dir, \"model.pt\"), map_location=\"cpu\")\n",
    "            )\n",
    "            start_epoch = torch.load(os.path.join(ckpt_dir, \"meta.pt\")).get(\"epoch\", 0) + 1\n",
    "        if rank == 0:\n",
    "            print(f\"[Rank {rank}] ‚úÖ Resumed from checkpoint at epoch {start_epoch}\")\n",
    "\n",
    "    # ---------------- Training loop ---------------- #\n",
    "    for epoch in range(start_epoch, config.get(\"epochs\", 5)):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            user = batch[\"user_idx\"].long()\n",
    "            item = batch[\"item_idx\"].long()\n",
    "            rating = batch[\"rating\"].float()\n",
    "\n",
    "            pred = model(user, item)\n",
    "            loss = F.mse_loss(pred, rating)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        avg_train_loss = sum(train_losses) / max(1, len(train_losses))\n",
    "\n",
    "        # ---- Validate ----\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                user = batch[\"user_idx\"].long()\n",
    "                item = batch[\"item_idx\"].long()\n",
    "                rating = batch[\"rating\"].float()\n",
    "\n",
    "                pred = model(user, item)\n",
    "                loss = F.mse_loss(pred, rating)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        avg_val_loss = sum(val_losses) / max(1, len(val_losses))\n",
    "\n",
    "        # Console log (optional)\n",
    "        if rank == 0:\n",
    "            print(f\"[Epoch {epoch}] Train MSE: {avg_train_loss:.4f} | Val MSE: {avg_val_loss:.4f}\")\n",
    "\n",
    "        metrics = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "        }\n",
    "\n",
    "        # ---- Save checkpoint & report (rank 0 attaches checkpoint; others report metrics only) ----\n",
    "        if rank == 0:\n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                torch.save(model.state_dict(), os.path.join(tmpdir, \"model.pt\"))\n",
    "                torch.save({\"epoch\": epoch}, os.path.join(tmpdir, \"meta.pt\"))\n",
    "                ckpt_out = Checkpoint.from_directory(tmpdir)\n",
    "                report(metrics, checkpoint=ckpt_out)\n",
    "        else:\n",
    "            report(metrics, checkpoint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Launch distributed training with Ray Train  \n",
    "Now, launch distributed training using `TorchTrainer`, Ray Train‚Äôs high-level orchestration interface. Provide it with:\n",
    "\n",
    "- Your custom `train_loop_per_worker` function\n",
    "- A `train_config` dictionary that specifies model dimensions, learning rate, and number of epochs\n",
    "- The sharded `train` and `val` Ray Datasets\n",
    "- A `ScalingConfig` that sets the number of workers and GPU usage\n",
    "\n",
    "Also, configure checkpointing and fault tolerance:\n",
    "- Ray keeps all checkpoints checkpoints for later plotting\n",
    "- Failed workers retry up to two times\n",
    "\n",
    "Calling `trainer.fit()` kicks off training across the cluster. If any workers fail or disconnect, Ray restarts them and resume from the latest checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. Launch distributed training with Ray TorchTrainer\n",
    "\n",
    "# Define config params (use Ray-derived counts)\n",
    "train_config = {\n",
    "    \"num_users\": NUM_USERS,\n",
    "    \"num_items\": NUM_ITEMS,\n",
    "    \"embedding_dim\": 64,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 20,\n",
    "}\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_config,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=8,       # Increase as needed\n",
    "        use_gpu=True         # Set to True if training on GPUs\n",
    "    ),\n",
    "    datasets={\"train\": train_ds, \"val\": val_ds},\n",
    "    run_config=RunConfig(\n",
    "        name=\"mf_ray_train\",\n",
    "        storage_path=\"/mnt/cluster_storage/rec_sys_tutorial/results\",\n",
    "        checkpoint_config=CheckpointConfig(num_to_keep=20),\n",
    "        failure_config=FailureConfig(max_failures=2)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Run distributed training\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot train and validation loss curves\n",
    "\n",
    "After training, retrieve the full metrics history directly from **Ray Train‚Äôs internal tracking** via `result.metrics_dataframe`.\n",
    "\n",
    "This DataFrame automatically includes all reported metrics across epochs (e.g., `train_loss`, `val_loss`) for every call to `ray.train.report()`.  \n",
    "You use it to visualize model convergence and ensure the training loop, checkpointing, and reporting worked correctly.\n",
    "\n",
    "The plotted curves show how the **training** and **validation** MSE losses evolve over time‚Äîconfirming whether the model is learning effectively and when it begins to stabilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Plot train/val loss curves (from Ray Train results)\n",
    "\n",
    "# Pull the full metrics history Ray stored for this run\n",
    "df = result.metrics_dataframe.copy()\n",
    "\n",
    "# Keep only the columns we need (guard against extra columns)\n",
    "cols = [c for c in [\"epoch\", \"train_loss\", \"val_loss\"] if c in df.columns]\n",
    "df = df[cols].dropna()\n",
    "\n",
    "# If multiple rows per epoch exist, keep the last report per epoch\n",
    "if \"epoch\" in df.columns:\n",
    "    df = df.sort_index().groupby(\"epoch\", as_index=False).last()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "if \"train_loss\" in df.columns:\n",
    "    plt.plot(df[\"epoch\"], df[\"train_loss\"], marker=\"o\", label=\"Train\")\n",
    "if \"val_loss\" in df.columns:\n",
    "    plt.plot(df[\"epoch\"], df[\"val_loss\"], marker=\"o\", label=\"Val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Matrix Factorization - Loss per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Resume training from checkpoint  \n",
    "Run `trainer.fit()` again to resume training from the most recent checkpoint. Since `TorchTrainer` was originally configured with `resume_from_checkpoint=True` and a persistent `storage_path`, Ray automatically restores the latest saved model state and continues training from the correct epoch.\n",
    "\n",
    "This demonstrates Ray Train‚Äôs built-in support for fault tolerance and iterative experimentation, allowing training to pick up exactly where it left off without manual intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Run trainer.fit() again to resume from last checkpoint\n",
    "\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Inference: recommend top-N items for a user  \n",
    "To demonstrate inference, generate top-10 item recommendations for a randomly selected user. Please note that the following method is meant for this small example, and **Ray Data** should be used for inference at scale.\n",
    "\n",
    "First, reload the original `ratings.csv` and rebuild the user and item ID mappings used during training. Then, load the latest model checkpoint and restore the trained embedding weights. If you trained the model with DDP, strip the `'module.'` prefix from checkpoint keys.\n",
    "\n",
    "Next, select a user, compute their embedding, and take the dot product against all item embeddings to produce predicted scores. Finally, extract the top-N items with the highest scores and print their IDs and associated scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Inference: recommend top-N items for a user\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 1: Reload original ratings CSV and mappings\n",
    "# ---------------------------------------------\n",
    "df = pd.read_csv(\"/mnt/cluster_storage/rec_sys_tutorial/raw/ratings.csv\")\n",
    "\n",
    "# Recompute ID mappings (same as during preprocessing)\n",
    "unique_users = sorted(df[\"user_id\"].unique())\n",
    "unique_items = sorted(df[\"item_id\"].unique())\n",
    "\n",
    "user2idx = {uid: j for j, uid in enumerate(unique_users)}\n",
    "item2idx = {iid: j for j, iid in enumerate(unique_items)}\n",
    "idx2item = {v: k for k, v in item2idx.items()}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 2: Load model from checkpoint\n",
    "# ---------------------------------------------\n",
    "model = MatrixFactorizationModel(\n",
    "    num_users=len(user2idx),\n",
    "    num_items=len(item2idx),\n",
    "    embedding_dim=train_config[\"embedding_dim\"]\n",
    ")\n",
    "\n",
    "with result.checkpoint.as_directory() as ckpt_dir:\n",
    "    state_dict = torch.load(os.path.join(ckpt_dir, \"model.pt\"), map_location=\"cpu\")\n",
    "\n",
    "    # Remove 'module.' prefix if using DDP-trained model\n",
    "    if any(k.startswith(\"module.\") for k in state_dict):\n",
    "        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 3: Select a user and generate recommendations\n",
    "# ---------------------------------------------\n",
    "# Choose a random user from the original dataset\n",
    "original_user_id = df[\"user_id\"].sample(1).iloc[0]\n",
    "user_idx = user2idx[original_user_id]\n",
    "\n",
    "print(f\"Generating recommendations for user_id={original_user_id} (internal idx={user_idx})\")\n",
    "\n",
    "# Compute scores for all items for this user\n",
    "with torch.no_grad():\n",
    "    user_vector = model.user_embedding(torch.tensor([user_idx]))           # [1, D]\n",
    "    item_vectors = model.item_embedding.weight                             # [num_items, D]\n",
    "    scores = torch.matmul(user_vector, item_vectors.T).squeeze(0)          # [num_items]\n",
    "\n",
    "    topk = torch.topk(scores, k=10)\n",
    "    top_item_ids = [idx2item[j.item()] for j in topk.indices]\n",
    "    top_scores = topk.values.tolist()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 4: Print top-N recommendations\n",
    "# ---------------------------------------------\n",
    "print(\"\\nTop 10 Recommended Item IDs:\")\n",
    "for i, (item_id, score) in enumerate(zip(top_item_ids, top_scores), 1):\n",
    "    print(f\"{i:2d}. Item ID: {item_id} | Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Join top-N item IDs with movie titles  \n",
    "To make your recommendations more interpretable, join the top-10 recommended `item_id`s with movie titles from the original `u.item` metadata file.\n",
    "\n",
    "Load only the relevant columns‚Äî`item_id` and `title`‚Äîfrom `u.item`, then merge them with the top-N predictions you computed in the previous step. The result is a user-friendly list of movie titles with associated predicted scores, rather than raw item IDs.\n",
    "\n",
    "This small addition makes the model outputs easier to understand and more useful for downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Join top-N item IDs with movie titles from u.item\n",
    "\n",
    "item_metadata = pd.read_csv(\n",
    "    \"/mnt/cluster_storage/rec_sys_tutorial/ml-100k/u.item\",\n",
    "    sep=\"|\",\n",
    "    encoding=\"latin-1\",\n",
    "    header=None,\n",
    "    usecols=[0, 1],  # Only item_id and title\n",
    "    names=[\"item_id\", \"title\"]\n",
    ")\n",
    "\n",
    "# Join with top-N items\n",
    "top_items_df = pd.DataFrame({\n",
    "    \"item_id\": top_item_ids,\n",
    "    \"score\": top_scores\n",
    "})\n",
    "\n",
    "merged = top_items_df.merge(item_metadata, on=\"item_id\", how=\"left\")\n",
    "\n",
    "print(\"\\nTop 10 Recommended Movies:\")\n",
    "for j, row in merged.iterrows():\n",
    "    print(f\"{j+1:2d}. {row['title']} | Score: {row['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Clean up shared storage  \n",
    "Reclaim cluster disk space by deleting the entire tutorial output directory.  \n",
    "Run this only when you‚Äôre **sure** you don‚Äôt need the checkpoints or metrics anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Cleanup -- delete checkpoints and metrics from model training\n",
    "\n",
    "TARGET_PATH = \"/mnt/cluster_storage/rec_sys_tutorial\"  # please note, that /mnt/cluster_storage/ only exists on Anyscale\n",
    "\n",
    "if os.path.exists(TARGET_PATH):\n",
    "    shutil.rmtree(TARGET_PATH)\n",
    "    print(f\"‚úÖ Deleted everything under {TARGET_PATH}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Path does not exist: {TARGET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up and next steps\n",
    "\n",
    "In this tutorial, you used **Ray Train and Ray Data on Anyscale** to scale a full matrix factorization recommendation system, end-to-end, from a raw CSV to multi-GPU distributed training and personalized top-N item recommendations.\n",
    "\n",
    "This tutorial demonstrates:\n",
    "\n",
    "* Using **Ray Data** to preprocess, encode, and shard large tabular datasets.  \n",
    "* Streaming data into PyTorch with `iter_torch_batches()` for efficient training.  \n",
    "* Scaling matrix factorization across multiple GPUs with **Ray Train's `TorchTrainer`**.  \n",
    "* Saving and resuming training with **Ray Checkpoints**.  \n",
    "* Running multi-node, fault-tolerant jobs without touching orchestration code.  \n",
    "* Performing post-training inference using Ray-restored model checkpoints and learned user and item embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "The following are a few directions you can explore to extend or adapt this workload:\n",
    "\n",
    "1. **Ranking metrics and evaluation**  \n",
    "   * Add metrics like **Root Mean Squared Error (RMSE)**, **Normalized Discounted Cumulative Gain (NDCG)**, or **Hit@K** to evaluate recommendation quality.  \n",
    "   * Filter out already-rated items during inference to measure novelty.\n",
    "\n",
    "2. **Two-tower and deep models**  \n",
    "   * Replace dot product with a **two-tower neural model** or a **deep MLP**.  \n",
    "   * Add side features (for example, timestamp, genre) into each tower for better personalization.\n",
    "\n",
    "3. **Recommendation personalization**  \n",
    "   * Store and cache user embeddings after training.  \n",
    "   * Run lightweight inference tasks to generate recommendations in real-time.\n",
    "\n",
    "4. **Content-based or hybrid models**  \n",
    "   * Join movie metadata (genres, tags) and build a hybrid collaborative‚Äìcontent model.  \n",
    "   * Embed titles or genres using pre-trained language models.\n",
    "\n",
    "5. **Hyperparameter optimization**  \n",
    "   * Use **Ray Tune** to sweep embedding sizes, learning rates, or regularization.  \n",
    "   * Track performance over epochs and checkpoint the best models automatically.\n",
    "\n",
    "6. **Data scaling**  \n",
    "   * Switch from MovieLens 100K to 1M or 10M as Ray Data handles it seamlessly.  \n",
    "   * Save and load from cloud object storage (S3, GCS) for real-world deployments.\n",
    "\n",
    "7. **Production inference**  \n",
    "   * Wrap the recommendation system into a **Ray Serve** endpoint for serving top-N results using **Ray Data**-based inference.  \n",
    "   * Build a simple demo that recommends movies to live users.\n",
    "\n",
    "8. **End-to-end MLOps**  \n",
    "   * Register the best model with MLflow or Weights & Biases.  \n",
    "   * Package the training job as a Ray job and schedule it with Anyscale.\n",
    "\n",
    "9. **Multi-tenant recommendation systems**  \n",
    "   * Extend this to support **multiple audiences** or contexts (for example, multi-country, A/B groups).  \n",
    "   * Train and serve context-aware models in parallel using Ray.\n",
    "\n",
    "This pattern gives you a solid foundation for scaling recommendation workloads across real datasets and real infrastructure‚Äîwithout rewriting your model or managing your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
