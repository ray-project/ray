{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision pattern\n",
    "\n",
    "<div align=\"left\">\n",
    "<a target=\"_blank\" href=\"https://console.anyscale.com/template-preview/ray_train_workloads?file=%252Ffiles%252Fworkload-pattern%252F04a_vision_pattern.ipynb\"><img src=\"https://img.shields.io/badge/ðŸš€ Run_on-Anyscale-9hf\"></a>&nbsp;\n",
    "<a href=\"https://github.com/ray-project/ray/tree/master/doc/source/train/tutorials/content/workload-patterns/04a_vision_pattern.ipynb\" role=\"button\"><img src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
    "</div>\n",
    "\n",
    "\n",
    "This notebook is an end-to-end, **real-world computer-vision workflow** that runs seamlessly on an Anyscale cluster using **Ray Train**. You start by pulling a slice of the Food-101 dataset, push it through a lightweight preprocessing pipeline, store it efficiently in Parquet, and then fine-tune a ResNet-18 model in a fault-tolerant, distributed manner. Along the way, you lean on Rayâ€™s helpers to prepare data loaders, coordinate workers, checkpoint automatically, and resume after failure. Afterwards, you perform inference with Ray Data, all without writing a single line of low-level distributed code.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Launch distributed training with **Ray Trainâ€™s `TorchTrainer`** and configure it for multi-GPU, multi-node execution.  \n",
    "- Use **Ray Trainâ€™s built-in utilities** (`prepare_model`, `prepare_data_loader`, `get_checkpoint`, `train.report`) to wrap your existing PyTorch code without modifying your modeling logic.  \n",
    "- Save and resume from **automatic, fault-tolerant checkpoints** across epochs.  \n",
    "- Offload batch **inference using Ray Data**. This allows you to treat inference as a scalable workload.  \n",
    "- Run end-to-end training and evaluation without needing to understand the low-level mechanics of distributed systems.\n",
    "\n",
    "By the end of the tutorial, you produce a working model, clear loss curves, and a hands-on experience of how Ray Train simplifies distributed computer-vision workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What problem are you solving? (image classification with Food-101-Lite)\n",
    "\n",
    "This notebook trains a neural network to **classify food photos** into one of **10 categories**  \n",
    "using the **Food-101-Lite** datasetâ€”a compact, 10-class subset of the original Food-101 benchmark.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs  \n",
    "\n",
    "Every sample is a 3-channel Red-Green-Blue (RGB) image, resized to $224 \\times 224$:\n",
    "\n",
    "$$\n",
    "x \\;\\in\\; [0,1]^{3 \\times 224 \\times 224}\\;.\n",
    "$$\n",
    "\n",
    "You apply standard vision transforms (normalization, random crop/flip) and batch the data with a plain **PyTorch DataLoader** (wrapped by `ray.train.torch.prepare_data_loader` for distributed training).\n",
    "\n",
    "---\n",
    "\n",
    "## Labels  \n",
    "\n",
    "Each image belongs to one of ten classes:\n",
    "\n",
    "['pizza', 'hamburger', 'sushi', 'ramen', 'fried rice',\n",
    "'steak', 'hot dog', 'pancake', 'burrito', 'caesar salad']\n",
    "\n",
    "\n",
    "The label is an integer $y \\in \\{0, \\dots, 9\\}$ used for supervision.\n",
    "\n",
    "---\n",
    "\n",
    "## What does the model learn?\n",
    "\n",
    "You train a compact CNN (For example, **ResNet-18**) to map an image \\(x\\) to class probabilities:\n",
    "\n",
    "$$\n",
    "f_\\theta(x)\\;=\\;\\hat{y}\\;\\in\\;\\mathbb{R}^{10}.\n",
    "$$\n",
    "\n",
    "Training minimizes the **cross-entropy loss**,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x,y)\\;=\\;-\\log \\bigl(\\hat{y}_{\\,y}\\bigr),\n",
    "$$\n",
    "\n",
    "so the network assigns high likelihood to the correct class.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to migrate this computer vision workload to a distributed setup using Ray on Anyscale\n",
    "In this tutorial, you start with a small PyTorch-based image classification taskâ€”training a ResNet-18 model on a 10% slice of the Food-101 dataset, and progressively migrate it into a fully distributed, fault-tolerant training job using **Ray Train on Anyscale**. The goal is to show you exactly how to scale *your existing workflow* without rewriting it from scratch.\n",
    "\n",
    "Use the following steps to migrate:\n",
    "\n",
    "1. **Preprocess data and persist it in a distributed-friendly format**  \n",
    "   You take raw images from Hugging Face's `food101` dataset, apply `torchvision` resizing and center-cropping, and serialize them to **Parquet** using `pyarrow`. The system writes these Parquet files to the **Anyscale cluster's shared storage volume** (`/mnt/cluster_storage`), so any node can access them, on any worker, without duplication or sync issues.\n",
    "\n",
    "2. **Create a lightweight PyTorch `Dataset` for Parquet ingestion**  \n",
    "   You implement a custom `Food101Dataset` that reads directly from the Parquet files. This provides control over the way the system reads rows and row groups. While this isn't yet fully distributed, it allows you to simulate a real-world scenario where a developer starts with something simple before optimizing. **Note:** you use PyTorch style data loading in this tutorial to demonstrate (1) low level control in a PyTorch native environment and (2) how to move pre-existing PyTorch code into a distributed Anyscale environment. Other tutorials in this module incorporate Ray Data, so you can see how the two approaches differ.\n",
    "\n",
    "3. **Integrate Ray Train into the training loop**  \n",
    "   You encapsulate your existing PyTorch training logic in a `train_loop_per_worker()` function, which Ray Train executes on each worker, typically one per GPU. Inside this loop, you:\n",
    "\n",
    "   - Wrap the model with `prepare_model()` to make it compatible with distributed data parallelism.  \n",
    "   - Wrap the `DataLoader` with `prepare_data_loader()` to enable device placement and Ray worker context handling.  \n",
    "   - Use Ray's `Checkpoint` API to save and resume from checkpoints as needed.  \n",
    "   - Report training and validation metrics with `train.report()` after each epoch.\n",
    "\n",
    "4. **Launch training with `TorchTrainer` on an Anyscale cluster**  \n",
    "   You instantiate a `TorchTrainer` that runs:\n",
    "   - With `num_workers=8` and `use_gpu=True`. For example, across eight A10 or A100 GPUs on Anyscale. Please note that this amount of compute is not necessary for the example in this tutorial, as the excess resources are for educational purposes only.  \n",
    "   - With `RunConfig` that sets checkpoint retention and auto-resume (with `max_failures=3`).  \n",
    "   - On infrastructure that's provisioned and scheduled by Anyscale with no manual Ray cluster setup required.  \n",
    "\n",
    "   Once launched, Ray automatically handles:\n",
    "   - Multi-node orchestration  \n",
    "   - Worker assignment and device pinning  \n",
    "   - Failure recovery and retry logic  \n",
    "   - Checkpointing and logging\n",
    "\n",
    "5. **Validate fault tolerance**  \n",
    "   You run `trainer.fit()` a second time. If manual intervention or failure interrupts the previous training, Ray picks up from the latest checkpoint. This shows **real-world robustness** without any manual checkpoint management or scripting.\n",
    "\n",
    "6. **Launch distributed GPU inference tasks**  \n",
    "   At the end, you provide inference with a Ray Data pipeline that loads the best checkpoint and runs inference on a single image from the validation set. You run this task on one GPU from the cluster.\n",
    "\n",
    "All of this runs inside a **managed Anyscale workspace**. You don't need to start or SSH into clusters, worry about node IP, or configure NCCL. The entire setup is **declarative and self-contained in this notebook**, and you can re-run it or scale it up by changing a single parameter (`num_workers`).\n",
    "\n",
    "This tutorial mirrors how many ML teams operate in practice: starting with a working PyTorch training loop and migrating it to the cloud without rewriting core logic. With Ray Train on Anyscale, the migration is clean, incremental, and production-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports  \n",
    "Before you start, gather every library you use throughout this notebook. Pull in core Python utilities for file handling and plotting, PyTorch and TorchVision for deep-learning components, Ray Train for distributed orchestration, Hugging Face Datasets for quick data access, and PyArrow plus Pandas for fast Parquet IO. Importing everything up-front keeps the rest of the tutorial clean and predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00. Runtime setup \n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Non-secret env var \n",
    "os.environ[\"RAY_TRAIN_V2_ENABLED\"] = \"1\"\n",
    "\n",
    "# Install Python dependencies \n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\",\n",
    "    \"torch==2.8.0\",\n",
    "    \"torchvision==0.23.0\",\n",
    "    \"matplotlib==3.10.6\",\n",
    "    \"pyarrow==14.0.2\",\n",
    "    \"datasets==2.19.2\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. Imports\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Standard Library Utilities\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "import os, io, tempfile, shutil  # file I/O and temp dirs\n",
    "import json                      # reading/writing configs\n",
    "import random, uuid              # randomness and unique IDs\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Core Data & Storage Libraries\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "import pandas as pd              # tabular data handling\n",
    "import numpy as np               # numerical ops\n",
    "import pyarrow as pa             # in-memory columnar format\n",
    "import pyarrow.parquet as pq     # reading/writing Parquet files\n",
    "from tqdm import tqdm            # progress bars\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Image Handling & Visualization\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt  # plotting loss curves, images\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# PyTorch + TorchVision Core\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Ray Train: Distributed Training Primitives\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "import ray\n",
    "import ray.train as train\n",
    "from ray.train.torch import (\n",
    "    prepare_model,\n",
    "    prepare_data_loader,\n",
    "    TorchTrainer,\n",
    ")\n",
    "from ray.train import (\n",
    "    ScalingConfig,\n",
    "    RunConfig,\n",
    "    FailureConfig,\n",
    "    CheckpointConfig,\n",
    "    Checkpoint,\n",
    "    get_checkpoint,\n",
    "    get_context,\n",
    ")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# Dataset Access\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "from datasets import load_dataset  # Hugging Face Datasets\n",
    "from ray.data import DataContext\n",
    "DataContext.get_current().use_streaming_executor = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load 10 % of Food-101  \n",
    "Next, get roughly 7,500 images, exactly 10% of Food-101â€”using a single call to `load_dataset`. This trimmed subset trains quickly while still being large enough to demonstrate Rayâ€™s scaling behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. Load 10% of food101 (~7,500 images)\n",
    "ds = load_dataset(\"food101\", split=\"train[:10%]\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resize and encode images  \n",
    "Preprocess each image: resize to 256 pixels, center-crop to 224 pixels (the size expected by most ImageNet models), and then convert the result to raw Joint Photographic Experts Group (JPEG) bytes. By storing bytes instead of full Python Imaging Library (PIL) objects, you keep the dataset compact and Parquet-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03. Resize and encode as JPEG bytes\n",
    "transform = Compose([Resize(256), CenterCrop(224)])\n",
    "records = []\n",
    "\n",
    "for example in tqdm(ds, desc=\"Preprocessing images\", unit=\"img\"):\n",
    "    try:\n",
    "        img = transform(example[\"image\"])\n",
    "        buf = io.BytesIO()\n",
    "        img.save(buf, format=\"JPEG\")\n",
    "        records.append({\n",
    "            \"image_bytes\": buf.getvalue(),\n",
    "            \"label\": example[\"label\"]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visual sanity check  \n",
    "Before committing to hours of training, take nine random samples and plot them with their class names. This quick inspection lets you properly align labels and confirm that images are correctly resized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04. Visualize the dataset\n",
    "\n",
    "label_names = ds.features[\"label\"].names  # maps int â†’ string\n",
    "\n",
    "samples = random.sample(records, 9)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(8, 8))\n",
    "fig.suptitle(\"Sample Resized Images from food101-lite\", fontsize=16)\n",
    "\n",
    "for ax, rec in zip(axs.flatten(), samples):\n",
    "    img = Image.open(io.BytesIO(rec[\"image_bytes\"]))\n",
    "    label_name = label_names[rec[\"label\"]]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(label_name)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Persist to Parquet  \n",
    "Write the images and labels to a Parquet file. Because Parquet is columnar, you can read just the columns you need during training, which speeds up IOâ€”especially when multiple workers are reading in parallel under Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05. Write Dataset to Parquet\n",
    "\n",
    "output_dir = \"/mnt/cluster_storage/food101_lite/parquet_256\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "table = pa.Table.from_pydict({\n",
    "    \"image_bytes\": [r[\"image_bytes\"] for r in records],\n",
    "    \"label\": [r[\"label\"] for r in records]\n",
    "})\n",
    "pq.write_table(table, os.path.join(output_dir, \"shard_0.parquet\"))\n",
    "\n",
    "print(f\"Wrote {len(records)} records to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom `Food101Dataset` for Parquet  \n",
    "To feed data into PyTorch, define a custom `Dataset`. You cache Parquet metadata, map global indices to specific row groups, and pull only the row you need. Each `__getitem__` returns an `(image, label)` pair that's immediately ready for further transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. Define PyTorch Dataset that loads from Parquet\n",
    "\n",
    "class Food101Dataset(Dataset):\n",
    "    def __init__(self, parquet_path: str, transform=None):\n",
    "        self.parquet_file = pq.ParquetFile(parquet_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Precompute a global row index to (row_group_idx, local_idx) map\n",
    "        self.row_group_map = []\n",
    "        for rg_idx in range(self.parquet_file.num_row_groups):\n",
    "            rg_meta = self.parquet_file.metadata.row_group(rg_idx)\n",
    "            num_rows = rg_meta.num_rows\n",
    "            self.row_group_map.extend([(rg_idx, i) for i in range(num_rows)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.row_group_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_group_idx, local_idx = self.row_group_map[idx]\n",
    "        # Read only the relevant row group (in memory-efficient batch---for scalability)\n",
    "        table = self.parquet_file.read_row_group(row_group_idx, columns=[\"image_bytes\", \"label\"])\n",
    "        row = table.to_pandas().iloc[local_idx]\n",
    "\n",
    "        img = Image.open(io.BytesIO(row[\"image_bytes\"])).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, row[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Image transform  \n",
    "Create a transform pipeline: `ToTensor()` followed by ImageNet mean and standard-deviation normalisation. By applying the transform inside the dataset, you make sure every worker, no matter where it runs, processes images in exactly the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07. Define data preprocessing transform\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train/validation split  \n",
    "Shuffle the full Parquet table once (seeded for reproducibility) and then slice off the last 500 rows to construct the validation set. Write the train and validation partitions to their own Parquet files so you can load them independently later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. Create train/val Parquet splits \n",
    "full_path = \"/mnt/cluster_storage/food101_lite/parquet_256/shard_0.parquet\"\n",
    "\n",
    "df = (\n",
    "    pq.read_table(full_path)\n",
    "    .to_pandas()\n",
    "    .sample(frac=1.0, random_state=42)  # shuffle for reproducibility\n",
    ")\n",
    "\n",
    "df[:-500].to_parquet(\"/mnt/cluster_storage/food101_lite/train.parquet\")   # training\n",
    "df[-500:].to_parquet(\"/mnt/cluster_storage/food101_lite/val.parquet\")     # validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inspect a DataLoader batch  \n",
    "Before you scale out, build a regular single-process `DataLoader`, pull one batch, and print its shape. This tiny test reassures you that batching, multiprocessing, and transforms work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 09. Observe data shape\n",
    "\n",
    "loader = DataLoader(\n",
    "    Food101Dataset(\"/mnt/cluster_storage/food101_lite/train.parquet\", transform=transform),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "for images, labels in loader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Helper: Ray-prepared DataLoaders  \n",
    "\n",
    "Wrap the DataLoader with `prepare_data_loader`.  \n",
    "Ray automatically injects a `DistributedSampler`, pins the loader to the correct GPU, and manages all worker-rank bookkeeping. This means you donâ€™t need to manually construct a `DistributedSampler`, as itâ€™s handled internally by Ray.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Define helper to create prepared DataLoader\n",
    "def build_dataloader(parquet_path: str, batch_size: int, shuffle=True):\n",
    "    dataset = Food101Dataset(parquet_path, transform=transform)\n",
    "\n",
    "    # Let Ray handle DistributedSampler and device placement via prepare_data_loader.\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    return prepare_data_loader(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. `train_loop_per_worker`  \n",
    "\n",
    "This function defines the **per-worker training logic** that Ray Train executes on each distributed worker.  \n",
    "\n",
    "Each worker builds its own model, optimizer, and dataloaders; resumes automatically from the most recent Ray-managed checkpoint (if available); and then trains and validates the model across epochs.  \n",
    "\n",
    "Key behaviors to note:\n",
    "\n",
    "- **Checkpoints** are first written to a fast **temporary local directory** on each worker, then safely persisted to the runâ€™s configured `storage_path` by `train.report()`â€”ensuring reliability and retry support even under transient node failures.  \n",
    "- **Metrics** (train and validation loss) are automatically collected and stored by Ray Trainâ€”no need for manual file writes or JSON logging.  \n",
    "- **Fault tolerance** is fully handled by Ray Trainâ€™s checkpointing and retry mechanism via `RunConfig` and `FailureConfig`.  \n",
    "- **Final accuracy** is computed using `torchmetrics.MulticlassAccuracy`, which performs synchronized, **distributed accuracy aggregation** across all workers, ensuring a correct global metric instead of rank-0-only evaluation.  \n",
    "\n",
    "This design keeps the training loop clean, fault-tolerant, and fully aligned with Ray Trainâ€™s built-in distributed orchestration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Define Ray Train train_loop_per_worker (tempdir checkpoints + Ray-managed metrics)\n",
    "def train_loop_per_worker(config):\n",
    "    import tempfile\n",
    "\n",
    "    rank = get_context().get_world_rank()\n",
    "\n",
    "    # === Model ===\n",
    "    net = resnet18(num_classes=101)\n",
    "    model = prepare_model(net)\n",
    "\n",
    "    # === Optimizer / Loss ===\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # === Resume from Checkpoint ===\n",
    "    start_epoch = 0\n",
    "    ckpt = get_checkpoint()\n",
    "    if ckpt:\n",
    "        with ckpt.as_directory() as ckpt_dir:\n",
    "            # Map to CPU is fine; prepare_model will handle device placement.\n",
    "            model.load_state_dict(torch.load(os.path.join(ckpt_dir, \"model.pt\"), map_location=\"cpu\"))\n",
    "            opt_path = os.path.join(ckpt_dir, \"optimizer.pt\")\n",
    "            if os.path.exists(opt_path):\n",
    "                optimizer.load_state_dict(torch.load(opt_path, map_location=\"cpu\"))\n",
    "            meta_path = os.path.join(ckpt_dir, \"meta.pt\")\n",
    "            if os.path.exists(meta_path):\n",
    "                # Continue from the next epoch after the saved one\n",
    "                start_epoch = int(torch.load(meta_path).get(\"epoch\", -1)) + 1\n",
    "        if rank == 0:\n",
    "            print(f\"[Rank {rank}] Resumed from checkpoint at epoch {start_epoch}\")\n",
    "\n",
    "    # === DataLoaders ===\n",
    "    train_loader = build_dataloader(\n",
    "        \"/mnt/cluster_storage/food101_lite/train.parquet\", config[\"batch_size\"], shuffle=True\n",
    "    )\n",
    "    val_loader = build_dataloader(\n",
    "        \"/mnt/cluster_storage/food101_lite/val.parquet\", config[\"batch_size\"], shuffle=False\n",
    "    )\n",
    "\n",
    "    # === Training Loop ===\n",
    "    for epoch in range(start_epoch, config[\"epochs\"]):\n",
    "        # Required when using DistributedSampler\n",
    "        if hasattr(train_loader, \"sampler\") and hasattr(train_loader.sampler, \"set_epoch\"):\n",
    "            train_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        model.train()\n",
    "        train_loss_total, train_batches = 0.0, 0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_total += loss.item()\n",
    "            train_batches += 1\n",
    "        train_loss = train_loss_total / max(train_batches, 1)\n",
    "\n",
    "        # === Validation Loop ===\n",
    "        model.eval()\n",
    "        val_loss_total, val_batches = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for val_xb, val_yb in val_loader:\n",
    "                val_loss_total += criterion(model(val_xb), val_yb).item()\n",
    "                val_batches += 1\n",
    "        val_loss = val_loss_total / max(val_batches, 1)\n",
    "\n",
    "        metrics = {\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss}\n",
    "        if rank == 0:\n",
    "            print(metrics)\n",
    "\n",
    "        # ---- Save checkpoint to fast local temp dir; Ray persists it via report() ----\n",
    "        if rank == 0:\n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                torch.save(model.state_dict(), os.path.join(tmpdir, \"model.pt\"))\n",
    "                torch.save(optimizer.state_dict(), os.path.join(tmpdir, \"optimizer.pt\"))\n",
    "                torch.save({\"epoch\": epoch}, os.path.join(tmpdir, \"meta.pt\"))\n",
    "                ckpt_out = Checkpoint.from_directory(tmpdir)\n",
    "                train.report(metrics, checkpoint=ckpt_out)\n",
    "        else:\n",
    "            # Non-zero ranks report metrics only (no checkpoint attachment)\n",
    "            train.report(metrics)\n",
    "\n",
    "    # === Final validation accuracy (distributed via TorchMetrics) ===\n",
    "    from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    # Sync across DDP workers when computing the final value\n",
    "    acc_metric = MulticlassAccuracy(\n",
    "        num_classes=101, average=\"micro\", sync_on_compute=True\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            logits = model(xb)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc_metric.update(preds, yb)\n",
    "\n",
    "    dist_val_acc = acc_metric.compute().item()\n",
    "    if rank == 0:\n",
    "        print(f\"Val Accuracy (distributed): {dist_val_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Launch distributed training with `TorchTrainer`  \n",
    "Instantiate a `TorchTrainer`. Ask for eight GPU workers, enable up to three automatic retries, and tell Ray to keep the five checkpoints with the lowest validation loss. One call to `trainer.fit()` kicks off a fault-tolerant job on your Anyscale cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Run Training with Ray Train \n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 5},\n",
    "    scaling_config=ScalingConfig(num_workers=8, use_gpu=True),\n",
    "    run_config=RunConfig(\n",
    "        name=\"food101_ft_resume\",\n",
    "        storage_path=\"/mnt/cluster_storage/food101_lite/results\",\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=5, \n",
    "            checkpoint_score_attribute=\"val_loss\",\n",
    "            checkpoint_score_order=\"min\"\n",
    "        ),\n",
    "        failure_config=FailureConfig(max_failures=3),\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "print(\"Final metrics:\", result.metrics)\n",
    "best_ckpt = result.checkpoint  # this is the one with lowest val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Plot training and validation loss curves  \n",
    "\n",
    "After training completes, visualize the recorded metrics directly from Ray Trainâ€™s results object. No manual CSV handling required.  \n",
    "`result.metrics_dataframe` automatically contains every metric reported during training, including per-epoch loss values from all workers.  \n",
    "\n",
    "This plot extracts the training and validation losses, groups them by epoch, and displays the most recent report for each.  \n",
    "By comparing these two curves, you quickly assess convergence behavior and detect overfitting (for example, when training loss continues to decrease while validation loss rises).  \n",
    "\n",
    "Because Ray Train automatically stores all metrics and checkpoints, this visualization reflects the same information used to select the **best checkpoint** based on validation loss in your `RunConfig`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Plot training / validation loss curves \n",
    "\n",
    "# Pull the full metrics history Ray stored for this run\n",
    "df = result.metrics_dataframe.copy()\n",
    "\n",
    "# Keep only the columns we need (guard against extra columns)\n",
    "cols = [c for c in [\"epoch\", \"train_loss\", \"val_loss\"] if c in df.columns]\n",
    "df = df[cols].dropna()\n",
    "\n",
    "# If multiple rows per epoch exist, keep the last report per epoch\n",
    "if \"epoch\" in df.columns:\n",
    "    df = df.sort_index().groupby(\"epoch\", as_index=False).last()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "if \"train_loss\" in df.columns:\n",
    "    plt.plot(df[\"epoch\"], df[\"train_loss\"], marker=\"o\", label=\"Train Loss\")\n",
    "if \"val_loss\" in df.columns:\n",
    "    plt.plot(df[\"epoch\"], df[\"val_loss\"], marker=\"o\", label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train/Val Loss across Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Demonstrate fault-tolerant resumption  \n",
    "To prove that checkpointing works, run `trainer.fit()` a second time without changing anything. If the earlier run crashed mid-epoch, Ray automatically picks up the latest checkpoint and continues. If it already finished, Ray starts a clean new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Run the trainer again to demonstrate resuming from latest checkpoint  \n",
    "\n",
    "result = trainer.fit()\n",
    "print(\"Final metrics:\", result.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Batch inference with Ray Data  \n",
    "\n",
    "Define a **stateful, GPU-backed batch inference pipeline** using Ray Data.  \n",
    "Each actor loads the model **once per GPU**, keeps it in memory, and performs inference on incoming batches in parallel.  \n",
    "This pattern scales efficiently across multiple GPUs and avoids redundant model loading for every prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Batch inference with Ray Data (force GPU actors if available on the cluster)\n",
    "\n",
    "import ray.data as rdata\n",
    "\n",
    "class ImageBatchPredictor:\n",
    "    \"\"\"Stateful per-actor batch predictor that keeps the model in memory.\"\"\"\n",
    "    def __init__(self, checkpoint_path: str):\n",
    "        # Pick the best available device on the ACTOR (worker), not the driver.\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # === Load model & weights once per actor ===\n",
    "        model = resnet18(num_classes=101)\n",
    "        checkpoint = Checkpoint.from_directory(checkpoint_path)\n",
    "        with checkpoint.as_directory() as ckpt_dir:\n",
    "            state_dict = torch.load(\n",
    "                os.path.join(ckpt_dir, \"model.pt\"),\n",
    "                map_location=self.device,\n",
    "            )\n",
    "            # Strip DDP \"module.\" prefix if present\n",
    "            state_dict = {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n",
    "            model.load_state_dict(state_dict)\n",
    "\n",
    "        self.model = model.eval().to(self.device)\n",
    "        self.transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ])\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"batch: Pandas DataFrame with columns ['image_bytes', 'label']\"\"\"\n",
    "        imgs = []\n",
    "        for b in batch[\"image_bytes\"]:\n",
    "            img = Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
    "            imgs.append(self.transform(img).numpy())  # (C,H,W) as numpy\n",
    "        x = torch.from_numpy(np.stack(imgs, axis=0)).to(self.device)  # (N,C,H,W)\n",
    "\n",
    "        logits = self.model(x)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        out = batch.copy()\n",
    "        out[\"predicted_label\"] = preds.astype(int)\n",
    "        return out[[\"predicted_label\", \"label\"]]\n",
    "\n",
    "def build_inference_dataset(\n",
    "    checkpoint_path: str,\n",
    "    parquet_path: str,\n",
    "    *,\n",
    "    num_actors: int = 1,\n",
    "    batch_size: int = 64,\n",
    "    use_gpu_actors: bool = True,   # <â€” default to GPU actors on the cluster\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a Ray Dataset pipeline that performs batch inference using\n",
    "    stateful per-actor model loading. By default, requests 1 GPU per actor\n",
    "    so each actor runs on a GPU worker (driver may have no GPU).\n",
    "    \"\"\"\n",
    "    ds = rdata.read_parquet(parquet_path, columns=[\"image_bytes\", \"label\"])\n",
    "\n",
    "    pred_ds = ds.map_batches(\n",
    "        ImageBatchPredictor,                     # pass the CLASS (stateful actors)\n",
    "        fn_constructor_args=(checkpoint_path,),  # ctor args for each actor\n",
    "        batch_size=batch_size,\n",
    "        batch_format=\"pandas\",\n",
    "        concurrency=num_actors,                  # number of actor workers\n",
    "        num_gpus=1 if use_gpu_actors else 0,     # <â€” force GPU placement on workers\n",
    "    )\n",
    "    return pred_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Run and visualize Ray Data inference  \n",
    "\n",
    "Use the best checkpoint to run **Ray Data Inference** on a validation sample.  \n",
    "The model loads once per GPU actor, batches and parallelizes predictions, and visualizes the result alongside the ground-truth label for quick qualitative evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Perform inference with Ray Data using the best checkpoint\n",
    "\n",
    "checkpoint_root = \"/mnt/cluster_storage/food101_lite/results/food101_ft_resume\"\n",
    "\n",
    "checkpoint_dirs = sorted(\n",
    "    [\n",
    "        d for d in os.listdir(checkpoint_root)\n",
    "        if d.startswith(\"checkpoint_\") and os.path.isdir(os.path.join(checkpoint_root, d))\n",
    "    ],\n",
    "    reverse=True,\n",
    ")\n",
    "\n",
    "if not checkpoint_dirs:\n",
    "    raise FileNotFoundError(\"No checkpoint directories found.\")\n",
    "\n",
    "# Use the best checkpoint from the training result\n",
    "with result.checkpoint.as_directory() as ckpt_dir:\n",
    "    print(\"Best checkpoint contents:\", os.listdir(ckpt_dir))\n",
    "    best_ckpt_path = ckpt_dir\n",
    "\n",
    "parquet_path = \"/mnt/cluster_storage/food101_lite/val.parquet\"\n",
    "\n",
    "# Which item to visualize\n",
    "idx = 2\n",
    "\n",
    "# Build a Ray Data inference pipeline (model is loaded once per GPU actor)\n",
    "pred_ds = build_inference_dataset(\n",
    "    checkpoint_path=best_ckpt_path,\n",
    "    parquet_path=parquet_path,\n",
    "    num_actors=1,       # adjust to scale out\n",
    "    batch_size=64,      # adjust for throughput\n",
    ")\n",
    "\n",
    "# Materialize predictions up to the desired index and grab the row\n",
    "import itertools\n",
    "row_iter = pred_ds.iter_rows()\n",
    "inference_row = next(itertools.islice(row_iter, idx, idx + 1))  # {\"predicted_label\": ..., \"label\": ...}\n",
    "print(inference_row)\n",
    "\n",
    "# Load label map from Hugging Face (for pretty titles)\n",
    "ds_tmp = load_dataset(\"food101\", split=\"train[:1%]\")  # just to get label names\n",
    "label_names = ds_tmp.features[\"label\"].names\n",
    "\n",
    "# Load the raw image locally for visualization\n",
    "dataset = Food101Dataset(parquet_path, transform=None)\n",
    "img, _ = dataset[idx]\n",
    "\n",
    "# Plot the image with predicted and true labels\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\n",
    "    f\"Pred: {label_names[int(inference_row['predicted_label'])]}\\n\"\n",
    "    f\"True: {label_names[int(inference_row['label'])]}\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Clean up  \n",
    "Finally, tidy up by deleting temporary checkpoint folders, the metrics CSV, and any intermediate result directories. Clearing out old artifacts frees disk space and leaves your workspace clean for whatever comes next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Cleanup---delete checkpoints and metrics from model training\n",
    "\n",
    "# Base directory\n",
    "BASE_DIR = \"/mnt/cluster_storage/food101_lite\"\n",
    "\n",
    "# Paths to clean\n",
    "paths_to_delete = [\n",
    "    os.path.join(BASE_DIR, \"tmp_checkpoints\"),           # custom checkpoints\n",
    "    os.path.join(BASE_DIR, \"results\", \"history.csv\"),    # metrics history file\n",
    "    os.path.join(BASE_DIR, \"results\", \"food101_ft_resume\"),  # ray trainer run dir\n",
    "    os.path.join(BASE_DIR, \"results\", \"food101_ft_run\"),\n",
    "    os.path.join(BASE_DIR, \"results\", \"food101_single_run\"),\n",
    "]\n",
    "\n",
    "# Delete each path if it exists\n",
    "for path in paths_to_delete:\n",
    "    if os.path.exists(path):\n",
    "        if os.path.isfile(path):\n",
    "            os.remove(path)\n",
    "            print(f\"Deleted file: {path}\")\n",
    "        else:\n",
    "            shutil.rmtree(path)\n",
    "            print(f\"Deleted directory: {path}\")\n",
    "    else:\n",
    "        print(f\"Not found (skipped): {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up and next steps\n",
    "\n",
    "You've taken a realistic computer-vision workload, from raw images all the way to distributed training and GPU inference, and run it on Ray Train with zero boilerplate around GPUs, data parallelism, or fault-tolerance. This tutorial demonstrates:\n",
    "\n",
    "* Using **Ray Train's TorchTrainer** to scale PyTorch training across multiple GPUs and nodes with minimal code changes.  \n",
    "* Wrapping models and data loaders with **`prepare_model()`** and **`prepare_data_loader()`** to enable Ray-managed device placement and distributed execution.  \n",
    "* Sharding data across workers and coordinating training epochs across Ray workers.  \n",
    "* Configuring **automatic checkpointing and failure recovery** using Ray Train's built-in `Checkpoint`, `RunConfig`, and `FailureConfig` APIs.  \n",
    "* Running **Ray Data-based inference** for distributed inference, showing how to serve and scale model predictions across a Ray cluster.  \n",
    "\n",
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Below are a few directions you might explore to adapt or extend the pattern:\n",
    "\n",
    "1. **Larger or custom datasets**  \n",
    "   * Swap in the full 75 k-image Food-101 splitâ€”or your own dataset in any storage backend (S3, GCS, Azure Blob).  \n",
    "   * Add multi-file Parquet sharding and let each worker read a different shard.\n",
    "\n",
    "2. **Model architectures**  \n",
    "   * Drop in Vision Transformers (`vit_b_16`, `vit_l_32`) or ConvNeXt; the prepare helpers work exactly the same.  \n",
    "   * Experiment with transfer learning versus training from scratch.\n",
    "\n",
    "3. **Mixed precision and performance tuning**  \n",
    "   * Enable automatic mixed precision (`torch.cuda.amp`) or bfloat16 to speed up training and save memory.  \n",
    "   * Profile data-loading throughput and play with `num_workers`, prefetching, and caching.\n",
    "\n",
    "4. **Hyperparameter sweeps**  \n",
    "   * Wrap the training loop in **Ray Tune** to search over learning rates, augmentations, or optimizers.  \n",
    "   * Use Ray's integrated reporting to schedule early stopping.\n",
    "\n",
    "5. **Data augmentation pipelines**  \n",
    "   * Integrate additional transforms inside the dataset class for image augmentation.  \n",
    "   * Compare CPU versus GPU-side augmentations for throughput.\n",
    "\n",
    "6. **Distributed validation and metrics**  \n",
    "   * Replace your simple accuracy printout with more advanced metrics (F1, top-5 accuracy, confusion matrices).  \n",
    "\n",
    "7. **Model serving**  \n",
    "   * Convert the remote inference helper into a **Ray Serve** deployment for low-latency online predictions.  \n",
    "   * Auto-scale replicas based on request volume.\n",
    "\n",
    "8. **End-to-end MLOps**  \n",
    "   * Register checkpoints in a model registry (for example, MLflow, Weights & Biases, or Ray's built-in MLflow integration).  \n",
    "   * Schedule the notebook as a Ray Job or CI/CD pipeline for regular retraining runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
