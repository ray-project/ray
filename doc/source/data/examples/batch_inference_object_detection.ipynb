{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Batch Inference with PyTorch & torchvision\n",
    "\n",
    "This example demostrates how to do object detection batch inference at scale with a pre-tained PyTorch model and Ray Data.\n",
    "\n",
    "Here is what you'll do:\n",
    "1. Perform object detection on a single image with a pre-trained PyTorch model.\n",
    "1. Scale the PyTorch model with Ray Data, and perform object detection batch inference on a large set of images.\n",
    "1. Evaluate the results and save them to S3 or local disk.\n",
    "1. Learn how to use Ray Data with multiple GPU workers.\n",
    "\n",
    "\n",
    "## Before You Begin\n",
    "\n",
    "Install the following dependencies if you haven't already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision ipywidgets tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Object Detection on a single Image with PyTorch\n",
    "\n",
    "First, let's take a look at this [object detection example](https://pytorch.org/vision/stable/models.html#object-detection) from PyTorch's official documentation. \n",
    "\n",
    "This example includes the following steps:\n",
    "1. Download an image file from the Internet.\n",
    "2. Load and intialize a pre-trained PyTorch model.\n",
    "3. Apply inference preprocessing transforms.\n",
    "4. Use the model for inference.\n",
    "5. Visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# 1: Download an image file from the Internet.\n",
    "url = \"https://s3-us-west-2.amazonaws.com/air-example-data/AnimalDetection/JPEGImages/2007_000063.jpg\"\n",
    "img = Image.open(requests.get(url, stream=True).raw)\n",
    "display(img)\n",
    "\n",
    "# 2: Load and intialize the model.\n",
    "weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "model = fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.9)\n",
    "model.eval()\n",
    "\n",
    "# 3: Apply inference preprocessing transforms.\n",
    "img = transforms.Compose([transforms.PILToTensor()])(img)\n",
    "preprocess = weights.transforms()\n",
    "batch = [preprocess(img)]\n",
    "\n",
    "# 4: Use the model for interence.\n",
    "prediction = model(batch)[0]\n",
    "\n",
    "# 5: Visualize the result.\n",
    "labels = [weights.meta[\"categories\"][i] for i in prediction[\"labels\"]]\n",
    "box = draw_bounding_boxes(img, boxes=prediction[\"boxes\"],\n",
    "                          labels=labels,\n",
    "                          colors=\"red\",\n",
    "                          width=4, font_size=30)\n",
    "im = to_pil_image(box.detach())\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing with Ray Data\n",
    "\n",
    "Then we will scale the previous example to a large set of images. We will use Ray Data to do batch inference in a distributed fashion.\n",
    "\n",
    "### Loading Image Dataset\n",
    "\n",
    "First, we use the {meth}`ray.data.read_images <ray.data.read_images>` API to read image data from S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ds = ray.data.read_images(\"s3://anonymous@air-example-data/AnimalDetection/JPEGImages\")\n",
    "display(ds.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Batching\n",
    "\n",
    "To boost performance with hardware acceleration, we usually do inference in batches. In Ray Data, a batch is by default defined as a `Dict[str, np.ndarray]`. \n",
    "\n",
    "In the following code snippet, we use the {meth}`take_batch <ray.data.Dataset.take_batch>` API to fetch a single batch and inspect its internal data structure. As we can see, the batch is a dict that has one key named \"image\", and the value is an array of images represented in the `np.ndarray` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch = ds.take_batch(batch_size=3)\n",
    "display(single_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch inference with Ray Data\n",
    "\n",
    "Then we will demostrate how to convert the PyTorch example to Ray Data, and do batch inference in a distributed cluster.\n",
    "\n",
    "The first step is to package the model in a Python class. The class mainly consists of two parts. In the `__init__` constructor, we package the code that loads and initializes the model. And in the `__call__` method, we package the code that applies model on each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import (FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "                                          fasterrcnn_resnet50_fpn_v2)\n",
    "from typing import Dict\n",
    "from ray.data.extensions.tensor_extension import create_ragged_ndarray\n",
    "\n",
    "class ObjectDetectionModel:\n",
    "    def __init__(self):\n",
    "        # Define the model loading and initialization code in `__init__`\n",
    "        self.weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "        self.model = fasterrcnn_resnet50_fpn_v2(\n",
    "            weights=self.weights,\n",
    "            box_score_thresh=0.9,\n",
    "        )\n",
    "        self.model.eval()\n",
    "        # Note, since the data in the batch input is `np.ndarray`s, \n",
    "        # we need `transforms.ToTensor` to convert the data to torch tensors.\n",
    "        self.preprossor = transforms.Compose(\n",
    "            [transforms.ToTensor(), self.weights.transforms()]\n",
    "        )\n",
    "\n",
    "    def __call__(self, input_batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        # Define the per-batch inference code in `__call__`\n",
    "        # Preprocess the images.\n",
    "        batch = [self.preprossor(image) for image in input_batch[\"image\"]]\n",
    "        # Do inference on the images.\n",
    "        predictions = self.model(batch)\n",
    "        return {\n",
    "            \"image\": input_batch[\"image\"],\n",
    "            \"labels\": create_ragged_ndarray([pred[\"labels\"].detach().numpy() for pred in predictions]),\n",
    "            \"boxes\": create_ragged_ndarray([pred[\"boxes\"].detach().numpy() for pred in predictions]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the `map_batches` API to apply the model to the whole image data set. Here, the `compute` argument indicates the number of concurrent Ray actors that run the model, and the `batch_size` argument indicates the number of images in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map_batches(\n",
    "    ObjectDetectionModel,\n",
    "    compute=ray.data.ActorPoolStrategy(size=4),\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can use `ds.show` to inspect samples in the result, or the the `ds.write_xxx` APIS to write results to external storages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds.take_batch(batch_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for image, labels, boxes in zip(batch[\"image\"], batch[\"labels\"], batch[\"boxes\"]):\n",
    "    image = torch.from_numpy(image.transpose(2,0,1))\n",
    "    labels = [weights.meta[\"categories\"][i] for i in labels]\n",
    "    boxes = torch.from_numpy(boxes)\n",
    "    box = draw_bounding_boxes(image, \n",
    "                              boxes,\n",
    "                          labels=labels,\n",
    "                          colors=\"red\",\n",
    "                          width=4, font_size=30)\n",
    "    im = to_pil_image(box)\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPUs\n",
    "\n",
    "To use GPUs in the previous example, we first need to change to model to use GPU.\n",
    "\n",
    "```diff\n",
    "         self.model = fasterrcnn_resnet50_fpn_v2(\n",
    "             weights=self.weights,\n",
    "             box_score_thresh=0.9,\n",
    "-        )\n",
    "+        ).cuda()\n",
    "         self.model.eval()\n",
    "         # Note, since the data in the batch input is `np.ndarray`s,\n",
    "         # we need `transforms.ToTensor` to convert the data to torch tensors.\n",
    "```\n",
    "\n",
    "```diff\n",
    "     def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "         # Define the per-batch inference code in `__call__`\n",
    "         # Preprocess the images.\n",
    "-        batch = [self.prepross(image) for image in batch[\"image\"]]\n",
    "+        batch = [self.prepross(image).cuda() for image in batch[\"image\"]]\n",
    "         # Do inference on the images.\n",
    "         predictions = self.model(batch)\n",
    "         # Get the inferred labels and convert it to a np.ndarray\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add the `num_gpus` argument to the `map_batches` API. This will tell Ray to schedule the actors to nodes with GPU resources and assign a GPU to each actor.\n",
    "\n",
    "```diff\n",
    " ds = ds.map_batches(\n",
    "     ObjecytDetectionModel,\n",
    "     compute=ray.data.ActorPoolStrategy(size=4),\n",
    "     batch_size=16,\n",
    "+    num_gpus=1,\n",
    " )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
