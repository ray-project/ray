name: llm-batch-inference-text
entrypoint: python batch_inference_text.py
image_uri: anyscale/ray:2.49.0-py312-cu128
compute_config:
  head_node:
    instance_type: m5.2xlarge
  worker_nodes:
    - instance_type: g6.2xlarge
      min_nodes: 1
      max_nodes: 4
max_retries: 2