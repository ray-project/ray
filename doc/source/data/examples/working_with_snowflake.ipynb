{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Snowflake connector](images/snowflake_connector_logo.png)\n",
    "This example walks through the basics of reading and writing data with the Ray Snowflake connector.\n",
    "\n",
    "## Connection properties\n",
    "The Snowflake connection properties need to be provided to the data source upon creation. The minimal required properties are `user`, `password`, `account` and `warehouse`. To use API keys instead of a password, functionality to load Snowflake API keys is also provided. API keys can be loaded from a file specified by the `private_key_file` property, or can be passed directly via the `private_key` property. If the key is password protected, the password can be given via the `pk_password` property.  Optional properties like database and schema can also be provided at construction or be included in the fully specified table name of format `db.schema.table` when calling read or write operations with a table or subquery.\n",
    "\n",
    "Below is an example of loading properties from the environment, and filtering them by the 'SNOWFLAKE_' prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection properties:\n",
      "database\n",
      "schema\n",
      "warehouse\n",
      "account\n",
      "private_key_file\n",
      "pk_password\n",
      "user\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# get properties form env\n",
    "env_connect_props = {\n",
    "    key.replace('SNOWFLAKE_','').lower(): value \n",
    "    for key,value in os.environ.items() if 'SNOWFLAKE_' in key\n",
    "}\n",
    "\n",
    "# add db and schema in connect props\n",
    "connect_props = dict(\n",
    "    database = 'SNOWFLAKE_SAMPLE_DATA',\n",
    "    schema = 'TPCH_SF1',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    **env_connect_props\n",
    ")\n",
    "\n",
    "print('Connection properties:')\n",
    "print('\\n'.join(connect_props.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from Snowflake\n",
    "Ray will use Snowflake optimizations that allow query results to be read in parallel into a Ray cluster. The created Ray datasets is composed of Pandas dataframes that are spread across the Ray cluster to allow for the distributed operations required in machine learning.\n",
    "\n",
    "![Snowflake read table](images/snowflake_read.png)\n",
    "\n",
    "### Read from tables\n",
    "In order to read an entire table into a a Ray cluster, utilize the Ray data `read_snowflake` method. The code below will read in a sample table from the Snowflake sample database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:04,885\tINFO worker.py:1242 -- Using address localhost:9031 set in the environment variable RAY_ADDRESS\n",
      "find: ‘.git’: No such file or directory\n",
      "2023-02-22 21:12:05,139\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.60.86:9031...\n",
      "2023-02-22 21:12:05,147\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_vnmb5jgl4z6q98h61dx25rccju/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-02-22 21:12:05,152\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_48402d355c084b8cd6a5fcc3d258b432.zip' (0.86MiB) to Ray cluster...\n",
      "2023-02-22 21:12:05,165\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_48402d355c084b8cd6a5fcc3d258b432.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s]\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 1048.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_CUSTKEY</th>\n",
       "      <th>C_NAME</th>\n",
       "      <th>C_ADDRESS</th>\n",
       "      <th>C_NATIONKEY</th>\n",
       "      <th>C_PHONE</th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "      <th>C_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Customer#000000001</td>\n",
       "      <td>IVhzIApeRb ot,c,E</td>\n",
       "      <td>15</td>\n",
       "      <td>25-989-741-2988</td>\n",
       "      <td>711.56</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>to the even, regular platelets. regular, ironi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer#000000002</td>\n",
       "      <td>XSTf4,NCwDVaWNe6tEgvwfmRchLXak</td>\n",
       "      <td>13</td>\n",
       "      <td>23-768-687-3665</td>\n",
       "      <td>121.65</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>l accounts. blithely ironic theodolites integr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Customer#000000003</td>\n",
       "      <td>MG9kdTD2WBHm</td>\n",
       "      <td>1</td>\n",
       "      <td>11-719-748-3364</td>\n",
       "      <td>7498.12</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>deposits eat slyly ironic, even instructions....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_CUSTKEY              C_NAME                       C_ADDRESS  C_NATIONKEY  \\\n",
       "0          1  Customer#000000001               IVhzIApeRb ot,c,E           15   \n",
       "1          2  Customer#000000002  XSTf4,NCwDVaWNe6tEgvwfmRchLXak           13   \n",
       "2          3  Customer#000000003                    MG9kdTD2WBHm            1   \n",
       "\n",
       "           C_PHONE  C_ACCTBAL C_MKTSEGMENT  \\\n",
       "0  25-989-741-2988     711.56     BUILDING   \n",
       "1  23-768-687-3665     121.65   AUTOMOBILE   \n",
       "2  11-719-748-3364    7498.12   AUTOMOBILE   \n",
       "\n",
       "                                           C_COMMENT  \n",
       "0  to the even, regular platelets. regular, ironi...  \n",
       "1  l accounts. blithely ironic theodolites integr...  \n",
       "2   deposits eat slyly ironic, even instructions....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.data import read_snowflake\n",
    "\n",
    "# read the entire table\n",
    "ds = read_snowflake(connect_props, table='CUSTOMER') \n",
    "\n",
    "# display the first 3 results\n",
    "print('count:',ds.count())\n",
    "ds.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read with a query\n",
    "For more control over columns and rows read, as well as joining data from multiple tables, a query can be specified instead of a table name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:11,244\tWARNING read_api.py:331 -- ⚠️  The number of blocks in this dataset (2) limits its parallelism to 2 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 13692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 931.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-485.69</td>\n",
       "      <td>MACHINERY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-759.74</td>\n",
       "      <td>FURNITURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-12.97</td>\n",
       "      <td>MACHINERY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_ACCTBAL C_MKTSEGMENT\n",
       "0    -485.69    MACHINERY\n",
       "1    -759.74    FURNITURE\n",
       "2     -12.97    MACHINERY"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = 'SELECT C_ACCTBAL, C_MKTSEGMENT FROM CUSTOMER WHERE C_ACCTBAL < 0'\n",
    "\n",
    "# read the result of the query\n",
    "ds2 = read_snowflake(connect_props, query=QUERY)\n",
    "\n",
    "# display the first 3 results\n",
    "print('count:',ds2.count())\n",
    "ds2.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional read parameters\n",
    "For reading from Snowflake, underlying Python API arguments are also available. The `timeout` and `params` arguments may be used in the [cursor execute method](https://docs.snowflake.com/en/user-guide/python-connector-api.html#object-cursor).\n",
    "\n",
    "The code below uses the params to specify params to be used by Snowflake when executing the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 122881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 1021.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9957.56</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2526.92</td>\n",
       "      <td>BUILDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7975.22</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_ACCTBAL C_MKTSEGMENT\n",
       "0    9957.56    HOUSEHOLD\n",
       "1    2526.92     BUILDING\n",
       "2    7975.22   AUTOMOBILE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = 'SELECT C_ACCTBAL, C_MKTSEGMENT FROM CUSTOMER WHERE C_ACCTBAL > ?'\n",
    "\n",
    "ds3 = read_snowflake(connect_props, query=QUERY, params=[1000], timeout=1000)\n",
    "print('count:',ds3.count())\n",
    "ds3.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing\n",
    "The Ray Snowflake connector will use Snowflake API to write each partition of data in parallel. Each partition of data in the Ray dataset will have a write task that writes in parallel to Snowflake. \n",
    "![Snowflake write table](images/snowflake_write.png)\n",
    "\n",
    "### Write to tables\n",
    "In order to write a dataset into Snowflake table, use the `write_snowflake` method of the dataset object. Repartition the dataset in order to set the number of write tasks.\n",
    "\n",
    "First, a new database and table needs to be created using the Ray Snowflake Connector or the native Snowflake API. \n",
    "\n",
    "> Note: When using the Ray data connector, we can use the API key loading functionality built into the connector class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.datasource import SnowflakeConnector\n",
    "\n",
    "write_connect_props = {\n",
    "    **connect_props, \n",
    "    'database':'RAY_SAMPLE', \n",
    "    'schema':'PUBLIC'\n",
    "}\n",
    "with SnowflakeConnector(**write_connect_props) as con:\n",
    "    # create destination database\n",
    "    con.query(f'CREATE DATABASE IF NOT EXISTS RAY_SAMPLE')\n",
    "    con.commit()\n",
    "    \n",
    "    # create destination table\n",
    "    con.query('''\n",
    "        CREATE OR REPLACE TABLE CUSTOMER_COPY \n",
    "        LIKE SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER\n",
    "    ''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below writes the previously read data into a new database table that are created using the Snowflake Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:14,301\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read->write]\n",
      "read->write: 100%|██████████| 19/19 [00:11<00:00,  1.60it/s]\n",
      "2023-02-22 21:12:26,201\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:12:26,202\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:12:26,327\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:26,370\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:26,371\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:26,372\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:12:26,385\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 966.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_CUSTKEY</th>\n",
       "      <th>C_NAME</th>\n",
       "      <th>C_ADDRESS</th>\n",
       "      <th>C_NATIONKEY</th>\n",
       "      <th>C_PHONE</th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "      <th>C_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87868</td>\n",
       "      <td>Customer#000087868</td>\n",
       "      <td>uPZ8cB41EapBpopIsIFmDo</td>\n",
       "      <td>1</td>\n",
       "      <td>11-552-716-1697</td>\n",
       "      <td>1049.32</td>\n",
       "      <td>FURNITURE</td>\n",
       "      <td>platelets affix quickly after the boldly iron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87869</td>\n",
       "      <td>Customer#000087869</td>\n",
       "      <td>nmpIurFWrzzqZgXGlIRdlDkXpJkEd</td>\n",
       "      <td>17</td>\n",
       "      <td>27-765-230-3208</td>\n",
       "      <td>825.60</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>ke regular accounts. express ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87870</td>\n",
       "      <td>Customer#000087870</td>\n",
       "      <td>kzLemw38LYB0djEi9kYMbUgQsgHiCCJG</td>\n",
       "      <td>8</td>\n",
       "      <td>18-436-876-3101</td>\n",
       "      <td>2827.08</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>regular asymptotes according to the slyly fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_CUSTKEY              C_NAME                         C_ADDRESS  \\\n",
       "0      87868  Customer#000087868            uPZ8cB41EapBpopIsIFmDo   \n",
       "1      87869  Customer#000087869     nmpIurFWrzzqZgXGlIRdlDkXpJkEd   \n",
       "2      87870  Customer#000087870  kzLemw38LYB0djEi9kYMbUgQsgHiCCJG   \n",
       "\n",
       "   C_NATIONKEY          C_PHONE  C_ACCTBAL C_MKTSEGMENT  \\\n",
       "0            1  11-552-716-1697    1049.32    FURNITURE   \n",
       "1           17  27-765-230-3208     825.60   AUTOMOBILE   \n",
       "2            8  18-436-876-3101    2827.08     BUILDING   \n",
       "\n",
       "                                           C_COMMENT  \n",
       "0   platelets affix quickly after the boldly iron...  \n",
       "1                    ke regular accounts. express ac  \n",
       "2   regular asymptotes according to the slyly fin...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the dataset to the table \n",
    "ds.write_snowflake(\n",
    "    write_connect_props, \n",
    "    table='CUSTOMER_COPY'\n",
    ")\n",
    "\n",
    "# read the new table\n",
    "ds4 = read_snowflake(write_connect_props, table='CUSTOMER_COPY')\n",
    "print('count:',ds4.count())\n",
    "ds4.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional write parameters\n",
    "For writing to Snowflake, the native Snowflake API arguments are also available from the [write_pandas](https://docs.snowflake.com/en/user-guide/python-connector-api.html#module-snowflake-connector-pandas-tools) method. The following is a list of the parameters that may be useful:\n",
    "\n",
    "- `auto_create_table`: When true, will automatically create a table with corresponding columns for each column in the passed in DataFrame. The table will not be created if it already exists\n",
    "- `overwrite`: When true, and if auto_create_table is true, then it drops the table. Otherwise, it truncates the table. In both cases it will replace the existing contents of the table with that of the passed in Pandas DataFrame.\n",
    "- `table_type`: The table type of to-be-created table. The supported table types include ``temp``/``temporary`` and ``transient``. Empty means permanent table as per SQL convention.\n",
    "\n",
    "In the example below, we use the `auto_create_table` parameter to create the output table before writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:28,484\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read->write]\n",
      "read->write: 100%|██████████| 19/19 [00:12<00:00,  1.57it/s]\n",
      "2023-02-22 21:12:40,591\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:12:40,592\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:12:40,808\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:40,854\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:40,855\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:40,855\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:12:40,866\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1800000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 864.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_CUSTKEY</th>\n",
       "      <th>C_NAME</th>\n",
       "      <th>C_ADDRESS</th>\n",
       "      <th>C_NATIONKEY</th>\n",
       "      <th>C_PHONE</th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "      <th>C_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87868</td>\n",
       "      <td>Customer#000087868</td>\n",
       "      <td>uPZ8cB41EapBpopIsIFmDo</td>\n",
       "      <td>1</td>\n",
       "      <td>11-552-716-1697</td>\n",
       "      <td>1049.32</td>\n",
       "      <td>FURNITURE</td>\n",
       "      <td>platelets affix quickly after the boldly iron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87869</td>\n",
       "      <td>Customer#000087869</td>\n",
       "      <td>nmpIurFWrzzqZgXGlIRdlDkXpJkEd</td>\n",
       "      <td>17</td>\n",
       "      <td>27-765-230-3208</td>\n",
       "      <td>825.60</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>ke regular accounts. express ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87870</td>\n",
       "      <td>Customer#000087870</td>\n",
       "      <td>kzLemw38LYB0djEi9kYMbUgQsgHiCCJG</td>\n",
       "      <td>8</td>\n",
       "      <td>18-436-876-3101</td>\n",
       "      <td>2827.08</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>regular asymptotes according to the slyly fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_CUSTKEY              C_NAME                         C_ADDRESS  \\\n",
       "0      87868  Customer#000087868            uPZ8cB41EapBpopIsIFmDo   \n",
       "1      87869  Customer#000087869     nmpIurFWrzzqZgXGlIRdlDkXpJkEd   \n",
       "2      87870  Customer#000087870  kzLemw38LYB0djEi9kYMbUgQsgHiCCJG   \n",
       "\n",
       "   C_NATIONKEY          C_PHONE  C_ACCTBAL C_MKTSEGMENT  \\\n",
       "0            1  11-552-716-1697    1049.32    FURNITURE   \n",
       "1           17  27-765-230-3208     825.60   AUTOMOBILE   \n",
       "2            8  18-436-876-3101    2827.08     BUILDING   \n",
       "\n",
       "                                           C_COMMENT  \n",
       "0   platelets affix quickly after the boldly iron...  \n",
       "1                    ke regular accounts. express ac  \n",
       "2   regular asymptotes according to the slyly fin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the dataset to the table, using an autocreated table\n",
    "ds.write_snowflake(\n",
    "    write_connect_props, \n",
    "    table='CUSTOMER_COPY_2',\n",
    "    auto_create_table=True\n",
    ")\n",
    "\n",
    "# read the new table\n",
    "ds5 = read_snowflake(write_connect_props, table='CUSTOMER_COPY_2')\n",
    "print('count:',ds5.count())\n",
    "ds5.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "If more low level access to the Ray Snowflake connector is needed, the underlying `SnowflakConnector` and `SnowflakeDatasource` can be used.\n",
    "\n",
    "### Snowflake Connector\n",
    "The `SnowflakeConnector` class holds the connection properties and logic required to establish a connection with Snowflake. Internally it calls the native Python Snowflake API in order to read and write from and to Snowflake tables in parallel across the cluster. The datasource uses the Snowflake Python API's optimized `read_batch` and `write_pandas` methods to enable parallel read and writes of data.\n",
    "\n",
    "The connector is also a Python context manager, and utilize `with` semantics to define when a connection should be established, db operations commited to the database, and the connection closed. \n",
    "\n",
    "The code below will read from a sample table using the connector to manage the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:44,437\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:12:44,438\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:12:44,554\tINFO cursor.py:727 -- query: [SELECT COUNT(*) FROM CUSTOMER]\n",
      "2023-02-22 21:12:44,631\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:44,632\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:44,633\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:44,681\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:44,682\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:44,683\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:12:44,695\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "from ray.data.datasource import SnowflakeConnector\n",
    "\n",
    "# query the number of rows, using the connection context to\n",
    "# manage transactions\n",
    "with SnowflakeConnector(**connect_props) as con:\n",
    "    count = con.query_int(f'SELECT COUNT(*) FROM CUSTOMER')\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use `try` blocks with the connector's `open`, `commit` and `close` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:44,788\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:12:44,789\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:12:44,910\tINFO cursor.py:727 -- query: [SELECT COUNT(*) FROM CUSTOMER]\n",
      "2023-02-22 21:12:44,976\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:44,976\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:44,977\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:45,023\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:45,024\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:45,025\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:12:45,039\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "connector = SnowflakeConnector(**connect_props)\n",
    "try:\n",
    "    connector.open()\n",
    "    count = connector.query_int(f'SELECT COUNT(*) FROM CUSTOMER')\n",
    "finally:\n",
    "    connector.close()\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowflake Datasource\n",
    "The Snowflake datasource can be used with the Ray data `read_datasource` and `write_datasource` methods to read and write to Snowflake databases using the distibuted processing capabilities of Ray data. The datasource uses a SnowflakeConnector class that is derived from the DBAPI2Connector class. \n",
    "\n",
    "Below is an exmaple of creating the datasource using the previously defined connect properties, and then using it to read and write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s]\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 1132.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_CUSTKEY</th>\n",
       "      <th>C_NAME</th>\n",
       "      <th>C_ADDRESS</th>\n",
       "      <th>C_NATIONKEY</th>\n",
       "      <th>C_PHONE</th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "      <th>C_COMMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Customer#000000001</td>\n",
       "      <td>IVhzIApeRb ot,c,E</td>\n",
       "      <td>15</td>\n",
       "      <td>25-989-741-2988</td>\n",
       "      <td>711.56</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>to the even, regular platelets. regular, ironi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer#000000002</td>\n",
       "      <td>XSTf4,NCwDVaWNe6tEgvwfmRchLXak</td>\n",
       "      <td>13</td>\n",
       "      <td>23-768-687-3665</td>\n",
       "      <td>121.65</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>l accounts. blithely ironic theodolites integr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Customer#000000003</td>\n",
       "      <td>MG9kdTD2WBHm</td>\n",
       "      <td>1</td>\n",
       "      <td>11-719-748-3364</td>\n",
       "      <td>7498.12</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>deposits eat slyly ironic, even instructions....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_CUSTKEY              C_NAME                       C_ADDRESS  C_NATIONKEY  \\\n",
       "0          1  Customer#000000001               IVhzIApeRb ot,c,E           15   \n",
       "1          2  Customer#000000002  XSTf4,NCwDVaWNe6tEgvwfmRchLXak           13   \n",
       "2          3  Customer#000000003                    MG9kdTD2WBHm            1   \n",
       "\n",
       "           C_PHONE  C_ACCTBAL C_MKTSEGMENT  \\\n",
       "0  25-989-741-2988     711.56     BUILDING   \n",
       "1  23-768-687-3665     121.65   AUTOMOBILE   \n",
       "2  11-719-748-3364    7498.12   AUTOMOBILE   \n",
       "\n",
       "                                           C_COMMENT  \n",
       "0  to the even, regular platelets. regular, ironi...  \n",
       "1  l accounts. blithely ironic theodolites integr...  \n",
       "2   deposits eat slyly ironic, even instructions....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.data import read_datasource\n",
    "from ray.data.datasource import SnowflakeDatasource\n",
    "\n",
    "# use read_datasource to read\n",
    "ds = read_datasource(\n",
    "    SnowflakeDatasource(connector), \n",
    "    table='CUSTOMER'\n",
    ")\n",
    " \n",
    "ds.limit(3).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:46,588\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read->write]\n",
      "read->write: 100%|██████████| 19/19 [00:08<00:00,  2.18it/s]\n",
      "2023-02-22 21:12:55,326\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:12:55,327\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:12:55,457\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:55,501\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:55,502\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:55,502\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:12:55,520\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n"
     ]
    }
   ],
   "source": [
    "# use write_datasource to write\n",
    "connector = SnowflakeConnector(**write_connect_props)\n",
    "datasource = SnowflakeDatasource(connector)\n",
    "ds.write_datasource(\n",
    "    datasource, \n",
    "    table='CUSTOMER_3',\n",
    "    auto_create_table=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DML and DDL\n",
    "The connector can also be used for any DDL or DML operations you would normally execute through the Snowflake Python API. These operations just pass through to the underlying Snowflake API. \n",
    "\n",
    "The code below will create the objects needed for writing to tables. Note that a commit is issued between the queries so the DDL operation executes prior to the next one that is dependent. An alternative is to use two `with` blocks to define transaction boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:55,605\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:12:55,607\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:12:55,734\tINFO cursor.py:727 -- query: [CREATE DATABASE IF NOT EXISTS RAY]\n",
      "2023-02-22 21:12:55,775\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:55,776\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:55,777\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:55,851\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:55,852\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:55,853\tINFO cursor.py:727 -- query: [CREATE OR REPLACE TABLE RAY.PUBLIC.CUSTOMER_COPY LIKE SNOWFLAKE_SAMPLE_DATA.TPCH...]\n",
      "2023-02-22 21:12:56,080\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:56,081\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:56,082\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:56,120\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:56,121\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:56,122\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:12:56,135\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n"
     ]
    }
   ],
   "source": [
    "with connector as con:\n",
    "    con.query(f'CREATE DATABASE IF NOT EXISTS RAY')\n",
    "    con.commit()\n",
    "    con.query(f'''\n",
    "        CREATE OR REPLACE TABLE RAY.PUBLIC.CUSTOMER_COPY\n",
    "            LIKE SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER\n",
    "    ''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas data mapping\n",
    "The Snowflake Datasource converts Pandas data types using the Snowflake Python Connector API. Data mappings are available from the Snowflake [documentation](https://docs.snowflake.com/en/user-guide/python-connector-pandas.html#snowflake-to-pandas-data-mapping). \n",
    "\n",
    "The below code is an example of reading and writing all the available data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:56,241\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:12:56,242\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:12:56,377\tINFO cursor.py:727 -- query: [CREATE OR REPLACE TABLE SAMPLE_TABLE ( ID INT, SAMPLE_NUMBER NUMBER(6,2), SAMPLE...]\n",
      "2023-02-22 21:12:56,515\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:56,516\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:56,517\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:56,567\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:56,568\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:56,568\tINFO cursor.py:727 -- query: [INSERT INTO SAMPLE_TABLE VALUES ( 0, 1111.11, 22222.222, 3.333333333, '444444444...]\n",
      "2023-02-22 21:12:56,906\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:56,907\tINFO cursor.py:727 -- query: [UPDATE SAMPLE_TABLE SET SAMPLE_VARIANT = to_variant(parse_json('{\"key3\": \"value3...]\n",
      "2023-02-22 21:12:57,441\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:57,442\tINFO cursor.py:727 -- query: [UPDATE SAMPLE_TABLE SET SAMPLE_ARRAY = [1,'two',3,4]]\n",
      "2023-02-22 21:12:57,872\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:57,873\tINFO cursor.py:727 -- query: [UPDATE SAMPLE_TABLE SET SAMPLE_OBJECT = {'thirteen':13, 'zero':0}]\n",
      "2023-02-22 21:12:58,287\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:58,288\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:12:58,326\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:12:58,327\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:12:58,328\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:12:58,342\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n",
      "2023-02-22 21:12:59,465\tWARNING read_api.py:331 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLE_NUMBER</th>\n",
       "      <th>SAMPLE_DECIMAL</th>\n",
       "      <th>SAMPLE_FLOAT</th>\n",
       "      <th>SAMPLE_VARCHAR</th>\n",
       "      <th>SAMPLE_BINARY</th>\n",
       "      <th>SAMPLE_INT</th>\n",
       "      <th>SAMPLE_DATE</th>\n",
       "      <th>SAMPLE_TIME</th>\n",
       "      <th>SAMPLE_TIMESTAMP_TZ</th>\n",
       "      <th>SAMPLE_TIMESTAMP_NTZ</th>\n",
       "      <th>SAMPLE_TIMESTAMP_LTZ</th>\n",
       "      <th>SAMPLE_GEOGRAPHY</th>\n",
       "      <th>SAMPLE_VARIANT</th>\n",
       "      <th>SAMPLE_ARRAY</th>\n",
       "      <th>SAMPLE_OBJECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>b'\\x01\\xff\\xee\\xdd\\xaa'</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 08:00:00-07:00</td>\n",
       "      <td>2010-07-08 08:00:00</td>\n",
       "      <td>2011-07-08 08:00:00-07:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SAMPLE_NUMBER  SAMPLE_DECIMAL  SAMPLE_FLOAT SAMPLE_VARCHAR  \\\n",
       "0   0        1111.11       22222.222      3.333333     4444444444   \n",
       "\n",
       "             SAMPLE_BINARY  SAMPLE_INT SAMPLE_DATE SAMPLE_TIME  \\\n",
       "0  b'\\x01\\xff\\xee\\xdd\\xaa'        6666  2007-07-07    08:00:00   \n",
       "\n",
       "        SAMPLE_TIMESTAMP_TZ SAMPLE_TIMESTAMP_NTZ      SAMPLE_TIMESTAMP_LTZ  \\\n",
       "0 2009-07-08 08:00:00-07:00  2010-07-08 08:00:00 2011-07-08 08:00:00-07:00   \n",
       "\n",
       "                                    SAMPLE_GEOGRAPHY  \\\n",
       "0  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "\n",
       "                                  SAMPLE_VARIANT  \\\n",
       "0  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "\n",
       "                      SAMPLE_ARRAY                         SAMPLE_OBJECT  \n",
       "0  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with connector as con:\n",
    "    con.query(\"\"\"\n",
    "        CREATE OR REPLACE TABLE SAMPLE_TABLE (\n",
    "            ID INT,\n",
    "            SAMPLE_NUMBER NUMBER(6,2),\n",
    "            SAMPLE_DECIMAL DECIMAL(8,3),\n",
    "            SAMPLE_FLOAT FLOAT,\n",
    "            SAMPLE_VARCHAR VARCHAR,\n",
    "            SAMPLE_BINARY BINARY,\n",
    "            SAMPLE_INT INT,\n",
    "            SAMPLE_DATE DATE,\n",
    "            SAMPLE_TIME TIME,\n",
    "            SAMPLE_TIMESTAMP_TZ TIMESTAMP_TZ,\n",
    "            SAMPLE_TIMESTAMP_NTZ TIMESTAMP_NTZ,\n",
    "            SAMPLE_TIMESTAMP_LTZ TIMESTAMP_LTZ,\n",
    "            SAMPLE_GEOGRAPHY GEOGRAPHY,\n",
    "            SAMPLE_VARIANT VARIANT,\n",
    "            SAMPLE_ARRAY ARRAY,\n",
    "            SAMPLE_OBJECT OBJECT\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.commit()\n",
    "    con.query(\"\"\"\n",
    "        INSERT INTO SAMPLE_TABLE \n",
    "        VALUES (\n",
    "            0,\n",
    "            1111.11,\n",
    "            22222.222,\n",
    "            3.333333333,\n",
    "            '4444444444',\n",
    "            '01ffeeddaa',\n",
    "            6666,\n",
    "            TO_DATE('2007-07-07'),\n",
    "            TO_TIME('08:00:00.000'),\n",
    "            TO_TIMESTAMP_TZ('2009-07-08 08:00:00'),\n",
    "            TO_TIMESTAMP_NTZ('2010-07-08 08:00:00.000'),\n",
    "            TO_TIMESTAMP_LTZ('2011-07-08 08:00:00.000'),\n",
    "            'POINT(-122.35 37.55)',\n",
    "            NULL,\n",
    "            NULL,\n",
    "            NULL\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.query(\"\"\"UPDATE SAMPLE_TABLE SET SAMPLE_VARIANT = to_variant(parse_json('{\"key3\": \"value3\", \"key4\": \"value4\"}'))\"\"\")\n",
    "    con.query(\"UPDATE SAMPLE_TABLE SET SAMPLE_ARRAY = [1,'two',3,4]\")\n",
    "    con.query(\"UPDATE SAMPLE_TABLE SET SAMPLE_OBJECT = {'thirteen':13, 'zero':0}\")\n",
    "\n",
    "sample = read_snowflake(write_connect_props, table='SAMPLE_TABLE')\n",
    "sample.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code writes the sample data back to Snowflake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:12:59,780\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read->MapBatches(<lambda>)->write]\n",
      "read->MapBatches(<lambda>)->write: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "2023-02-22 21:13:02,129\tINFO connection.py:280 -- Snowflake Connector for Python Version: 3.0.0, Python Version: 3.10.9, Platform: Linux-5.13.0-1025-aws-x86_64-with-glibc2.31\n",
      "2023-02-22 21:13:02,130\tINFO connection.py:974 -- This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "2023-02-22 21:13:02,261\tINFO cursor.py:727 -- query: [COMMIT]\n",
      "2023-02-22 21:13:02,305\tINFO cursor.py:740 -- query execution done\n",
      "2023-02-22 21:13:02,306\tINFO cursor.py:878 -- Number of results in first chunk: 1\n",
      "2023-02-22 21:13:02,307\tINFO connection.py:581 -- closed\n",
      "2023-02-22 21:13:02,319\tINFO connection.py:584 -- No async queries seem to be running, deleting session\n",
      "2023-02-22 21:13:03,390\tWARNING read_api.py:331 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLE_NUMBER</th>\n",
       "      <th>SAMPLE_DECIMAL</th>\n",
       "      <th>SAMPLE_FLOAT</th>\n",
       "      <th>SAMPLE_VARCHAR</th>\n",
       "      <th>SAMPLE_INT</th>\n",
       "      <th>SAMPLE_DATE</th>\n",
       "      <th>SAMPLE_TIME</th>\n",
       "      <th>SAMPLE_TIMESTAMP_TZ</th>\n",
       "      <th>SAMPLE_TIMESTAMP_NTZ</th>\n",
       "      <th>SAMPLE_TIMESTAMP_LTZ</th>\n",
       "      <th>SAMPLE_GEOGRAPHY</th>\n",
       "      <th>SAMPLE_VARIANT</th>\n",
       "      <th>SAMPLE_ARRAY</th>\n",
       "      <th>SAMPLE_OBJECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1111.11</td>\n",
       "      <td>22222.222</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4444444444</td>\n",
       "      <td>6666</td>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2009-07-08 15:00:00</td>\n",
       "      <td>1278576000000000</td>\n",
       "      <td>2011-07-08 15:00:00</td>\n",
       "      <td>{\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...</td>\n",
       "      <td>{\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}</td>\n",
       "      <td>[\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]</td>\n",
       "      <td>{\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SAMPLE_NUMBER  SAMPLE_DECIMAL  SAMPLE_FLOAT SAMPLE_VARCHAR  SAMPLE_INT  \\\n",
       "0   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "1   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "2   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "3   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "4   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "5   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "6   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "7   0        1111.11       22222.222      3.333333     4444444444        6666   \n",
       "\n",
       "  SAMPLE_DATE SAMPLE_TIME SAMPLE_TIMESTAMP_TZ  SAMPLE_TIMESTAMP_NTZ  \\\n",
       "0  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "1  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "2  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "3  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "4  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "5  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "6  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "7  2007-07-07    08:00:00 2009-07-08 15:00:00      1278576000000000   \n",
       "\n",
       "  SAMPLE_TIMESTAMP_LTZ                                   SAMPLE_GEOGRAPHY  \\\n",
       "0  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "1  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "2  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "3  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "4  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "5  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "6  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "7  2011-07-08 15:00:00  {\\n  \"coordinates\": [\\n    -122.35,\\n    37.55...   \n",
       "\n",
       "                                  SAMPLE_VARIANT  \\\n",
       "0  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "1  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "2  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "3  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "4  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "5  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "6  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "7  {\\n  \"key3\": \"value3\",\\n  \"key4\": \"value4\"\\n}   \n",
       "\n",
       "                      SAMPLE_ARRAY                         SAMPLE_OBJECT  \n",
       "0  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  \n",
       "1  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  \n",
       "2  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  \n",
       "3  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  \n",
       "4  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  \n",
       "5  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  \n",
       "6  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  \n",
       "7  [\\n  1,\\n  \"two\",\\n  3,\\n  4\\n]  {\\n  \"thirteen\": 13,\\n  \"zero\": 0\\n}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sample = sample.drop_columns(['SAMPLE_BINARY']) # binary column write does not work in Snowflake API\n",
    "new_sample.write_snowflake(\n",
    "    write_connect_props, \n",
    "    table='SAMPLE_TABLE_DEST', \n",
    "    auto_create_table=True\n",
    ")\n",
    "read_snowflake(\n",
    "    write_connect_props, \n",
    "    table='SAMPLE_TABLE_DEST'\n",
    ").to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5abf9a257024fa0ae177d32ddc0977bda32aa95f4f2d5d07f829679a9e9e7642"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
