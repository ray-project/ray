{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-J-6B Fine-Tuning with Ray AIR and DeepSpeed\n",
    "\n",
    "In this example, we will showcase how to use the Ray AIR for **GPT-J fine-tuning**. GPT-J is a GPT-2-like causal language model trained on the Pile dataset. This particular model has 6 billion parameters. For more information on GPT-J, click [here](https://huggingface.co/docs/transformers/model_doc/gptj).\n",
    "\n",
    "We will use Ray AIR (with the ðŸ¤— Transformers integration) and a pretrained model from Hugging Face hub. Note that you can easily adapt this example to use other similar models.\n",
    "\n",
    "This example focuses more on the performance and distributed computing aspects of Ray AIR. If you are looking for a more beginner friendly introduction to Ray AIR ðŸ¤— Transformers integration, see {doc}`this example </ray-air/examples/huggingface_text_classification>`.\n",
    "\n",
    "It is highly recommended to read [Ray AIR Key Concepts](air-key-concepts) and [Ray Data Key Concepts](data_key_concepts) before starting this example.\n",
    "\n",
    "```{note}\n",
    "In order to run this example, make sure your Ray cluster has access to at least one GPU with 16 or more GBs of memory. The amount of memory needed will depend on the model. This notebook is being tested with 16 g4dn.4xlarge instances.\n",
    "```\n",
    "\n",
    "In this notebook, we will:\n",
    "1. [Set up Ray](#setup)\n",
    "2. [Load the dataset](#load)\n",
    "3. [Preprocess the dataset with Ray AIR](#preprocess)\n",
    "4. [Run the training with Ray AIR](#train)\n",
    "5. [Generate text from prompt with Ray AIR](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the following line in order to install all the necessary dependencies (this notebook is being tested with `transformers==4.26.0`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install \"datasets\" \"evaluate\" \"accelerate>=0.16.0\" \"transformers>=4.26.0\" \"torch>=1.12.0\" \"deepspeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Ray <a name=\"setup\"></a>\n",
    "\n",
    "First, let's set some global variables. We will use 16 workers, each being assigned 1 GPU and 8 CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "use_gpu = True\n",
    "num_workers = 16\n",
    "cpus_per_worker = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `ray.init()` to initialize a local cluster. By default, this cluster will be comprised of only the machine you are running this notebook on. You can also run this notebook on an Anyscale cluster.\n",
    "\n",
    "We define a {ref}`runtime environment <runtime-environments>` to ensure that the Ray workers have access to all the necessary packages. You can omit the `runtime_env` argument if you have all of the packages already installed on each node in your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:35:03,964\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.30.196:6379...\n",
      "2023-03-06 16:35:03,973\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale-staging.com/api/v2/sessions/ses_sedlspnpy16naa5lm9kf2cmi2y/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-06 16:35:04,548\tINFO packaging.py:503 -- Creating a file package for local directory '/tmp/ray_tmp_module/ray'.\n",
      "2023-03-06 16:35:04,664\tWARNING packaging.py:377 -- File /tmp/ray_tmp_module/ray/jars/ray_dist.jar is very large (30.44MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/jars/ray_dist.jar']})`\n",
      "2023-03-06 16:35:04,721\tWARNING packaging.py:377 -- File /tmp/ray_tmp_module/ray/_raylet.so is very large (25.09MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/_raylet.so']})`\n",
      "2023-03-06 16:35:04,769\tWARNING packaging.py:377 -- File /tmp/ray_tmp_module/ray/core/src/ray/gcs/gcs_server is very large (21.16MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/core/src/ray/gcs/gcs_server']})`\n",
      "2023-03-06 16:35:04,809\tWARNING packaging.py:377 -- File /tmp/ray_tmp_module/ray/core/src/ray/raylet/raylet is very large (20.48MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/core/src/ray/raylet/raylet']})`\n",
      "2023-03-06 16:35:05,467\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_f864ba6869d6802c.zip' (145.05MiB) to Ray cluster...\n",
      "2023-03-06 16:35:07,789\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_f864ba6869d6802c.zip'.\n",
      "2023-03-06 16:35:08,306\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_9628256c2f3f4cb7c4a2b90d6cdc5bef.zip' (162.95MiB) to Ray cluster...\n",
      "2023-03-06 16:35:10,727\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_9628256c2f3f4cb7c4a2b90d6cdc5bef.zip'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.16</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://console.anyscale-staging.com/api/v2/sessions/ses_sedlspnpy16naa5lm9kf2cmi2y/services?redirect_to=dashboard\" target=\"_blank\">http://console.anyscale-staging.com/api/v2/sessions/ses_sedlspnpy16naa5lm9kf2cmi2y/services?redirect_to=dashboard</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='console.anyscale-staging.com/api/v2/sessions/ses_sedlspnpy16naa5lm9kf2cmi2y/services?redirect_to=dashboard', python_version='3.8.16', ray_version='3.0.0.dev0', ray_commit='4ddbbb3c4b19c2d27bbf54f8c5ffc100dceafbcf', address_info={'node_ip_address': '10.0.30.196', 'raylet_ip_address': '10.0.30.196', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-03-06_15-55-37_997701_162/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-03-06_15-55-37_997701_162/sockets/raylet', 'webui_url': 'console.anyscale-staging.com/api/v2/sessions/ses_sedlspnpy16naa5lm9kf2cmi2y/services?redirect_to=dashboard', 'session_dir': '/tmp/ray/session_2023-03-06_15-55-37_997701_162', 'metrics_export_port': 8085, 'gcs_address': '10.0.30.196:6379', 'address': '10.0.30.196:6379', 'dashboard_agent_listen_port': 52365, 'node_id': '77de483c435bf4987fd6f1e91d47602554e876fd41230d8d50c05333'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"datasets\",\n",
    "            \"evaluate\",\n",
    "            \"accelerate>=0.16.0\",\n",
    "            \"transformers>=4.26.0\",\n",
    "            \"torch>=1.12.0\",\n",
    "            \"deepspeed\",\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SHOULD BE HIDDEN IN DOCS AND ONLY RAN IN CI\n",
    "# Download the model from our S3 mirror as it's faster\n",
    "\n",
    "import ray\n",
    "import subprocess\n",
    "import ray.util.scheduling_strategies\n",
    "\n",
    "\n",
    "def force_on_node(node_id: str, remote_func_or_actor_class):\n",
    "    scheduling_strategy = ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy(\n",
    "        node_id=node_id, soft=False\n",
    "    )\n",
    "    options = {\"scheduling_strategy\": scheduling_strategy}\n",
    "    return remote_func_or_actor_class.options(**options)\n",
    "\n",
    "\n",
    "def run_on_every_node(remote_func_or_actor_class, **remote_kwargs):\n",
    "    refs = []\n",
    "    for node in ray.nodes():\n",
    "        if node[\"Alive\"] and node[\"Resources\"].get(\"GPU\", None):\n",
    "            refs.append(\n",
    "                force_on_node(node[\"NodeID\"], remote_func_or_actor_class).remote(\n",
    "                    **remote_kwargs\n",
    "                )\n",
    "            )\n",
    "    return ray.get(refs)\n",
    "\n",
    "\n",
    "@ray.remote(num_gpus=1)\n",
    "def download_model():\n",
    "    from transformers.utils.hub import TRANSFORMERS_CACHE\n",
    "\n",
    "    path = os.path.expanduser(\n",
    "        os.path.join(TRANSFORMERS_CACHE, \"models--EleutherAI--gpt-j-6B\")\n",
    "    )\n",
    "    subprocess.run([\"mkdir\", \"-p\", os.path.join(path, \"snapshots\", \"main\")])\n",
    "    subprocess.run([\"mkdir\", \"-p\", os.path.join(path, \"refs\")])\n",
    "    if os.path.exists(os.path.join(path, \"refs\", \"main\")):\n",
    "        return\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"aws\",\n",
    "            \"s3\",\n",
    "            \"sync\",\n",
    "            \"--quiet\",\n",
    "            \"s3://large-dl-models-mirror/models--EleutherAI--gpt-j-6B/main/\",\n",
    "            os.path.join(path, \"snapshots\", \"main\"),\n",
    "        ]\n",
    "    )\n",
    "    with open(os.path.join(path, \"snapshots\", \"main\", \"hash\"), \"r\") as f:\n",
    "        f_hash = f.read().strip()\n",
    "    with open(os.path.join(path, \"refs\", \"main\"), \"w\") as f:\n",
    "        f.write(f_hash)\n",
    "    os.rename(\n",
    "        os.path.join(path, \"snapshots\", \"main\"), os.path.join(path, \"snapshots\", f_hash)\n",
    "    )\n",
    "\n",
    "\n",
    "_ = run_on_every_node(download_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset <a name=\"load\"></a>\n",
    "\n",
    "We will be fine-tuning the model on the [`tiny_shakespeare` dataset](https://huggingface.co/datasets/tiny_shakespeare), comprised of 40,000 lines of Shakespeare from a variety of Shakespeare's plays. The aim will be to make the GPT-J model better at generating text in the style of Shakespeare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tiny_shakespeare dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tiny_shakespeare (/home/ray/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65894225f3b84e5caa117c4d08d9f99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading tiny_shakespeare dataset\")\n",
    "current_dataset = load_dataset(\"tiny_shakespeare\")\n",
    "current_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [Ray Data](datasets) for distributed preprocessing and data ingestion. We can easily convert the dataset obtained from Hugging Face Hub to Ray Data by using {meth}`ray.data.read_api.from_huggingface`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset(num_blocks=1, num_rows=1, schema={text: string}),\n",
       " 'validation': Dataset(num_blocks=1, num_rows=1, schema={text: string}),\n",
       " 'test': Dataset(num_blocks=1, num_rows=1, schema={text: string})}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray.data\n",
    "\n",
    "ray_datasets = ray.data.from_huggingface(current_dataset)\n",
    "ray_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dataset is represented by a single large string, we will need to do some preprocessing. For that, we will define two [Ray AIR Preprocessors](air-preprocessors) using the {class}`~ray.data.preprocessors.BatchMapper` API, allowing us to define functions that will be applied on batches of data.\n",
    "\n",
    "The `split_text` function will take the single string and split it into separate lines, removing empty lines and character names ending with ':' (eg. 'ROMEO:'). The `tokenize` function will take the lines and tokenize them using the ðŸ¤— Tokenizer associated with the model, ensuring each entry has the same length (`block_size`) by padding and truncating. This is necessary for training.\n",
    "\n",
    "```{note}\n",
    "This preprocessing can be done in other ways. A common pattern is to tokenize first, and then split the obtained tokens into equally-sized blocks.\n",
    "```\n",
    "\n",
    "We will use the `splitter` and `tokenizer` Preprocessors below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "from ray.data.preprocessors import BatchMapper\n",
    "\n",
    "\n",
    "def split_text(batch: pd.DataFrame) -> pd.DataFrame:\n",
    "    text = list(batch[\"text\"])\n",
    "    flat_text = \"\".join(text)\n",
    "    split_text = [\n",
    "        x.strip()\n",
    "        for x in flat_text.split(\"\\n\")\n",
    "        if x.strip() and not x.strip()[-1] == \":\"\n",
    "    ]\n",
    "    return pd.DataFrame(split_text, columns=[\"text\"])\n",
    "\n",
    "\n",
    "def tokenize(batch: pd.DataFrame) -> dict:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    ret = tokenizer(\n",
    "        list(batch[\"text\"]),\n",
    "        truncation=True,\n",
    "        max_length=block_size,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    ret[\"labels\"] = ret[\"input_ids\"].copy()\n",
    "    return dict(ret)\n",
    "\n",
    "\n",
    "splitter = BatchMapper(split_text, batch_format=\"pandas\")\n",
    "tokenizer = BatchMapper(tokenize, batch_format=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning the model with Ray AIR <a name=\"train\"></a>\n",
    "\n",
    "We can now configure Ray AIR's {class}`~ray.train.huggingface.huggingface_trainer.HuggingFaceTrainer` to perform distributed fine-tuning of the model. In order to do that, we specify a `trainer_init_per_worker` function, which creates a ðŸ¤— Transformers `Trainer` that will be distributed by Ray using Distributed Data Parallelism (using PyTorch Distributed backend internally). This means that each worker will have its own copy of the model, but operate on different data, At the end of each step, all the workers will sync gradients.\n",
    "\n",
    "Because GPT-J is a relatively large model, it may not be possible to fit it on smaller GPU types (<=16 GB GRAM). To deal with that issue, we can use [DeepSpeed](https://github.com/microsoft/DeepSpeed), a library to optimize the training process and allow us to (among other things) offload and partition optimizer and parameter states, reducing GRAM usage. Furthermore, DeepSpeed ZeRO Stage 3 allows us to load large models without running out of memory.\n",
    "\n",
    "ðŸ¤— Transformers and Ray AIR's integration (`HuggingFaceTrainer`) allow you to easily configure and use DDP and DeepSpeed. All you need to do is specify the DeepSpeed configuration in the [`TrainingArguments`](https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments) object.\n",
    "\n",
    "```{tip}\n",
    "There are many DeepSpeed settings, allowing you to trade-off speed for memory usage. The settings used below are tailored to the cluster setup used (16 g4dn.4xlarge nodes) and batch size of 16. Some things to keep in mind:\n",
    "- If your GPUs support bfloat16, it is recommended to use that instead of float16 mixed precision as it gives better performance and prevents overflows. Simply replace `fp16=True` with `bf16=True` in `TrainingArguments`\n",
    "- If you are running out of GRAM: try reducing batch size (defined in the cell below the next one), set `\"overlap_comm\": False` in DeepSpeed config.\n",
    "- If you are running out of RAM: try adding more nodes to your cluster, use nodes with more RAM, set `\"pin_memory\": False` in DeepSpeed config, reduce batch size and remove `\"offload_param\"` from DeepSpeed config.\n",
    "\n",
    "For more information on DeepSpeed configuration, refer to [Hugging Face documentation](https://huggingface.co/docs/transformers/main_classes/deepspeed) and [DeepSpeed documentation](https://www.deepspeed.ai/docs/config-json/).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import (\n",
    "    GPTJForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    default_data_collator,\n",
    ")\n",
    "from transformers.utils.logging import disable_progress_bar, enable_progress_bar\n",
    "import torch\n",
    "\n",
    "from ray.air import session\n",
    "\n",
    "\n",
    "def trainer_init_per_worker(train_dataset, eval_dataset=None, **config):\n",
    "    # Use the actual number of CPUs assigned by Ray\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(\n",
    "        session.get_trial_resources().bundles[-1].get(\"CPU\", 1)\n",
    "    )\n",
    "    # Enable tf32 for better performance\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "    batch_size = config.get(\"batch_size\", 4)\n",
    "    epochs = config.get(\"epochs\", 2)\n",
    "    warmup_steps = config.get(\"warmup_steps\", 0)\n",
    "    learning_rate = config.get(\"learning_rate\", 0.00002)\n",
    "    weight_decay = config.get(\"weight_decay\", 0.01)\n",
    "\n",
    "    deepspeed = {\n",
    "        \"fp16\": {\n",
    "            \"enabled\": \"auto\",\n",
    "            \"initial_scale_power\": 8,\n",
    "        },\n",
    "        \"bf16\": {\"enabled\": \"auto\"},\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"AdamW\",\n",
    "            \"params\": {\n",
    "                \"lr\": \"auto\",\n",
    "                \"betas\": \"auto\",\n",
    "                \"eps\": \"auto\",\n",
    "            },\n",
    "        },\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 3,\n",
    "            \"offload_optimizer\": {\n",
    "                \"device\": \"cpu\",\n",
    "                \"pin_memory\": True,\n",
    "            },\n",
    "            \"offload_param\": {\n",
    "                \"device\": \"cpu\",\n",
    "                \"pin_memory\": True,\n",
    "            },\n",
    "            \"overlap_comm\": True,\n",
    "            \"contiguous_gradients\": True,\n",
    "            \"reduce_bucket_size\": \"auto\",\n",
    "            \"stage3_prefetch_bucket_size\": \"auto\",\n",
    "            \"stage3_param_persistence_threshold\": \"auto\",\n",
    "            \"gather_16bit_weights_on_model_save\": True,\n",
    "            \"round_robin_gradients\": True,\n",
    "        },\n",
    "        \"gradient_accumulation_steps\": \"auto\",\n",
    "        \"gradient_clipping\": \"auto\",\n",
    "        \"steps_per_print\": 10,\n",
    "        \"train_batch_size\": \"auto\",\n",
    "        \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "        \"wall_clock_breakdown\": False,\n",
    "    }\n",
    "\n",
    "    print(\"Preparing training arguments\")\n",
    "    training_args = TrainingArguments(\n",
    "        \"output\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        logging_steps=1,\n",
    "        save_strategy=\"no\",\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_steps=warmup_steps,\n",
    "        label_names=[\"input_ids\", \"attention_mask\"],\n",
    "        num_train_epochs=epochs,\n",
    "        push_to_hub=False,\n",
    "        disable_tqdm=True,  # declutter the output a little\n",
    "        fp16=True,\n",
    "        gradient_checkpointing=True,\n",
    "        deepspeed=deepspeed,\n",
    "    )\n",
    "    disable_progress_bar()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    print(\"Loading model\")\n",
    "\n",
    "    model = GPTJForCausalLM.from_pretrained(model_name, use_cache=False)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    print(\"Model loaded\")\n",
    "\n",
    "    enable_progress_bar()\n",
    "\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=default_data_collator,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `trainer_init_per_worker` complete, we can now instantiate the `HuggingFaceTrainer`. Aside from the function, we set the `scaling_config`, controlling the amount of workers and resources used, and the `datasets` we will use for training and evaluation.\n",
    "\n",
    "We pass the preprocessors we have defined earlier as an argument, wrapped in a {class}`~ray.data.preprocessors.chain.Chain`. The preprocessor will be included with the returned `Checkpoint`, meaning it will also be applied during inference.\n",
    "\n",
    "```{note}\n",
    "If you want to upload checkpoints to cloud storage (eg. S3), use {class}`ray.tune.syncer.SyncConfig` - see {ref}`train-config-sync` for an example. Using cloud storage is highly recommended, especially for production.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.huggingface import HuggingFaceTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.data.preprocessors import Chain\n",
    "\n",
    "\n",
    "trainer = HuggingFaceTrainer(\n",
    "    trainer_init_per_worker=trainer_init_per_worker,\n",
    "    trainer_init_config={\n",
    "        \"batch_size\": 16,  # per device\n",
    "        \"epochs\": 1,\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=num_workers,\n",
    "        use_gpu=use_gpu,\n",
    "        resources_per_worker={\"GPU\": 1, \"CPU\": cpus_per_worker},\n",
    "    ),\n",
    "    datasets={\"train\": ray_datasets[\"train\"], \"evaluation\": ray_datasets[\"validation\"]},\n",
    "    preprocessor=Chain(splitter, tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we call the `fit` method to start training with Ray AIR. We will save the `Result` object to a variable so we can access metrics and checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-06 17:18:41</td></tr>\n",
       "<tr><td>Running for: </td><td>00:43:11.46        </td></tr>\n",
       "<tr><td>Memory:      </td><td>31.9/62.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/256 CPUs, 0/16 GPUs, 0.0/675.29 GiB heap, 0.0/291.99 GiB objects (0.0/16.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  loss</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  epoch</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>HuggingFaceTrainer_f623d_00000</td><td>TERMINATED</td><td>10.0.30.196:30861</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">          2579.3</td><td style=\"text-align: right;\">0.0715</td><td style=\"text-align: right;\">    4.70588e-07</td><td style=\"text-align: right;\">      1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:35:29,548\tWARNING trial_runner.py:1337 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (281 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.\n",
      "(pid=30861) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(pid=30861)   from pandas import MultiIndex, Int64Index\n",
      "(pid=30861) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(HuggingFaceTrainer pid=30861) 2023-03-06 16:35:39,040\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper] -> AllToAllOperator[randomize_block_order]\n",
      "(HuggingFaceTrainer pid=30861) 2023-03-06 16:35:40,878\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper] -> AllToAllOperator[randomize_block_order]\n",
      "(RayTrainWorker pid=31281) 2023-03-06 16:35:44,877\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=16]\n",
      "(HuggingFaceTrainer pid=30861) 2023-03-06 16:35:45,497\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(HuggingFaceTrainer pid=30861) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(HuggingFaceTrainer pid=30861)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=31281) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=31281)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) /home/ray/anaconda3/lib/python3.8/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   from pandas import MultiIndex, Int64Index\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=31281) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   warnings.warn(\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   warnings.warn(\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   warnings.warn(\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) 2023-03-06 16:36:00,453\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) 2023-03-06 16:36:00,452\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) 2023-03-06 16:36:00,454\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   warnings.warn(\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) 2023-03-06 16:36:00,454\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) 2023-03-06 16:36:00,453\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) 2023-03-06 16:36:00,452\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   warnings.warn(\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) 2023-03-06 16:36:00,452\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) 2023-03-06 16:36:00,453\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=31281) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=31281)   warnings.warn(\n",
      "(RayTrainWorker pid=31281) 2023-03-06 16:36:00,447\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   warnings.warn(\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) 2023-03-06 16:36:00,453\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) 2023-03-06 16:36:00,452\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   warnings.warn(\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) 2023-03-06 16:36:00,452\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) /tmp/ray/session_2023-03-06_15-55-37_997701_162/runtime_resources/py_modules_files/_ray_pkg_f864ba6869d6802c/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   warnings.warn(\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) 2023-03-06 16:36:00,453\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) 2023-03-06 16:36:00,452\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) 2023-03-06 16:36:00,452\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) 2023-03-06 16:36:00,454\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) Preparing training arguments\n",
      "(RayTrainWorker pid=31281) Loading model\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Preparing training arguments\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Loading model\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Preparing training arguments\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Preparing training arguments\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Preparing training arguments\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Preparing training arguments\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Preparing training arguments\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Preparing training arguments\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Preparing training arguments\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Preparing training arguments\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Preparing training arguments\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Preparing training arguments\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Preparing training arguments\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Preparing training arguments\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Preparing training arguments\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Preparing training arguments\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Loading model\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Loading model\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Loading model\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Loading model\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Loading model\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Loading model\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Loading model\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Loading model\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Loading model\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Loading model\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Loading model\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Loading model\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Loading model\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Loading model\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:37:21,252] [INFO] [partition_parameters.py:415:__exit__] finished initializing model with 6.05B parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=31281)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   warnings.warn(\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   warnings.warn(\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   warnings.warn(\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   warnings.warn(\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   warnings.warn(\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   warnings.warn(\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   warnings.warn(\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Model loaded\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Model loaded\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Model loaded\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Model loaded\n",
      "(RayTrainWorker pid=31281) Model loaded\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Model loaded\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Model loaded\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Model loaded\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Model loaded\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Model loaded\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Model loaded\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Model loaded\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Model loaded\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Model loaded\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Model loaded\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) 2023-03-06 16:38:03,416\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 11\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) 2023-03-06 16:38:03,434\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 8\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) 2023-03-06 16:38:03,423\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 10\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) 2023-03-06 16:38:03,419\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 7\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) 2023-03-06 16:38:03,424\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 9\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) 2023-03-06 16:38:03,432\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 3\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) 2023-03-06 16:38:03,453\tINFO distributed_c10d.py:353 -- Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=31281) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=31281) 2023-03-06 16:38:03,448\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "(RayTrainWorker pid=31281) 2023-03-06 16:38:03,448\tINFO distributed_c10d.py:353 -- Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:03,431] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed info: version=0.8.1, git-hash=unknown, git-branch=unknown\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:03,450] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) 2023-03-06 16:38:03,428\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 5\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) 2023-03-06 16:38:03,449\tINFO distributed_c10d.py:353 -- Rank 5: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) 2023-03-06 16:38:03,428\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 1\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) 2023-03-06 16:38:03,449\tINFO distributed_c10d.py:353 -- Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) 2023-03-06 16:38:03,412\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 12\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) 2023-03-06 16:38:03,453\tINFO distributed_c10d.py:353 -- Rank 12: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) 2023-03-06 16:38:03,427\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 2\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) 2023-03-06 16:38:03,448\tINFO distributed_c10d.py:353 -- Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) 2023-03-06 16:38:03,429\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 15\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) 2023-03-06 16:38:03,449\tINFO distributed_c10d.py:353 -- Rank 15: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) 2023-03-06 16:38:03,421\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 13\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) 2023-03-06 16:38:03,452\tINFO distributed_c10d.py:353 -- Rank 13: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Using cuda_amp half precision backend\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) 2023-03-06 16:38:03,431\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 14\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) 2023-03-06 16:38:03,451\tINFO distributed_c10d.py:353 -- Rank 14: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) 2023-03-06 16:38:03,431\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 4\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) 2023-03-06 16:38:03,452\tINFO distributed_c10d.py:353 -- Rank 4: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) 2023-03-06 16:38:03,435\tINFO distributed_c10d.py:319 -- Added key: store_based_barrier_key:2 to store for rank: 6\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) 2023-03-06 16:38:03,455\tINFO distributed_c10d.py:353 -- Rank 6: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) 2023-03-06 16:38:03,448\tINFO distributed_c10d.py:353 -- Rank 11: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) 2023-03-06 16:38:03,455\tINFO distributed_c10d.py:353 -- Rank 8: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) 2023-03-06 16:38:03,454\tINFO distributed_c10d.py:353 -- Rank 10: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) 2023-03-06 16:38:03,450\tINFO distributed_c10d.py:353 -- Rank 7: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) 2023-03-06 16:38:03,456\tINFO distributed_c10d.py:353 -- Rank 9: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=31281) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2334, ip=10.0.53.213) ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) ninja: no work to do.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Time to load cpu_adam op: 2.6751821041107178 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Loading extension module cpu_adam...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Loading extension module cpu_adam...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.51.113) ninja: no work to do.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Time to load cpu_adam op: 2.6925859451293945 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) ninja: no work to do.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Loading extension module cpu_adam...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) ninja: no work to do.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Time to load cpu_adam op: 2.7105295658111572 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) ninja: no work to do.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Time to load cpu_adam op: 2.7104923725128174 seconds\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) ninja: no work to do.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Time to load cpu_adam op: 2.7040586471557617 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) ninja: no work to do.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Time to load cpu_adam op: 2.718742609024048 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Time to load cpu_adam op: 2.683342456817627 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) ninja: no work to do.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Time to load cpu_adam op: 2.7268447875976562 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) Detected CUDA files, patching ldflags\n",
      "(RayTrainWorker pid=31281) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/cpu_adam/build.ninja...\n",
      "(RayTrainWorker pid=31281) Building extension module cpu_adam...\n",
      "(RayTrainWorker pid=31281) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=31281) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) ninja: no work to do.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Time to load cpu_adam op: 2.714007616043091 seconds\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) ninja: no work to do.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Time to load cpu_adam op: 2.712510347366333 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Time to load cpu_adam op: 2.7184810638427734 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Time to load cpu_adam op: 2.719329595565796 seconds\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Time to load cpu_adam op: 2.7163612842559814 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) ninja: no work to do.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) ninja: no work to do.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Time to load cpu_adam op: 2.725243091583252 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) Time to load cpu_adam op: 2.75288987159729 seconds\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Time to load cpu_adam op: 2.7566170692443848 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,767] [INFO] [logging.py:75:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,782] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,782] [INFO] [utils.py:53:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,782] [INFO] [logging.py:75:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer\n",
      "(RayTrainWorker pid=31281) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=31281) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Building extension module utils...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=31281) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,979] [INFO] [utils.py:825:see_memory_usage] Stage 3 initialize beginning\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,980] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 1.26 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,980] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 11.88 GB, percent = 19.1%\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,982] [INFO] [stage3.py:114:__init__] Reduce bucket size 16777216\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:09,982] [INFO] [stage3.py:115:__init__] Prefetch bucket size 15099494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) ninja: no work to do.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Time to load utils op: 0.33064842224121094 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=31281) Building extension module utils...\n",
      "(RayTrainWorker pid=31281) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=31281) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) ninja: no work to do.\n",
      "(RayTrainWorker pid=31281) Time to load utils op: 0.34462642669677734 seconds\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Building extension module utils...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Building extension module utils...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Building extension module utils...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,526] [INFO] [utils.py:825:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,526] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,527] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 11.89 GB, percent = 19.2%\n",
      "(RayTrainWorker pid=31281) Parameter Offload: Total persistent parameters: 811008 in 114 params\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) ninja: no work to do.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Time to load utils op: 0.29694080352783203 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Loading extension module utils...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Building extension module utils...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Building extension module utils...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Building extension module utils...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Building extension module utils...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.51.113) ninja: no work to do.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Time to load utils op: 0.30550432205200195 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Building extension module utils...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Building extension module utils...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Adam Optimizer #0 is created with AVX512 arithmetic capability.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Config: alpha=0.000020, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Building extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Loading extension module utils...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Building extension module utils...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) ninja: no work to do.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Time to load utils op: 0.30418896675109863 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Loading extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Building extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2334, ip=10.0.53.213) ninja: no work to do.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Time to load utils op: 0.3006570339202881 seconds\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,702] [INFO] [utils.py:825:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,702] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,703] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 11.89 GB, percent = 19.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) ninja: no work to do.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Time to load utils op: 0.30536675453186035 seconds\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) ninja: no work to do.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Time to load utils op: 0.30983710289001465 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) ninja: no work to do.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Time to load utils op: 0.3104853630065918 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Loading extension module utils...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) ninja: no work to do.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Time to load utils op: 0.31006431579589844 seconds\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) ninja: no work to do.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Time to load utils op: 0.3110191822052002 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Loading extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Building extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Time to load utils op: 0.30796074867248535 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) ninja: no work to do.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Time to load utils op: 0.3120288848876953 seconds\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) ninja: no work to do.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Time to load utils op: 0.3079547882080078 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Loading extension module utils...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Emitting ninja build file /home/ray/.cache/torch_extensions/py38_cu116/utils/build.ninja...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Building extension module utils...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) ninja: no work to do.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Time to load utils op: 0.31665754318237305 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,862] [INFO] [utils.py:825:see_memory_usage] Before creating fp16 partitions\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,863] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:10,863] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 11.89 GB, percent = 19.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) ninja: no work to do.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Time to load utils op: 0.33661627769470215 seconds\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:11,921] [INFO] [utils.py:825:see_memory_usage] After creating fp16 partitions: 1\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:11,922] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:11,922] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 12.91 GB, percent = 20.8%\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:12,072] [INFO] [utils.py:825:see_memory_usage] Before creating fp32 partitions\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:12,072] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:12,072] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 12.91 GB, percent = 20.8%\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:13,638] [INFO] [utils.py:825:see_memory_usage] After creating fp32 partitions\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:13,638] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:13,638] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 14.32 GB, percent = 23.1%\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:13,784] [INFO] [utils.py:825:see_memory_usage] Before initializing optimizer states\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:13,784] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:13,785] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 14.32 GB, percent = 23.1%\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:18,867] [INFO] [utils.py:825:see_memory_usage] After initializing optimizer states\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:18,868] [INFO] [utils.py:826:see_memory_usage] MA 0.11 GB         Max_MA 0.11 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:18,868] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 19.19 GB, percent = 30.9%\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:18,868] [INFO] [stage3.py:382:_setup_for_real_optimizer] optimizer state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Loading extension module utils...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) ***** Running training *****\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   Num examples = 1348\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   Number of trainable parameters = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Time to load utils op: 0.0005335807800292969 seconds\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Time to load utils op: 0.0005166530609130859 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Loading extension module utils...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) ***** Running training *****\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   Num examples = 1348\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Loading extension module utils...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) ***** Running training *****\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   Num examples = 1348\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   Num Epochs = 1\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   Number of trainable parameters = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Time to load utils op: 0.0005464553833007812 seconds\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Time to load utils op: 0.0005373954772949219 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Loading extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) ***** Running training *****\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   Num examples = 1348\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Loading extension module utils...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) ***** Running training *****\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   Num examples = 1348\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   Number of trainable parameters = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Time to load utils op: 0.0005829334259033203 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Loading extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) ***** Running training *****\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   Num examples = 1348\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   Number of trainable parameters = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Time to load utils op: 0.0005500316619873047 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Loading extension module utils...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) ***** Running training *****\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   Num examples = 1348\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   Number of trainable parameters = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Time to load utils op: 0.000522613525390625 seconds\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Time to load utils op: 0.0005176067352294922 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Loading extension module utils...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) ***** Running training *****\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   Num examples = 1348\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   Number of trainable parameters = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Time to load utils op: 0.0005319118499755859 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Loading extension module utils...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) ***** Running training *****\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   Num examples = 1348\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Loading extension module utils...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) ***** Running training *****\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   Num examples = 1348\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   Num Epochs = 1\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Time to load utils op: 0.000518798828125 seconds\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Time to load utils op: 0.0005497932434082031 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Loading extension module utils...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) ***** Running training *****\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   Num examples = 1348\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Time to load utils op: 0.0005505084991455078 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Loading extension module utils...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) ***** Running training *****\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   Num examples = 1348\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Loading extension module utils...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) ***** Running training *****\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   Num examples = 1348\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Loading extension module utils...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) ***** Running training *****\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   Num examples = 1348\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Time to load utils op: 0.0005173683166503906 seconds\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Time to load utils op: 0.0005285739898681641 seconds\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Time to load utils op: 0.0005178451538085938 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Loading extension module utils...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) ***** Running training *****\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   Num examples = 1348\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   Num Epochs = 1\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   warnings.warn(\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   warnings.warn(\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   warnings.warn(\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   warnings.warn(\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   warnings.warn(\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   warnings.warn(\n",
      "(RayTrainWorker pid=31281) Using /home/ray/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "(RayTrainWorker pid=31281) No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "(RayTrainWorker pid=31281) Loading extension module utils...\n",
      "(RayTrainWorker pid=31281) ***** Running training *****\n",
      "(RayTrainWorker pid=31281)   Num examples = 1348\n",
      "(RayTrainWorker pid=31281)   Num Epochs = 1\n",
      "(RayTrainWorker pid=31281)   Instantaneous batch size per device = 16\n",
      "(RayTrainWorker pid=31281)   Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "(RayTrainWorker pid=31281)   Gradient Accumulation steps = 1\n",
      "(RayTrainWorker pid=31281)   Total optimization steps = 85\n",
      "(RayTrainWorker pid=31281)   Number of trainable parameters = 0\n",
      "(RayTrainWorker pid=31281) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "(RayTrainWorker pid=31281)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,023] [INFO] [utils.py:825:see_memory_usage] After initializing ZeRO optimizer\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,024] [INFO] [utils.py:826:see_memory_usage] MA 0.14 GB         Max_MA 0.91 GB         CA 1.54 GB         Max_CA 2 GB \n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,024] [INFO] [utils.py:834:see_memory_usage] CPU Virtual Memory:  used = 20.25 GB, percent = 32.7%\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,024] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,024] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed using client callable to create LR scheduler\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,025] [INFO] [logging.py:75:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f10a01d7ee0>\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,025] [INFO] [logging.py:75:log_dist] [Rank 0] step=0, skipped=0, lr=[2e-05], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,025] [INFO] [config.py:1009:print] DeepSpeedEngine configuration:\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,026] [INFO] [config.py:1013:print]   activation_checkpointing_config  {\n",
      "(RayTrainWorker pid=31281)     \"partition_activations\": false, \n",
      "(RayTrainWorker pid=31281)     \"contiguous_memory_optimization\": false, \n",
      "(RayTrainWorker pid=31281)     \"cpu_checkpointing\": false, \n",
      "(RayTrainWorker pid=31281)     \"number_checkpoints\": null, \n",
      "(RayTrainWorker pid=31281)     \"synchronize_checkpoint_boundary\": false, \n",
      "(RayTrainWorker pid=31281)     \"profile\": false\n",
      "(RayTrainWorker pid=31281) }\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,026] [INFO] [config.py:1013:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,026] [INFO] [config.py:1013:print]   amp_enabled .................. False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,026] [INFO] [config.py:1013:print]   amp_params ................... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   autotuning_config ............ {\n",
      "(RayTrainWorker pid=31281)     \"enabled\": false, \n",
      "(RayTrainWorker pid=31281)     \"start_step\": null, \n",
      "(RayTrainWorker pid=31281)     \"end_step\": null, \n",
      "(RayTrainWorker pid=31281)     \"metric_path\": null, \n",
      "(RayTrainWorker pid=31281)     \"arg_mappings\": null, \n",
      "(RayTrainWorker pid=31281)     \"metric\": \"throughput\", \n",
      "(RayTrainWorker pid=31281)     \"model_info\": null, \n",
      "(RayTrainWorker pid=31281)     \"results_dir\": \"autotuning_results\", \n",
      "(RayTrainWorker pid=31281)     \"exps_dir\": \"autotuning_exps\", \n",
      "(RayTrainWorker pid=31281)     \"overwrite\": true, \n",
      "(RayTrainWorker pid=31281)     \"fast\": true, \n",
      "(RayTrainWorker pid=31281)     \"start_profile_step\": 3, \n",
      "(RayTrainWorker pid=31281)     \"end_profile_step\": 5, \n",
      "(RayTrainWorker pid=31281)     \"tuner_type\": \"gridsearch\", \n",
      "(RayTrainWorker pid=31281)     \"tuner_early_stopping\": 5, \n",
      "(RayTrainWorker pid=31281)     \"tuner_num_trials\": 50, \n",
      "(RayTrainWorker pid=31281)     \"model_info_path\": null, \n",
      "(RayTrainWorker pid=31281)     \"mp_size\": 1, \n",
      "(RayTrainWorker pid=31281)     \"max_train_batch_size\": null, \n",
      "(RayTrainWorker pid=31281)     \"min_train_batch_size\": 1, \n",
      "(RayTrainWorker pid=31281)     \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "(RayTrainWorker pid=31281)     \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "(RayTrainWorker pid=31281)     \"num_tuning_micro_batch_sizes\": 3\n",
      "(RayTrainWorker pid=31281) }\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   bfloat16_enabled ............. False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   checkpoint_parallel_write_pipeline  False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   checkpoint_tag_validation_enabled  True\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   checkpoint_tag_validation_fail  False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1102c55910>\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   communication_data_type ...... None\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   curriculum_enabled_legacy .... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   curriculum_params_legacy ..... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   data_efficiency_enabled ...... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   dataloader_drop_last ......... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   disable_allgather ............ False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   dump_state ................... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   dynamic_loss_scale_args ...... {'init_scale': 256, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_enabled ........... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_gas_boundary_resolution  1\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_layer_num ......... 0\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_max_iter .......... 100\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_stability ......... 1e-06\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_tol ............... 0.01\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   eigenvalue_verbose ........... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   elasticity_enabled ........... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   flops_profiler_config ........ {\n",
      "(RayTrainWorker pid=31281)     \"enabled\": false, \n",
      "(RayTrainWorker pid=31281)     \"profile_step\": 1, \n",
      "(RayTrainWorker pid=31281)     \"module_depth\": -1, \n",
      "(RayTrainWorker pid=31281)     \"top_modules\": 1, \n",
      "(RayTrainWorker pid=31281)     \"detailed\": true, \n",
      "(RayTrainWorker pid=31281)     \"output_file\": null\n",
      "(RayTrainWorker pid=31281) }\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   fp16_auto_cast ............... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   fp16_enabled ................. True\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   fp16_master_weights_and_gradients  False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   global_rank .................. 0\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   grad_accum_dtype ............. None\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,027] [INFO] [config.py:1013:print]   gradient_accumulation_steps .. 1\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   gradient_clipping ............ 1.0\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   gradient_predivide_factor .... 1.0\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   initial_dynamic_scale ........ 256\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   load_universal_checkpoint .... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   loss_scale ................... 0\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   memory_breakdown ............. False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   nebula_config ................ {\n",
      "(RayTrainWorker pid=31281)     \"enabled\": false, \n",
      "(RayTrainWorker pid=31281)     \"persistent_storage_path\": null, \n",
      "(RayTrainWorker pid=31281)     \"persistent_time_interval\": 100, \n",
      "(RayTrainWorker pid=31281)     \"num_of_version_in_retention\": 2, \n",
      "(RayTrainWorker pid=31281)     \"enable_nebula_load\": true, \n",
      "(RayTrainWorker pid=31281)     \"load_path\": null\n",
      "(RayTrainWorker pid=31281) }\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   optimizer_legacy_fusion ...... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   optimizer_name ............... adamw\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   optimizer_params ............. {'lr': 2e-05, 'betas': [0.9, 0.999], 'eps': 1e-08}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   pld_enabled .................. False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   pld_params ................... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   prescale_gradients ........... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   scheduler_name ............... None\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   scheduler_params ............. None\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   sparse_attention ............. None\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   sparse_gradients_enabled ..... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   steps_per_print .............. 10\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   train_batch_size ............. 256\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   train_micro_batch_size_per_gpu  16\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   use_node_local_storage ....... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   wall_clock_breakdown ......... False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   world_size ................... 16\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   zero_allow_untested_optimizer  False\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=True\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   zero_enabled ................. True\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,028] [INFO] [config.py:1013:print]   zero_optimization_stage ...... 3\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:38:25,029] [INFO] [config.py:998:print_user_config]   json = {\n",
      "(RayTrainWorker pid=31281)     \"fp16\": {\n",
      "(RayTrainWorker pid=31281)         \"enabled\": true, \n",
      "(RayTrainWorker pid=31281)         \"initial_scale_power\": 8\n",
      "(RayTrainWorker pid=31281)     }, \n",
      "(RayTrainWorker pid=31281)     \"bf16\": {\n",
      "(RayTrainWorker pid=31281)         \"enabled\": false\n",
      "(RayTrainWorker pid=31281)     }, \n",
      "(RayTrainWorker pid=31281)     \"optimizer\": {\n",
      "(RayTrainWorker pid=31281)         \"type\": \"AdamW\", \n",
      "(RayTrainWorker pid=31281)         \"params\": {\n",
      "(RayTrainWorker pid=31281)             \"lr\": 2e-05, \n",
      "(RayTrainWorker pid=31281)             \"betas\": [0.9, 0.999], \n",
      "(RayTrainWorker pid=31281)             \"eps\": 1e-08\n",
      "(RayTrainWorker pid=31281)         }\n",
      "(RayTrainWorker pid=31281)     }, \n",
      "(RayTrainWorker pid=31281)     \"zero_optimization\": {\n",
      "(RayTrainWorker pid=31281)         \"stage\": 3, \n",
      "(RayTrainWorker pid=31281)         \"offload_optimizer\": {\n",
      "(RayTrainWorker pid=31281)             \"device\": \"cpu\", \n",
      "(RayTrainWorker pid=31281)             \"pin_memory\": true\n",
      "(RayTrainWorker pid=31281)         }, \n",
      "(RayTrainWorker pid=31281)         \"offload_param\": {\n",
      "(RayTrainWorker pid=31281)             \"device\": \"cpu\", \n",
      "(RayTrainWorker pid=31281)             \"pin_memory\": true\n",
      "(RayTrainWorker pid=31281)         }, \n",
      "(RayTrainWorker pid=31281)         \"overlap_comm\": true, \n",
      "(RayTrainWorker pid=31281)         \"contiguous_gradients\": true, \n",
      "(RayTrainWorker pid=31281)         \"reduce_bucket_size\": 1.677722e+07, \n",
      "(RayTrainWorker pid=31281)         \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
      "(RayTrainWorker pid=31281)         \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
      "(RayTrainWorker pid=31281)         \"gather_16bit_weights_on_model_save\": true, \n",
      "(RayTrainWorker pid=31281)         \"round_robin_gradients\": true\n",
      "(RayTrainWorker pid=31281)     }, \n",
      "(RayTrainWorker pid=31281)     \"gradient_accumulation_steps\": 1, \n",
      "(RayTrainWorker pid=31281)     \"gradient_clipping\": 1.0, \n",
      "(RayTrainWorker pid=31281)     \"steps_per_print\": 10, \n",
      "(RayTrainWorker pid=31281)     \"train_batch_size\": 256, \n",
      "(RayTrainWorker pid=31281)     \"train_micro_batch_size_per_gpu\": 16, \n",
      "(RayTrainWorker pid=31281)     \"wall_clock_breakdown\": false\n",
      "(RayTrainWorker pid=31281) }\n",
      "(RayTrainWorker pid=31281) Time to load utils op: 0.00039315223693847656 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   warnings.warn(\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   warnings.warn(\n",
      "(RayTrainWorker pid=31281) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=31281)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   warnings.warn(\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   warnings.warn(\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   warnings.warn(\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   warnings.warn(\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   warnings.warn(\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   warnings.warn(\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   warnings.warn(\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   warnings.warn(\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   warnings.warn(\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) /home/ray/anaconda3/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=31281) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname      </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  loss</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  step</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_runtime</th><th style=\"text-align: right;\">  train_samples_per_second</th><th style=\"text-align: right;\">  train_steps_per_second</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>HuggingFaceTrainer_f623d_00000</td><td>2023-03-06_17-18-38</td><td>True  </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">               0</td><td>ip-10-0-30-196</td><td style=\"text-align: right;\">                        85</td><td style=\"text-align: right;\">    4.70588e-07</td><td style=\"text-align: right;\">0.0715</td><td>10.0.30.196</td><td style=\"text-align: right;\">30861</td><td>True               </td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">              2579.3</td><td style=\"text-align: right;\">            75.785</td><td style=\"text-align: right;\">        2579.3</td><td style=\"text-align: right;\"> 1678151918</td><td style=\"text-align: right;\">    0.324921</td><td style=\"text-align: right;\">        2413.12</td><td style=\"text-align: right;\">                     0.559</td><td style=\"text-align: right;\">                   0.035</td><td style=\"text-align: right;\">                  85</td><td>f623d_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 12.1235, 'learning_rate': 1.9764705882352945e-05, 'epoch': 0.01}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:39:25,636] [WARNING] [stage3.py:1945:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "(RayTrainWorker pid=31281) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 6.7834, 'learning_rate': 1.9529411764705885e-05, 'epoch': 0.02}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:39:53,720] [WARNING] [stage3.py:1945:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "(RayTrainWorker pid=31281) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 2.215, 'learning_rate': 1.9294117647058825e-05, 'epoch': 0.04}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.1739, 'learning_rate': 1.9058823529411764e-05, 'epoch': 0.05}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.121, 'learning_rate': 1.8823529411764708e-05, 'epoch': 0.06}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.1423, 'learning_rate': 1.8588235294117647e-05, 'epoch': 0.07}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.1007, 'learning_rate': 1.8352941176470587e-05, 'epoch': 0.08}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.1081, 'learning_rate': 1.811764705882353e-05, 'epoch': 0.09}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.094, 'learning_rate': 1.7882352941176474e-05, 'epoch': 0.11}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:43:05,862] [INFO] [logging.py:75:log_dist] [Rank 0] step=10, skipped=0, lr=[1.7647058823529414e-05], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:43:05,863] [INFO] [timer.py:198:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=9.305092191655733, CurrSamplesPerSec=9.320723858265133, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0935, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.12}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0922, 'learning_rate': 1.7411764705882353e-05, 'epoch': 0.13}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0915, 'learning_rate': 1.7176470588235293e-05, 'epoch': 0.14}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0883, 'learning_rate': 1.6941176470588237e-05, 'epoch': 0.15}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0869, 'learning_rate': 1.670588235294118e-05, 'epoch': 0.16}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0815, 'learning_rate': 1.647058823529412e-05, 'epoch': 0.18}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0824, 'learning_rate': 1.623529411764706e-05, 'epoch': 0.19}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0814, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0816, 'learning_rate': 1.5764705882352943e-05, 'epoch': 0.21}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0812, 'learning_rate': 1.5529411764705882e-05, 'epoch': 0.22}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:47:43,658] [INFO] [logging.py:75:log_dist] [Rank 0] step=20, skipped=0, lr=[1.5294117647058822e-05], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:47:43,658] [INFO] [timer.py:198:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=9.258140495476479, CurrSamplesPerSec=9.239576138456105, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0765, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.24}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0833, 'learning_rate': 1.5058823529411765e-05, 'epoch': 0.25}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.084, 'learning_rate': 1.4823529411764707e-05, 'epoch': 0.26}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0838, 'learning_rate': 1.4588235294117647e-05, 'epoch': 0.27}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0833, 'learning_rate': 1.435294117647059e-05, 'epoch': 0.28}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0838, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.29}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0846, 'learning_rate': 1.3882352941176471e-05, 'epoch': 0.31}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0788, 'learning_rate': 1.3647058823529413e-05, 'epoch': 0.32}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0781, 'learning_rate': 1.3411764705882353e-05, 'epoch': 0.33}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.081, 'learning_rate': 1.3176470588235294e-05, 'epoch': 0.34}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:52:21,159] [INFO] [logging.py:75:log_dist] [Rank 0] step=30, skipped=0, lr=[1.2941176470588238e-05], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:52:21,159] [INFO] [timer.py:198:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=9.248354160020558, CurrSamplesPerSec=9.28214394183285, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0755, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.35}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0771, 'learning_rate': 1.2705882352941177e-05, 'epoch': 0.36}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0745, 'learning_rate': 1.2470588235294119e-05, 'epoch': 0.38}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.074, 'learning_rate': 1.223529411764706e-05, 'epoch': 0.39}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0721, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0741, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.41}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0761, 'learning_rate': 1.1529411764705882e-05, 'epoch': 0.42}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0781, 'learning_rate': 1.1294117647058825e-05, 'epoch': 0.44}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0734, 'learning_rate': 1.1058823529411766e-05, 'epoch': 0.45}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0779, 'learning_rate': 1.0823529411764706e-05, 'epoch': 0.46}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:56:55,809] [INFO] [logging.py:75:log_dist] [Rank 0] step=40, skipped=0, lr=[1.0588235294117648e-05], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 16:56:55,810] [INFO] [timer.py:198:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=9.268852163619982, CurrSamplesPerSec=9.372063261799616, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0781, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.47}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0711, 'learning_rate': 1.035294117647059e-05, 'epoch': 0.48}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0736, 'learning_rate': 1.011764705882353e-05, 'epoch': 0.49}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0764, 'learning_rate': 9.882352941176472e-06, 'epoch': 0.51}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0821, 'learning_rate': 9.647058823529412e-06, 'epoch': 0.52}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0746, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.53}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0734, 'learning_rate': 9.176470588235294e-06, 'epoch': 0.54}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0751, 'learning_rate': 8.941176470588237e-06, 'epoch': 0.55}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0742, 'learning_rate': 8.705882352941177e-06, 'epoch': 0.56}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.075, 'learning_rate': 8.470588235294118e-06, 'epoch': 0.58}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:01:28,306] [INFO] [logging.py:75:log_dist] [Rank 0] step=50, skipped=0, lr=[8.23529411764706e-06], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:01:28,307] [INFO] [timer.py:198:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=9.295940772913527, CurrSamplesPerSec=9.323433252297212, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0736, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.59}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:01:54,400] [INFO] [stage3.py:1836:_overflow_clean_up] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 256, reducing to 256\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0725, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.6}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:02:23,682] [WARNING] [stage3.py:1945:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0719, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.61}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0727, 'learning_rate': 7.764705882352941e-06, 'epoch': 0.62}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.071, 'learning_rate': 7.529411764705883e-06, 'epoch': 0.64}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0742, 'learning_rate': 7.294117647058823e-06, 'epoch': 0.65}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0723, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.66}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0696, 'learning_rate': 6.8235294117647065e-06, 'epoch': 0.67}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.073, 'learning_rate': 6.588235294117647e-06, 'epoch': 0.68}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0712, 'learning_rate': 6.352941176470589e-06, 'epoch': 0.69}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:06:04,767] [INFO] [logging.py:75:log_dist] [Rank 0] step=60, skipped=1, lr=[6.11764705882353e-06], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:06:04,768] [INFO] [timer.py:198:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=9.29066108461865, CurrSamplesPerSec=8.909149489481312, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0705, 'learning_rate': 6.11764705882353e-06, 'epoch': 0.71}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0707, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.72}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0709, 'learning_rate': 5.6470588235294125e-06, 'epoch': 0.73}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0701, 'learning_rate': 5.411764705882353e-06, 'epoch': 0.74}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.073, 'learning_rate': 5.176470588235295e-06, 'epoch': 0.75}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0683, 'learning_rate': 4.941176470588236e-06, 'epoch': 0.76}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0678, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.78}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0707, 'learning_rate': 4.4705882352941184e-06, 'epoch': 0.79}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0706, 'learning_rate': 4.235294117647059e-06, 'epoch': 0.8}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0764, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.81}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:10:46,854] [INFO] [logging.py:75:log_dist] [Rank 0] step=70, skipped=1, lr=[3.7647058823529414e-06], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:10:46,854] [INFO] [timer.py:198:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=9.259169226198756, CurrSamplesPerSec=9.147502767252472, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.074, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.82}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:11:13,684] [INFO] [stage3.py:1836:_overflow_clean_up] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 256, reducing to 128.0\n",
      "(RayTrainWorker pid=31281) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.075, 'learning_rate': 3.7647058823529414e-06, 'epoch': 0.84}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:11:43,119] [WARNING] [stage3.py:1945:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0716, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.85}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:12:11,942] [WARNING] [stage3.py:1945:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0692, 'learning_rate': 3.2941176470588236e-06, 'epoch': 0.86}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:12:40,194] [WARNING] [stage3.py:1945:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0706, 'learning_rate': 3.058823529411765e-06, 'epoch': 0.87}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0726, 'learning_rate': 2.8235294117647062e-06, 'epoch': 0.88}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0748, 'learning_rate': 2.5882352941176473e-06, 'epoch': 0.89}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0703, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.91}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0706, 'learning_rate': 2.1176470588235296e-06, 'epoch': 0.92}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.072, 'learning_rate': 1.8823529411764707e-06, 'epoch': 0.93}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:15:28,497] [INFO] [logging.py:75:log_dist] [Rank 0] step=80, skipped=2, lr=[1.6470588235294118e-06], mom=[[0.9, 0.999]]\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:15:28,497] [INFO] [timer.py:198:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=9.237791927647233, CurrSamplesPerSec=9.170908646711112, MemAllocated=0.14GB, MaxMemAllocated=8.92GB\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0685, 'learning_rate': 1.6470588235294118e-06, 'epoch': 0.94}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0712, 'learning_rate': 1.4117647058823531e-06, 'epoch': 0.95}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0697, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.96}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0712, 'learning_rate': 9.411764705882353e-07, 'epoch': 0.98}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=31281) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0686, 'learning_rate': 7.058823529411766e-07, 'epoch': 0.99}\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) Saving model checkpoint to output/checkpoint-85\n",
      "(RayTrainWorker pid=31281) Configuration saved in output/checkpoint-85/config.json\n",
      "(RayTrainWorker pid=31281) Configuration saved in output/checkpoint-85/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'loss': 0.0715, 'learning_rate': 4.7058823529411767e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) Model weights saved in output/checkpoint-85/pytorch_model.bin\n",
      "(RayTrainWorker pid=31281) tokenizer config file saved in output/checkpoint-85/tokenizer_config.json\n",
      "(RayTrainWorker pid=31281) Special tokens file saved in output/checkpoint-85/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:13,320] [INFO] [engine.py:3516:save_16bit_model] Saving model weights to output/checkpoint-85/pytorch_model.bin\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:13,320] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/pytorch_model.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) [2023-03-06 17:18:29,095] [INFO] [logging.py:75:log_dist] [Rank 1] Saving model checkpoint: output/checkpoint-85/global_step85/zero_pp_rank_1_mp_rank_00_model_states.pt\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_1_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_11_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.51.113) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.51.113) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_15_mp_rank_00_model_states.pt...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_14_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.25.154) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154)   warnings.warn(\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_13_mp_rank_00_model_states.pt...\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_12_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_5_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70)   warnings.warn(\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2334, ip=10.0.53.213) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_3_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_4_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=31281)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:29,075] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/pytorch_model.bin.\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:29,087] [INFO] [logging.py:75:log_dist] [Rank 0] [Torch] Checkpoint global_step85 is begin to save!\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:29,109] [INFO] [logging.py:75:log_dist] [Rank 0] Saving model checkpoint: output/checkpoint-85/global_step85/zero_pp_rank_0_mp_rank_00_model_states.pt\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:29,109] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_0_mp_rank_00_model_states.pt...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_2_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_7_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149)   warnings.warn(\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) [2023-03-06 17:18:29,094] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_10_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) [2023-03-06 17:18:29,094] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_8_mp_rank_00_model_states.pt...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_9_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) [2023-03-06 17:18:29,095] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_6_mp_rank_00_model_states.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) /home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) [2023-03-06 17:18:29,249] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_2_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) [2023-03-06 17:18:29,251] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_7_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) [2023-03-06 17:18:29,252] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_8_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) [2023-03-06 17:18:29,256] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_9_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) [2023-03-06 17:18:29,252] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_6_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) [2023-03-06 17:18:29,255] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_1_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) [2023-03-06 17:18:29,250] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_11_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) [2023-03-06 17:18:29,251] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_15_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) [2023-03-06 17:18:29,252] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_14_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) [2023-03-06 17:18:29,254] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_13_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) [2023-03-06 17:18:29,265] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_12_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_12_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) [2023-03-06 17:18:29,250] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_5_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_5_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) [2023-03-06 17:18:29,253] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_3_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_3_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) [2023-03-06 17:18:29,259] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_4_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_4_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:29,316] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_0_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:29,328] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_2_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_7_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) [2023-03-06 17:18:29,310] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_10_mp_rank_00_model_states.pt.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_10_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) [2023-03-06 17:18:29,328] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_8_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_9_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_6_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_1_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_11_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_15_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_14_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) [2023-03-06 17:18:29,329] [INFO] [torch_checkpoint_engine.py:15:save] [Torch] Saving output/checkpoint-85/global_step85/zero_pp_rank_13_mp_rank_00_optim_states.pt...\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) [2023-03-06 17:18:33,857] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_3_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) [2023-03-06 17:18:33,857] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_3_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) [2023-03-06 17:18:33,881] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_2_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) [2023-03-06 17:18:33,881] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_2_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) [2023-03-06 17:18:33,900] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_7_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) [2023-03-06 17:18:33,900] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_7_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) [2023-03-06 17:18:33,905] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_8_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) [2023-03-06 17:18:33,905] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_8_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) [2023-03-06 17:18:33,896] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_10_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) [2023-03-06 17:18:33,896] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_10_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) [2023-03-06 17:18:33,870] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_9_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) [2023-03-06 17:18:33,871] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_9_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) [2023-03-06 17:18:33,918] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_6_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) [2023-03-06 17:18:33,918] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_6_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) [2023-03-06 17:18:33,887] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_1_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) [2023-03-06 17:18:33,887] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_1_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) [2023-03-06 17:18:33,900] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_11_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) [2023-03-06 17:18:33,901] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_11_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) [2023-03-06 17:18:33,913] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_14_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) [2023-03-06 17:18:33,913] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_14_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) [2023-03-06 17:18:33,903] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_15_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) [2023-03-06 17:18:33,903] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_15_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) [2023-03-06 17:18:33,898] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_13_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) [2023-03-06 17:18:33,898] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_13_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) [2023-03-06 17:18:33,884] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_12_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) [2023-03-06 17:18:33,885] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_12_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) [2023-03-06 17:18:33,892] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_5_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) [2023-03-06 17:18:33,892] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_5_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) [2023-03-06 17:18:33,953] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_4_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) [2023-03-06 17:18:33,953] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_4_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:37,982] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saved output/checkpoint-85/global_step85/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:37,984] [INFO] [engine.py:3407:_save_zero_checkpoint] zero checkpoint saved output/checkpoint-85/global_step85/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) \n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) \n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) \n",
      "(RayTrainWorker pid=1943, ip=10.0.24.217) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) [2023-03-06 17:18:38,142] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) \n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) \n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) \n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.57.85) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.51.113) \n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) \n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) \n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.51.113) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1942, ip=10.0.51.113) {'train_runtime': 2413.2956, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) {'train_runtime': 2413.2957, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.25.154) \n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) \n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) \n",
      "(RayTrainWorker pid=1954, ip=10.0.25.154) \n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) \n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) \n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) \n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1964, ip=10.0.26.83) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1964, ip=10.0.26.83) {'train_runtime': 2413.2955, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) {'train_runtime': 2413.2954, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1955, ip=10.0.58.255) \n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) \n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) \n",
      "(RayTrainWorker pid=1955, ip=10.0.58.255) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) {'train_runtime': 2413.2964, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1942, ip=10.0.35.70) \n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) \n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) \n",
      "(RayTrainWorker pid=1942, ip=10.0.35.70) \n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) \n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) \n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) \n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2334, ip=10.0.53.213) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=2334, ip=10.0.53.213) {'train_runtime': 2413.2958, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) \n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) \n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) \n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.29.205) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1963, ip=10.0.29.205) {'train_runtime': 2413.2962, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) {'train_runtime': 2413.2961, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1954, ip=10.0.15.115) \n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) \n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) \n",
      "(RayTrainWorker pid=1954, ip=10.0.15.115) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) {'train_runtime': 2413.2961, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1956, ip=10.0.47.149) \n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) \n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) \n",
      "(RayTrainWorker pid=1956, ip=10.0.47.149) \n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) \n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) \n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) \n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1963, ip=10.0.54.163) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1963, ip=10.0.54.163) {'train_runtime': 2413.2956, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) {'train_runtime': 2413.2963, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.37.101) \n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) \n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) \n",
      "(RayTrainWorker pid=1943, ip=10.0.37.101) \n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) \n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) \n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) \n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) \n",
      "(RayTrainWorker pid=31281) \n",
      "(RayTrainWorker pid=31281) \n",
      "(RayTrainWorker pid=31281) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=31281) \n",
      "(RayTrainWorker pid=31281) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2623, ip=10.0.4.206) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=2623, ip=10.0.4.206) {'train_runtime': 2413.2958, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=31281) [2023-03-06 17:18:38,143] [INFO] [torch_checkpoint_engine.py:27:commit] [Torch] Checkpoint global_step85 is ready now!\n",
      "(RayTrainWorker pid=31281) {'train_runtime': 2413.1243, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) {'train_runtime': 2413.2961, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.14.60) \n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) \n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) \n",
      "(RayTrainWorker pid=1943, ip=10.0.14.60) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1943, ip=10.0.24.217) {'train_runtime': 2413.2958, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n",
      "(RayTrainWorker pid=1942, ip=10.0.57.85) {'train_runtime': 2413.2959, 'train_samples_per_second': 0.559, 'train_steps_per_second': 0.035, 'train_loss': 0.32492108064539293, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 17:18:41,018\tINFO tune.py:825 -- Total run time: 2591.59 seconds (2591.46 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the returned `Result` object to access metrics and the Ray AIR `Checkpoint` associated with the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceCheckpoint(local_path=/home/ray/ray_results/HuggingFaceTrainer_2023-03-06_16-35-29/HuggingFaceTrainer_f623d_00000_0_2023-03-06_16-35-30/checkpoint_000000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = results.checkpoint\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text from prompt\n",
    "\n",
    "We can use the {class}`~ray.train.huggingface.huggingface_predictor.HuggingFacePredictor` to generate predictions from our fine-tuned model.\n",
    "\n",
    "```{tip}\n",
    "For large scale batch inference, consider configuring cloud checkpointing and then pass the cloud-backed `Checkpoint` to {class}`~ray.train.batch_predictor.BatchPredictor`. More information [here](air-predictors).\n",
    "```\n",
    "\n",
    "Because the `HuggingFacePredictor` uses a ðŸ¤— Transformers [`pipeline`](https://huggingface.co/docs/transformers/en/main_classes/pipelines) under the hood, we disable the tokenizer AIR Preprocessor we have used for training and let the `pipeline` to tokenize the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.set_preprocessor(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". We also set `device_map=\"auto\"` so that the model is automatically placed on the right device and set the `task` to `\"text-generation\"`. The `predict` method passes the arguments to a ðŸ¤— Transformers `pipeline` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from ray.train.huggingface import HuggingFacePredictor\n",
    "import pandas as pd\n",
    "\n",
    "prompts = pd.DataFrame([\"Romeo and Juliet\", \"Romeo\", \"Juliet\"], columns=[\"text\"])\n",
    "\n",
    "# Predict on the head node.\n",
    "predictor = HuggingFacePredictor.from_checkpoint(\n",
    "    checkpoint=checkpoint,\n",
    "    task=\"text-generation\",\n",
    "    torch_dtype=torch.float16 if use_gpu else None,\n",
    "    device_map=\"auto\",\n",
    "    use_gpu=use_gpu,\n",
    ")\n",
    "prediction = predictor.predict(\n",
    "    prompts,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    min_length=32,\n",
    "    max_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Romeo and Juliet, they are married: and it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Romeo, thou art Romeo and a Montague; for only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Juliet's name; but I do not sound an ear to na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      generated_text\n",
       "0  Romeo and Juliet, they are married: and it is ...\n",
       "1  Romeo, thou art Romeo and a Montague; for only...\n",
       "2  Juliet's name; but I do not sound an ear to na..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c0d54d489a08ae47a06eae2fd00ff032d6cddb527c382959b7b2575f6a8167f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
