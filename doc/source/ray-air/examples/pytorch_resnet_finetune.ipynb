{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning a Pytorch ResNet Model for Image Classification\n",
    "In this example we will finetune a pretrained ResNet model with Ray Train. You should be familiar with [PyTorch](https://pytorch.org/) before starting the tutorial. \n",
    "\n",
    "For fine-tuning, our network architecture consists of a pretrained ResNet model as the backbone and a randomly initialized linear layer as the classifier. The ResNet model is pretrained on the 1000-class Imagenet dataset. We will unfreeze and retrain all parameters of the model for the new task.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform datasets\n",
    "We will use the *hymenoptera_data* as the fintuning dataset, which contains two classes(bees and ants) and 397 images(244 for train, 153 for validation). The dataset is provided by Pytorch and can be downloaded [here](https://download.pytorch.org/tutorial/hymenoptera_data.zip). The dataset folder is structured such that we can load with Pytorch [ImageFolder](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html) dataset.\n",
    "\n",
    "Notice that the ResNet model was pretrained with hard-coded normalization values. We'll keep these numbers the same for fine-tuning, as shown in *data_transforms*. More details can be found [here](https://pytorch.org/hub/pytorch_vision_resnet/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\")\n",
    "os.system(\"unzip hymenoptera_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Replace with your own path of the dataset\n",
    "DATA_DIR = \"./hymenoptera_data\"\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "input_size = 224\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "torch_datasets = dict()\n",
    "for split in [\"train\", \"val\"]:\n",
    "    torch_datasets[split] = datasets.ImageFolder(os.path.join(DATA_DIR, split), data_transforms[split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will transform our ImageFolder dataset into a Ray dataset, which will partition the whole dataset and distribute the data blocks across the nodes in cluster. You will benefit from faster parallel pre-processing and data ingestion.\n",
    "\n",
    "Note that **batch** here refers to the chunk of data that the map function will execute on, not the batch we use for model training. To learn more about writing functions for {meth}`map_batches <ray.data.Dataset.map_batches>`, read [writing user-defined functions](https://docs.ray.io/en/latest/data/transforming-datasets.html#transform-datasets-writing-udfs) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:07:46,488\tINFO worker.py:1352 -- Connecting to existing Ray cluster at address: 10.0.29.191:6379...\n",
      "2023-02-11 20:07:46,631\tINFO worker.py:1529 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-02-11 20:07:47,037\tINFO packaging.py:373 -- Pushing file package 'gcs://_ray_pkg_36533f2e8a8ea9ade3d97c03aa113b26.zip' (135.91MiB) to Ray cluster...\n",
      "2023-02-11 20:07:49,572\tINFO packaging.py:386 -- Successfully pushed file package 'gcs://_ray_pkg_36533f2e8a8ea9ade3d97c03aa113b26.zip'.\n",
      "Map_Batches: 100%|██████████| 244/244 [00:07<00:00, 33.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: extension<arrow.py_extension_type<ArrowTensorType>>\n",
      "label: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map_Batches: 100%|██████████| 153/153 [00:00<00:00, 287.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: extension<arrow.py_extension_type<ArrowTensorType>>\n",
      "label: int64\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "def convert_batch_to_numpy(batch):\n",
    "    images = np.array([image.numpy() for image, _ in batch])\n",
    "    labels = np.array([label for _, label in batch])\n",
    "    return {\"image\": images, \"label\": labels}\n",
    "\n",
    "ray_datasets = dict()\n",
    "for split in [\"train\", \"val\"]:\n",
    "    ray_datasets[split] = ray.data.from_torch(torch_datasets[split]).map_batches(convert_batch_to_numpy)\n",
    "    print(ray_datasets[split].schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Fine-tuning configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes):\n",
    "    # Load pretrained model params\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Replace the original classifier with a new Linear layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    # Ensure all params get updated during fintuning\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = dict()\n",
    "\n",
    "# Input image size (224 x 224)\n",
    "configs[\"input_size\"] = 224\n",
    "\n",
    "# Number of label classes\n",
    "configs[\"num_classes\"] = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "configs[\"batch_size\"] = 16\n",
    "\n",
    "# Number of epochs to train for\n",
    "configs[\"num_epochs\"] = 15\n",
    "\n",
    "# Hyper-parameters for optimizer\n",
    "configs[\"lr\"] = 0.001\n",
    "configs[\"momentum\"] = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Training Loop\n",
    "\n",
    "The `train_loop_per_worker` function defines the finetuning procedure for each worker.\n",
    "\n",
    "**1. Load dataset shard for each worker**:\n",
    "- A ray trainer will take a dictionary of ray datasets as input. One can accessed these data by `session.get_dataset_shard(DATASET_KEY)` in the workers.\n",
    "- Only the dataset with key \"train\" will be split into multiple shards, while all the others will remain the same. \n",
    "- One can use {meth}`iter_torch_batches <ray.data.Dataset.iter_torch_batches>` to iterate the datasets with automatic tensor batching. If you need more flexible customized batching function, please refer to our lower-level api {meth}`iter_batches <ray.data.Dataset.iter_batches>`.\n",
    "\n",
    "**2. Prepare your model**:\n",
    "- `train.torch.prepare_model` will prepares the model for distributed training. Under the hood, it converts your torch model to `DistributedDataParallel` model, and synchronizes the gradients and buffers across all workers.\n",
    "\n",
    "**3. Report metrics and checkpoint**:\n",
    "- `session.report` will gather the metrics from each worker and save them into log files.\n",
    "- You don't have to save checkpoints manually with `torch.save()`, `session.report()` will help you sync checkpoints to local/cloud storage.\n",
    "- The best checkpoints will be saved according to the specified `checkpoint_score_attribute` in {class}`CheckpointConfig <ray.air.config.CheckpointConfig>`. Here we only save the best model with highest validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train as train\n",
    "from ray.air import session\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "\n",
    "def evaluate(logits, labels):\n",
    "    _, preds = torch.max(logits, 1)\n",
    "    corrects = torch.sum(preds == labels).item()\n",
    "    return corrects\n",
    "\n",
    "def train_loop_per_worker(configs):\n",
    "    # Prepare dataloader for each worker\n",
    "    datasets = dict()\n",
    "    datasets[\"train\"] = session.get_dataset_shard(\"train\")\n",
    "    datasets[\"val\"] = session.get_dataset_shard(\"val\")\n",
    "\n",
    "    # Calculate the batch size for a single worker\n",
    "    worker_batch_size = configs[\"batch_size\"] // session.get_world_size()\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "\n",
    "    # Prepare DDP Model, optimizer, and loss function\n",
    "    model = initialize_model(num_classes=configs[\"num_classes\"])\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=configs[\"lr\"], momentum=configs[\"momentum\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Start training loops\n",
    "    for epoch in range(configs[\"num_epochs\"]):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Create a dataset iterator for the shard on the current worker\n",
    "            dataset_iterator = datasets[phase].iter_torch_batches(batch_size=worker_batch_size)\n",
    "            for batch in dataset_iterator:\n",
    "                inputs = batch[\"image\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "            \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # calculate statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += evaluate(outputs, labels)\n",
    "\n",
    "            epoch_loss = running_loss / datasets[phase].count()\n",
    "            epoch_acc = running_corrects / datasets[phase].count()\n",
    "\n",
    "            print('Epoch {}-{} Loss: {:.4f} Acc: {:.4f}'.format(epoch, phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Report metrics and checkpoint every epoch\n",
    "            if phase == \"val\":\n",
    "                checkpoint = TorchCheckpoint.from_dict(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"model\": model.module.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict()\n",
    "                    }\n",
    "                )\n",
    "                session.report(metrics={\"loss\": epoch_loss, \"acc\": epoch_acc}, checkpoint=checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, setup the TorchTrainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer, TorchCheckpoint\n",
    "from ray.air.config import ScalingConfig, RunConfig, CheckpointConfig\n",
    "from ray.tune.syncer import SyncConfig\n",
    "\n",
    "# Scale out model training across 4 GPUs.\n",
    "scaling_config = ScalingConfig(num_workers=4, use_gpu=True, resources_per_worker={\"CPU\": 4, \"GPU\": 1})\n",
    "\n",
    "# Save the best checkpoint with highest validation accuracy \n",
    "checkpoint_config = CheckpointConfig(num_to_keep=1, checkpoint_score_attribute=\"acc\", checkpoint_score_order=\"max\")\n",
    "\n",
    "# Set experiment name and checkpoint configs\n",
    "run_config = RunConfig(\n",
    "    name=\"resnet-finetune\",\n",
    "    local_dir=\"/tmp/ray_results\",\n",
    "    sync_config=SyncConfig(),\n",
    "    checkpoint_config=checkpoint_config\n",
    ")\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=configs,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    datasets=ray_datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training procedure completed in 53 seconds, it saved the best checkpoint in the `local_dir` provided to the trainer. You can now check the experiment metrics and checkpoint information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-02-11 20:09:59</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:07.54        </td></tr>\n",
       "<tr><td>Memory:      </td><td>26.4/62.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/64 CPUs, 0/4 GPUs, 0.0/163.86 GiB heap, 0.0/72.81 GiB objects (0.0/4.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  _timestamp</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_f56f5_00000</td><td>TERMINATED</td><td>10.0.50.149:4404</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">          56.321</td><td style=\"text-align: right;\">0.342963</td><td style=\"text-align: right;\">0.888889</td><td style=\"text-align: right;\">  1676174990</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=4481, ip=10.0.50.149) 2023-02-11 20:08:57,904\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=4]\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149)   warnings.warn(\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149)   warnings.warn(msg)\n",
      "(RayTrainWorker pid=1964717) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "(RayTrainWorker pid=1964717)   warnings.warn(\n",
      "(RayTrainWorker pid=1964717) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "(RayTrainWorker pid=1964717)   warnings.warn(msg)\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175)   warnings.warn(\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175)   warnings.warn(msg)\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38)   warnings.warn(\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) /home/ray/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38)   warnings.warn(msg)\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) 2023-02-11 20:08:59,066\tINFO train_loop_utils.py:270 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=1964717) 2023-02-11 20:08:59,067\tINFO train_loop_utils.py:270 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) 2023-02-11 20:08:59,047\tINFO train_loop_utils.py:270 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) 2023-02-11 20:08:59,059\tINFO train_loop_utils.py:270 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) 2023-02-11 20:09:00,583\tINFO train_loop_utils.py:330 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=1964717) 2023-02-11 20:09:00,636\tINFO train_loop_utils.py:330 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) 2023-02-11 20:09:00,600\tINFO train_loop_utils.py:330 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) 2023-02-11 20:09:00,796\tINFO train_loop_utils.py:330 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 0-train Loss: 0.5419 Acc: 0.7869\n",
      "(RayTrainWorker pid=1964717) Epoch 0-train Loss: 0.5718 Acc: 0.7213\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 0-train Loss: 0.8408 Acc: 0.4754\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 0-train Loss: 0.7600 Acc: 0.5410\n",
      "(RayTrainWorker pid=1964717) Epoch 0-val Loss: 0.4704 Acc: 0.7647\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 0-val Loss: 0.4704 Acc: 0.7647\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 0-val Loss: 0.4704 Acc: 0.7647\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 0-val Loss: 0.4704 Acc: 0.7647\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _training_iteration</th><th style=\"text-align: right;\">     acc</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname      </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">    loss</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_f56f5_00000</td><td style=\"text-align: right;\">            3.06015</td><td style=\"text-align: right;\">  1676174990</td><td style=\"text-align: right;\">                   15</td><td style=\"text-align: right;\">0.888889</td><td>2023-02-11_20-09-51</td><td>True  </td><td>                </td><td>e2bfb42152344b97bd6089d2c1bf2c1b</td><td style=\"text-align: right;\">               0</td><td>ip-10-0-50-149</td><td style=\"text-align: right;\">                        15</td><td style=\"text-align: right;\">0.342963</td><td>10.0.50.149</td><td style=\"text-align: right;\"> 4404</td><td>True               </td><td style=\"text-align: right;\">              56.321</td><td style=\"text-align: right;\">           3.10375</td><td style=\"text-align: right;\">        56.321</td><td style=\"text-align: right;\"> 1676174991</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  15</td><td>f56f5_00000</td><td style=\"text-align: right;\">     0.183336</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 1-train Loss: 0.2978 Acc: 0.9016\n",
      "(RayTrainWorker pid=1964717) Epoch 1-train Loss: 0.6057 Acc: 0.6721\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 1-train Loss: 0.5975 Acc: 0.6721\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 1-train Loss: 0.5828 Acc: 0.6557\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 1-val Loss: 0.5355 Acc: 0.7124\n",
      "(RayTrainWorker pid=1964717) Epoch 1-val Loss: 0.5355 Acc: 0.7124\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 1-val Loss: 0.5355 Acc: 0.7124\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 1-val Loss: 0.5355 Acc: 0.7124\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 2-train Loss: 0.4905 Acc: 0.7377\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 2-train Loss: 0.3701 Acc: 0.8525\n",
      "(RayTrainWorker pid=1964717) Epoch 2-train Loss: 0.8300 Acc: 0.5574\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 2-train Loss: 0.6091 Acc: 0.6066\n",
      "(RayTrainWorker pid=1964717) Epoch 2-val Loss: 0.5647 Acc: 0.7190\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 2-val Loss: 0.5647 Acc: 0.7190\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 2-val Loss: 0.5647 Acc: 0.7190\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 2-val Loss: 0.5647 Acc: 0.7190\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 3-train Loss: 0.6165 Acc: 0.7705\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 3-train Loss: 0.2930 Acc: 0.8361\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 3-train Loss: 0.5362 Acc: 0.7705\n",
      "(RayTrainWorker pid=1964717) Epoch 3-train Loss: 0.9796 Acc: 0.5410\n",
      "(RayTrainWorker pid=1964717) Epoch 3-val Loss: 0.3309 Acc: 0.8693\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 3-val Loss: 0.3309 Acc: 0.8693\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 3-val Loss: 0.3309 Acc: 0.8693\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 3-val Loss: 0.3309 Acc: 0.8693\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 4-train Loss: 0.1423 Acc: 0.9672\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 4-train Loss: 0.4485 Acc: 0.7705\n",
      "(RayTrainWorker pid=1964717) Epoch 4-train Loss: 0.7047 Acc: 0.6393\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 4-train Loss: 0.4340 Acc: 0.8197\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 4-val Loss: 0.2833 Acc: 0.8824\n",
      "(RayTrainWorker pid=1964717) Epoch 4-val Loss: 0.2833 Acc: 0.8824\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 4-val Loss: 0.2833 Acc: 0.8824\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 4-val Loss: 0.2833 Acc: 0.8824\n",
      "(RayTrainWorker pid=1964717) Epoch 5-train Loss: 0.3556 Acc: 0.7541\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 5-train Loss: 0.2447 Acc: 0.8361\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 5-train Loss: 0.1120 Acc: 1.0000\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 5-train Loss: 0.2577 Acc: 0.8525\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 5-val Loss: 0.2954 Acc: 0.8758\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 5-val Loss: 0.2954 Acc: 0.8758\n",
      "(RayTrainWorker pid=1964717) Epoch 5-val Loss: 0.2954 Acc: 0.8758\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 5-val Loss: 0.2954 Acc: 0.8758\n",
      "(RayTrainWorker pid=1964717) Epoch 6-train Loss: 0.2678 Acc: 0.8852\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 6-train Loss: 0.2312 Acc: 0.8361\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 6-train Loss: 0.1000 Acc: 1.0000\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 6-train Loss: 0.1402 Acc: 1.0000\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 6-val Loss: 0.2900 Acc: 0.8824\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 6-val Loss: 0.2900 Acc: 0.8824\n",
      "(RayTrainWorker pid=1964717) Epoch 6-val Loss: 0.2900 Acc: 0.8824\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 6-val Loss: 0.2900 Acc: 0.8824\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 7-train Loss: 0.0801 Acc: 1.0000\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 7-train Loss: 0.1400 Acc: 0.9672\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 7-train Loss: 0.2313 Acc: 0.8197\n",
      "(RayTrainWorker pid=1964717) Epoch 7-train Loss: 0.2919 Acc: 0.7869\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 7-val Loss: 0.2950 Acc: 0.8824\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 7-val Loss: 0.2950 Acc: 0.8824\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 7-val Loss: 0.2950 Acc: 0.8824\n",
      "(RayTrainWorker pid=1964717) Epoch 7-val Loss: 0.2950 Acc: 0.8824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:29,441\tWARNING util.py:244 -- The `process_trial_save` operation took 2.530 s, which may be a performance bottleneck.\n",
      "2023-02-11 20:09:29,442\tWARNING trial_runner.py:1059 -- Consider turning off forced head-worker trial checkpoint syncs by setting sync_on_checkpoint=False. Note that this may result in faulty trial restoration if a failure occurs while the checkpoint is being synced from the worker to the head node.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 8-train Loss: 0.2025 Acc: 0.9016\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 8-train Loss: 0.1332 Acc: 0.9836\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 8-train Loss: 0.0755 Acc: 1.0000\n",
      "(RayTrainWorker pid=1964717) Epoch 8-train Loss: 0.2536 Acc: 0.9180\n",
      "(RayTrainWorker pid=1964717) Epoch 8-val Loss: 0.3055 Acc: 0.8824\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 8-val Loss: 0.3055 Acc: 0.8824\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 8-val Loss: 0.3055 Acc: 0.8824\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 8-val Loss: 0.3055 Acc: 0.8824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:32,478\tWARNING util.py:244 -- The `process_trial_save` operation took 2.403 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 9-train Loss: 0.0725 Acc: 1.0000\n",
      "(RayTrainWorker pid=1964717) Epoch 9-train Loss: 0.2266 Acc: 0.9836\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 9-train Loss: 0.1900 Acc: 0.9672\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 9-train Loss: 0.1149 Acc: 0.9836\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 9-val Loss: 0.3029 Acc: 0.8758\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 9-val Loss: 0.3029 Acc: 0.8758\n",
      "(RayTrainWorker pid=1964717) Epoch 9-val Loss: 0.3029 Acc: 0.8758\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 9-val Loss: 0.3029 Acc: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:35,514\tWARNING util.py:244 -- The `process_trial_save` operation took 2.394 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 10-train Loss: 0.1107 Acc: 0.9836\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 10-train Loss: 0.1787 Acc: 0.9672\n",
      "(RayTrainWorker pid=1964717) Epoch 10-train Loss: 0.2134 Acc: 0.9836\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 10-train Loss: 0.0671 Acc: 1.0000\n",
      "(RayTrainWorker pid=1964717) Epoch 10-val Loss: 0.3204 Acc: 0.8758\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 10-val Loss: 0.3204 Acc: 0.8758\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 10-val Loss: 0.3204 Acc: 0.8758\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 10-val Loss: 0.3204 Acc: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:38,510\tWARNING util.py:244 -- The `process_trial_save` operation took 2.365 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 11-train Loss: 0.1709 Acc: 0.9672\n",
      "(RayTrainWorker pid=1964717) Epoch 11-train Loss: 0.1989 Acc: 0.9836\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 11-train Loss: 0.0642 Acc: 1.0000\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 11-train Loss: 0.1046 Acc: 0.9836\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 11-val Loss: 0.3125 Acc: 0.8758\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 11-val Loss: 0.3125 Acc: 0.8758\n",
      "(RayTrainWorker pid=1964717) Epoch 11-val Loss: 0.3125 Acc: 0.8758\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 11-val Loss: 0.3125 Acc: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:41,572\tWARNING util.py:244 -- The `process_trial_save` operation took 2.412 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 12-train Loss: 0.0609 Acc: 1.0000\n",
      "(RayTrainWorker pid=1964717) Epoch 12-train Loss: 0.1879 Acc: 0.9344\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 12-train Loss: 0.1594 Acc: 0.9672\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 12-train Loss: 0.0977 Acc: 0.9672\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 12-val Loss: 0.3345 Acc: 0.8758\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 12-val Loss: 0.3345 Acc: 0.8758\n",
      "(RayTrainWorker pid=1964717) Epoch 12-val Loss: 0.3345 Acc: 0.8758\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 12-val Loss: 0.3345 Acc: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:44,602\tWARNING util.py:244 -- The `process_trial_save` operation took 2.402 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 13-train Loss: 0.0903 Acc: 0.9836\n",
      "(RayTrainWorker pid=1964717) Epoch 13-train Loss: 0.1829 Acc: 0.9836\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 13-train Loss: 0.0582 Acc: 1.0000\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 13-train Loss: 0.1531 Acc: 0.9836\n",
      "(RayTrainWorker pid=1964717) Epoch 13-val Loss: 0.3233 Acc: 0.8758\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 13-val Loss: 0.3233 Acc: 0.8758\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 13-val Loss: 0.3233 Acc: 0.8758\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 13-val Loss: 0.3233 Acc: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:47,650\tWARNING util.py:244 -- The `process_trial_save` operation took 2.409 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 14-train Loss: 0.1386 Acc: 1.0000\n",
      "(RayTrainWorker pid=1964717) Epoch 14-train Loss: 0.1710 Acc: 0.9180\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 14-train Loss: 0.0554 Acc: 1.0000\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 14-train Loss: 0.0840 Acc: 1.0000\n",
      "(RayTrainWorker pid=2126, ip=10.0.53.38) Epoch 14-val Loss: 0.3430 Acc: 0.8889\n",
      "(RayTrainWorker pid=1964717) Epoch 14-val Loss: 0.3430 Acc: 0.8889\n",
      "(RayTrainWorker pid=4315, ip=10.0.62.175) Epoch 14-val Loss: 0.3430 Acc: 0.8889\n",
      "(RayTrainWorker pid=4481, ip=10.0.50.149) Epoch 14-val Loss: 0.3430 Acc: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:09:50,710\tWARNING util.py:244 -- The `process_trial_save` operation took 2.448 s, which may be a performance bottleneck.\n",
      "2023-02-11 20:09:53,567\tWARNING util.py:244 -- The `process_trial_save` operation took 2.197 s, which may be a performance bottleneck.\n",
      "2023-02-11 20:09:57,403\tWARNING util.py:244 -- The `process_trial_save` operation took 1.776 s, which may be a performance bottleneck.\n",
      "2023-02-11 20:09:59,693\tINFO tune.py:762 -- Total run time: 67.87 seconds (67.54 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(metrics={'loss': 0.34296345968960534, 'acc': 0.8888888888888888, '_timestamp': 1676174990, '_time_this_iter_s': 3.0601508617401123, '_training_iteration': 15, 'should_checkpoint': True, 'done': True, 'trial_id': 'f56f5_00000', 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/tmp/ray_results/resnet-finetune/TorchTrainer_f56f5_00000_0_2023-02-11_20-08-52'))\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the checkpoint for batch prediction:\n",
    "\n",
    "TorchTrainer has already saved the best model parameters in `log_dir`. Now we want to load this model into memory and perform batch prediction and evaluation on test data.\n",
    "`TorchCheckpoint.from_directory` will automatically extract pickled params. BatchPredictor will identify the dict key \"model\", and load the corresponding parameters into model. You can also specify the \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log and checkpoints will be saved into `local_dir` specified in TrainerTrainer. The format of Checkpoint path is \"{local_dir}/{experiment_name}/{trail_name}/{checkpoint_name}\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = \"/tmp/ray_results/resnet-finetune/TorchTrainer_42662_00000_0_2023-02-11_19-56-42/checkpoint_000014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "checkpoint_folder = result.checkpoint.uri[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.torch import TorchCheckpoint, TorchPredictor\n",
    "\n",
    "ckpt = TorchCheckpoint.from_directory(checkpoint_folder)\n",
    "predictor = BatchPredictor.from_checkpoint(ckpt, TorchPredictor, model=initialize_model(configs[\"num_classes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 20:11:23,027\tWARNING compute.py:549 -- Requested batch size 4096 results in batches of 2466299904 bytes for map_batches tasks, which is larger than the configured target max block size 536870912. This may result in out-of-memory errors for certain workloads, and you may want to decrease your batch size or increase the configured target max block size, e.g.: from ray.data.context import DatasetContext; DatasetContext.get_current().target_max_block_size = 4_000_000_000\n",
      "2023-02-11 20:11:23,027\tWARNING compute.py:520 -- `batch_size` is set to 4096, which reduces parallelism from 153 to 1. If the performance is worse than expected, this may indicate that the batch size is too large or the input block size is too small. To reduce batch size, consider decreasing `batch_size` or use the default in `map_batches`. To increase input block size, consider decreasing `parallelism` in read.\n",
      "Map_Batches:   0%|          | 0/1 [00:00<?, ?it/s]2023-02-11 20:11:23,646\tWARNING worker.py:1851 -- Warning: The actor BlockWorker is very large (42 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "Map Progress (3 actors 1 pending): 100%|██████████| 1/1 [00:16<00:00, 16.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: extension<arrow.py_extension_type<ArrowTensorType>>\n",
      "label: int64\n",
      "[{'predictions': array([ 2.3760695, -0.7187623], dtype=float32), 'label': 0}, {'predictions': array([ 2.1758888, -2.2852275], dtype=float32), 'label': 0}, {'predictions': array([ 2.9107504, -2.6489625], dtype=float32), 'label': 0}, {'predictions': array([ 2.845186, -2.409718], dtype=float32), 'label': 0}, {'predictions': array([ 3.203075 , -3.5486095], dtype=float32), 'label': 0}]\n"
     ]
    }
   ],
   "source": [
    "prediction_ds = predictor.predict(ray_datasets[\"val\"], feature_columns=[\"image\"], keep_columns=[\"label\"])\n",
    "print(prediction_ds.schema())\n",
    "print(prediction_ds.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions results\n",
    "The BatchPredictor returns a ray dataset as result, which consists a column of `predictions` and the columns specified by `keep_columns` argument. The `predictions` column contains the model's tensor output. Here we define a function `convert_logits_to_classes` to convert tensor outputs to labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map_Batches: 100%|██████████| 1/1 [00:00<00:00, 62.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 0, 'label': 0, 'correct': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffle Map: 100%|██████████| 1/1 [00:00<00:00, 111.20it/s]\n",
      "Shuffle Reduce: 100%|██████████| 1/1 [00:00<00:00, 168.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy =  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def convert_logits_to_classes(df):\n",
    "    pred_class = df[\"predictions\"].map(lambda x: x.argmax())\n",
    "    df[\"prediction\"] = pred_class\n",
    "    df[\"correct\"] = df[\"prediction\"] == df[\"label\"]\n",
    "    return df[[\"prediction\", \"label\", \"correct\"]]\n",
    "\n",
    "predictions = prediction_ds.map_batches(convert_logits_to_classes)\n",
    "predictions.show(1)\n",
    "\n",
    "print(\"Evaluation Accuracy = \", predictions.mean(on=\"correct\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of rewriting a new evaluation function in pandas format, one can also reuse the evaluation function they wrote in the training loop. Note that the previous approach using `map_batches()` is more efficient than iterating over the dataset, because it parallelizes the evaluation on each partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy =  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "def evaluate(logits, labels):\n",
    "    _, preds = torch.max(logits, 1)\n",
    "    corrects = torch.sum(preds == labels).item()\n",
    "    return corrects\n",
    "\n",
    "accuracy = 0\n",
    "for batch in prediction_ds.iter_torch_batches(batch_size=10):\n",
    "    accuracy += evaluate(batch[\"predictions\"], batch[\"label\"])\n",
    "accuracy /= prediction_ds.count()\n",
    "\n",
    "print(\"Evaluation Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is adapted from Pytorch's [Fintuning Torchvision Models](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html) tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
