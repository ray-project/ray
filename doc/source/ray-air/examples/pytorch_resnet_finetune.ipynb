{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning a Pytorch Image Classifier with Ray AIR\n",
    "In this example we will finetune a pretrained ResNet model with Ray Train. \n",
    "\n",
    "For this example, our network architecture consists of the intermediate layer output of a pretrained ResNet model, which feeds into a randomly initialized linear layer that outputs classification logits for our new task.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess finetuning dataset\n",
    "This example is adapted from Pytorch's [Fintuning Torchvision Models](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html) tutorial.\n",
    "We will use *hymenoptera_data* as the finetuning dataset, which contains two classes (bees and ants) and 397 total images (across training and validation). This is a quite small dataset and we use this only for demenstration purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# If you want to run full example, please set SMOKE_TEST as False\n",
    "SMOKE_TEST = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\")\n",
    "os.system(\"unzip hymenoptera_data.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is structured with directory names as the labels. We use `torchvision.datasets.ImageFolder()` to load the images and their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Replace with your own path of the dataset\n",
    "DATA_DIR = \"./hymenoptera_data\"\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "torch_datasets = dict()\n",
    "for split in [\"train\", \"val\"]:\n",
    "    torch_datasets[split] = datasets.ImageFolder(\n",
    "        os.path.join(DATA_DIR, split), data_transforms[split]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if SMOKE_TEST:\n",
    "    from torch.utils.data import Subset\n",
    "\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        indices = list(range(100))\n",
    "        torch_datasets[split] = Subset(torch_datasets[split], indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the images from PyTorch ImageFolder to a Ray dataset, which will partition the whole dataset and distribute the data blocks across the nodes in cluster. You will benefit from faster parallel pre-processing and data ingestion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 20:58:28,112\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.3.6:6379...\n",
      "2023-02-28 20:58:28,124\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale-staging.com/api/v2/sessions/ses_49hwcjc1pzcddc2nf6cg9itj6b/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-02-28 20:58:28,521\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_281310c9b14127d68ef8fadde956f87a.zip' (136.06MiB) to Ray cluster...\n",
      "2023-02-28 20:58:31,340\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_281310c9b14127d68ef8fadde956f87a.zip'.\n",
      "2023-02-28 20:58:32,007\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "MapBatches(convert_batch_to_numpy): 100%|██████████| 200/200 [00:06<00:00, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: extension<arrow.py_extension_type<ArrowTensorType>>\n",
      "label: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 20:58:39,675\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(convert_batch_to_numpy)]\n",
      "MapBatches(convert_batch_to_numpy): 100%|██████████| 153/153 [00:00<00:00, 2200.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: extension<arrow.py_extension_type<ArrowTensorType>>\n",
      "label: int64\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "def convert_batch_to_numpy(batch):\n",
    "    images = np.array([image.numpy() for image, _ in batch])\n",
    "    labels = np.array([label for _, label in batch])\n",
    "    return {\"image\": images, \"label\": labels}\n",
    "\n",
    "\n",
    "ray_datasets = dict()\n",
    "for split in [\"train\", \"val\"]:\n",
    "    ray_datasets[split] = ray.data.from_torch(torch_datasets[split]).map_batches(\n",
    "        convert_batch_to_numpy\n",
    "    )\n",
    "    print(ray_datasets[split].schema())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Note that **batch** here refers to the chunk of data for preprocessing, not the batch for model training. To learn more about writing functions for mapping batches, read [writing user-defined functions](transform_datasets_writing_udfs).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Fine-tuning configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define the training configuration, which will be passed into training loop function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop_config = {\n",
    "    \"input_size\": 224,  # Input image size (224 x 224)\n",
    "    \"batch_size\": 32,  # Batch size for training\n",
    "    \"num_epochs\": 10,  # Number of epochs to train for\n",
    "    \"lr\": 0.001,  # Learning Rate\n",
    "    \"momentum\": 0.9,  # SGD optimizer momentum\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's define our model, you can either create a model from a pretrained weights, or reload the model checkpoint from a previous run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 20:58:39,990\tINFO instantiator.py:21 -- Created a temporary directory at /tmp/tmp0wtd7j01\n",
      "2023-02-28 20:58:39,992\tINFO instantiator.py:76 -- Writing /tmp/tmp0wtd7j01/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "from ray.train.torch import TorchCheckpoint\n",
    "\n",
    "# Option 1: Initialize model with pretrained weights\n",
    "def initialize_model():\n",
    "    # Load pretrained model params\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Replace the original classifier with a new Linear layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "    # Ensure all params get updated during fintuning\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    return model\n",
    "\n",
    "\n",
    "# Option 2: Initialize model with an AIR checkpoint\n",
    "CHECKPOINT_URI = \"s3://air-example-data/finetune-resnet-checkpoint/TorchTrainer_4f69f_00000_0_2023-02-14_14-04-09/checkpoint_000000/\"\n",
    "\n",
    "\n",
    "def initialize_model_from_ckpt():\n",
    "    checkpoint = TorchCheckpoint.from_uri(CHECKPOINT_URI)\n",
    "    resnet18 = initialize_model()\n",
    "    return checkpoint.get_model(model=resnet18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Training Loop\n",
    "\n",
    "The `train_loop_per_worker` function defines the finetuning procedure for each worker.\n",
    "\n",
    "**1. Load dataset shard for each worker**:\n",
    "- The Trainer will take a dictionary of Ray {class}`~ray.data.Dataset`s as input. These will be preprocessed and accessible in the worker's training loop via {meth}`session.get_dataset_shard() <ray.air.session.get_dataset_shard>`.\n",
    "- By default, only the dataset under the key \"train\" will be split into multiple shards. `session.get_dataset_shard()` will return the full dataset for other keys. To configure this, see {class}`~ray.air.DatasetConfig`.\n",
    "- Use {meth}`iter_torch_batches <ray.data.Dataset.iter_torch_batches>` to iterate the datasets with automatic tensor batching and device placement. If you need a more flexible customized batching function, please refer to our lower-level {meth}`iter_batches <ray.data.Dataset.iter_batches>` API.\n",
    "\n",
    "**2. Prepare your model**:\n",
    "- {meth}`train.torch.prepare_model() <ray.train.torch.prepare_model>` will prepares the model for distributed training. Under the hood, it converts your torch model to `DistributedDataParallel` model, which will synchronize its weights across all workers.\n",
    "\n",
    "**3. Report metrics and checkpoint**:\n",
    "- {meth}`session.report() <ray.air.session.report>` will report metrics and checkpoints to Ray AIR.\n",
    "- Saving checkpoints through {meth}`session.report(metrics, checkpoint=...) <ray.air.session.report>` will automatically [upload checkpoints to cloud storage](tune-cloud-checkpointing) (if configured), and allow you to easily enable Ray AIR worker fault tolerance in the future.\n",
    "- The best checkpoints will be saved according to the specified `checkpoint_score_attribute` in {class}`CheckpointConfig <ray.air.config.CheckpointConfig>`. Here we only save the best model with highest validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train as train\n",
    "from ray.air import session\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "\n",
    "\n",
    "def evaluate(logits, labels):\n",
    "    _, preds = torch.max(logits, 1)\n",
    "    corrects = torch.sum(preds == labels).item()\n",
    "    return corrects\n",
    "\n",
    "\n",
    "def train_loop_per_worker(configs):\n",
    "    import warnings\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Prepare dataloader for each worker\n",
    "    datasets = dict()\n",
    "    datasets[\"train\"] = session.get_dataset_shard(\"train\")\n",
    "    datasets[\"val\"] = session.get_dataset_shard(\"val\")\n",
    "\n",
    "    # Calculate the batch size for a single worker\n",
    "    worker_batch_size = configs[\"batch_size\"] // session.get_world_size()\n",
    "\n",
    "    device = train.torch.get_device()\n",
    "\n",
    "    # Prepare DDP Model, optimizer, and loss function\n",
    "    model = initialize_model()\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=configs[\"lr\"], momentum=configs[\"momentum\"]\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Start training loops\n",
    "    for epoch in range(configs[\"num_epochs\"]):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Create a dataset iterator for the shard on the current worker\n",
    "            dataset_iterator = datasets[phase].iter_torch_batches(\n",
    "                batch_size=worker_batch_size, device=device\n",
    "            )\n",
    "            for batch in dataset_iterator:\n",
    "                inputs = batch[\"image\"]\n",
    "                labels = batch[\"label\"]\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # calculate statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += evaluate(outputs, labels)\n",
    "\n",
    "            epoch_loss = running_loss / datasets[phase].count()\n",
    "            epoch_acc = running_corrects / datasets[phase].count()\n",
    "\n",
    "            if session.get_world_rank() == 0:\n",
    "                print(\n",
    "                    \"Epoch {}-{} Loss: {:.4f} Acc: {:.4f}\".format(\n",
    "                        epoch, phase, epoch_loss, epoch_acc\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Report metrics and checkpoint every epoch\n",
    "            if phase == \"val\":\n",
    "                checkpoint = TorchCheckpoint.from_dict(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"model\": model.module.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    }\n",
    "                )\n",
    "                session.report(\n",
    "                    metrics={\"loss\": epoch_loss, \"acc\": epoch_acc},\n",
    "                    checkpoint=checkpoint,\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, setup the TorchTrainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer, TorchCheckpoint\n",
    "from ray.air.config import ScalingConfig, RunConfig, CheckpointConfig\n",
    "from ray.tune.syncer import SyncConfig\n",
    "\n",
    "# Scale out model training across 4 GPUs.\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=4, use_gpu=True, resources_per_worker={\"CPU\": 1, \"GPU\": 1}\n",
    ")\n",
    "\n",
    "# Save the latest checkpoint\n",
    "checkpoint_config = CheckpointConfig(num_to_keep=1)\n",
    "\n",
    "# Set experiment name and checkpoint configs\n",
    "run_config = RunConfig(\n",
    "    name=\"finetune-resnet\",\n",
    "    local_dir=\"/tmp/ray_results\",\n",
    "    checkpoint_config=checkpoint_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if SMOKE_TEST:\n",
    "    scaling_config = ScalingConfig(\n",
    "        num_workers=8, use_gpu=False, resources_per_worker={\"CPU\": 1}\n",
    "    )\n",
    "    train_loop_config[\"num_epochs\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-02-28 21:06:20</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:42.16        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.1/62.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/64 CPUs, 0/4 GPUs, 0.0/164.24 GiB heap, 0.0/72.97 GiB objects (0.0/4.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">    acc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_b4f06_00000</td><td>TERMINATED</td><td>10.0.3.6:99124</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         36.3842</td><td style=\"text-align: right;\">0.157967</td><td style=\"text-align: right;\">0.96732</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=99244) 2023-02-28 21:05:45,574\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=4]\n",
      "(TorchTrainer pid=99124) 2023-02-28 21:05:46,211\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n",
      "(TorchTrainer pid=99124) /home/ray/anaconda3/lib/python3.9/site-packages/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(TorchTrainer pid=99124)   warnings.warn(\n",
      "(RayTrainWorker pid=2059, ip=10.0.47.22) 2023-02-28 21:05:46,949\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=1945, ip=10.0.23.119) 2023-02-28 21:05:46,948\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=99244) 2023-02-28 21:05:46,953\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=1951, ip=10.0.31.3) 2023-02-28 21:05:46,952\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=1951, ip=10.0.31.3) 2023-02-28 21:05:48,628\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=2059, ip=10.0.47.22) 2023-02-28 21:05:48,625\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=1945, ip=10.0.23.119) 2023-02-28 21:05:48,615\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=99244) 2023-02-28 21:05:48,687\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=1945, ip=10.0.23.119) 2023-02-28 21:05:52,228\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n",
      "(RayTrainWorker pid=1951, ip=10.0.31.3) 2023-02-28 21:05:52,229\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n",
      "(RayTrainWorker pid=99244) 2023-02-28 21:05:52,229\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=99244) Epoch 0-train Loss: 0.6717 Acc: 0.5574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=2059, ip=10.0.47.22) 2023-02-28 21:05:52,228\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=99244) Epoch 0-val Loss: 0.5739 Acc: 0.5621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">    acc</th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname   </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">    loss</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_b4f06_00000</td><td style=\"text-align: right;\">0.96732</td><td>2023-02-28_21-06-18</td><td>True  </td><td style=\"text-align: right;\">               0</td><td>ip-10-0-3-6</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">0.157967</td><td>10.0.3.6 </td><td style=\"text-align: right;\">99124</td><td>True               </td><td style=\"text-align: right;\">             36.3842</td><td style=\"text-align: right;\">           2.61072</td><td style=\"text-align: right;\">       36.3842</td><td style=\"text-align: right;\"> 1677647177</td><td style=\"text-align: right;\">                  10</td><td>b4f06_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=99244) Epoch 1-train Loss: 0.4580 Acc: 0.8361\n",
      "(RayTrainWorker pid=99244) Epoch 1-val Loss: 0.3622 Acc: 0.9477\n",
      "(RayTrainWorker pid=99244) Epoch 2-train Loss: 0.2940 Acc: 0.9508\n",
      "(RayTrainWorker pid=99244) Epoch 2-val Loss: 0.2779 Acc: 0.9542\n",
      "(RayTrainWorker pid=99244) Epoch 3-train Loss: 0.2059 Acc: 0.9344\n",
      "(RayTrainWorker pid=99244) Epoch 3-val Loss: 0.2230 Acc: 0.9673\n",
      "(RayTrainWorker pid=99244) Epoch 4-train Loss: 0.1383 Acc: 0.9836\n",
      "(RayTrainWorker pid=99244) Epoch 4-val Loss: 0.1988 Acc: 0.9608\n",
      "(RayTrainWorker pid=99244) Epoch 5-train Loss: 0.0962 Acc: 1.0000\n",
      "(RayTrainWorker pid=99244) Epoch 5-val Loss: 0.1810 Acc: 0.9673\n",
      "(RayTrainWorker pid=99244) Epoch 6-train Loss: 0.0724 Acc: 1.0000\n",
      "(RayTrainWorker pid=99244) Epoch 6-val Loss: 0.1710 Acc: 0.9673\n",
      "(RayTrainWorker pid=99244) Epoch 7-train Loss: 0.0511 Acc: 1.0000\n",
      "(RayTrainWorker pid=99244) Epoch 7-val Loss: 0.1644 Acc: 0.9673\n",
      "(RayTrainWorker pid=99244) Epoch 8-train Loss: 0.0397 Acc: 1.0000\n",
      "(RayTrainWorker pid=99244) Epoch 8-val Loss: 0.1607 Acc: 0.9673\n",
      "(RayTrainWorker pid=99244) Epoch 9-train Loss: 0.0320 Acc: 1.0000\n",
      "(RayTrainWorker pid=99244) Epoch 9-val Loss: 0.1580 Acc: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 21:06:20,577\tINFO tune.py:825 -- Total run time: 42.17 seconds (42.16 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'loss': 0.15796673334404535, 'acc': 0.9673202614379085, 'should_checkpoint': True, 'done': True, 'trial_id': 'b4f06_00000', 'experiment_tag': '0'},\n",
      "  log_dir=PosixPath('/tmp/ray_results/finetune-resnet/TorchTrainer_b4f06_00000_0_2023-02-28_21-05-38'),\n",
      "  checkpoint=TorchCheckpoint(local_path=/tmp/ray_results/finetune-resnet/TorchTrainer_b4f06_00000_0_2023-02-28_21-05-38/checkpoint_000009)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    datasets=ray_datasets,\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the checkpoint for batch prediction:\n",
    "\n",
    " \n",
    " The metadata and checkpoints have already been saved into `local_dir` specified in TrainerTrainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ray_results/finetune-resnet/TorchTrainer_b4f06_00000_0_2023-02-28_21-05-38/checkpoint_000009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.metadata.pkl', 'dict_checkpoint.pkl', '.is_checkpoint', '.tune_metadata']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_folder = result.checkpoint.uri.replace(\"file://\", \"\")\n",
    "print(checkpoint_folder)\n",
    "os.listdir(checkpoint_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to load the trained model and evaluation it on test data. TorchTrainer has already saved the best model parameters in `log_dir`. We can use {ref}`TorchCheckpoint.from_directory() <ray.train.torch.TorchCheckpoint.from_directory>` to load the resulting checkpoint from our fine-tuning run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = TorchCheckpoint.from_directory(checkpoint_folder)\n",
    "model = checkpoint.get_model(initialize_model())\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if SMOKE_TEST:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define a simple evaluation loop and check the checkpoint model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9673202614379085\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "dataloader = DataLoader(torch_datasets[\"val\"], batch_size=32, num_workers=4)\n",
    "corrects = 0\n",
    "for inputs, labels in dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    preds = model(inputs)\n",
    "    corrects += evaluate(preds, labels)\n",
    "\n",
    "print(\"Accuracy: \", corrects / len(dataloader.dataset))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
