{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62191af",
   "metadata": {},
   "source": [
    "# Analyzing results from hyperparameter tuning\n",
    "In this example, we will go through how you can use Ray AIR to run a distributed hyperparameter experiment to find optimal hyperparameters for an XGBoost model.\n",
    "\n",
    "What we'll cover:\n",
    "- How to load data from an Sklearn example dataset\n",
    "- How to initialize an XGBoost trainer\n",
    "- How to define a search space for regular XGBoost parameters and for data preprocessors\n",
    "- How to fetch the best obtained result from the tuning run\n",
    "- How to fetch a dataframe to do further analysis on the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abda7b",
   "metadata": {},
   "source": [
    "We'll use the [Covertype dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn-datasets-fetch-covtype) provided from sklearn to train a multiclass classification task using XGBoost.\n",
    "\n",
    "In this dataset, we try to predict the forst cover type (e.g. \"lodgehole pine\") from cartographic variables, like the distance to the closest road, or the hillshade at different times of the day. The features are binary, discrete and continuous and thus well suited for a decision-tree based classification task.\n",
    "\n",
    "You can find more information about the dataset [on the dataset homepage](https://archive.ics.uci.edu/ml/datasets/Covertype).\n",
    "\n",
    "We will train XGBoost models on this dataset. Because model training performance can be influenced by hyperparameter choices, we will generate several different configurations and train them in parallel. Notably each of these trials will itself start a distributed training job to speed up training. All of this happens automatically within Ray AIR.\n",
    "\n",
    "First, let's make sure we have all dependencies installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db506971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[all] in /Users/kai/coding/ray/python (2.0.0.dev0)\n",
      "Requirement already satisfied: sklearn in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: attrs in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (21.2.0)\n",
      "Requirement already satisfied: click<=8.0.4,>=7.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (8.0.4)\n",
      "Requirement already satisfied: filelock in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (3.6.0)\n",
      "Requirement already satisfied: grpcio!=1.44.0,>=1.28.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.43.0)\n",
      "Requirement already satisfied: jsonschema in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (4.4.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.0.3)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (3.20.0)\n",
      "Requirement already satisfied: pyyaml in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (6.0)\n",
      "Requirement already satisfied: aiosignal in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.2.0)\n",
      "Requirement already satisfied: frozenlist in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.3.0)\n",
      "Requirement already satisfied: requests in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (2.25.1)\n",
      "Requirement already satisfied: virtualenv in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (20.14.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.21.6)\n",
      "Requirement already satisfied: scikit-image in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.19.2)\n",
      "Requirement already satisfied: lz4 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (4.0.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (2.5)\n",
      "Requirement already satisfied: aiohttp_cors in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.7.0)\n",
      "Requirement already satisfied: pandas in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.3.5)\n",
      "Requirement already satisfied: matplotlib!=3.4.3 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (3.5.0)\n",
      "Requirement already satisfied: starlette in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.17.1)\n",
      "Requirement already satisfied: kopf in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.35.4)\n",
      "Requirement already satisfied: opencensus in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.9.0)\n",
      "Requirement already satisfied: colorful in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.5.4)\n",
      "Requirement already satisfied: aiorwlock in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.3.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (3.8.1)\n",
      "Requirement already satisfied: scipy in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.4.1)\n",
      "Requirement already satisfied: prometheus_client<0.14.0,>=0.7.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.13.1)\n",
      "Requirement already satisfied: tabulate in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.8.9)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=6.0.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (6.0.1)\n",
      "Requirement already satisfied: fastapi in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.75.2)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.1.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp==1.1.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.1.0)\n",
      "Requirement already satisfied: gym<0.22 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.21.0)\n",
      "Requirement already satisfied: dm_tree in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.1.7)\n",
      "Requirement already satisfied: opentelemetry-api==1.1.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.1.0)\n",
      "Requirement already satisfied: kubernetes in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (23.3.0)\n",
      "Requirement already satisfied: fsspec in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (2022.3.0)\n",
      "Requirement already satisfied: uvicorn==0.16.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.16.0)\n",
      "Requirement already satisfied: gpustat>=1.0.0b1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.0.0b1)\n",
      "Requirement already satisfied: urllib3 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (1.26.9)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (0.3.11)\n",
      "Requirement already satisfied: smart_open in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from ray[all]) (5.2.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.1.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.20b0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from opentelemetry-sdk==1.1.0->ray[all]) (0.20b0)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from uvicorn==0.16.0->ray[all]) (0.12.0)\n",
      "Requirement already satisfied: asgiref>=3.4.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from uvicorn==0.16.0->ray[all]) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from uvicorn==0.16.0->ray[all]) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.1.0->opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.53.0)\n",
      "Requirement already satisfied: backoff~=1.10.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.1.0->opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.10.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.1.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.1.0->opentelemetry-exporter-otlp==1.1.0->ray[all]) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from aiohttp>=3.7->ray[all]) (2.0.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from aiohttp>=3.7->ray[all]) (5.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from aiohttp>=3.7->ray[all]) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from aiohttp>=3.7->ray[all]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from aiohttp>=3.7->ray[all]) (1.7.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from click<=8.0.4,>=7.0->ray[all]) (4.10.1)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from gpustat>=1.0.0b1->ray[all]) (1.19.0)\n",
      "Requirement already satisfied: psutil in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from gpustat>=1.0.0b1->ray[all]) (5.8.0)\n",
      "Requirement already satisfied: six>=1.7 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from gpustat>=1.0.0b1->ray[all]) (1.15.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from gpustat>=1.0.0b1->ray[all]) (7.352.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from gym<0.22->ray[all]) (2.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (4.28.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (9.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (2.8.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib!=3.4.3->ray[all]) (6.3.2)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from fastapi->ray[all]) (1.9.0)\n",
      "Requirement already satisfied: anyio<4,>=3.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from starlette->ray[all]) (3.4.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from jsonschema->ray[all]) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from jsonschema->ray[all]) (0.16.1)\n",
      "Requirement already satisfied: python-json-logger in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from kopf->ray[all]) (2.0.2)\n",
      "Requirement already satisfied: iso8601 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from kopf->ray[all]) (1.0.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from kubernetes->ray[all]) (59.5.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from kubernetes->ray[all]) (1.35.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from kubernetes->ray[all]) (2021.10.8)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from kubernetes->ray[all]) (1.2.1)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from kubernetes->ray[all]) (1.3.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.2 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from opencensus->ray[all]) (0.1.2)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from opencensus->ray[all]) (1.31.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from pandas->ray[all]) (2021.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from requests->ray[all]) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from requests->ray[all]) (4.0.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from scikit-image->ray[all]) (2.13.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from scikit-image->ray[all]) (2.6.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from scikit-image->ray[all]) (2021.11.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from scikit-image->ray[all]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from virtualenv->ray[all]) (0.3.4)\n",
      "Requirement already satisfied: platformdirs<3,>=2 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from virtualenv->ray[all]) (2.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from anyio<4,>=3.0.0->starlette->ray[all]) (1.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[all]) (0.2.5)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from google-auth>=1.0.1->kubernetes->ray[all]) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from google-auth>=1.0.1->kubernetes->ray[all]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from google-auth>=1.0.1->kubernetes->ray[all]) (4.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from importlib-metadata->click<=8.0.4,>=7.0->ray[all]) (3.7.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib!=3.4.3->ray[all]) (1.2.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from requests-oauthlib->kubernetes->ray[all]) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/kai/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes->ray[all]) (0.4.8)\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/kai/.pyenv/versions/3.7.7/bin/python3.7 -m pip install --upgrade pip' command.\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"ray[all]\" sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82829d",
   "metadata": {},
   "source": [
    "Then we can start with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45b4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.ml import RunConfig\n",
    "from ray.ml.train.integrations.xgboost import XGBoostTrainer\n",
    "from ray.tune.tune_config import TuneConfig\n",
    "from ray.tune.tuner import Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b242c",
   "metadata": {},
   "source": [
    "We'll define a utility function to create a Ray Dataset from the Sklearn dataset. We expect the target column to be in the dataframe, so we'll add it to the dataframe manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3875df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 13:38:00,419\tINFO services.py:1484 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [
    "def get_training_data() -> ray.data.Dataset:\n",
    "    data_raw = fetch_covtype()\n",
    "    df = pd.DataFrame(data_raw[\"data\"], columns=data_raw[\"feature_names\"])\n",
    "    df[\"target\"] = data_raw[\"target\"]\n",
    "    return ray.data.from_pandas(df)\n",
    "\n",
    "\n",
    "train_dataset = get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd6fc5",
   "metadata": {},
   "source": [
    "Let's take a look at the schema here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936c9b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=1, num_rows=581012, schema={Elevation: float64, Aspect: float64, Slope: float64, Horizontal_Distance_To_Hydrology: float64, Vertical_Distance_To_Hydrology: float64, Horizontal_Distance_To_Roadways: float64, Hillshade_9am: float64, Hillshade_Noon: float64, Hillshade_3pm: float64, Horizontal_Distance_To_Fire_Points: float64, Wilderness_Area_0: float64, Wilderness_Area_1: float64, Wilderness_Area_2: float64, Wilderness_Area_3: float64, Soil_Type_0: float64, Soil_Type_1: float64, Soil_Type_2: float64, Soil_Type_3: float64, Soil_Type_4: float64, Soil_Type_5: float64, Soil_Type_6: float64, Soil_Type_7: float64, Soil_Type_8: float64, Soil_Type_9: float64, Soil_Type_10: float64, Soil_Type_11: float64, Soil_Type_12: float64, Soil_Type_13: float64, Soil_Type_14: float64, Soil_Type_15: float64, Soil_Type_16: float64, Soil_Type_17: float64, Soil_Type_18: float64, Soil_Type_19: float64, Soil_Type_20: float64, Soil_Type_21: float64, Soil_Type_22: float64, Soil_Type_23: float64, Soil_Type_24: float64, Soil_Type_25: float64, Soil_Type_26: float64, Soil_Type_27: float64, Soil_Type_28: float64, Soil_Type_29: float64, Soil_Type_30: float64, Soil_Type_31: float64, Soil_Type_32: float64, Soil_Type_33: float64, Soil_Type_34: float64, Soil_Type_35: float64, Soil_Type_36: float64, Soil_Type_37: float64, Soil_Type_38: float64, Soil_Type_39: float64, target: int32})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a6078",
   "metadata": {},
   "source": [
    "Since we'll be training a multiclass prediction model, we have to pass some information to XGBoost. For instance, XGBoost expects us to provide the number of classes, and multiclass-enabled evaluation metrices.\n",
    "\n",
    "For a good overview of commonly used hyperparameters, see [our tutorial in the docs](https://docs.ray.io/en/latest/tune/examples/tune-xgboost.html#xgboost-hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fdd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost specific params\n",
    "params = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"eval_metric\": [\"mlogloss\", \"merror\"],\n",
    "    \"num_class\": 8,\n",
    "    \"min_child_weight\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ae052",
   "metadata": {},
   "source": [
    "With these parameters in place, we'll create a Ray AIR `XGBoostTrainer`.\n",
    "\n",
    "Note a few things here. First, we pass in a `scaling_config` to configure the distributed training behavior of each individual XGBoost training job. Here, we want to distribute training across 2 workers.\n",
    "\n",
    "The `label_column` specifies which columns in the dataset contains the target values. `params` are the XGBoost training params defined above - we can tune these later! The `datasets` dict contains the dataset we would like to train on. Lastly, we pass the number of boosting rounds to XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbece53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = XGBoostTrainer(\n",
    "    scaling_config={\"num_workers\": 2},\n",
    "    label_column=\"target\",\n",
    "    params=params,\n",
    "    datasets={\"train\": train_dataset},\n",
    "    num_boost_round=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436035b",
   "metadata": {},
   "source": [
    "We can now create the Tuner with a search space to override some of the default parameters in the XGBoost trainer.\n",
    "\n",
    "Here, we just want to the XGBoost `max_depth` and `min_child_weights` parameters. Note that we specifically specified `min_child_weight=2` in the default XGBoost trainer - this value will be overwritten during tuning.\n",
    "\n",
    "We configure Tune to minimize the `train-mlogloss` metric. In random search, this doesn't affect the evaluated configurations, but it will affect our default results fetching for analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d00628",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space={\n",
    "        \"params\": {\n",
    "            \"max_depth\": tune.randint(2, 8), \n",
    "            \"min_child_weight\": tune.randint(1, 10), \n",
    "        },\n",
    "    },\n",
    "    tune_config=TuneConfig(num_samples=8, metric=\"train-mlogloss\", mode=\"min\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378128cc",
   "metadata": {},
   "source": [
    "Let's run the tuning. This will take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab642705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-05-11 13:45:19 (running for 00:07:13.64)<br>Memory usage on this node: 10.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/5.83 GiB heap, 0.0/2.0 GiB objects<br>Current best trial: d21c1_00000 with train-mlogloss=0.557201 and parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}<br>Result logdir: /Users/kai/ray_results/XGBoostTrainer_2022-05-11_13-38-04<br>Number of trials: 8/8 (8 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  params/max_depth</th><th style=\"text-align: right;\">  params/min_child_...</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-mlogloss</th><th style=\"text-align: right;\">  train-merror</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_d21c1_00000</td><td>TERMINATED</td><td>127.0.0.1:80007</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        334.061 </td><td style=\"text-align: right;\">        0.557201</td><td style=\"text-align: right;\">      0.195385</td></tr>\n",
       "<tr><td>XGBoostTrainer_d21c1_00001</td><td>TERMINATED</td><td>127.0.0.1:80013</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        341.875 </td><td style=\"text-align: right;\">        0.562744</td><td style=\"text-align: right;\">      0.199397</td></tr>\n",
       "<tr><td>XGBoostTrainer_d21c1_00002</td><td>TERMINATED</td><td>127.0.0.1:80014</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        310.46  </td><td style=\"text-align: right;\">        0.608054</td><td style=\"text-align: right;\">      0.220109</td></tr>\n",
       "<tr><td>XGBoostTrainer_d21c1_00003</td><td>TERMINATED</td><td>127.0.0.1:80015</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         92.1437</td><td style=\"text-align: right;\">        0.79498 </td><td style=\"text-align: right;\">      0.311035</td></tr>\n",
       "<tr><td>XGBoostTrainer_d21c1_00004</td><td>TERMINATED</td><td>127.0.0.1:80016</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        342.625 </td><td style=\"text-align: right;\">        0.559456</td><td style=\"text-align: right;\">      0.197772</td></tr>\n",
       "<tr><td>XGBoostTrainer_d21c1_00005</td><td>TERMINATED</td><td>127.0.0.1:80182</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        283.301 </td><td style=\"text-align: right;\">        0.607898</td><td style=\"text-align: right;\">      0.219964</td></tr>\n",
       "<tr><td>XGBoostTrainer_d21c1_00006</td><td>TERMINATED</td><td>127.0.0.1:80298</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         88.7628</td><td style=\"text-align: right;\">        0.607927</td><td style=\"text-align: right;\">      0.220801</td></tr>\n",
       "<tr><td>XGBoostTrainer_d21c1_00007</td><td>TERMINATED</td><td>127.0.0.1:80313</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         69.4095</td><td style=\"text-align: right;\">        0.69843 </td><td style=\"text-align: right;\">      0.262468</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:38:12,105\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80015)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:38:13,526\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:38:15,073\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80015)\u001B[0m 2022-05-11 13:38:15,149\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:38:15,322\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:38:18,803\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80040)\u001B[0m [13:38:18] task [xgboost.ray]:6810631568 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80041)\u001B[0m [13:38:18] task [xgboost.ray]:4494198672 got new rank 1\n",
      "\u001B[2m\u001B[36m(raylet)\u001B[0m Spilled 2293 MiB, 24 objects, write throughput 404 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:38:25,470\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80085)\u001B[0m [13:38:25] task [xgboost.ray]:4476894992 got new rank 1\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80084)\u001B[0m [13:38:25] task [xgboost.ray]:4395143696 got new rank 0\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:38:27,172\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80015)\u001B[0m 2022-05-11 13:38:27,158\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:38:27,150\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80060)\u001B[0m [13:38:27] task [xgboost.ray]:6971124304 got new rank 1\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80061)\u001B[0m [13:38:27] task [xgboost.ray]:4595393808 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80108)\u001B[0m [13:38:27] task [xgboost.ray]:6879218512 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80090)\u001B[0m [13:38:27] task [xgboost.ray]:4653184144 got new rank 1\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80088)\u001B[0m [13:38:27] task [xgboost.ray]:6798452688 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80109)\u001B[0m [13:38:27] task [xgboost.ray]:6870584336 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=1.45 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=1.57 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=1.47 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n",
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=1.33 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:38:49,547\tINFO main.py:1113 -- Training in progress (31 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=1.45 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=1.45 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=1.17 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=1.18 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:38:56,357\tINFO main.py:1113 -- Training in progress (31 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:38:59,693\tINFO main.py:1113 -- Training in progress (32 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80015)\u001B[0m 2022-05-11 13:38:59,665\tINFO main.py:1113 -- Training in progress (32 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:38:59,699\tINFO main.py:1113 -- Training in progress (32 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=1.07 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=1.20 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n",
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=1.17 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=1.17 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=0.99 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.99 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=0.93 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=1.03 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:39:20,050\tINFO main.py:1113 -- Training in progress (61 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=0.88 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.99 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.99 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=0.85 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:39:31,856\tINFO main.py:1113 -- Training in progress (65 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:39:31,839\tINFO main.py:1113 -- Training in progress (65 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.87 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=0.91 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80015)\u001B[0m 2022-05-11 13:39:33,715\tINFO main.py:1113 -- Training in progress (67 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:39:33,715\tINFO main.py:1113 -- Training in progress (68 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=0.82 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.87 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00003 reported train-mlogloss=0.79 with parameters={'params': {'max_depth': 2, 'min_child_weight': 1}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80015)\u001B[0m 2022-05-11 13:39:44,366\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 89.39 seconds (77.19 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00003 completed. Last result: train-mlogloss=0.79498,train-merror=0.311035,should_checkpoint=True\n",
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.87 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=0.82 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.78 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:39:50,943\tINFO main.py:1113 -- Training in progress (92 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.78 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=0.76 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.71 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.78 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:40:02,353\tINFO main.py:1113 -- Training in progress (95 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:40:02,407\tINFO main.py:1113 -- Training in progress (95 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:40:03,754\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(raylet)\u001B[0m Spilled 4223 MiB, 92 objects, write throughput 307 MiB/s.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:40:04,436\tINFO main.py:1113 -- Training in progress (99 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:40:15,336\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80202)\u001B[0m [13:40:15] task [xgboost.ray]:4618403664 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80203)\u001B[0m [13:40:15] task [xgboost.ray]:4561953808 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[1m\u001B[36m(scheduler +2m19s)\u001B[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001B[2m\u001B[1m\u001B[33m(scheduler +2m19s)\u001B[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=0.70 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n",
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.71 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.66 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.71 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:40:21,910\tINFO main.py:1113 -- Training in progress (123 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=0.67 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:40:32,675\tINFO main.py:1113 -- Training in progress (125 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:40:32,695\tINFO main.py:1113 -- Training in progress (125 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=1.47 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:40:34,879\tINFO main.py:1113 -- Training in progress (129 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.66 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.66 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.62 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:40:45,568\tINFO main.py:1113 -- Training in progress (30 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=0.63 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n",
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=1.20 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:40:51,987\tINFO main.py:1113 -- Training in progress (153 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.62 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:41:20,516\tINFO main.py:1113 -- Training in progress (175 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:41:20,484\tINFO main.py:1113 -- Training in progress (65 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:41:21,391\tINFO main.py:1113 -- Training in progress (174 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:43:22,373\tINFO main.py:1113 -- Training in progress (295 seconds since last restart).2022-05-11 13:43:24,431\tWARNING util.py:214 -- The `process_trial_result` operation took 54.096 s, which may be a performance bottleneck.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.58 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00002 reported train-mlogloss=0.61 with parameters={'params': {'max_depth': 6, 'min_child_weight': 9}}.\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.62 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=1.03 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:43:25,058\tINFO main.py:1113 -- Training in progress (298 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:43:25,002\tINFO main.py:1113 -- Training in progress (299 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:43:25,138\tINFO main.py:1113 -- Training in progress (306 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:43:25,195\tINFO main.py:1113 -- Training in progress (190 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80014)\u001B[0m 2022-05-11 13:43:25,306\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 310.45 seconds (299.72 pure XGBoost training time).\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80085)\u001B[0m E0511 13:43:25.420395000 123145388179456 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80084)\u001B[0m E0511 13:43:25.422403000 123145580593152 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00002 completed. Last result: train-mlogloss=0.608054,train-merror=0.220109,should_checkpoint=True\n",
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.59 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}.\n",
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.59 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 reported train-mlogloss=0.56 with parameters={'params': {'max_depth': 7, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=0.91 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n",
      "Trial XGBoostTrainer_d21c1_00000 completed. Last result: train-mlogloss=0.557201,train-merror=0.195385,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80298)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80007)\u001B[0m 2022-05-11 13:43:50,273\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 338.30 seconds (331.46 pure XGBoost training time).\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80040)\u001B[0m E0511 13:43:50.286508000 123145418387456 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80041)\u001B[0m E0511 13:43:50.288599000 123145354575872 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:43:53,241\tINFO main.py:1113 -- Training in progress (326 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00001 reported train-mlogloss=0.56 with parameters={'params': {'max_depth': 7, 'min_child_weight': 6}}. This trial completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80013)\u001B[0m 2022-05-11 13:43:54,124\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 338.99 seconds (326.94 pure XGBoost training time).\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80108)\u001B[0m E0511 13:43:54.143030000 123145546432512 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80109)\u001B[0m E0511 13:43:54.140347000 4391695872 chttp2_transport.cc:1103]          Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80016)\u001B[0m 2022-05-11 13:43:54,867\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 341.49 seconds (327.67 pure XGBoost training time).\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80060)\u001B[0m E0511 13:43:54.879104000 123145432559616 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80061)\u001B[0m E0511 13:43:54.880066000 123145439019008 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00004 reported train-mlogloss=0.56 with parameters={'params': {'max_depth': 7, 'min_child_weight': 7}}. This trial completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:43:55,319\tINFO main.py:1113 -- Training in progress (220 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80313)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80298)\u001B[0m 2022-05-11 13:43:59,149\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80313)\u001B[0m 2022-05-11 13:44:01,140\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=0.76 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80298)\u001B[0m 2022-05-11 13:44:03,916\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80333)\u001B[0m [13:44:03] task [xgboost.ray]:4709416592 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80335)\u001B[0m [13:44:03] task [xgboost.ray]:4465884944 got new rank 1\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80313)\u001B[0m 2022-05-11 13:44:08,833\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80355)\u001B[0m [13:44:08] task [xgboost.ray]:4659109136 got new rank 1\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80354)\u001B[0m [13:44:08] task [xgboost.ray]:4488156496 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=0.71 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=1.47 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=1.52 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=0.67 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=1.20 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=1.27 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:44:25,737\tINFO main.py:1113 -- Training in progress (250 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=0.63 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=1.10 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=1.03 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80298)\u001B[0m 2022-05-11 13:44:34,612\tINFO main.py:1113 -- Training in progress (31 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00005 reported train-mlogloss=0.61 with parameters={'params': {'max_depth': 6, 'min_child_weight': 8}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80182)\u001B[0m 2022-05-11 13:44:36,595\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 273.05 seconds (261.23 pure XGBoost training time).\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80202)\u001B[0m E0511 13:44:36.636644000 123145465180160 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=80203)\u001B[0m E0511 13:44:36.640197000 123145377869824 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00005 completed. Last result: train-mlogloss=0.607898,train-merror=0.219964,should_checkpoint=True\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=0.99 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80313)\u001B[0m 2022-05-11 13:44:38,915\tINFO main.py:1113 -- Training in progress (30 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=0.91 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=0.90 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=0.82 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=0.84 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=0.79 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=0.76 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=0.71 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=0.72 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80298)\u001B[0m 2022-05-11 13:45:04,963\tINFO main.py:1113 -- Training in progress (61 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80313)\u001B[0m 2022-05-11 13:45:06,589\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 65.59 seconds (57.75 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=0.67 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00007 reported train-mlogloss=0.70 with parameters={'params': {'max_depth': 4, 'min_child_weight': 1}}. This trial completed.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=0.63 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n",
      "Trial XGBoostTrainer_d21c1_00006 reported train-mlogloss=0.61 with parameters={'params': {'max_depth': 6, 'min_child_weight': 4}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=80298)\u001B[0m 2022-05-11 13:45:18,924\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 79.91 seconds (75.00 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_d21c1_00006 completed. Last result: train-mlogloss=0.607927,train-merror=0.220801,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 13:45:19,353\tINFO tune.py:753 -- Total run time: 434.76 seconds (433.62 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c444e",
   "metadata": {},
   "source": [
    "Now that we obtained the results, we can analyze them. For instance, we can fetch the best observed result according to the configured `metric` and `mode` and print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4e5187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result error rate 0.195385\n"
     ]
    }
   ],
   "source": [
    "# This will fetch the best result according to the `metric` and `mode` specified\n",
    "# in the `TuneConfig` above:\n",
    "\n",
    "best_result = results.get_best_result()\n",
    "\n",
    "print(\"Best result error rate\", best_result.metrics[\"train-merror\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d71b08",
   "metadata": {},
   "source": [
    "For more sophisticated analysis, we can get a pandas dataframe with all trial results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50e76e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['train-mlogloss', 'train-merror', 'time_this_iter_s',\n",
      "       'should_checkpoint', 'done', 'timesteps_total', 'episodes_total',\n",
      "       'training_iteration', 'trial_id', 'experiment_id', 'date', 'timestamp',\n",
      "       'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore',\n",
      "       'timesteps_since_restore', 'iterations_since_restore', 'warmup_time',\n",
      "       'config/params/max_depth', 'config/params/min_child_weight', 'logdir'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = results.get_dataframe()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a05668",
   "metadata": {},
   "source": [
    "As an example, let's group the results per `min_child_weight` parameter and fetch the minimal obtained values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b017b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min child weight 1 error 0.262468\n",
      "Min child weight 2 error 0.195385\n",
      "Min child weight 4 error 0.220801\n",
      "Min child weight 6 error 0.199397\n",
      "Min child weight 7 error 0.197772\n",
      "Min child weight 8 error 0.219964\n",
      "Min child weight 9 error 0.220109\n"
     ]
    }
   ],
   "source": [
    "groups = df.groupby(\"config/params/min_child_weight\")\n",
    "mins = groups.min()\n",
    "\n",
    "for min_child_weight, row in mins.iterrows():\n",
    "    print(\"Min child weight\", min_child_weight, \"error\", row[\"train-merror\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e135ee9",
   "metadata": {},
   "source": [
    "As you can see in our example run, the min child weight of `2` showed the best prediction accuracy with `0.195385`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f478e4c",
   "metadata": {},
   "source": [
    "The `results.get_dataframe()` returns the last reported results per trial. If you want to obtain the best _ever_ observed results, you can pass the `filter_metric` and `filter_mode` arguments to `results.get_dataframe()`. In our example, we'll filter the minimum _ever_ observed `train-merror` for each trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa83cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.195385\n",
       "1    0.199397\n",
       "2    0.220109\n",
       "3    0.310307\n",
       "4    0.197772\n",
       "5    0.219964\n",
       "6    0.220801\n",
       "7    0.262468\n",
       "Name: train-merror, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_error = results.get_dataframe(filter_metric=\"train-merror\", filter_mode=\"min\")\n",
    "df_min_error[\"train-merror\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4525cb",
   "metadata": {},
   "source": [
    "The best ever observed `train-merror` is `0.195385`, the same as the minimum error in our grouped results. This is expected, as the classification error in XGBoost usually goes down over time - meaning our last results are usually the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47236b0a",
   "metadata": {},
   "source": [
    "And that's how you analyze your hyperparameter tuning results. If you would like to have access to more analytics, please feel free to file a feature request e.g. [as a Github issue](https://github.com/ray-project/ray/issues) or on our [Discuss platform](https://discuss.ray.io/)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}