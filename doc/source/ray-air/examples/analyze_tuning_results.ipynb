{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62191af",
   "metadata": {},
   "source": [
    "# Analyzing results from hyperparameter tuning\n",
    "In this example, we will go through how you can use Ray AIR to run a distributed hyperparameter experiment to find optimal hyperparameters for an XGBoost model.\n",
    "\n",
    "What we'll cover:\n",
    "- How to load data from an Sklearn example dataset\n",
    "- How to initialize an XGBoost trainer\n",
    "- How to define a search space for regular XGBoost parameters and for data preprocessors\n",
    "- How to fetch the best obtained result from the tuning run\n",
    "- How to fetch a dataframe to do further analysis on the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abda7b",
   "metadata": {},
   "source": [
    "We'll use the [Covertype dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn-datasets-fetch-covtype) provided from sklearn to train a multiclass classification task using XGBoost.\n",
    "\n",
    "In this dataset, we try to predict the forst cover type (e.g. \"lodgehole pine\") from cartographic variables, like the distance to the closest road, or the hillshade at different times of the day. The features are binary, discrete and continuous and thus well suited for a decision-tree based classification task.\n",
    "\n",
    "You can find more information about the dataset [on the dataset homepage](https://archive.ics.uci.edu/ml/datasets/Covertype).\n",
    "\n",
    "We will train XGBoost models on this dataset. Because model training performance can be influenced by hyperparameter choices, we will generate several different configurations and train them in parallel. Notably each of these trials will itself start a distributed training job to speed up training. All of this happens automatically within Ray AIR.\n",
    "\n",
    "First, let's make sure we have all dependencies installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ray[all]\" sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac8670e",
   "metadata": {},
   "source": [
    "Then we can start with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45b4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.ml import RunConfig\n",
    "from ray.ml.train.integrations.xgboost import XGBoostTrainer\n",
    "from ray.tune.tune_config import TuneConfig\n",
    "from ray.tune.tuner import Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93b242c",
   "metadata": {},
   "source": [
    "We'll define a utility function to create a Ray Dataset from the Sklearn dataset. We expect the target column to be in the dataframe, so we'll add it to the dataframe manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3875df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 12:56:03,661\tINFO services.py:1484 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    }
   ],
   "source": [
    "def get_training_data() -> ray.data.Dataset:\n",
    "    data_raw = fetch_covtype()\n",
    "    df = pd.DataFrame(data_raw[\"data\"], columns=data_raw[\"feature_names\"])\n",
    "    df[\"target\"] = data_raw[\"target\"]\n",
    "    return ray.data.from_pandas(df)\n",
    "\n",
    "\n",
    "train_dataset = get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd6fc5",
   "metadata": {},
   "source": [
    "Let's take a look at the schema here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936c9b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(num_blocks=1, num_rows=581012, schema={Elevation: float64, Aspect: float64, Slope: float64, Horizontal_Distance_To_Hydrology: float64, Vertical_Distance_To_Hydrology: float64, Horizontal_Distance_To_Roadways: float64, Hillshade_9am: float64, Hillshade_Noon: float64, Hillshade_3pm: float64, Horizontal_Distance_To_Fire_Points: float64, Wilderness_Area_0: float64, Wilderness_Area_1: float64, Wilderness_Area_2: float64, Wilderness_Area_3: float64, Soil_Type_0: float64, Soil_Type_1: float64, Soil_Type_2: float64, Soil_Type_3: float64, Soil_Type_4: float64, Soil_Type_5: float64, Soil_Type_6: float64, Soil_Type_7: float64, Soil_Type_8: float64, Soil_Type_9: float64, Soil_Type_10: float64, Soil_Type_11: float64, Soil_Type_12: float64, Soil_Type_13: float64, Soil_Type_14: float64, Soil_Type_15: float64, Soil_Type_16: float64, Soil_Type_17: float64, Soil_Type_18: float64, Soil_Type_19: float64, Soil_Type_20: float64, Soil_Type_21: float64, Soil_Type_22: float64, Soil_Type_23: float64, Soil_Type_24: float64, Soil_Type_25: float64, Soil_Type_26: float64, Soil_Type_27: float64, Soil_Type_28: float64, Soil_Type_29: float64, Soil_Type_30: float64, Soil_Type_31: float64, Soil_Type_32: float64, Soil_Type_33: float64, Soil_Type_34: float64, Soil_Type_35: float64, Soil_Type_36: float64, Soil_Type_37: float64, Soil_Type_38: float64, Soil_Type_39: float64, target: int32})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a6078",
   "metadata": {},
   "source": [
    "Since we'll be training a multiclass prediction model, we have to pass some information to XGBoost. For instance, XGBoost expects us to provide the number of classes, and multiclass-enabled evaluation metrices.\n",
    "\n",
    "For a good overview of commonly used hyperparameters, see [our tutorial in the docs](https://docs.ray.io/en/latest/tune/examples/tune-xgboost.html#xgboost-hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67cad464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost specific params\n",
    "params = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"multi:softmax\",\n",
    "    \"eval_metric\": [\"mlogloss\", \"merror\"],\n",
    "    \"num_class\": 8,\n",
    "    \"min_child_weight\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a22162",
   "metadata": {},
   "source": [
    "With these parameters in place, we'll create a Ray AIR `XGBoostTrainer`.\n",
    "\n",
    "Note a few things here. First, we pass in a `scaling_config` to configure the distributed training behavior of each individual XGBoost training job. Here, we want to distribute training across 2 workers.\n",
    "\n",
    "The `label_column` specifies which columns in the dataset contains the target values. `params` are the XGBoost training params defined above - we can tune these later! The `datasets` dict contains the dataset we would like to train on. Lastly, we pass the number of boosting rounds to XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbece53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = XGBoostTrainer(\n",
    "    scaling_config={\"num_workers\": 2},\n",
    "    label_column=\"target\",\n",
    "    params=params,\n",
    "    datasets={\"train\": train_dataset},\n",
    "    num_boost_round=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436035b",
   "metadata": {},
   "source": [
    "We can now create the Tuner with a search space to override some of the default parameters in the XGBoost trainer.\n",
    "\n",
    "Here, we just want to the XGBoost `max_depth` and `min_child_weights` parameters. Note that we specifically specified `min_child_weight=2` in the default XGBoost trainer - this value will be overwritten during tuning.\n",
    "\n",
    "We configure Tune to minimize the `train-mlogloss` metric. In random search, this doesn't affect the evaluated configurations, but it will affect our default results fetching for analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d00628",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space={\n",
    "        \"params\": {\n",
    "            \"max_depth\": tune.randint(2, 8), \n",
    "            \"min_child_weight\": tune.randint(1, 10), \n",
    "        },\n",
    "    },\n",
    "    tune_config=TuneConfig(num_samples=4, metric=\"train-mlogloss\", mode=\"min\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378128cc",
   "metadata": {},
   "source": [
    "Let's run the tuning. This will take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab642705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-05-11 12:57:55 (running for 00:01:30.04)<br>Memory usage on this node: 9.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.8 GiB heap, 0.0/2.0 GiB objects<br>Current best trial: ffee6_00003 with train-mlogloss=0.698445 and parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}<br>Result logdir: /Users/kai/ray_results/XGBoostTrainer_2022-05-11_12-56-21<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  params/max_depth</th><th style=\"text-align: right;\">  params/min_child_weight</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-mlogloss</th><th style=\"text-align: right;\">  train-merror</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_ffee6_00000</td><td>TERMINATED</td><td>127.0.0.1:73693</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">                        2</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         70.3546</td><td style=\"text-align: right;\">        0.79498 </td><td style=\"text-align: right;\">      0.311035</td></tr>\n",
       "<tr><td>XGBoostTrainer_ffee6_00001</td><td>TERMINATED</td><td>127.0.0.1:73701</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">                        6</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         66.4745</td><td style=\"text-align: right;\">        0.794983</td><td style=\"text-align: right;\">      0.311035</td></tr>\n",
       "<tr><td>XGBoostTrainer_ffee6_00002</td><td>TERMINATED</td><td>127.0.0.1:73702</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">                        3</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         60.9231</td><td style=\"text-align: right;\">        0.79498 </td><td style=\"text-align: right;\">      0.311035</td></tr>\n",
       "<tr><td>XGBoostTrainer_ffee6_00003</td><td>TERMINATED</td><td>127.0.0.1:73703</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">                        3</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         81.6666</td><td style=\"text-align: right;\">        0.698445</td><td style=\"text-align: right;\">      0.262468</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73693)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73702)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73703)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73701)\u001B[0m UserWarning: Dataset 'train' has 1 blocks, which is less than the `num_workers` 2. This dataset will be automatically repartitioned to 2 blocks.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73702)\u001B[0m 2022-05-11 12:56:34,914\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73693)\u001B[0m 2022-05-11 12:56:36,564\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73703)\u001B[0m 2022-05-11 12:56:38,559\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73701)\u001B[0m 2022-05-11 12:56:39,235\tINFO main.py:984 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73702)\u001B[0m 2022-05-11 12:56:40,561\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73737)\u001B[0m [12:56:40] task [xgboost.ray]:4599733072 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73738)\u001B[0m [12:56:40] task [xgboost.ray]:4574565712 got new rank 1\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73693)\u001B[0m 2022-05-11 12:56:48,566\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73701)\u001B[0m 2022-05-11 12:56:48,563\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73762)\u001B[0m [12:56:48] task [xgboost.ray]:4482078096 got new rank 1\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73763)\u001B[0m [12:56:48] task [xgboost.ray]:4591774352 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73800)\u001B[0m [12:56:48] task [xgboost.ray]:4469288656 got new rank 1\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73798)\u001B[0m [12:56:48] task [xgboost.ray]:6939379984 got new rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00002 reported train-mlogloss=1.57 with parameters={'params': {'max_depth': 2, 'min_child_weight': 3}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(raylet)\u001B[0m Spilled 2170 MiB, 42 objects, write throughput 387 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73703)\u001B[0m 2022-05-11 12:56:50,521\tINFO main.py:1029 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73776)\u001B[0m [12:56:50] task [xgboost.ray]:4557005776 got new rank 0\n",
      "\u001B[2m\u001B[36m(_RemoteRayXGBoostActor pid=73777)\u001B[0m [12:56:50] task [xgboost.ray]:4561024272 got new rank 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00002 reported train-mlogloss=1.33 with parameters={'params': {'max_depth': 2, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00001 reported train-mlogloss=1.57 with parameters={'params': {'max_depth': 2, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_ffee6_00000 reported train-mlogloss=1.57 with parameters={'params': {'max_depth': 2, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=1.52 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00002 reported train-mlogloss=1.07 with parameters={'params': {'max_depth': 2, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00000 reported train-mlogloss=1.18 with parameters={'params': {'max_depth': 2, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_ffee6_00001 reported train-mlogloss=1.18 with parameters={'params': {'max_depth': 2, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=1.27 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73702)\u001B[0m 2022-05-11 12:57:12,434\tINFO main.py:1113 -- Training in progress (32 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00002 reported train-mlogloss=0.99 with parameters={'params': {'max_depth': 2, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00000 reported train-mlogloss=1.07 with parameters={'params': {'max_depth': 2, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_ffee6_00001 reported train-mlogloss=1.07 with parameters={'params': {'max_depth': 2, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=1.10 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73693)\u001B[0m 2022-05-11 12:57:19,586\tINFO main.py:1113 -- Training in progress (31 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73701)\u001B[0m 2022-05-11 12:57:19,605\tINFO main.py:1113 -- Training in progress (31 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00002 reported train-mlogloss=0.88 with parameters={'params': {'max_depth': 2, 'min_child_weight': 3}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73703)\u001B[0m 2022-05-11 12:57:21,552\tINFO main.py:1113 -- Training in progress (31 seconds since last restart).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00000 reported train-mlogloss=0.93 with parameters={'params': {'max_depth': 2, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_ffee6_00001 reported train-mlogloss=0.93 with parameters={'params': {'max_depth': 2, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=0.99 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00002 reported train-mlogloss=0.85 with parameters={'params': {'max_depth': 2, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=0.90 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00001 reported train-mlogloss=0.85 with parameters={'params': {'max_depth': 2, 'min_child_weight': 6}}.\n",
      "Trial XGBoostTrainer_ffee6_00000 reported train-mlogloss=0.85 with parameters={'params': {'max_depth': 2, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_ffee6_00002 reported train-mlogloss=0.79 with parameters={'params': {'max_depth': 2, 'min_child_weight': 3}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73702)\u001B[0m 2022-05-11 12:57:34,888\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 60.11 seconds (54.31 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00002 completed. Last result: train-mlogloss=0.79498,train-merror=0.311035,should_checkpoint=True\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=0.84 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00000 reported train-mlogloss=0.79 with parameters={'params': {'max_depth': 2, 'min_child_weight': 2}}.\n",
      "Trial XGBoostTrainer_ffee6_00001 reported train-mlogloss=0.79 with parameters={'params': {'max_depth': 2, 'min_child_weight': 6}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73693)\u001B[0m 2022-05-11 12:57:40,484\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 64.06 seconds (51.91 pure XGBoost training time).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73701)\u001B[0m 2022-05-11 12:57:40,502\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 61.44 seconds (51.93 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00000 completed. Last result: train-mlogloss=0.79498,train-merror=0.311035,should_checkpoint=True\n",
      "Trial XGBoostTrainer_ffee6_00001 completed. Last result: train-mlogloss=0.794983,train-merror=0.311035,should_checkpoint=True\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=0.79 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n",
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=0.72 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73703)\u001B[0m 2022-05-11 12:57:52,067\tINFO main.py:1113 -- Training in progress (62 seconds since last restart).\n",
      "\u001B[2m\u001B[36m(GBDTTrainable pid=73703)\u001B[0m 2022-05-11 12:57:55,563\tINFO main.py:1526 -- [RayXGBoost] Finished XGBoost training on training data with total N=581,012 in 77.27 seconds (65.02 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial XGBoostTrainer_ffee6_00003 reported train-mlogloss=0.70 with parameters={'params': {'max_depth': 4, 'min_child_weight': 3}}. This trial completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 12:57:55,963\tINFO tune.py:753 -- Total run time: 91.48 seconds (90.03 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c444e",
   "metadata": {},
   "source": [
    "Now that we obtained the results, we can analyze them. For instance, we can fetch the best observed result according to the configured `metric` and `mode` and print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4e5187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result error rate 0.262468\n"
     ]
    }
   ],
   "source": [
    "# This will fetch the best result according to the `metric` and `mode` specified\n",
    "# in the `TuneConfig` above:\n",
    "\n",
    "best_result = results.get_best_result()\n",
    "\n",
    "print(\"Best result error rate\", best_result.metrics[\"train-merror\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d71b08",
   "metadata": {},
   "source": [
    "For more sophisticated analysis, we can get a pandas dataframe with all trial results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50e76e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['train-mlogloss', 'train-merror', 'time_this_iter_s',\n",
      "       'should_checkpoint', 'done', 'timesteps_total', 'episodes_total',\n",
      "       'training_iteration', 'trial_id', 'experiment_id', 'date', 'timestamp',\n",
      "       'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore',\n",
      "       'timesteps_since_restore', 'iterations_since_restore', 'warmup_time',\n",
      "       'config/params', 'logdir'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = results.get_dataframe()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a05668",
   "metadata": {},
   "source": [
    "As an example, let's group the results per preprocessor and fetch the minimal obtained values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b017b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Dropping invalid columns in DataFrameGroupBy.min is deprecated. In a future version, a TypeError will be raised. Before calling .min, select only columns which should be valid for the function.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/b2/0_91bd757rz02lrmr920v0gw0000gn/T/ipykernel_72744/2772955756.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mgroups\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupby\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"config/params\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mmins\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgroups\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001B[0m in \u001B[0;36mmin\u001B[0;34m(self, numeric_only, min_count)\u001B[0m\n\u001B[1;32m   1871\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumeric_only\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin_count\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1872\u001B[0m         return self._agg_general(\n\u001B[0;32m-> 1873\u001B[0;31m             \u001B[0mnumeric_only\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnumeric_only\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmin_count\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmin_count\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"min\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnpfunc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1874\u001B[0m         )\n\u001B[1;32m   1875\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001B[0m in \u001B[0;36m_agg_general\u001B[0;34m(self, numeric_only, min_count, alias, npfunc)\u001B[0m\n\u001B[1;32m   1366\u001B[0m                 \u001B[0malt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnpfunc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1367\u001B[0m                 \u001B[0mnumeric_only\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnumeric_only\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1368\u001B[0;31m                 \u001B[0mmin_count\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmin_count\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1369\u001B[0m             )\n\u001B[1;32m   1370\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"groupby\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001B[0m in \u001B[0;36m_cython_agg_general\u001B[0;34m(self, how, alt, numeric_only, min_count)\u001B[0m\n\u001B[1;32m   1092\u001B[0m             )\n\u001B[1;32m   1093\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1094\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_wrap_agged_manager\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_mgr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1095\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1096\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_aggregate_frame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001B[0m in \u001B[0;36m_wrap_agged_manager\u001B[0;34m(self, mgr)\u001B[0m\n\u001B[1;32m   1686\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_consolidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1687\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1688\u001B[0;31m             \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrouper\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult_index\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1689\u001B[0m             \u001B[0mmgr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_axis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1690\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_constructor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmgr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/_libs/properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001B[0m in \u001B[0;36mresult_index\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    962\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mresult_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    963\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupings\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 964\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult_index\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    965\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    966\u001B[0m         \u001B[0mcodes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreconstructed_codes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/_libs/properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001B[0m in \u001B[0;36mresult_index\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgroup_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCategoricalIndex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    628\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mrecode_from_groupby\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_all_grouper\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sort\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgroup_idx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 629\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroup_index\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    630\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    631\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mcache_readonly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/_libs/properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001B[0m in \u001B[0;36mgroup_index\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    634\u001B[0m             \u001B[0;31m# _group_index is set in __init__ for MultiIndex cases\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    635\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_group_index\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 636\u001B[0;31m         \u001B[0muniques\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroup_arraylike\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    637\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mIndex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/_libs/properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001B[0m in \u001B[0;36mgroup_arraylike\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    618\u001B[0m         \u001B[0mwe\u001B[0m \u001B[0mcan\u001B[0m \u001B[0mcan\u001B[0m \u001B[0mretain\u001B[0m \u001B[0mExtensionDtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    619\u001B[0m         \"\"\"\n\u001B[0;32m--> 620\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_codes_and_uniques\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    621\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    622\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mcache_readonly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/_libs/properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.CachedProperty.__get__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001B[0m in \u001B[0;36m_codes_and_uniques\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m                 \u001B[0mna_sentinel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    670\u001B[0m             codes, uniques = algorithms.factorize(\n\u001B[0;32m--> 671\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrouping_vector\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msort\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sort\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mna_sentinel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mna_sentinel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    672\u001B[0m             )\n\u001B[1;32m    673\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcodes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muniques\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/algorithms.py\u001B[0m in \u001B[0;36mfactorize\u001B[0;34m(values, sort, na_sentinel, size_hint)\u001B[0m\n\u001B[1;32m    760\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    761\u001B[0m         codes, uniques = factorize_array(\n\u001B[0;32m--> 762\u001B[0;31m             \u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mna_sentinel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mna_sentinel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msize_hint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msize_hint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mna_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mna_value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    763\u001B[0m         )\n\u001B[1;32m    764\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/core/algorithms.py\u001B[0m in \u001B[0;36mfactorize_array\u001B[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001B[0m\n\u001B[1;32m    562\u001B[0m     \u001B[0mtable\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhash_klass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msize_hint\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m     uniques, codes = table.factorize(\n\u001B[0;32m--> 564\u001B[0;31m         \u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mna_sentinel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mna_sentinel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mna_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mna_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    565\u001B[0m     )\n\u001B[1;32m    566\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "groups = df.groupby(\"config/params\")\n",
    "mins = groups.min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f478e4c",
   "metadata": {},
   "source": [
    "The `results.get_dataframe()` returns the last reported results per trial. If you want to obtain the best _ever_ observed results, you can pass the `filter_metric` and `filter_mode` arguments to `results.get_dataframe()`. In our example, we'll filter the minimum _ever_ observed `train-merror` for each trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afa83cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.197125\n",
       "1    0.279679\n",
       "2    0.262468\n",
       "3    0.197125\n",
       "4    0.310307\n",
       "5    0.310307\n",
       "6    0.310307\n",
       "7    0.220687\n",
       "Name: train-merror, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_error = results.get_dataframe(filter_metric=\"train-merror\", filter_mode=\"min\")\n",
    "df_min_error[\"train-merror\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47236b0a",
   "metadata": {},
   "source": [
    "And that's how you analyze your hyperparameter tuning results. If you would like to have access to more analytics, please feel free to file a feature request e.g. [as a Github issue](https://github.com/ray-project/ray/issues) or on our [Discuss platform](https://discuss.ray.io/)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}