Ray for ML Platforms
====================

.. tip::

    We'd love to hear from you if you are using Ray to build a ML platform! Fill out `this short form <https://forms.gle/wCCdbaQDtgErYycT6>`__ to get involved.

Ray's best-in-class AI Runtime (AIR) libraries such as Ray Train, Ray Data, and Ray Serve can be used for end-to-end ML workflows together, providing features and APIs for
data preprocessing as part of training, and transitioning from training to serving.

In effect, Ray provides unified compute runtime for teams looking to simplify their ML infrastructure.

..
  https://docs.google.com/drawings/d/1atB1dLjZIi8ibJ2-CoHdd3Zzyl_hDRWyK2CJAVBBLdU/edit

.. image:: images/ray-air.svg


ML Compute, Simplified
----------------------

Ray's ML libraries simplify the ecosystem of machine learning frameworks, platforms, and tools, by providing a seamless, unified, and open experience for scalable ML:


.. image:: images/why-air-2.svg

..
  https://docs.google.com/drawings/d/1oi_JwNHXVgtR_9iTdbecquesUd4hOk0dWgHaTaFj6gk/edit

**1. Seamless Dev to Prod**: Ray's ML libraries reduces friction going from development to production. With Ray and its libraries, the same Python code scales seamlessly from a laptop to a large cluster.

**2. Unified ML API**: Ray's APIs enables swapping between popular frameworks, such as XGBoost, PyTorch, and Hugging Face, with just a single class change in your code.

**3. Open and Extensible**: Ray is fully open-source and can run on any cluster, cloud, or Kubernetes. Build custom components and integrations on top of scalable developer APIs.

For ML Engineers, AIR provides scalable platform abstractions that can be used to easily onboard and integrate tooling from the broader ML ecosystem.

What's Next
-----------

* Take a look at our :ref:`deployment guide <mlplatform-deployment>`.
* Take a look at how to use Ray for end-to-end :ref:`computer vision workloads <computer-vision>`.`
