// Copyright 2017 The Ray Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//  http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";
option cc_enable_arenas = true;

package ray.rpc;

import "src/ray/protobuf/common.proto";

option java_package = "io.ray.runtime.generated";

// These indexes are mapped to table names in backend storage.
enum TablePrefix {
  TABLE_PREFIX_MIN = 0;
  UNUSED = 1;
  TASK = 2;
  RAYLET_TASK = 3;
  NODE = 4;
  OBJECT = 5;
  ACTOR = 6;
  FUNCTION = 7;
  TASK_RECONSTRUCTION = 8;
  RESOURCE_USAGE_BATCH = 9;
  JOB = 10;
  TASK_LEASE = 12;
  NODE_RESOURCE = 13;
  DIRECT_ACTOR = 14;
  // WORKER is already used in WorkerType, so use WORKERS here.
  WORKERS = 15;
  INTERNAL_CONFIG = 16;
  PLACEMENT_GROUP_SCHEDULE = 17;
  PLACEMENT_GROUP = 18;
  KV = 19;
  ACTOR_TASK_SPEC = 20;
}

// The channel that Add operations to the Table should be published on, if any.
enum TablePubsub {
  TABLE_PUBSUB_MIN = 0;
  NO_PUBLISH = 1;
  TASK_PUBSUB = 2;
  RAYLET_TASK_PUBSUB = 3;
  NODE_PUBSUB = 4;
  OBJECT_PUBSUB = 5;
  ACTOR_PUBSUB = 6;
  RESOURCE_USAGE_BATCH_PUBSUB = 7;
  TASK_LEASE_PUBSUB = 8;
  JOB_PUBSUB = 9;
  NODE_RESOURCE_PUBSUB = 10;
  DIRECT_ACTOR_PUBSUB = 11;
  WORKER_FAILURE_PUBSUB = 12;
  TABLE_PUBSUB_MAX = 13;
}

enum GcsChangeMode {
  APPEND_OR_ADD = 0;
  REMOVE = 1;
}

message GcsEntry {
  GcsChangeMode change_mode = 1;
  bytes id = 2;
  repeated bytes entries = 3;
}

message ObjectTableData {
  // The node manager ID that this object appeared on or was evicted by.
  bytes manager = 1;
}

message ActorTableData {
  // State of an actor.
  enum ActorState {
    // Actor info is registered in GCS. But its dependencies are not ready.
    DEPENDENCIES_UNREADY = 0;
    // Actor local dependencies are ready. This actor is being created.
    PENDING_CREATION = 1;
    // Actor is alive.
    ALIVE = 2;
    // Actor is dead, now being restarted.
    // After reconstruction finishes, the state will become alive again.
    RESTARTING = 3;
    // Actor is already dead and won't be restarted.
    DEAD = 4;
  }
  // The ID of the actor that was created.
  bytes actor_id = 1;
  // The ID of the caller of the actor creation task.
  bytes parent_id = 2;
  // The dummy object ID returned by the actor creation task. If the actor
  // dies, then this is the object that should be restarted for the actor
  // to be recreated.
  bytes actor_creation_dummy_object_id = 3;
  // The ID of the job that created the actor.
  bytes job_id = 4;
  // Current state of this actor.
  ActorState state = 6;
  // Max number of times this actor should be restarted,
  // a value of -1 indicates an infinite number of reconstruction attempts.
  int64 max_restarts = 7;
  // Number of restarts that has been tried on this actor.
  // This will be greater by 1 than what's published before in ALIVE.
  // ALIVE:0 RESTARTING:1 ALIVE:1 RESTARTING:2, etc
  uint64 num_restarts = 8;
  // The address of the the actor.
  Address address = 9;
  // The address of the the actor's owner (parent).
  Address owner_address = 10;
  // Whether the actor is persistent.
  bool is_detached = 11;
  // Name of the actor.
  string name = 12;
  // Last timestamp that the actor state was updated.
  double timestamp = 13;
  // Resource mapping ids acquired by the leased worker. This field is only set when this
  // actor already has a leased worker.
  repeated ResourceMapEntry resource_mapping = 15;
  // The process id of this actor.
  uint32 pid = 16;
  // The function descriptor of the actor creation task.
  FunctionDescriptor function_descriptor = 17;
  // The actor's namespace. Named `ray_namespace` to avoid confusions when invoked in c++.
  string ray_namespace = 19;
  // The unix ms timestamp the actor was started at.
  uint64 start_time = 20;
  // The unix ms timestamp the actor was ended at.
  uint64 end_time = 21;
  // Serialized runtime_env used to report in the dashboard snapshot. We need to populate
  // it here instead of grabbing it from the task spec because the task spec is cleared
  // for deleted actors: https://github.com/ray-project/ray/pull/11149.
  string serialized_runtime_env = 22;
  // The actor's class name. This is necessary because the task spec's lifetime
  // is shorter than the ActorTableData.
  string class_name = 23;
  // Contains metadata about why the actor is dead.
  ActorDeathCause death_cause = 24;
  // Quantities of the different resources required by this actor.
  map<string, double> required_resources = 28;
  // The node id of the actor once it is created.
  // address field can contain an address although actor is not created
  // so we have a separate field to track this.
  // If the actor is restarting, the node id could be incorrect.
  optional bytes node_id = 29;
  // Placement group ID if the actor requires a placement group.
  optional bytes placement_group_id = 30;
  // The repr name of the actor if specified with a customized repr method, e.g. __repr__
  // This field is only available after the actor creation task has been run since it
  // might depend on actor fields to be initialized in __init__.
  // Default to empty string if no customized repr is defined.
  string repr_name = 31;
}

message ErrorTableData {
  // The ID of the job that the error is for.
  bytes job_id = 1;
  // The type of the error.
  string type = 2;
  // The error message.
  string error_message = 3;
  // The timestamp of the error message.
  double timestamp = 4;
}

message ScheduleData {
  map<string, bytes> schedule_plan = 1;
}

message ProfileEventEntry {
  // The start timestamp of the event time.
  int64 start_time = 1;
  // The end timestamp of the event. Empty if it's a point event, e.g. TaskStatus
  // change.
  int64 end_time = 2;
  // Additional data associated with the event. This data must be serialized
  // using JSON.
  optional string extra_data = 3;
  // Customized event name if not a TaskStatus change point event.
  string event_name = 4;
}

message ProfileEvents {
  // The type of the component that generated the event, e.g., worker or
  // object_manager, or node_manager.
  string component_type = 1;
  // An identifier for the component that generated the event.
  bytes component_id = 2;
  // Node IP address.
  string node_ip_address = 3;
  // Events.
  repeated ProfileEventEntry events = 4;
}

// Represents the info of a worker's log file for which executes the task.
message TaskLogInfo {
  // stdout log file absolute path.
  optional string stdout_file = 1;
  // stderr log file absolute path.
  optional string stderr_file = 2;
  // Start offset of stdout when task starts.
  optional int32 stdout_start = 3;
  // End offset of stdout when task finishes.
  optional int32 stdout_end = 4;
  // Start offset of stderr when task starts.
  optional int32 stderr_start = 5;
  // End offset of stderr when task finishes.
  optional int32 stderr_end = 6;
}

// Represents task states which could be changed during task execution.
message TaskStateUpdate {
  // Node that runs the task.
  optional bytes node_id = 1;
  // Timestamp when status changes to PENDING_ARGS_AVAIL.
  optional int64 pending_args_avail_ts = 2;
  // Timestamp when status changes to PENDING_NODE_ASSIGNMENT.
  optional int64 pending_node_assignment_ts = 3;
  // Timestamp when status changes to SUBMITTED_TO_WORKER.
  optional int64 submitted_to_worker_ts = 4;
  // Timestamp when status changes to RUNNING.
  optional int64 running_ts = 5;
  // Timestamp when status changes to FINISHED.
  optional int64 finished_ts = 6;
  // Timestamp when status changes to FAILED.
  optional int64 failed_ts = 7;
  // Worker that runs the task.
  optional bytes worker_id = 8;
  // Task faulure info.
  optional RayErrorInfo error_info = 9;
  // Task logs info.
  optional TaskLogInfo task_log_info = 10;
  // Actor task repr name.
  optional string actor_repr_name = 11;
  // Worker Pid.
  optional int32 worker_pid = 12;
}

// Represents events and state changes from a single task run.
message TaskEvents {
  // Metadata shared by all event types.
  bytes task_id = 1;
  // The current retry attempt number for the task.
  int32 attempt_number = 2;
  // Task Info.
  optional TaskInfoEntry task_info = 3;
  // Task state updates.
  optional TaskStateUpdate state_updates = 4;
  // Task profiling events.
  optional ProfileEvents profile_events = 5;
  // Job id of the task
  bytes job_id = 6;
}

// Represents a compact list of task state events by different tasks,
// where each task has a list of state change events.
message TaskEventData {
  // A batch of task state change events.
  repeated TaskEvents events_by_task = 1;
  // Number of dropped profile task events due to buffer size limit on workers.
  int32 num_profile_task_events_dropped = 3;
  // Number of dropped status task events due to buffer size limit on workers.
  int32 num_status_task_events_dropped = 4;
}

message ResourceTableData {
  // The total capacity of this resource type.
  double resource_capacity = 1;
}

message AvailableResources {
  // Node id.
  bytes node_id = 1;
  // Resource capacity currently available on this node manager.
  map<string, double> resources_available = 2;
}

// A snapshot of the state of a node.
message NodeSnapshot {
  // The idle state of a node.
  // May be extended to include dead.
  enum State {
    UNDEFINED = 0;
    // Node is idle.
    IDLE = 1;
    // Node is not idle.
    ACTIVE = 2;
    // Node is draining.
    DRAINING = 3;
  }

  // The idle state of the node.
  State state = 1;
  // How long the node has been idle.
  int64 idle_duration_ms = 2;
  // Observability strings describing why the node is not idle.
  // Each string is a reason.
  repeated string node_activity = 3;
}

message GcsNodeInfo {
  // State of a node.
  enum GcsNodeState {
    // Node is alive.
    ALIVE = 0;
    // Node is dead.
    DEAD = 1;
  }

  // The ID of node.
  bytes node_id = 1;
  // The IP address of the node manager.
  string node_manager_address = 2;
  // The IPC socket name of raylet.
  string raylet_socket_name = 3;
  // The IPC socket name of the node's plasma store.
  string object_store_socket_name = 4;
  // The port at which the node manager is listening for TCP
  // connections from other node managers.
  int32 node_manager_port = 5;
  // The port at which the object manager is listening for TCP
  // connections from other object managers.
  int32 object_manager_port = 6;

  // Current state of this node.
  GcsNodeState state = 7;

  // The Hostname address of the node manager.
  string node_manager_hostname = 8;

  // The port at which the node will expose metrics to.
  int32 metrics_export_port = 9;

  // The port at which the runtime env agent listens as HTTP.
  int32 runtime_env_agent_port = 27;

  // The total resources of this node.
  map<string, double> resources_total = 11;

  // The user-provided identifier or name for this node.
  string node_name = 12;

  // The instance id of the node if it's running on a cloud provider.
  string instance_id = 13;

  // The instance node type of the node if it's running on a cloud provider.
  // Set through ENV of src/ray/common/constants.h::kNodeTypeNameEnv
  string node_type_name = 14;

  // The instance type name of the node if running on a cloud provider and
  // set through ENV of src/ray/common/constants.h::kNodeCloudInstanceTypeNameEnv
  // e.g. m4.16xlarge
  string instance_type_name = 15;

  // The unix ms timestamp the node was started at.
  uint64 start_time_ms = 23;
  // The unix ms timestamp the node was ended at.
  uint64 end_time_ms = 24;
  // If this is a head node.
  bool is_head_node = 25;
  // The key-value labels of this node.
  map<string, string> labels = 26;

  // A snapshot of node state.
  NodeSnapshot state_snapshot = 28;
}

// Please keep this in sync with the definition of JobInfo in
// dashboard/modules/job/common.py
message JobsAPIInfo {
  // The status of the job.
  string status = 1;
  // The entrypoint command for this job.
  string entrypoint = 2;
  // A message describing the status in more detail.
  optional string message = 3;
  // TODO(architkulkarni): Populate this field
  // Error type (e.g. Runtime env setup failure, Internal error, user script error)
  optional string error_type = 4;
  // The time when the job was started.  A Unix timestamp in ms.
  optional uint64 start_time = 5;
  // The time when the job moved into a terminal state.  A Unix timestamp in ms.
  optional uint64 end_time = 6;
  // Arbitrary user-provided metadata for the job.
  map<string, string> metadata = 7;
  // The JSON-serialized runtime environment for the job.
  optional string runtime_env_json = 8;
  // The quantity of CPU cores to reserve for the entrypoint command.
  optional double entrypoint_num_cpus = 9;
  // The number of GPUs to reserve for the entrypoint command.
  optional double entrypoint_num_gpus = 10;
  // The quantity of various custom resources to reserve for the entrypoint command.
  map<string, double> entrypoint_resources = 11;
  // Driver agent http address
  optional string driver_agent_http_address = 12;
  // The node id that driver running on. It will be None only when the job status
  // is PENDING, and this field will not be deleted or modified even if the driver dies
  optional string driver_node_id = 13;
  // The driver process exit code after the driver executed. Return None if driver
  // doesn't finish executing
  optional int32 driver_exit_code = 14;
  // The amount of reservable memory resource in bytes for the entrypoint command.
  optional uint64 entrypoint_memory = 15;
}

message WorkerTableData {
  // Is this worker alive.
  bool is_alive = 1;
  // Address of the worker that failed.
  Address worker_address = 2;
  // The UNIX timestamp at which this worker's state was updated.
  int64 timestamp = 3;
  // Type of this worker.
  WorkerType worker_type = 5;
  // This is for AddWorker.
  map<string, bytes> worker_info = 6;
  // The exception thrown in creation task. This field is set if this worker died because
  // of exception thrown in actor's creation task. Only applies when is_alive=false.
  RayException creation_task_exception = 18;
  // Whether it's an intentional disconnect, only applies then `is_alive` is false.
  optional WorkerExitType exit_type = 19;
  // The detailed message about worker exit.
  optional string exit_detail = 20;
  // pid of the worker process.
  uint32 pid = 21;

  /* The below fields are worker lifecycle events
     worker_launch_time_ms (process startup requested).
     -> worker_launched_time_ms (process started).
     -> start_time_ms (worker is ready to be used).
     -> end_time_ms (worker is destroyed).
  */

  // The unix ms timestamp the worker was started and finished initialization.
  uint64 start_time_ms = 23;
  // The unix ms timestamp the worker was ended at.
  uint64 end_time_ms = 24;
  // The time when this worker process is requested from raylet.
  // The field exists only when the worker is launched
  // by a raylet. (I.e., driver worker won't have this value).
  // If the value doesn't present, it is -1.
  uint64 worker_launch_time_ms = 25;
  // The time when this worker process is successfully started.
  // The field exists only when the worker is launched
  // by a raylet. (I.e., driver worker won't have this value).
  // If the value doesn't present, it is -1.
  uint64 worker_launched_time_ms = 26;
}

// Fields to publish when worker fails.
message WorkerDeltaData {
  bytes raylet_id = 1;
  bytes worker_id = 2;
}

message ResourceMap {
  map<string, ResourceTableData> items = 1;
}

message StoredConfig {
  string config = 1;
}

// A notification message about one node's resources being changed.
message NodeResourceChange {
  // ID of the node whose resources have changed.
  bytes node_id = 1;
  // Labels of the updated resources and their latest capacities.
  map<string, double> updated_resources = 2;
  // Labels of the resources that were deleted.
  repeated string deleted_resources = 3;
}

message PubSubMessage {
  bytes id = 1;
  bytes data = 2;
}

// A notification that the resource table has changed.
message ResourceUpdate {
  oneof resource_change_or_data {
    // The total resources on a node have changed.
    NodeResourceChange change = 1;
    // The available resources on a node have changed.
    ResourcesData data = 2;
  }
}

message ResourceUsageBroadcastData {
  // An incrementing sequence number, used for correcting network errors.
  int64 seq_no = 1;
  // The changes to the state of the cluster.
  repeated ResourceUpdate batch = 2;
}

///////////////////////////////////////////////////////////////////////////////
/* Please do not modify/remove/change the following messages to maintain
backwards compatibility in autoscaler. This is necessary to make sure we can
run autoscaler with any version of ray. For example, the K8s operator runs
autoscaler in a separate pod, if the user upgrades the ray version on the head
pod autoscaler can crash (if the newer version of ray modified the messages
below). */

// Represents the demand for a particular resource shape.
message ResourceDemand {
  // The resource shape requested. This is a map from the resource string
  // (e.g., "CPU") to the amount requested.
  map<string, double> shape = 1;
  // The number of requests that are ready to run (i.e., dependencies have been
  // fulfilled), but that are waiting for resources.
  uint64 num_ready_requests_queued = 2;
  // The number of requests for which there is no node that is a superset of
  // the requested resource shape.
  uint64 num_infeasible_requests_queued = 3;
  // The number of requests of this shape still queued in CoreWorkers that this
  // raylet knows about.
  int64 backlog_size = 4;
}

// Represents the demand sorted by resource shape.
message ResourceLoad {
  // A list of all resource demands. The resource shape in each demand is
  // unique.
  repeated ResourceDemand resource_demands = 1;
}

message ResourcesData {
  reserved 3;
  // Node id.
  bytes node_id = 1;
  // Resource capacity currently available on this node manager.
  map<string, double> resources_available = 2;
  // Total resource capacity configured for this node manager.
  map<string, double> resources_total = 4;
  // Aggregate outstanding resource load on this node manager.
  map<string, double> resource_load = 5;
  // Indicates whether resource load is changed. Only used when
  // light heartbeat enabled.
  bool resource_load_changed = 6;
  // The resource load on this node, sorted by resource shape.
  ResourceLoad resource_load_by_shape = 7;
  // Whether this node manager is requesting global GC.
  bool should_global_gc = 8;
  // IP address of the node.
  string node_manager_address = 9;
  // Whether this node has object pulls queued. This can happen if
  // the node has more pull requests than available object store
  // memory. This is a proxy for available object store memory.
  bool object_pulls_queued = 10;
  // Normal task resources.
  map<string, double> resources_normal_task = 11;
  // Indicates whether resource normal task is changed. Only used when
  // light heartbeat enabled.
  bool resources_normal_task_changed = 12;
  // The timestamp that normal task resources are measured.
  int64 resources_normal_task_timestamp = 13;
  // Whether this node has detected a resource deadlock (full of actors).
  bool cluster_full_of_actors_detected = 14;
  // The duration in ms during which all the node's resources are idle. If the
  // node currently has any resource being used, this will be 0.
  int64 idle_duration_ms = 15;
  // Whether the node is being drained.
  bool is_draining = 16;
  // Why the node is not idle.
  repeated string node_activity = 17;
}

message ResourceUsageBatchData {
  repeated ResourcesData batch = 1;
  // The total resource demand on all nodes included in the batch, sorted by
  // resource shape.
  ResourceLoad resource_load_by_shape = 2;
  // The pending list of placement groups.
  PlacementGroupLoad placement_group_load = 3;
}

message PlacementGroupLoad {
  // The list of pending placement group specifications.
  repeated PlacementGroupTableData placement_group_data = 1;
}

message PlacementGroupStats {
  // The scheduling state of the placement group.
  // This is purely for observability and the
  // information could not be consistent
  // if GCS restarts.
  // QUEUED / REMOVED <-----------------------------
  //          |                                     |
  // SCHEDULING_STARTED / NO_RESOURCES / INFEASIBLE |
  //          |                                     |
  // FINISHED / FAILED_TO_COMMIT_RESOURCES ----------
  enum SchedulingState {
    //
    // Initial scheduling states.
    //
    // Queued for scheduling.
    QUEUED = 0;
    // Scheduling has cancelled because it is removed.
    REMOVED = 1;

    //
    // Scheduling In Progress.
    //
    // Scheduling has started.
    SCHEDULING_STARTED = 2;
    // Placement group creation failed because there was
    // no nodes that satisfy resources.
    NO_RESOURCES = 3;
    // Placement group creation has failed because the
    // requested resources are infeasible.
    INFEASIBLE = 4;

    //
    // Scheduling Finished.
    //
    // Placement group creation failed because there was
    // an issue commiting resources to nodes
    // (e.g., node failures).
    FAILED_TO_COMMIT_RESOURCES = 5;
    // Scheduling has finished properly.
    FINISHED = 6;
  }
  // The time creation request is first received.
  int64 creation_request_received_ns = 2;
  // The time scheduling is started after queuing.
  int64 scheduling_started_time_ns = 3;
  // The time from scheduling started <-> scheduling succeeds.
  int64 scheduling_latency_us = 4;
  // The time from first request received <-> all placement group
  // resources are available on all relevant nodes.
  // end_to_end_creation_latency_us - scheduling_latency_us
  // == queuing time.
  int64 end_to_end_creation_latency_us = 5;
  // The number of time scheduling has attempted on this placement group.
  uint32 scheduling_attempt = 6;
  // Scheduler retries the pg scheduling with
  // exponential backoff delay.
  // The biggest delay that's ever seen from
  // this placement group creation process.
  double highest_retry_delay_ms = 7;
  // The cause of placement group creation failure.
  SchedulingState scheduling_state = 8;
}

message PlacementGroupTableData {
  // State of a placement group.
  enum PlacementGroupState {
    // Placement Group is pending or scheduling
    PENDING = 0;
    // Placement Group is created.
    CREATED = 1;
    // Placement Group is already removed and won't be reschedule.
    REMOVED = 2;
    // Placement Group is rescheduling because the node it placed is dead.
    RESCHEDULING = 3;
  }

  // ID of the PlacementGroup.
  bytes placement_group_id = 1;
  // The name of the placement group.
  string name = 2;
  // The array of the bundle in Placement Group.
  repeated Bundle bundles = 3;
  // The schedule strategy of this Placement Group.
  PlacementStrategy strategy = 4;
  // Current state of this placement group.
  PlacementGroupState state = 5;
  // Fields to detect the owner of the placement group
  // for automatic lifecycle management.
  // The job id that created this placement group.
  bytes creator_job_id = 6;
  // The actor id that created this placement group.
  bytes creator_actor_id = 7;
  // Whether or not if the creator job is dead.
  bool creator_job_dead = 8;
  // Whether or not if the creator actor is dead.
  bool creator_actor_dead = 9;
  // Whether the placement group is persistent.
  bool is_detached = 10;
  // The pg's namespace. Named `ray_namespace` to avoid confusions when invoked in c++.
  string ray_namespace = 11;
  // The placement group's stats / information such as when it is created or
  // what's the current scheduling state.
  PlacementGroupStats stats = 12;
  // The maximum fraction of CPU cores that this placement group can use on each node.
  double max_cpu_fraction_per_node = 13;
  // The time that the placement group was created at.
  int64 placement_group_creation_timestamp_ms = 14;
  // The time that the last bundle of a placement group is committed at,
  // effectively when the placement group has been "scheduled".
  int64 placement_group_final_bundle_placement_timestamp_ms = 15;
}

message JobTableData {
  // The job ID.
  bytes job_id = 1;
  // Whether it's dead.
  bool is_dead = 2;
  // The UNIX timestamp corresponding to this event (job added or removed).
  int64 timestamp = 3;
  // IP address of the driver that started this job.
  // Deprecated
  string driver_ip_address = 4;
  // Process ID of the driver running this job.
  int64 driver_pid = 5;
  // The config of this job.
  JobConfig config = 6;
  // The timestamp the job was started at.
  uint64 start_time = 7;
  // The timestamp the job was ended at.
  uint64 end_time = 8;
  // The entrypoint of the job.
  string entrypoint = 9;
  // The optional JobInfo from the Ray Job API.
  optional JobsAPIInfo job_info = 10;
  // Whether this job has running tasks.
  bool is_running_tasks = 11;
  // Address of the driver that started this job.
  Address driver_address = 12;
}
///////////////////////////////////////////////////////////////////////////////
