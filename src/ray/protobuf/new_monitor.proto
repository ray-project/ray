// ============= Scheduling Status Primitives ====================
//
// Following fields represents the Ray state autoscaler interested
// in.

// Represents anti affinity constraints for a resource requirement.
message AntiAffinity {
  string label = 1;
}

message ResourceBundle {
  map<string, double> resources = 1;
  repeated AntiAffinity anti_affinities = 2;
  // Note: for optimization, soft contraints 
  // can be added here.
  // label affinity constraints could be
  // added here too.
}

// All unbundles in a resource request requires gang
// allocation semantics: they should be
// fullfilled all or nothing.
message ResourceRequest {
  repeated ResourceBundle bundles = 1;
}

// Cluster constraint represents minimial cluster size requirement,
// issued through ray.autoscaler.sdk.
message ClusterSizeConstraint {
  // The number of request_ids and bundles should match.
  repeated bytes request_ids = 1;
  repeated ResourceBundle bundles = 2;
}

message NodeStatus {
  bytes node_id = 1;

  // The address of the node.
  string address = 2;

  // The available resources on the node.
  map<string, double> available_resources = 3;

  // The corresponding total resources on the node.
  map<string, double> total_resources = 4;

  // Labels on the node.
  set<string> labels = 5;
}

// =========== Primitives autoscaler insights ====================

// Following states present the Autoscaler state GCS interested in,
// for observability and scheduling purpose.

enum AutoscalerNodeStates {
  // The underlying cloud resource is alive, it's up to the cluster to decide
  // if the node has joined the cluster (active) or not (still starting up).
  ALIVE = 1;
  // A terminal state, indicating the autoscaler believes this node will never
  // join the cluster.
  DEAD = 2;
  // A hint that this node will be downscaled. Ray doesn't get a say in whether
  // this node will be downscaled. It only has an opportunity to minimize the
  // blast radius. Preemption, can happen for multiple reasons such as spot
  // instance failure.
  PREMPTED = 3;
}

message AutoscalerNode {
  bytes node_id = 1;
  AutoscalerNodeStates node_state = 2;
  string description = 4;
}

message PendingNode {
  string node_type = 1;
  uint64 pending_count = 2;
  uint64 sent_count = 3;
}

message AutoscalerDecision {
  oneof possible_autoscaler_decisions {
    // Information about actions taken on nodes.
    AutoscalerNode autoscaler_node = 1;
    // Feedback about whether a resource request was infeasible.
    ResourceRequest infeasible_request_data = 2;
    // The unfinished requests in the autoscaler. Ray will only use this
    // information for observability.
    PendingNode pending_node = 3;
  }
}


// ============= Batched approach =======================
//
// Option 1 (recommended): Autoscaler periodically calls to
// two snapshot/batch APIs, GetBatchSchedulingStatus
// and ReportAutoscalerDecisions. 
// The GetBatchSchedulingStatus will return a snapshot
// of Ray state that Autoscaler interested, along with
// the snapshot_id (version).
//
// Separately, autoscaler will constantly making decisions
// based on the latest Ray state, and also change its
// state based on the information from node provider.
// Autoscaler will periodically report its state to GCS
// through ReportAutoscalerDecisions API.

message ReportBatchAutoscalerDecisionsReply {}

message ReportBatchAutoscalerDecisionsRequest {
  bytes scheduling_state_id = 1;
  // For the same secheduling state id, the
  // autoscaler state might be different. i.e.
  // pending node started, or some node terminated.
  // Thus it worths to report a separate autoscaler_sequence_no
  // for GCS to tell the staleness of the response.
  int64_t autoscaler_sequence_no = 2;
  repeated AutoscalerDecision decisions = 3;
}

message GetBatchSchedulingStatusReply {
  bytes scheduling_state_id = 1;
  repeated NodeStatus node_states = 2;
  repeated ResourceRequest resource_requests = 3;
  repeated ClusterSizeConstraint cluster_size_constraints = 4;
}

message GetBatchSchedulingStatusRequest {
  // The last seen scheduling state id. The default value is reserved for if a
  // previous scheduling state has never been seen.
  bytes last_seen_scheduling_state_id = 01;
}

service BatchAutoscalerService {
  rpc GetBatchSchedulingStatus(GetBatchSchedulingStatusRequest) returns GetBatchSchedulingStatusReply;
  rpc ReportAutoscalerDecisions(ReportBatchAutoscalerDecisionsRequest) returns ReportBatchAutoscalerDecisionsReply;
}

// ================ Streaming approach ================
// Option 2 (future): This is the streaming/delta update version of
// Option 1. Semantically it should be identical to option1, just
// that we allow Autoscaler/GCS to report delta update through 
// a stream.

message ReportBatchAutoscalerDecisionsStreamReply {}

message ReportAutoscalerDecisionsStreamPacket {
  bytes scheduling_state_id = 1;
  AutoscalerDecision decision = 2;
}

message GetStreamSchedulingStatusPacket{
  bytes scheduling_state_id = 1;
  oneof update_type {
     NodeStatus node_states = 2;
     ResourceRequest resource_requests = 3;
     ClusterSizeConstraint cluster_size_constraints = 4;
  }
}

message GetStreamSchedulingStatusRequest {
  // The last seen scheduling state id. The default value is reserved for if a
  // previous scheduling state has never been seen.
  bytes last_seen_scheduling_state_id = 01;
}


service StreamAutoscalerService {
  rpc GetBatchSchedulingStatus(GetStreamSchedulingStatusRequest) returns (stream GetStreamSchedulingStatusPacket);
  rpc ReportAutoscalerDecisionsStream(stream ReportAutoscalerDecisionsStreamPacket) returns ReportBatchAutoscalerDecisionsStreamReply;
}

// ============= Metrics =================

message EmitMetricRequest {
  string metric_name = 2;
  map<string, string> tags = 3;
  double value = 4;
}

message EmitMetricReply {}

message CreateMetricRequest {
  enum MetricType {

  }
  string metric_name = 1;
  string metric_description = 2;
  string unit = 4;
  repeated string tag_keys = 3;
}

message CreateMetricReply {}

service MetricService {
  rpc CreateMetric(CreateMetricRequest) returns CreateMetricReply;
  rpc EmitMetric(EmitMetricRequest) returns EmitMetricReply;
}
