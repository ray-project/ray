build_arg_sets:
  cu128:
    PYTHON_VERSION: py311
    CUDA_CODE: cu128
    # vLLM nightly only has cu129/cu130, use cu129 (compatible at runtime)
    VLLM_VARIANT: cu129


.common_settings: &common_settings
  append_flags:
    - --python-version=3.11
    - --unsafe-package ray
    - --python-platform=x86_64-manylinux_2_28
    - --extra-index-url https://download.pytorch.org/whl/${CUDA_CODE}
    # TODO: Remove vLLM nightly index when vLLM 0.13.0 is on PyPI.
    # Using nightly wheels to avoid building vLLM from source (which fails
    # because build-system.requires needs torch==2.9.0 but CPU index has 2.9.0+cpu).
    - --extra-index-url https://wheels.vllm.ai/nightly/${VLLM_VARIANT}/
  build_arg_sets:
    - cu128

depsets:
  - name: subset_rayllm_depset_${PYTHON_VERSION}_${CUDA_CODE}
    operation: subset
    source_depset: compiled_ray_llm_depset_${PYTHON_VERSION}_${CUDA_CODE}
    <<: *common_settings
    requirements:
      - python/requirements.txt
    output: python/deplocks/llm/rayllm_subset_${PYTHON_VERSION}_${CUDA_CODE}.lock

  - name: llm_batch_single_node_benchmark_${PYTHON_VERSION}_${CUDA_CODE}
    operation: expand
    depsets:
      - subset_rayllm_depset_${PYTHON_VERSION}_${CUDA_CODE}
    <<: *common_settings
    requirements:
      - release/llm_tests/batch/requirements.in
    output: release/ray_release/byod/llm_batch/llm_batch_single_node_benchmark_${PYTHON_VERSION}_${CUDA_CODE}.lock
