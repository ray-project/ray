halfcheetah-ddpg2:
    env: HalfCheetah-v2
    run: DDPG2
    stop:
        # episode_reward_mean: 2000
        # time_total_s: 18000
        training_iteration: 250
    config:
        # Same parameter, same default values
        actor_lr: 0.0001
        critic_lr: 0.001
        gamma: 0.99
        env_config: {}
        noise_parameters: {
            "mu": 0,
            "sigma": 0.2,
            "theta": 0.15,
        }

        # Same parameter, different values (set to default values of DDPG2)
        num_workers: 1
        train_steps: 1000
        tau: 0.001
        optimizer: {
            "buffer_size": 10000,
            "learning_starts": 500,
            "clip_rewards": False,
            "prioritized_replay": False,
            "train_batch_size": 64,
        }

        # Different parameters (different values)
        horizon: 500
        noise_add: True
        noise_epsilon: 0.0002
        num_local_steps: 1
