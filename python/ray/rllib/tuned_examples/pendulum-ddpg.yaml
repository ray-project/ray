# can expect improvement to -160 reward in ~30k timesteps
pendulum-ddpg:
    env: Pendulum-v0
    run: DDPG
    stop:
        episode_reward_mean: -160
    config:
        use_huber: True
        random_starts: False
        clip_rewards: False
        exploration_fraction: 0.1
