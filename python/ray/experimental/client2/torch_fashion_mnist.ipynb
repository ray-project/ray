{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b66b93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 21:39:26,009\tINFO client.py:205 -- client2 channel torch_fashion_mnist5 connected!\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.experimental.client2.client import Client as Client2\n",
    "if Client2.active_client is not None:\n",
    "    Client2.active_client.disconnect()\n",
    "client = Client2(\"http://localhost:8265\", \"torch_fashion_mnist5\", runtime_env={\"pip\":[\"torch==1.13.0\", \"torchvision\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1e5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/releases-2.7.0/train/examples/pytorch/torch_fashion_mnist_example.html#torch-fashion-mnist-ex\n",
    "# This is an easy adaptation, because most if not all code are already in a function, we can easily move it to remote.\n",
    "\n",
    "import os\n",
    "from filelock import FileLock\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloaders(batch_size):\n",
    "    \n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets, transforms\n",
    "    from torchvision.transforms import ToTensor, Normalize\n",
    "    \n",
    "    # Transform to normalize the input images\n",
    "    transform = transforms.Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    with FileLock(os.path.expanduser(\"~/data.lock\")):\n",
    "        # Download training data from open datasets.\n",
    "        training_data = datasets.FashionMNIST(\n",
    "            root=\"~/data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        # Download test data from open datasets.\n",
    "        test_data = datasets.FashionMNIST(\n",
    "            root=\"~/data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def train_func_per_worker(config: Dict):\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    import ray.train\n",
    "    \n",
    "    \n",
    "    # Model Definition\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28 * 28, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(512, 10),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.flatten(x)\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits\n",
    "\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    batch_size = config[\"batch_size_per_worker\"]\n",
    "\n",
    "    # Get dataloaders inside worker training function\n",
    "    train_dataloader, test_dataloader = get_dataloaders(batch_size=batch_size)\n",
    "\n",
    "    # [1] Prepare Dataloader for distributed training\n",
    "    # Shard the datasets among workers and move batches to the correct device\n",
    "    # =======================================================================\n",
    "    train_dataloader = ray.train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = ray.train.torch.prepare_data_loader(test_dataloader)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "\n",
    "    # [2] Prepare and wrap your model with DistributedDataParallel\n",
    "    # Move the model the correct GPU/CPU device\n",
    "    # ============================================================\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    # Model training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X, y in tqdm(train_dataloader, desc=f\"Train Epoch {epoch}\"):\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        test_loss, num_correct, num_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in tqdm(test_dataloader, desc=f\"Test Epoch {epoch}\"):\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                num_total += y.shape[0]\n",
    "                num_correct += (pred.argmax(1) == y).sum().item()\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        accuracy = num_correct / num_total\n",
    "\n",
    "        # [3] Report metrics to Ray Train\n",
    "        # ===============================\n",
    "        ray.train.report(metrics={\"loss\": test_loss, \"accuracy\": accuracy})\n",
    "\n",
    "@ray.remote\n",
    "def train_fashion_mnist(num_workers=2, use_gpu=False):\n",
    "    from ray.train import ScalingConfig\n",
    "    from ray.train.torch import TorchTrainer\n",
    "\n",
    "    global_batch_size = 32\n",
    "\n",
    "    train_config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size_per_worker\": global_batch_size // num_workers,\n",
    "    }\n",
    "\n",
    "    # Configure computation resources\n",
    "    scaling_config = ScalingConfig(num_workers=num_workers, use_gpu=use_gpu)\n",
    "\n",
    "    # Initialize a Ray TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_func_per_worker,\n",
    "        train_loop_config=train_config,\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "\n",
    "    # [4] Start Distributed Training\n",
    "    # Run `train_func_per_worker` on all workers\n",
    "    # =============================================\n",
    "    result = trainer.fit()\n",
    "    print(f\"Training result: {result}\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2f1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = client(train_fashion_mnist).remote(num_workers=1, use_gpu=False)\n",
    "result = client.get(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488ba5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'loss': 0.3557578268856667, 'accuracy': 0.8732},\n",
       "  path='/Users/ruiyangwang/ray_results/TorchTrainer_2023-11-20_21-33-50/TorchTrainer_8d0b9_00000_0_2023-11-20_21-33-50',\n",
       "  filesystem='local',\n",
       "  checkpoint=None\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada3657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
