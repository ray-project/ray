{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a395537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "\n",
    "# Create sample data with various types\n",
    "data = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"age\": 25,\n",
    "        \"salary\": 50000.0,\n",
    "        \"name\": \"Alice\",\n",
    "        \"scores\": [85, 90, 88],  # List type\n",
    "        \"embeddings\": np.array([0.1, 0.2, 0.3, 0.4]),  # Tensor/array type\n",
    "        \"address\": {\"street\": \"123 Main St\", \"city\": \"NYC\", \"zip\": 10001},  # Struct type\n",
    "        \"hire_date\": datetime(2020, 1, 15),  # Timestamp type\n",
    "        \"metadata\": b\"binary_data_1\",  # Binary type\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"age\": 30,\n",
    "        \"salary\": 60000.0,\n",
    "        \"name\": \"Bob\",\n",
    "        \"scores\": [92, 88, 95],\n",
    "        \"embeddings\": np.array([0.5, 0.6, 0.7, 0.8]),\n",
    "        \"address\": {\"street\": \"456 Oak Ave\", \"city\": \"LA\", \"zip\": 90001},\n",
    "        \"hire_date\": datetime(2019, 3, 20),\n",
    "        \"metadata\": b\"binary_data_2\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"age\": None,  # Missing value\n",
    "        \"salary\": None,\n",
    "        \"name\": None,\n",
    "        \"scores\": [78, 82, 80],\n",
    "        \"embeddings\": np.array([0.9, 1.0, 1.1, 1.2]),\n",
    "        \"address\": {\"street\": \"789 Pine Rd\", \"city\": None, \"zip\": None},\n",
    "        \"hire_date\": None,\n",
    "        \"metadata\": None,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab118c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled by default for nightly wheels. To disable this, run the following command: `ray disable-usage-stats` before starting Ray. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 00:07:16,806\tINFO worker.py:2004 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "/Users/goutam/Documents/ray/.venv/lib/python3.11/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "2025-10-15 00:07:17,324\tWARNING arrow.py:294 -- Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "2025-10-15 00:07:17,611\tINFO dataset.py:3475 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2025-10-15 00:07:17,616\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_2_0\n",
      "2025-10-15 00:07:17,630\tINFO hash_aggregate.py:180 -- Estimated memory requirement for aggregating aggregator (partitions=1, aggregators=1, dataset (estimate)=0.0GiB): shuffle=0.0MiB, output=0.0MiB, total=0.0MiB, \n",
      "2025-10-15 00:07:17,632\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_2_0. Full logs are in /tmp/ray/session_2025-10-15_00-07-15_585900_17483/logs/ray-data\n",
      "2025-10-15 00:07:17,633\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_2_0: InputDataBuffer[Input] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377a91be65aa420f8022e2812a6b332f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf0f334c11940a794f409eb9b43fb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- HashAggregate(key_columns=(), num_partitions=1) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d154eceaeb054fc2ace69ce1da9f7706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1928e95ba4d4766b2e53a872ee196f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregation 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee4919e24d1418585392c25901a5fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 00:07:17,705\tWARNING resource_manager.py:134 -- ⚠️  Ray's object store is configured to use only 15.2% of available memory (2.0GiB out of 13.1GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
      "2025-10-15 00:07:18,116\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_2_0 execution finished in 0.48 seconds\n",
      "\u001b[36m(HashShuffleAggregator pid=19620)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=19620)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "2025-10-15 00:07:18,130\tINFO util.py:257 -- Exiting prefetcher's background thread\n",
      "2025-10-15 00:07:18,132\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_3_0\n",
      "2025-10-15 00:07:18,134\tINFO hash_aggregate.py:180 -- Estimated memory requirement for aggregating aggregator (partitions=1, aggregators=1, dataset (estimate)=0.0GiB): shuffle=0.0MiB, output=0.0MiB, total=0.0MiB, \n",
      "2025-10-15 00:07:18,136\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_3_0. Full logs are in /tmp/ray/session_2025-10-15_00-07-15_585900_17483/logs/ray-data\n",
      "2025-10-15 00:07:18,136\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_3_0: InputDataBuffer[Input] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818c11b0d17e4e71a48415ed74164538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d0b64c79fc4e0991ce8fbe9c09b783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- HashAggregate(key_columns=(), num_partitions=1) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391f93b883847f9b58358ad66a55d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2028c81fac845c2a27c1d5ca363834b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregation 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c313210ffcba45229f2cc1fb5c3e7f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 00:07:18,461\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_3_0 execution finished in 0.32 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetSummary(\n",
       "  schema_matching_stats: 7 rows × 10 columns\n",
       "  schema_changing_stats: 5 rows × 10 columns\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(HashShuffleAggregator pid=19616)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=19616)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=19613)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=19613)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n"
     ]
    }
   ],
   "source": [
    "from ray.data.aggregate import Count, Max, Min, MissingValuePercentage\n",
    "from ray.data.datatype import DataType\n",
    "\n",
    "ds = ray.data.from_items(data)\n",
    "\n",
    "# Custom aggregations for Temporal type\n",
    "temporal_type_mapping = {\n",
    "    DataType.temporal_(): [\n",
    "        Count(ignore_nulls=False),\n",
    "        Min(ignore_nulls=True),\n",
    "        Max(ignore_nulls=True),\n",
    "        MissingValuePercentage()\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "summary = ds.summary(override_dtype_agg_mapping=temporal_type_mapping)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829caf1",
   "metadata": {},
   "source": [
    "# COMBINED SUMMARY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3064daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 00:07:18,523\tWARNING stats.py:587 -- Direct conversion to pandas failed (buffer is too small for requested array), attempting column-by-column conversion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>address</th>\n",
       "      <th>age</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-15 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-20 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic address        age embeddings            hire_date        id  \\\n",
       "0        count     3.0   3.000000        3.0                  3.0  3.000000   \n",
       "1          max     NaN  30.000000        NaN  2020-01-15 00:00:00  3.000000   \n",
       "2         mean     NaN  27.500000        NaN                  NaN  2.000000   \n",
       "3          min     NaN  25.000000        NaN  2019-03-20 00:00:00  1.000000   \n",
       "4  missing_pct     0.0  33.333333        0.0                 33.0  0.000000   \n",
       "5          std     NaN   2.500000        NaN                  NaN  0.816497   \n",
       "6     zero_pct     NaN   0.000000        NaN                  NaN  0.000000   \n",
       "\n",
       "  metadata  name        salary scores  \n",
       "0      3.0   3.0      3.000000    3.0  \n",
       "1      NaN   NaN  60000.000000    NaN  \n",
       "2      NaN   NaN  55000.000000    NaN  \n",
       "3      NaN   NaN  50000.000000    NaN  \n",
       "4     33.0  33.0     33.333333    0.0  \n",
       "5      NaN   NaN   5000.000000    NaN  \n",
       "6      NaN   NaN      0.000000    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff248314",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36817c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ray.data.datatype import DataType\n",
    "from ray.data.stats import DatasetSummary\n",
    "\n",
    "\n",
    "class FeatureType(str, Enum):\n",
    "    NUMERICAL = \"numerical\"\n",
    "    VECTOR = \"vector\"\n",
    "    CATEGORICAL = \"categorical\"\n",
    "\n",
    "\n",
    "def to_feature_type_dataset(summary: DatasetSummary) -> dict[FeatureType, \"pd.DataFrame\"]:\n",
    "    \"\"\"Convert the dataset summary to a dictionary of feature type datasets.\n",
    "\n",
    "    Args:\n",
    "        summary: The DatasetSummary object from ds.summary()\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping FeatureType to DataFrame, where each DataFrame contains\n",
    "        only the columns and statistics for that feature type.\n",
    "    \"\"\"\n",
    "\n",
    "    def classify_dtype(column_name: str) -> FeatureType:\n",
    "        \"\"\"Classify column by feature type using PyArrow type from schema-matching table.\n",
    "\n",
    "        The schema-matching table contains all columns with their original types,\n",
    "        so we can reliably infer the feature type from there.\n",
    "        \"\"\"\n",
    "        # Get PyArrow type from schema-matching table (which has original types for all columns)\n",
    "        pa_type = summary.schema_matching_stats.schema.field(column_name).type\n",
    "        dtype = DataType.from_arrow(pa_type)\n",
    "\n",
    "        # Use DataType's built-in methods\n",
    "        if dtype.is_list_type():  # Handles lists, tensors, etc.\n",
    "            return FeatureType.VECTOR\n",
    "        elif dtype.is_string_type() or dtype.is_temporal_type():\n",
    "            return FeatureType.CATEGORICAL\n",
    "        elif dtype.is_numerical_type():\n",
    "            return FeatureType.NUMERICAL\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Get all column names (both tables have the same columns)\n",
    "    all_columns = [name for name in summary.schema_matching_stats.schema.names if name != \"statistic\"]\n",
    "\n",
    "    # Get combined pandas DataFrame\n",
    "    df = summary.to_pandas()\n",
    "\n",
    "    # Drop columns where all stats are null\n",
    "    all_columns = [col for col in all_columns if not df[col].isna().all()]\n",
    "\n",
    "    # Build a mapping of column -> feature_type\n",
    "    column_to_feature_type = {}\n",
    "    for col_name in all_columns:\n",
    "        feature_type = classify_dtype(col_name)\n",
    "        if feature_type is not None:\n",
    "            column_to_feature_type[col_name] = feature_type\n",
    "\n",
    "    # Group columns by feature type and create separate DataFrames\n",
    "    result = {}\n",
    "    for ft in FeatureType:\n",
    "        # Find columns of this feature type\n",
    "        cols_of_type = [col for col, ftype in column_to_feature_type.items() if ftype == ft]\n",
    "\n",
    "        if not cols_of_type:\n",
    "            continue\n",
    "\n",
    "        # Select only the statistic column and columns of this feature type\n",
    "        selected_cols = [\"statistic\"] + cols_of_type\n",
    "        result[ft] = df[selected_cols].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9753348",
   "metadata": {},
   "source": [
    "# CATEGORICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc476b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 00:07:41,731\tWARNING stats.py:587 -- Direct conversion to pandas failed (buffer is too small for requested array), attempting column-by-column conversion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>2020-01-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>2019-03-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic            hire_date  name\n",
       "0        count                  3.0   3.0\n",
       "1          max  2020-01-15 00:00:00   NaN\n",
       "2         mean                  NaN   NaN\n",
       "3          min  2019-03-20 00:00:00   NaN\n",
       "4  missing_pct                 33.0  33.0\n",
       "5          std                  NaN   NaN\n",
       "6     zero_pct                  NaN   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_types = to_feature_type_dataset(summary)\n",
    "feature_types[FeatureType.CATEGORICAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69a22b",
   "metadata": {},
   "source": [
    "# VECTOR FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93acadfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic embeddings scores\n",
       "0        count        3.0    3.0\n",
       "1          max        NaN    NaN\n",
       "2         mean        NaN    NaN\n",
       "3          min        NaN    NaN\n",
       "4  missing_pct        0.0    0.0\n",
       "5          std        NaN    NaN\n",
       "6     zero_pct        NaN    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_types[FeatureType.VECTOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc5e5f",
   "metadata": {},
   "source": [
    "# NUMERICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1990b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>55000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic        age        id        salary\n",
       "0        count   3.000000  3.000000      3.000000\n",
       "1          max  30.000000  3.000000  60000.000000\n",
       "2         mean  27.500000  2.000000  55000.000000\n",
       "3          min  25.000000  1.000000  50000.000000\n",
       "4  missing_pct  33.333333  0.000000     33.333333\n",
       "5          std   2.500000  0.816497   5000.000000\n",
       "6     zero_pct   0.000000  0.000000      0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMERICAL FEATURES\n",
    "feature_types[FeatureType.NUMERICAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa4d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
