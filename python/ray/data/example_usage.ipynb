{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a395537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "\n",
    "# Create sample data with various types\n",
    "data = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"age\": 25,\n",
    "        \"salary\": 50000.0,\n",
    "        \"name\": \"Alice\",\n",
    "        \"scores\": [85, 90, 88],  # List type\n",
    "        \"embeddings\": np.array([0.1, 0.2, 0.3, 0.4]),  # Tensor/array type\n",
    "        \"address\": {\"street\": \"123 Main St\", \"city\": \"NYC\", \"zip\": 10001},  # Struct type\n",
    "        \"hire_date\": datetime(2020, 1, 15),  # Timestamp type\n",
    "        \"metadata\": b\"binary_data_1\",  # Binary type\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"age\": 30,\n",
    "        \"salary\": 60000.0,\n",
    "        \"name\": \"Bob\",\n",
    "        \"scores\": [92, 88, 95],\n",
    "        \"embeddings\": np.array([0.5, 0.6, 0.7, 0.8]),\n",
    "        \"address\": {\"street\": \"456 Oak Ave\", \"city\": \"LA\", \"zip\": 90001},\n",
    "        \"hire_date\": datetime(2019, 3, 20),\n",
    "        \"metadata\": b\"binary_data_2\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"age\": None,  # Missing value\n",
    "        \"salary\": None,\n",
    "        \"name\": None,\n",
    "        \"scores\": [78, 82, 80],\n",
    "        \"embeddings\": np.array([0.9, 1.0, 1.1, 1.2]),\n",
    "        \"address\": {\"street\": \"789 Pine Rd\", \"city\": None, \"zip\": None},\n",
    "        \"hire_date\": None,\n",
    "        \"metadata\": None,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab118c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled by default for nightly wheels. To disable this, run the following command: `ray disable-usage-stats` before starting Ray. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:09:20,535\tINFO worker.py:2004 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "/Users/goutam/Documents/ray/.venv/lib/python3.11/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "2025-10-10 17:09:21,049\tWARNING arrow.py:294 -- Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "2025-10-10 17:09:21,314\tINFO dataset.py:3366 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2025-10-10 17:09:21,319\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_2_0\n",
      "2025-10-10 17:09:21,332\tINFO hash_aggregate.py:180 -- Estimated memory requirement for aggregating aggregator (partitions=1, aggregators=1, dataset (estimate)=0.0GiB): shuffle=0.0MiB, output=0.0MiB, total=0.0MiB, \n",
      "2025-10-10 17:09:21,334\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_2_0. Full logs are in /tmp/ray/session_2025-10-10_17-09-19_252245_75259/logs/ray-data\n",
      "2025-10-10 17:09:21,334\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_2_0: InputDataBuffer[Input] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0871fa95776f44b39751ac1d195cca60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef802e9301914b858356484c4578d8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- HashAggregate(key_columns=(), num_partitions=1) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3d443df22d48819be8f81493dccdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bbe18eff6f4b37a9f04338dc91a90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregation 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c7a1c2daee46269620784aa02afa0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:09:21,363\tWARNING resource_manager.py:134 -- ⚠️  Ray's object store is configured to use only 17.3% of available memory (2.0GiB out of 11.5GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
      "\u001b[36m(_shuffle_block pid=77397)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(_shuffle_block pid=77397)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "2025-10-10 17:09:21,702\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_2_0 execution finished in 0.37 seconds\n",
      "2025-10-10 17:09:21,720\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_3_0\n",
      "2025-10-10 17:09:21,721\tINFO hash_aggregate.py:180 -- Estimated memory requirement for aggregating aggregator (partitions=1, aggregators=1, dataset (estimate)=0.0GiB): shuffle=0.0MiB, output=0.0MiB, total=0.0MiB, \n",
      "2025-10-10 17:09:21,723\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_3_0. Full logs are in /tmp/ray/session_2025-10-10_17-09-19_252245_75259/logs/ray-data\n",
      "2025-10-10 17:09:21,724\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_3_0: InputDataBuffer[Input] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcbdde07acd41238267b35306638399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5656372eb5274c9da318e9843899fb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- HashAggregate(key_columns=(), num_partitions=1) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fb2dbd22cc40e39455306e6957da5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7753bc7fdae488998e8c499dbe0afd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregation 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a718d66433d4852b01a79bb1349b8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:09:22,082\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_3_0 execution finished in 0.36 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetSummary(\n",
       "  schema_matching_stats: 7 rows × 10 columns\n",
       "  schema_changing_stats: 5 rows × 10 columns\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(HashShuffleAggregator pid=77396)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=77396)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=77399)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=77399)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=77398)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n",
      "\u001b[36m(HashShuffleAggregator pid=77398)\u001b[0m Converting a 'D' precision datetime NumPy array to 's' precision Arrow timestamp. This conversion occurs because Arrow supports fewer precisions than Arrow and might result in a loss of precision or unrepresentable values.\n"
     ]
    }
   ],
   "source": [
    "from ray.data.aggregate import Count, Max, Min, MissingValuePercentage\n",
    "from ray.data.datatype import DataType\n",
    "\n",
    "ds = ray.data.from_items(data)\n",
    "\n",
    "# Custom aggregations for Temporal type\n",
    "temporal_type_mapping = {\n",
    "    DataType.temporal_(): [\n",
    "        Count(ignore_nulls=False),\n",
    "        Min(ignore_nulls=True),\n",
    "        Max(ignore_nulls=True),\n",
    "        MissingValuePercentage()\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "summary = ds.summary(override_dtype_agg_mapping=temporal_type_mapping)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829caf1",
   "metadata": {},
   "source": [
    "# COMBINED SUMMARY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3064daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:09:26,286\tWARNING stats.py:584 -- Direct conversion to pandas failed (buffer is too small for requested array), attempting column-by-column conversion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>address</th>\n",
       "      <th>age</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-15 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-20 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic  address        age  embeddings            hire_date        id  \\\n",
       "0        count      3.0   3.000000         3.0                  3.0  3.000000   \n",
       "1          max      NaN  30.000000         NaN  2020-01-15 00:00:00  3.000000   \n",
       "2         mean      NaN  27.500000         NaN                  NaN  2.000000   \n",
       "3          min      NaN  25.000000         NaN  2019-03-20 00:00:00  1.000000   \n",
       "4  missing_pct      0.0  33.333333         0.0                 33.0  0.000000   \n",
       "5          std      NaN   2.500000         NaN                  NaN  0.816497   \n",
       "6     zero_pct      NaN   0.000000         NaN                  NaN  0.000000   \n",
       "\n",
       "   metadata  name        salary  scores  \n",
       "0       3.0   3.0      3.000000     3.0  \n",
       "1       NaN   NaN  60000.000000     NaN  \n",
       "2       NaN   NaN  55000.000000     NaN  \n",
       "3       NaN   NaN  50000.000000     NaN  \n",
       "4      33.0  33.0     33.333333     0.0  \n",
       "5       NaN   NaN   5000.000000     NaN  \n",
       "6       NaN   NaN      0.000000     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff248314",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36817c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ray.data.datatype import DataType\n",
    "from ray.data.stats import DatasetSummary\n",
    "\n",
    "\n",
    "class FeatureType(str, Enum):\n",
    "    NUMERICAL = \"numerical\"\n",
    "    VECTOR = \"vector\"\n",
    "    CATEGORICAL = \"categorical\"\n",
    "\n",
    "\n",
    "def to_feature_type_dataset(summary: DatasetSummary) -> dict[FeatureType, \"pd.DataFrame\"]:\n",
    "    \"\"\"Convert the dataset summary to a dictionary of feature type datasets.\n",
    "\n",
    "    Args:\n",
    "        summary: The DatasetSummary object from ds.summary()\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping FeatureType to DataFrame, where each DataFrame contains\n",
    "        only the columns and statistics for that feature type.\n",
    "    \"\"\"\n",
    "\n",
    "    def classify_dtype(column_name: str) -> FeatureType:\n",
    "        \"\"\"Classify column by feature type using PyArrow type from schema-matching table.\n",
    "\n",
    "        The schema-matching table contains all columns with their original types,\n",
    "        so we can reliably infer the feature type from there.\n",
    "        \"\"\"\n",
    "        # Get PyArrow type from schema-matching table (which has original types for all columns)\n",
    "        pa_type = summary.schema_matching_stats.schema.field(column_name).type\n",
    "        dtype = DataType.from_arrow(pa_type)\n",
    "\n",
    "        # Use DataType's built-in methods\n",
    "        if dtype.is_list_type():  # Handles lists, tensors, etc.\n",
    "            return FeatureType.VECTOR\n",
    "        elif dtype.is_string_type() or dtype.is_temporal_type():\n",
    "            return FeatureType.CATEGORICAL\n",
    "        elif dtype.is_numerical_type():\n",
    "            return FeatureType.NUMERICAL\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Get all column names (both tables have the same columns)\n",
    "    all_columns = [name for name in summary.schema_matching_stats.schema.names if name != \"statistic\"]\n",
    "\n",
    "    # Build a mapping of column -> feature_type\n",
    "    column_to_feature_type = {}\n",
    "    for col_name in all_columns:\n",
    "        feature_type = classify_dtype(col_name)\n",
    "        if feature_type is not None:\n",
    "            column_to_feature_type[col_name] = feature_type\n",
    "\n",
    "    # Get combined pandas DataFrame\n",
    "    df = summary.to_pandas()\n",
    "\n",
    "    # Group columns by feature type and create separate DataFrames\n",
    "    result = {}\n",
    "    for ft in FeatureType:\n",
    "        # Find columns of this feature type\n",
    "        cols_of_type = [col for col, ftype in column_to_feature_type.items() if ftype == ft]\n",
    "\n",
    "        if not cols_of_type:\n",
    "            continue\n",
    "\n",
    "        # Select only the statistic column and columns of this feature type\n",
    "        selected_cols = [\"statistic\"] + cols_of_type\n",
    "        result[ft] = df[selected_cols].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9753348",
   "metadata": {},
   "source": [
    "# CATEGORICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc476b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:09:45,048\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_5_0\n",
      "2025-10-10 17:09:45,052\tINFO hash_aggregate.py:180 -- Estimated memory requirement for aggregating aggregator (partitions=1, aggregators=1, dataset (estimate)=0.0GiB): shuffle=0.0MiB, output=0.0MiB, total=0.0MiB, \n",
      "2025-10-10 17:09:45,057\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_5_0. Full logs are in /tmp/ray/session_2025-10-10_17-09-19_252245_75259/logs/ray-data\n",
      "2025-10-10 17:09:45,059\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_5_0: InputDataBuffer[Input] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373747b556d8476da6d675cb1b917b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9e32e2e32a406f808a241f49e4426f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- HashAggregate(key_columns=(), num_partitions=1) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57332ee2b7f43c296c0a34c2b2e441a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfc7759014046d8b32f891028f5574a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregation 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb7c0a95214489292955e2eb6484d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:09:45,363\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_5_0 execution finished in 0.31 seconds\n",
      "2025-10-10 17:09:45,373\tINFO logging.py:293 -- Registered dataset logger for dataset dataset_6_0\n",
      "2025-10-10 17:09:45,375\tINFO hash_aggregate.py:180 -- Estimated memory requirement for aggregating aggregator (partitions=1, aggregators=1, dataset (estimate)=0.0GiB): shuffle=0.0MiB, output=0.0MiB, total=0.0MiB, \n",
      "2025-10-10 17:09:45,377\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_6_0. Full logs are in /tmp/ray/session_2025-10-10_17-09-19_252245_75259/logs/ray-data\n",
      "2025-10-10 17:09:45,378\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_6_0: InputDataBuffer[Input] -> HashAggregateOperator[HashAggregate(key_columns=(), num_partitions=1)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba59c558c5a84da7949e644c1ed29054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d070c5fb2a040eba41da2b0c564af4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- HashAggregate(key_columns=(), num_partitions=1) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948954a0d8624adfb711c3e6c3eeb110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fc5b6740494e0d814710135b106e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregation 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b33199f95e3415aa16e318d2b9ef48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 4: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:09:45,667\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_6_0 execution finished in 0.29 seconds\n",
      "2025-10-10 17:09:45,675\tWARNING stats.py:584 -- Direct conversion to pandas failed (buffer is too small for requested array), attempting column-by-column conversion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>2020-01-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>2019-03-20 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic            hire_date  name\n",
       "0        count                  3.0   3.0\n",
       "1          max  2020-01-15 00:00:00   NaN\n",
       "2         mean                  NaN   NaN\n",
       "3          min  2019-03-20 00:00:00   NaN\n",
       "4  missing_pct                 33.0  33.0\n",
       "5          std                  NaN   NaN\n",
       "6     zero_pct                  NaN   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_ds = ds.summary()\n",
    "feature_types = to_feature_type_dataset(summary_ds)\n",
    "feature_types[FeatureType.CATEGORICAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69a22b",
   "metadata": {},
   "source": [
    "# VECTOR FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93acadfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic  embeddings  scores\n",
       "0        count         3.0     3.0\n",
       "1          max         NaN     NaN\n",
       "2         mean         NaN     NaN\n",
       "3          min         NaN     NaN\n",
       "4  missing_pct         0.0     0.0\n",
       "5          std         NaN     NaN\n",
       "6     zero_pct         NaN     NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_types[FeatureType.VECTOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc5e5f",
   "metadata": {},
   "source": [
    "# NUMERICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1990b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>55000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing_pct</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zero_pct</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     statistic        age        id        salary\n",
       "0        count   3.000000  3.000000      3.000000\n",
       "1          max  30.000000  3.000000  60000.000000\n",
       "2         mean  27.500000  2.000000  55000.000000\n",
       "3          min  25.000000  1.000000  50000.000000\n",
       "4  missing_pct  33.333333  0.000000     33.333333\n",
       "5          std   2.500000  0.816497   5000.000000\n",
       "6     zero_pct   0.000000  0.000000      0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMERICAL FEATURES\n",
    "feature_types[FeatureType.NUMERICAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa4d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
