"""Task operator runtime metrics."""

import time
from collections import defaultdict
from dataclasses import dataclass
from typing import TYPE_CHECKING, Dict, Optional

from typing_extensions import override

import ray
from ray.data._internal.execution.bundle_queue import create_bundle_queue
from ray.data._internal.execution.interfaces.common import (
    RuntimeMetricsHistogram,
    histogram_bucket_rows,
    histogram_buckets_bytes,
    histogram_buckets_s,
)
from ray.data._internal.execution.interfaces.op_runtime_metrics import (
    NODE_UNKNOWN,
    MetricsGroup,
    MetricsType,
    NodeMetrics,
    ObjectStoreUsageDetails,
    QueuedOpMetrics,
    RunningTaskInfo,
    TaskDurationStats,
    metric_field,
    metric_property,
    node_id_from_block_metadata,
)
from ray.data._internal.memory_tracing import trace_allocation

if TYPE_CHECKING:
    from ray.data._internal.execution.interfaces.physical_operator import _ActorPoolInfo
    from ray.data._internal.execution.interfaces.ref_bundle import RefBundle
    from ray.data.context import DataContext


@dataclass
class TaskOpMetrics(QueuedOpMetrics):
    """Metrics for operators that execute tasks (including actor pools).

    Adds TASKS, ACTORS, and advanced RESOURCE_USAGE metrics to QueuedOpMetrics.
    Also adds task-specific INPUTS and OUTPUTS metrics.
    Used by operators that execute Ray tasks or actor pool tasks.

    Examples: TaskPoolMapOperator, ActorPoolMapOperator

    Available callbacks (in addition to QueuedOpMetrics):
    - on_task_submitted(): Tracks when a task is submitted
    - on_task_output_generated(): Tracks when a task generates output blocks
    - on_task_finished(): Tracks when a task completes or fails (also updates actor state if op provided)
    - on_toggle_task_submission_backpressure(): Tracks task submission backpressure
    - on_toggle_task_output_backpressure(): Tracks task output backpressure
    """

    # === Task-specific Inputs-related metrics ===
    num_task_inputs_processed: int = metric_field(
        default=0,
        description=(
            "Number of input blocks that operator's tasks have finished processing."
        ),
        metrics_group=MetricsGroup.INPUTS,
    )
    bytes_task_inputs_processed: int = metric_field(
        default=0,
        description=(
            "Byte size of input blocks that operator's tasks have finished processing."
        ),
        metrics_group=MetricsGroup.INPUTS,
    )
    bytes_inputs_of_submitted_tasks: int = metric_field(
        default=0,
        description="Byte size of input blocks passed to submitted tasks.",
        metrics_group=MetricsGroup.INPUTS,
    )
    rows_inputs_of_submitted_tasks: int = metric_field(
        default=0,
        description="Number of rows in the input blocks passed to submitted tasks.",
        metrics_group=MetricsGroup.INPUTS,
    )

    # === Task-specific Outputs-related metrics ===
    num_task_outputs_generated: int = metric_field(
        default=0,
        description="Number of output blocks generated by tasks.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    bytes_task_outputs_generated: int = metric_field(
        default=0,
        description="Byte size of output blocks generated by tasks.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    rows_task_outputs_generated: int = metric_field(
        default=0,
        description="Number of output rows generated by tasks.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    num_outputs_of_finished_tasks: int = metric_field(
        default=0,
        description="Number of generated output blocks that are from finished tasks.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    bytes_outputs_of_finished_tasks: int = metric_field(
        default=0,
        description=(
            "Total byte size of generated output blocks produced by finished tasks."
        ),
        metrics_group=MetricsGroup.OUTPUTS,
    )
    rows_outputs_of_finished_tasks: int = metric_field(
        default=0,
        description=("Number of rows generated by finished tasks."),
        metrics_group=MetricsGroup.OUTPUTS,
    )

    # === Tasks-related metrics ===
    num_tasks_submitted: int = metric_field(
        default=0,
        description="Number of submitted tasks.",
        metrics_group=MetricsGroup.TASKS,
    )
    num_tasks_running: int = metric_field(
        default=0,
        description="Number of running tasks.",
        metrics_group=MetricsGroup.TASKS,
    )
    num_tasks_have_outputs: int = metric_field(
        default=0,
        description="Number of tasks that already have output.",
        metrics_group=MetricsGroup.TASKS,
    )
    num_tasks_finished: int = metric_field(
        default=0,
        description="Number of finished tasks.",
        metrics_group=MetricsGroup.TASKS,
    )
    num_tasks_failed: int = metric_field(
        default=0,
        description="Number of failed tasks.",
        metrics_group=MetricsGroup.TASKS,
    )
    block_generation_time: float = metric_field(
        default=0,
        description="Time spent generating blocks in tasks.",
        metrics_group=MetricsGroup.TASKS,
    )
    task_submission_backpressure_time: float = metric_field(
        default=0,
        description="Time spent in task submission backpressure.",
        metrics_group=MetricsGroup.TASKS,
    )
    task_output_backpressure_time: float = metric_field(
        default=0,
        description="Time spent in task output backpressure.",
        metrics_group=MetricsGroup.TASKS,
    )
    task_completion_time_total_s: float = metric_field(
        default=0,
        description="Time spent running tasks to completion. This is a sum of all tasks' completion times.",
        metrics_group=MetricsGroup.TASKS,
    )
    task_completion_time: RuntimeMetricsHistogram = metric_field(
        default_factory=lambda: RuntimeMetricsHistogram(histogram_buckets_s),
        description="Time spent per task running those tasks to completion.",
        metrics_group=MetricsGroup.TASKS,
        metrics_type=MetricsType.Histogram,
        metrics_args={"boundaries": histogram_buckets_s},
    )
    block_completion_time: RuntimeMetricsHistogram = metric_field(
        default_factory=lambda: RuntimeMetricsHistogram(histogram_buckets_s),
        description="Time spent running a single block to completion. If multiple blocks are generated per task, this is approximated by assuming each block took an equal amount of time to process.",
        metrics_group=MetricsGroup.TASKS,
        metrics_type=MetricsType.Histogram,
        metrics_args={"boundaries": histogram_buckets_s},
    )
    task_completion_time_excl_backpressure_s: float = metric_field(
        default=0,
        description="Time spent running tasks to completion without backpressure.",
        metrics_group=MetricsGroup.TASKS,
    )
    block_size_bytes: RuntimeMetricsHistogram = metric_field(
        default_factory=lambda: RuntimeMetricsHistogram(histogram_buckets_bytes),
        description="Size of blocks generated by tasks.",
        metrics_group=MetricsGroup.TASKS,
        metrics_type=MetricsType.Histogram,
        metrics_args={"boundaries": histogram_buckets_bytes},
    )
    block_size_rows: RuntimeMetricsHistogram = metric_field(
        default_factory=lambda: RuntimeMetricsHistogram(histogram_bucket_rows),
        description="Number of rows in blocks generated by tasks.",
        metrics_group=MetricsGroup.TASKS,
        metrics_type=MetricsType.Histogram,
        metrics_args={"boundaries": histogram_bucket_rows},
    )

    # === Advanced Resource Usage-related metrics ===
    obj_store_mem_freed: int = metric_field(
        default=0,
        description="Byte size of freed memory in object store.",
        metrics_group=MetricsGroup.RESOURCE_USAGE,
    )
    obj_store_mem_spilled: int = metric_field(
        default=0,
        description="Byte size of spilled memory in object store.",
        metrics_group=MetricsGroup.RESOURCE_USAGE,
    )

    # === Actor-related metrics (for ActorPoolMapOperator) ===
    num_alive_actors: int = metric_field(
        default=0,
        description="Number of alive actors.",
        metrics_group=MetricsGroup.ACTORS,
    )
    num_restarting_actors: int = metric_field(
        default=0,
        description="Number of restarting actors.",
        metrics_group=MetricsGroup.ACTORS,
    )
    num_pending_actors: int = metric_field(
        default=0,
        description="Number of pending actors.",
        metrics_group=MetricsGroup.ACTORS,
    )

    def __init__(self, data_context: "DataContext"):
        """Initialize TaskOpMetrics.

        Args:
            data_context: DataContext instance for accessing configuration settings.
        """
        super().__init__(data_context)
        self._running_tasks: Dict[int, RunningTaskInfo] = {}
        self._pending_task_inputs = create_bundle_queue()
        self._op_task_duration_stats = TaskDurationStats()
        self._per_node_metrics: Dict[str, NodeMetrics] = defaultdict(NodeMetrics)
        self._per_node_metrics_enabled: bool = data_context.enable_per_node_metrics
        self._cum_max_uss_bytes: Optional[int] = None
        # Start time of current pause due to task submission backpressure
        self._task_submission_backpressure_start_time = -1
        # Start time of current pause due to task output backpressure
        self._task_output_backpressure_start_time = -1

        # Initialize the histogram metrics
        self.task_completion_time = RuntimeMetricsHistogram(histogram_buckets_s)
        self.block_completion_time = RuntimeMetricsHistogram(histogram_buckets_s)
        self.block_size_bytes = RuntimeMetricsHistogram(histogram_buckets_bytes)
        self.block_size_rows = RuntimeMetricsHistogram(histogram_bucket_rows)

    # === Pending Inputs-related metric properties ===

    @metric_property(
        description="Byte size of input blocks used by pending tasks.",
        metrics_group=MetricsGroup.PENDING_INPUTS,
    )
    def obj_store_mem_pending_task_inputs(self) -> int:
        return self._pending_task_inputs.estimate_size_bytes()

    # === Inputs-related metric properties ===

    @metric_property(
        description="Average number of blocks generated per task.",
        metrics_group=MetricsGroup.INPUTS,
    )
    def average_num_inputs_per_task(self) -> Optional[float]:
        """Average number of input blocks per task, or None if no task has finished."""
        if self.num_tasks_finished == 0:
            return None
        else:
            return self.num_task_inputs_processed / self.num_tasks_finished

    @metric_property(
        description="Average size of task inputs in bytes.",
        metrics_group=MetricsGroup.INPUTS,
    )
    def average_bytes_inputs_per_task(self) -> Optional[float]:
        """Average size in bytes of ref bundles passed to tasks, or ``None`` if no
        tasks have been submitted."""
        if self.num_tasks_submitted == 0:
            return None
        else:
            return self.bytes_inputs_of_submitted_tasks / self.num_tasks_submitted

    @metric_property(
        description="Average number of rows passed in to the task.",
        metrics_group=MetricsGroup.INPUTS,
    )
    def average_rows_inputs_per_task(self) -> Optional[float]:
        """Average number of rows in input blocks per task,
        or None if no task has been submitted."""
        if self.num_tasks_submitted == 0:
            return None
        else:
            return self.rows_inputs_of_submitted_tasks / self.num_tasks_submitted

    # === Pending Outputs-related metric properties ===

    @property
    def obj_store_mem_pending_task_outputs(self) -> Optional[float]:
        """Estimated size in bytes of output blocks in Ray generator buffers.

        For actor-based operators, multiple tasks can be in-flight (submitted) per
        actor, but only one task actually runs/executes per actor at a time. We cap
        the estimate to the number of alive actors to reflect actual running tasks.

        If an estimate isn't available, this property returns ``None``.
        """
        per_task_output = self.obj_store_mem_max_pending_output_per_task
        if per_task_output is None:
            return None

        num_actually_running = self.num_tasks_running

        # If this is an actor pool operator (has non-zero actor metrics), cap to total
        # number of actors since only 1 task executes per actor at a time
        # (even though multiple tasks can be in-flight/submitted per actor)
        total_actors = (
            self.num_alive_actors + self.num_pending_actors + self.num_restarting_actors
        )
        if total_actors > 0:
            num_actually_running = min(num_actually_running, total_actors)

        return num_actually_running * per_task_output

    @property
    def obj_store_mem_max_pending_output_per_task(self) -> Optional[float]:
        """Estimated size in bytes of output blocks in a task's generator buffer."""
        context = self._data_context
        if context._max_num_blocks_in_streaming_gen_buffer is None:
            return None

        bytes_per_output = self.average_bytes_per_output
        # If we don't have a sample yet and the limit is "unlimited", we can't
        # estimate â€“ just bail out.
        if bytes_per_output is None:
            if context.target_max_block_size is None:
                return None
            bytes_per_output = context.target_max_block_size

        num_pending_outputs = context._max_num_blocks_in_streaming_gen_buffer
        if self.average_num_outputs_per_task is not None:
            num_pending_outputs = min(
                num_pending_outputs, self.average_num_outputs_per_task
            )
        return bytes_per_output * num_pending_outputs

    # === Outputs-related metric properties ===

    @metric_property(
        description="Average number of blocks generated per task.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    def average_num_outputs_per_task(self) -> Optional[float]:
        """Average number of output blocks per task, or None if no task has finished."""
        if self.num_tasks_finished == 0:
            return None
        else:
            return self.num_outputs_of_finished_tasks / self.num_tasks_finished

    @metric_property(
        description="Average number of output blocks per task per second.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    def num_output_blocks_per_task_s(self) -> Optional[float]:
        """Average number of output blocks per task per second.

        If the operator hasn't produced any output yet, this metric returns `None`.
        """
        if self.block_generation_time == 0:
            return None
        else:
            return self.num_task_outputs_generated / self.block_generation_time

    @metric_property(
        description="Average size of task output in bytes.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    def average_bytes_per_output(self) -> Optional[float]:
        """Average size in bytes of output blocks."""
        if self.num_task_outputs_generated == 0:
            return None
        else:
            return self.bytes_task_outputs_generated / self.num_task_outputs_generated

    @metric_property(
        description="Average total output size of task in bytes.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    def average_bytes_outputs_per_task(self) -> Optional[float]:
        """Average size in bytes of output blocks per task,
        or None if no task has finished."""
        if self.num_tasks_finished == 0:
            return None
        else:
            return self.bytes_outputs_of_finished_tasks / self.num_tasks_finished

    @metric_property(
        description="Average number of rows produced per task.",
        metrics_group=MetricsGroup.OUTPUTS,
    )
    def average_rows_outputs_per_task(self) -> Optional[float]:
        """Average number of rows in output blocks per task,
        or None if no task has finished."""
        if self.num_tasks_finished == 0:
            return None
        else:
            return self.rows_outputs_of_finished_tasks / self.num_tasks_finished

    # === Tasks-related metric properties ===

    @metric_property(
        description="Average task's completion time in seconds (including throttling).",
        metrics_group=MetricsGroup.TASKS,
    )
    def average_total_task_completion_time_s(self) -> Optional[float]:
        """Average task's completion time in seconds (including throttling)"""
        if self.num_tasks_finished == 0:
            return None
        else:
            return self.task_completion_time_total_s / self.num_tasks_finished

    @metric_property(
        description="Average task's completion time in seconds (excluding throttling).",
        metrics_group=MetricsGroup.TASKS,
    )
    def average_task_completion_excl_backpressure_time_s(self) -> Optional[float]:
        """Average task's completion time in seconds (excluding throttling)"""
        if self.num_tasks_finished == 0:
            return None
        else:
            return (
                self.task_completion_time_excl_backpressure_s / self.num_tasks_finished
            )

    @metric_property(
        description="Average USS usage of tasks.",
        metrics_group=MetricsGroup.TASKS,
    )
    def average_max_uss_per_task(self) -> Optional[float]:
        """Average max USS usage of tasks."""
        if self._cum_max_uss_bytes is None:
            return None
        else:
            assert self.num_task_outputs_generated > 0, self.num_task_outputs_generated
            return self._cum_max_uss_bytes / self.num_task_outputs_generated

    # === Callbacks (override to implement task tracking) ===
    @override
    def on_task_submitted(self, task_index: int, inputs: "RefBundle"):
        """Callback when the operator submits a task."""
        self.num_tasks_submitted += 1
        self.num_tasks_running += 1
        self.bytes_inputs_of_submitted_tasks += inputs.size_bytes()
        self.rows_inputs_of_submitted_tasks += inputs.num_rows() or 0
        self._pending_task_inputs.add(inputs)
        self._running_tasks[task_index] = RunningTaskInfo(
            inputs=inputs,
            num_outputs=0,
            bytes_outputs=0,
            num_rows_produced=0,
            start_time=time.perf_counter(),
            cum_block_gen_time=0,
        )

    @override
    def on_task_output_generated(self, task_index: int, output: "RefBundle"):
        """Callback when a new task generates an output."""
        num_outputs = len(output)
        output_bytes = output.size_bytes()
        num_rows_produced = output.num_rows()

        self.num_task_outputs_generated += num_outputs
        self.bytes_task_outputs_generated += output_bytes
        self.rows_task_outputs_generated += num_rows_produced
        for block in output.metadata:
            if block.size_bytes is not None:
                self.block_size_bytes.observe(block.size_bytes)
            if block.num_rows is not None:
                self.block_size_rows.observe(block.num_rows)

        task_info = self._running_tasks[task_index]
        if task_info.num_outputs == 0:
            self.num_tasks_have_outputs += 1

        task_info.num_outputs += num_outputs
        task_info.bytes_outputs += output_bytes
        task_info.num_rows_produced += num_rows_produced

        for block_ref, meta in output.blocks:
            assert (
                meta.exec_stats is not None and meta.exec_stats.wall_time_s is not None
            )
            self.block_generation_time += meta.exec_stats.wall_time_s
            task_info.cum_block_gen_time += meta.exec_stats.wall_time_s
            assert meta.num_rows is not None
            trace_allocation(block_ref, "operator_output")
            if meta.exec_stats.max_uss_bytes is not None:
                if self._cum_max_uss_bytes is None:
                    self._cum_max_uss_bytes = meta.exec_stats.max_uss_bytes
                else:
                    self._cum_max_uss_bytes += meta.exec_stats.max_uss_bytes

        # Update per node metrics
        if self._per_node_metrics_enabled:
            for _, meta in output.blocks:
                node_id = node_id_from_block_metadata(meta)
                node_metrics = self._per_node_metrics[node_id]

                node_metrics.bytes_outputs_of_finished_tasks += meta.size_bytes
                node_metrics.blocks_outputs_of_finished_tasks += 1

    @override
    def on_task_finished(
        self,
        task_index: int,
        exception: Optional[Exception],
        actor_info: Optional["_ActorPoolInfo"] = None,
    ):
        """Callback when a task is finished.

        Args:
            task_index: Index of the finished task.
            exception: Exception raised by the task, if any.
            actor_info: Optional actor pool info for updating actor metrics (ActorPoolMapOperator only).
        """
        self.num_tasks_running -= 1
        self.num_tasks_finished += 1
        if exception is not None:
            self.num_tasks_failed += 1

        task_info = self._running_tasks[task_index]

        self.num_outputs_of_finished_tasks += task_info.num_outputs
        self.bytes_outputs_of_finished_tasks += task_info.bytes_outputs
        self.rows_outputs_of_finished_tasks += task_info.num_rows_produced

        task_time_delta = time.perf_counter() - task_info.start_time
        self.task_completion_time_total_s += task_time_delta
        self.task_completion_time.observe(task_time_delta)

        assert task_info.cum_block_gen_time is not None
        if task_info.num_outputs > 0:
            # Calculate the average block generation time per block
            block_time_delta = task_info.cum_block_gen_time / task_info.num_outputs
            self.block_completion_time.observe(
                block_time_delta, num_observations=task_info.num_outputs
            )

        # NOTE: This is used for Issue Detection
        self._op_task_duration_stats.add_duration(task_time_delta)

        self.task_completion_time_excl_backpressure_s += task_info.cum_block_gen_time
        inputs = self._running_tasks[task_index].inputs
        self.num_task_inputs_processed += len(inputs)
        total_input_size = inputs.size_bytes()
        self.bytes_task_inputs_processed += total_input_size
        input_size = inputs.size_bytes()
        self._pending_task_inputs.remove(inputs)
        assert self.obj_store_mem_pending_task_inputs >= 0, (
            self.obj_store_mem_pending_task_inputs,
            input_size,
        )

        if self._data_context.enable_get_object_locations_for_metrics:
            locations = ray.experimental.get_object_locations(inputs.block_refs)
            for block, meta in inputs.blocks:
                if locations[block].get("did_spill", False):
                    assert meta.size_bytes is not None
                    self.obj_store_mem_spilled += meta.size_bytes

        self.obj_store_mem_freed += total_input_size

        # Update per node metrics
        if self._per_node_metrics_enabled:
            node_ids = set()
            for _, meta in inputs.blocks:
                node_id = node_id_from_block_metadata(meta)
                node_metrics = self._per_node_metrics[node_id]

                # Stats to update once per node id or if node id is unknown
                if node_id not in node_ids or node_id == NODE_UNKNOWN:
                    node_metrics.num_tasks_finished += 1

                # Keep track of node ids to ensure we don't double count
                node_ids.add(node_id)

        inputs.destroy_if_owned()
        del self._running_tasks[task_index]

        # Update actor pool state if actor_info is provided (ActorPoolMapOperator)
        if actor_info is not None:
            self.num_alive_actors = actor_info.running
            self.num_pending_actors = actor_info.pending
            self.num_restarting_actors = actor_info.restarting

    @override
    def notify_in_task_submission_backpressure(self, in_backpressure: bool) -> None:
        """Called periodically from the executor to update internal in backpressure
        status for stats collection purposes.

        Args:
            in_backpressure: Value this operator's in_backpressure should be set to.
        """
        if in_backpressure and self._task_submission_backpressure_start_time == -1:
            # backpressure starting, start timer
            self._task_submission_backpressure_start_time = time.perf_counter()
        elif (
            not in_backpressure and self._task_submission_backpressure_start_time != -1
        ):
            # backpressure stopping, stop timer
            self.task_submission_backpressure_time += (
                time.perf_counter() - self._task_submission_backpressure_start_time
            )
            self._task_submission_backpressure_start_time = -1

    @override
    def notify_in_task_output_backpressure(self, in_backpressure: bool) -> None:
        """Called periodically from the executor to update internal output backpressure
        status for stats collection purposes.

        Args:
            in_backpressure: Value this operator's output backpressure should be set to.
        """
        if in_backpressure and self._task_output_backpressure_start_time == -1:
            # backpressure starting, start timer
            self._task_output_backpressure_start_time = time.perf_counter()
        elif not in_backpressure and self._task_output_backpressure_start_time != -1:
            # backpressure stopping, stop timer
            delta = time.perf_counter() - self._task_output_backpressure_start_time
            self.task_output_backpressure_time += delta
            self._task_output_backpressure_start_time = -1

    @override
    def in_task_submission_backpressure(self) -> bool:
        return self._task_submission_backpressure_start_time != -1

    @override
    def in_task_output_backpressure(self) -> bool:
        return self._task_output_backpressure_start_time != -1

    @override
    def get_object_store_usage_details(self) -> "ObjectStoreUsageDetails":
        """Get object store memory usage details for this operator.

        Returns queue memory + task memory usage. TaskOpMetrics tracks both
        internal queues (from parent) and task-related memory.

        Returns:
            ObjectStoreUsageDetails with all memory values populated.
        """

        return ObjectStoreUsageDetails(
            internal_outqueue_memory=self.obj_store_mem_internal_outqueue,
            internal_inqueue_memory=self.obj_store_mem_internal_inqueue,
            pending_task_outputs_memory=self.obj_store_mem_pending_task_outputs,
            pending_task_inputs_memory=self.obj_store_mem_pending_task_inputs,
        )

    @override
    def get_per_node_metrics(self) -> Dict[str, NodeMetrics]:
        """Get per-node metrics for this operator.

        Returns a dictionary mapping node IDs to NodeMetrics objects containing
        per-node execution statistics. Only populated if per-node metrics are
        enabled in DataContext.

        Returns:
            Dict mapping node IDs to NodeMetrics with execution stats per node.
        """
        return dict(self._per_node_metrics)
