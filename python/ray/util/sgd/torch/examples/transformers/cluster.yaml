# An unique identifier for the head node and workers of this cluster.
cluster_name: transformer-cluster

# The maximum number of workers nodes to launch in addition to the head
# node. This takes precedence over min_workers. min_workers default to 0.
min_workers: 3
max_workers: 3

# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-east-1
    availability_zone: us-east-1c

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu


head_node:
    InstanceType: p3.8xlarge
    ImageId: ami-0698bcaf8bd9ef56d
    InstanceMarketOptions:
        MarketType: spot
    BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
              VolumeSize: 300


worker_nodes:
    InstanceType: p3.8xlarge
    ImageId: ami-0698bcaf8bd9ef56d
    InstanceMarketOptions:
        MarketType: spot
    BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
              VolumeSize: 300
        # SpotOptions:
        #     MaxPrice: "9.0"
    #     # Run workers on spot by default. Comment this out to use on-demand.
    #     InstanceMarketOptions:
    #         MarketType: spot

setup_commands:
    # This replaces the standard anaconda Ray installation
    - ray || pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-2.0.0.dev0-cp36-cp36m-manylinux2014_x86_64.whl
    - pip install -q tqdm

    # Installing this without -U to make sure we don't replace the existing Ray installation
    - pip install ray[tune]
    - pip install -U ipdb torch
    # Install HuggingFace
    - git clone https://github.com/huggingface/transformers || true
    - cd transformers &&
      pip install . &&
      pip install -r ./examples/requirements.txt
    # Download glue
    - if [[ -e glue_data ]];
      then echo "not downloading glue";
      else wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py && python download_glue_data.py;
      fi

    # Install Apex
    - git clone https://github.com/NVIDIA/apex;
      cd apex &&
      pip install -v --no-cache-dir  ./ ||
      true


file_mounts: {
}

# Custom commands that will be run on the head node after common setup.
head_setup_commands: []
