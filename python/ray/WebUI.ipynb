{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the box below to initialize the web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import qgrid \n",
    "import ray\n",
    "import redis\n",
    "import sys\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import layout, widgetbox, row, gridplot\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Div, CustomJS, Range1d\n",
    "from bokeh.models.widgets import Slider, Select, TextInput\n",
    "from bokeh.io import curdoc, output_notebook, push_notebook\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redis_address = os.environ[\"REDIS_ADDRESS\"]\n",
    "ray.init(redis_address=redis_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task and Actor Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Function Information \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn_table = ray.global_state.function_table()\n",
    "fn_list = []\n",
    "if (len(fn_table) != 0): \n",
    "    for fn_id in fn_table:\n",
    "        val = fn_table[fn_id]\n",
    "        val[\"function_id\"] = fn_id\n",
    "        fn_list.append(val)\n",
    "else: \n",
    "    fn_list.append({\"DriverID\": \"None\", \"Module\": \"None\", \"Function\": \"None\", \"FunctionID\": \"None\"})\n",
    "qgrid.nbinstall(overwrite=True)\n",
    "frame = pd.DataFrame(fn_list) \n",
    "frame.columns = [\"DriverID\", \"Module\", \"Function\", \"FunctionID\"]\n",
    "qgrid.show_grid(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = ray.global_state.task_table()\n",
    "tt_list = list(tt.values())\n",
    "for d in tt_list:\n",
    "    d[\"TaskSpec\"][\"ReturnObjectIDs\"] = [oid.hex() for oid in d[\"TaskSpec\"][\"ReturnObjectIDs\"]]\n",
    "    d[\"TaskSpec\"][\"Args\"] = [arg.hex() if isinstance(arg, ray.local_scheduler.ObjectID) else arg for arg in d[\"TaskSpec\"][\"Args\"]]\n",
    "\n",
    "task_df = json_normalize(tt_list)\n",
    "task_df.columns = [\"Local Scheduler ID\", \"State\", \"Actor Counter\", \"ActorID\", \"Arguments\", \"DriverID\", \"FunctionID\", \n",
    "                  \"Parent Counter\", \"Parent Task ID\", \"Required CPUs\", \"Required GPUs\", \"Return Object IDs\", \"TaskID\" ]\n",
    "qgrid.show_grid(task_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_info = ray.global_state.task_profiles()\n",
    "task_breakdowns = dict()\n",
    "if len(task_info) != 0: \n",
    "    for task_id, data in task_info.items(): \n",
    "        task_breakdowns[task_id] = dict()\n",
    "        if \"import_remote_start\" and \"import_remote_end\" in data: \n",
    "            task_breakdowns[task_id][\"import_remote_time\"]  = data[\"import_remote_end\"] - data[\"import_remote_start\"] \n",
    "        if \"store_outputs_end\" and \"store_outputs_start\" in data: \n",
    "            task_breakdowns[task_id][\"store_outputs\"] = data[\"store_outputs_end\"] - data[\"store_outputs_start\"]\n",
    "        task_breakdowns[task_id][\"get_task_time\"] = data[\"get_task_end\"] - data[\"get_task_start\"]\n",
    "        task_breakdowns[task_id][\"get_arguments\"] = data[\"get_arguments_end\"] - data[\"get_arguments_start\"]\n",
    "        task_breakdowns[task_id][\"execute_time\"] = data[\"execute_end\"] - data[\"execute_start\"]\n",
    "        task_breakdowns[task_id][\"acquire_lock\"] = data[\"acquire_lock_end\"] - data[\"acquire_lock_start\"]\n",
    "        task_breakdowns[task_id][\"worker_id\"] = data[\"worker_id\"]\n",
    "else: \n",
    "    task_breakdowns[\"None\"] = {\"Acquire Lock\":\"None\", \n",
    "                               \"Execute Time\":\"None\", \n",
    "                               \"Get Arguments\":\"None\", \n",
    "                               \"Get Task\":\"None\", \n",
    "                               \"Import Remote Function\":\"None\", \n",
    "                               \"Store Outputs\":\"None\", \n",
    "                               \"Worker ID\":\"None\"}\n",
    "df = pd.DataFrame.from_dict(task_breakdowns)\n",
    "df_t = df.T\n",
    "df_t.index.name = \"Task ID\"\n",
    "df_t.columns = [\"Acquire Lock\", \"Execute Time\", \"Get Arguments\", \"Get Task\", \"Import Remote Function\", \"Store Outputs\", \"Worker ID\"] \n",
    "qgrid.show_grid(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-Worker Placement Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_worker = dict()\n",
    "for task_id, data in task_info.items(): \n",
    "    task_worker[task_id] = dict()\n",
    "    task_worker[task_id][\"worker_id\"] = data[\"worker_id\"]\n",
    "    task_worker[task_id][\"function_name\"] = data[\"function_name\"]\n",
    "if len(task_worker) == 0: \n",
    "    task_worker[\"None\"] = {\"Function ID\": \"None\", \"Worker ID\": \"None\"}\n",
    "df = pd.DataFrame.from_dict(task_worker)\n",
    "df_t = df.T \n",
    "df_t.index.name = \"Task ID\"\n",
    "df_t.columns = [\"Function Name\", \"Worker ID\"]\n",
    "qgrid.show_grid(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Profile Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_profs = task_info \n",
    "print(task_profs)\n",
    "workers = dict()\n",
    "\n",
    "counter = 0 \n",
    "for task_id, data in task_profs.items(): \n",
    "    worker_id = data[\"worker_id\"]\n",
    "    if worker_id not in workers: \n",
    "        workers[worker_id] = counter\n",
    "        counter += 1\n",
    "    data[\"wid\"] = workers[worker_id]        \n",
    "\n",
    "all_times = []\n",
    "for data in task_info.values(): \n",
    "    all_times.append(data[\"acquire_lock_start\"])\n",
    "    all_times.append(data[\"acquire_lock_end\"])\n",
    "    all_times.append(data[\"get_arguments_start\"])\n",
    "    all_times.append(data[\"get_arguments_end\"])\n",
    "    all_times.append(data[\"execute_start\"])\n",
    "    all_times.append(data[\"execute_end\"])\n",
    "    all_times.append(data[\"store_outputs_start\"])\n",
    "    all_times.append(data[\"store_outputs_end\"])\n",
    "\n",
    "min_time = min(all_times)\n",
    "for data in task_info.values(): \n",
    "    data[\"acquire_lock_start\"] = data[\"acquire_lock_start\"] - min_time \n",
    "    data[\"acquire_lock_end\"] = data[\"acquire_lock_end\"] - min_time\n",
    "    data[\"execute_start\"] = data[\"execute_start\"] - min_time  \n",
    "    data[\"execute_end\"] = data[\"execute_end\"] - min_time  \n",
    "    data[\"get_arguments_start\"] = data[\"get_arguments_start\"] - min_time  \n",
    "    data[\"get_arguments_end\"] = data[\"get_arguments_end\"] - min_time  \n",
    "    data[\"store_outputs_start\"] = data[\"store_outputs_start\"] - min_time  \n",
    "    data[\"store_outputs_end\"] = data[\"store_outputs_end\"] - min_time  \n",
    "\n",
    "object_dict = {oid.hex(): v for oid, v in ray.global_state.object_table().items()}\n",
    "for oid, data in object_dict.items(): \n",
    "    tid = data[\"TaskID\"]\n",
    "    if tid in task_info: \n",
    "        task_info[tid][\"object_id\"] = oid \n",
    "        \n",
    "output_notebook()\n",
    "source = ColumnDataSource(data=dict(\n",
    "                                    x=[],\n",
    "                                    y=[],\n",
    "                                    worker_id=[],\n",
    "                                    task_id=[],\n",
    "                                    function_name=[],\n",
    "                                    get_arguments_start=[],\n",
    "                                    get_arguments_end=[],\n",
    "                                    acquire_lock_start=[],\n",
    "                                    acquire_lock_end=[],\n",
    "                                    execute_start=[],\n",
    "                                    execute_end=[],\n",
    "                                    store_outputs_start=[],\n",
    "                                    store_outputs_end=[],\n",
    "                                    wid=[],\n",
    "                                    oid=[]\n",
    "                                    ))\n",
    "axis_map = {\n",
    "    \"worker_id\": \"worker_id\",\n",
    "    \"time\": \"time\",\n",
    "}\n",
    " \n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"TaskID\", \"@task_id\"),\n",
    "    (\"Function Name\", \"@function_name\"),\n",
    "    (\"WorkerID\", \"@wid\"),\n",
    "    (\"ObjectID\", \"@oid\"),\n",
    "    (\"Variables\", \"@vars\")\n",
    "])\n",
    " \n",
    "x_axis = Select(title=\"Time in seconds\", options=sorted(axis_map.keys()), value=\"time\")\n",
    "y_axis = Select(title=\"WorkerID\", options=sorted(axis_map.keys()), value=\"worker_id\")\n",
    " \n",
    "p = figure(plot_height=600, plot_width=700, title=\"\", toolbar_location=\"below\", tools=[hover,\"pan\",\"wheel_zoom\",\"box_zoom\"], toolbar_sticky=False)\n",
    "p.hbar(y=\"y\", height=1, left=\"acquire_lock_start\", right=\"acquire_lock_end\", source=source, color=\"#FF8633\", legend=\"Acquire lock\")\n",
    "p.hbar(y=\"y\", height=1, left=\"get_arguments_start\", right=\"get_arguments_end\", source=source, color=\"#8033FF\", legend=\"Get arguments\")\n",
    "p.hbar(y=\"y\", height=1, left=\"execute_start\", right=\"execute_end\", source=source, color=\"#3390FF\", legend=\"Execute task\")\n",
    "p.hbar(y=\"y\", height=1, left=\"store_outputs_start\", right=\"store_outputs_end\", source=source, color=\"#33FF9C\", legend=\"Store outputs\")\n",
    " \n",
    "def select(lock_time, args_time, exec_time, outputs_time, worker_id_val, task_id_val, function_name_val):\n",
    "    selected_tasks = dict()\n",
    "    for task_id, data in task_profs.items():\n",
    "        if ((data[\"acquire_lock_end\"]-data[\"acquire_lock_start\"]) > lock_time):\n",
    "            if ((data[\"get_arguments_end\"]-data[\"get_arguments_start\"]) > args_time):\n",
    "                if ((data[\"execute_end\"]-data[\"execute_start\"]) > exec_time):\n",
    "                    if ((data[\"store_outputs_end\"]-data[\"store_outputs_start\"]) > outputs_time):\n",
    "                        # these checks aren't actually right, whoops\n",
    "                        if task_id_val:\n",
    "                            if task_id_val in data[\"task_id\"]:\n",
    "                                selected_tasks[task_id] = data\n",
    "                        elif worker_id_val:\n",
    "                            if worker_id_val in data[\"worker_id\"]:\n",
    "                                selected_tasks[task_id] = data\n",
    "                        elif function_name_val:\n",
    "                            if function_name_val in data[\"function_name\"]:\n",
    "                                selected_tasks[task_id] = data \n",
    "                        else:\n",
    "                            selected_tasks[task_id] = data\n",
    "    return selected_tasks\n",
    "   \n",
    "def update(lock_time, args_time, exec_time, outputs_time, worker_id_val, task_id_val, function_name_val):\n",
    "    selected_tasks = select(lock_time, args_time, exec_time, outputs_time, worker_id_val, task_id_val, function_name_val)\n",
    "    print(\"update: selected {}\".format(len(selected_tasks)))\n",
    "    from collections import defaultdict\n",
    "    df = defaultdict(list)\n",
    "    for i, worker in selected_tasks.items():\n",
    "        df[\"x\"].append(worker[\"execute_start\"])\n",
    "        df[\"y\"].append(worker[\"worker_id\"])\n",
    "        df[\"worker_id\"].append(worker[\"worker_id\"])\n",
    "        df[\"task_id\"].append(i)\n",
    "        df[\"function_name\"].append(worker[\"function_name\"])\n",
    "        df[\"get_arguments_start\"].append(worker[\"get_arguments_start\"])\n",
    "        df[\"get_arguments_end\"].append(worker[\"get_arguments_end\"])\n",
    "        df[\"acquire_lock_start\"].append(worker[\"acquire_lock_start\"])\n",
    "        df['acquire_lock_end'].append(worker['acquire_lock_end'])\n",
    "        df['store_outputs_start'].append(worker['store_outputs_start'])\n",
    "        df['store_outputs_end'].append(worker['store_outputs_end'])\n",
    "        df['execute_start'].append(worker['execute_start'])\n",
    "        df['execute_end'].append(worker['execute_end'])\n",
    "        df['wid'].append(worker[\"wid\"])\n",
    "        df['oid'].append(worker[\"object_id\"])\n",
    " \n",
    "    x_name = axis_map[x_axis.value]\n",
    "    y_name = axis_map[y_axis.value]\n",
    "    p.xaxis.axis_label = \"Time in seconds\"\n",
    "    p.yaxis.axis_label = \"Worker ID\"\n",
    "    p.title.text = \"Task Information\"\n",
    "    source.data = dict(\n",
    "        x= df[\"x\"],\n",
    "        y= df[\"y\"],\n",
    "        worker_id=df[\"worker_id\"],\n",
    "        task_id=df[\"task_id\"],\n",
    "        function_name=df[\"function_name\"],\n",
    "        acquire_lock_start=df[\"acquire_lock_start\"],\n",
    "        acquire_lock_end=df[\"acquire_lock_start\"],\n",
    "        get_arguments_start=df[\"get_arguments_start\"],\n",
    "        get_arguments_end=df[\"get_arguments_end\"],\n",
    "        store_outputs_start=df[\"store_outputs_start\"],\n",
    "        store_outputs_end=df[\"store_outputs_start\"],\n",
    "        execute_start=df[\"execute_start\"],\n",
    "        execute_end=df[\"execute_end\"],\n",
    "        wid=df[\"wid\"],\n",
    "        oid=df[\"oid\"]\n",
    "    )\n",
    "    push_notebook()\n",
    "    \n",
    "show(p, notebook_handle=True)\n",
    "\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import FloatSlider, Text\n",
    "\n",
    "style = {\"description_width\": \"initial\"}\n",
    "lock_time = FloatSlider(value=0, min=0, max=10, step=.1, description=\"Time to acquire lock: \", style=style)\n",
    "args_time = FloatSlider(value=0, min=0, max=10, step=.1, description=\"Time to get arguments: \", style=style)\n",
    "exec_time = FloatSlider(value=0, min=0, max=10, step=.1, description=\"Time to execute task: \", style=style)\n",
    "outputs_time = FloatSlider(value=0, min=0, max=10, step=.1, description=\"Time to store outputs: \", style=style)\n",
    "worker_id_val = Text(value=\"\", description=\"Worker ID:\",disabled=False)\n",
    "task_id_val = Text(value=\"\", description=\"Task ID:\",disabled=False)\n",
    "function_name_val = Text(value=\"\", description=\"Function name:\",disabled=False)\n",
    "\n",
    "interact(update, lock_time=lock_time , args_time=args_time, exec_time=exec_time, outputs_time=outputs_time, \n",
    "         worker_id_val=worker_id_val, task_id_val=task_id_val, function_name_val=function_name_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook(resources=CDN)\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"TaskID\", \"@task_id\"),\n",
    "    (\"Function Name\", \"@function_name\"),\n",
    "    (\"ParentID\", \"@parent_id\"),\n",
    "])\n",
    "\n",
    "p1 = figure(title=\"Task Time Distribution (μ=0, σ=0.5)\",tools=[\"save\", \"hover\"],\n",
    "            background_fill_color=\"#C0C0C0\")\n",
    "\n",
    "mu, sigma = 0, 0.5\n",
    "\n",
    "task_profiles = ray.global_state.task_profiles()\n",
    "\n",
    "task_times = []\n",
    "for task_id, data in task_profiles.items(): \n",
    "    del data[\"worker_id\"]\n",
    "    del data[\"function_name\"]\n",
    "    time = max(data.values()) - min(data.values())\n",
    "    task_times.append(time)\n",
    "\n",
    "print(\"Task completion times:\")\n",
    "print(np.sort(task_times))\n",
    "        \n",
    "hist, edges = np.histogram(task_times, density=True, bins=50)\n",
    "\n",
    "x = np.linspace(-2, 2, 1000)\n",
    "pdf = 1/(sigma * np.sqrt(2*np.pi)) * np.exp(-(x-mu)**2 / (2*sigma**2))\n",
    "cdf = (1+scipy.special.erf((x-mu)/np.sqrt(2*sigma**2)))/2\n",
    "\n",
    "p1.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "        fill_color=\"#036564\", line_color=\"#033649\")\n",
    "p1.line(x, pdf, line_color=\"#AED19B\", line_width=8, alpha=0.7, legend=\"PDF\")\n",
    "p1.line(x, cdf, line_color=\"white\", line_width=2, alpha=0.7, legend=\"CDF\")\n",
    "\n",
    "p1.legend.location = \"top_right\"\n",
    "p1.legend.background_fill_color = \"darkgrey\"\n",
    "p1.xaxis.axis_label = 'Time in ms'\n",
    "p1.yaxis.axis_label = 'Pr(x)'\n",
    "\n",
    "show(gridplot(p1, ncols=2, plot_width=600, plot_height=600, toolbar_location=\"below\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Dependency Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook( resources=CDN )\n",
    "\n",
    "edges = []\n",
    "nodes = dict()\n",
    "\n",
    "DG = nx.DiGraph()\n",
    "\n",
    "task_info = ray.global_state.task_table()\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    task_id=[],\n",
    "    parent_id=[], \n",
    "    function_name=[],\n",
    "    errored=[]\n",
    "#     object_id=[],\n",
    "#     variables=[]\n",
    "))\n",
    "\n",
    "task_profiles = ray.global_state.task_profiles() \n",
    "\n",
    "for task_id, data in task_info.items(): \n",
    "    if task_id not in nodes:\n",
    "        nodes[task_id] = True \n",
    "        parent_id = data[\"TaskSpec\"][\"ParentTaskID\"]\n",
    "        DG.add_node(task_id, task_id = task_id, parent_id = parent_id)\n",
    "        edges.append((task_id, parent_id))\n",
    "        \n",
    "DG.add_edges_from(edges)\n",
    "from collections import defaultdict\n",
    "df = defaultdict(list)\n",
    "pts = nx.spectral_layout(DG, scale=5)\n",
    "# print(pts)\n",
    "# print(task_profiles)\n",
    "for task_id, indices in pts.items():\n",
    "    if task_id in task_info:\n",
    "        df[\"x\"].append(indices[0])\n",
    "        df[\"y\"].append(indices[1])\n",
    "        df[\"task_id\"].append(task_info[task_id][\"TaskSpec\"][\"TaskID\"])\n",
    "        if task_id in task_profiles: \n",
    "            df[\"function_name\"].append(task_profiles[task_id][\"function_name\"])\n",
    "        else: \n",
    "            df[\"function_name\"].append(\"None\")\n",
    "        if \"ParentTaskID\" in task_info[task_id][\"TaskSpec\"]: \n",
    "            df[\"parent_id\"].append(task_info[task_id][\"TaskSpec\"][\"ParentTaskID\"]) \n",
    "        else:\n",
    "            df[\"parent_id\"].append(\"None\")\n",
    "#         if task_id in error_profiles: \n",
    "#             df[\"errored\"].append(True)\n",
    "#         else: \n",
    "#             df[\"errored\"].append(False) \n",
    "\n",
    "source.data = dict(\n",
    "                x= df[\"x\"],\n",
    "                y= df[\"y\"],\n",
    "                parent_id=df[\"parent_id\"],\n",
    "                task_id=df[\"task_id\"],\n",
    "                function_name=df[\"function_name\"], \n",
    "#                 errored=df[\"errored\"]\n",
    "                )\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"TaskID\", \"@task_id\"),\n",
    "    (\"Function Name\", \"@function_name\"),\n",
    "    (\"ParentID\", \"@parent_id\"),\n",
    "#     (\"ObjectID\", \"@oid\"),\n",
    "#     (\"Variables\", \"@vars\")\n",
    "])\n",
    "\n",
    "p = figure(\n",
    "    x_range=(-5,5),\n",
    "    y_range=(-5,5),\n",
    "    height=700,\n",
    "    width=700,\n",
    "    tools=[hover,\"pan\",\"wheel_zoom\",\"box_zoom\"], \n",
    "    toolbar_sticky=False\n",
    ")\n",
    "\n",
    "p.xaxis.visible = False\n",
    "p.yaxis.visible = False\n",
    "\n",
    "p.line( \n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    source=source\n",
    ")\n",
    "\n",
    "p.circle( \n",
    "x=\"x\",\n",
    "y=\"y\",\n",
    "source=source,\n",
    "size=20)\n",
    "    \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor Information \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_info = ray.global_state.actor_classes() \n",
    "for actor_id, data in actor_info.items():\n",
    "    if \"class\" in data: \n",
    "        del data[\"class\"]\n",
    "actor_df = pd.DataFrame.from_dict(actor_info)\n",
    "df = actor_df.T\n",
    "df.index.name = \"ActorID\"\n",
    "qgrid.show_grid(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System State Information \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctable = ray.global_state.client_table()\n",
    "\n",
    "client_list = []\n",
    "for node_ip in ctable:\n",
    "    for client in ctable[node_ip]:\n",
    "        client[\"node_ip_address\"] = node_ip\n",
    "        client_list.append(client)\n",
    "\n",
    "client_df = pd.DataFrame(client_list)\n",
    "client_df.columns = [\"Aux Address\", \"Client Type\", \"DB Client ID\", \"Deleted\", \"Local Scheduler Socket\", \"Num CPUs\", \"NumGPUs\", \"Node IP Address\"]\n",
    "qgrid.show_grid(client_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worker_info = ray.global_state.workers() \n",
    "table = pd.DataFrame.from_dict(worker_info)\n",
    "table_t = table.T\n",
    "table_t.index.name = \"WorkerID\"\n",
    "table_t.columns = [\"Local Scheduler Socket\", \"Node IP Address\", \"Plasma Manager Socket\", \"Plasma Store Socket\", \"Stdout File\"]\n",
    "qgrid.show_grid(table_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Store Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_dict = {oid.hex(): v for oid, v in ray.global_state.object_table().items()}\n",
    "if len(object_dict) == 0: \n",
    "    object_dict[\"None\"] = {\"Data Size\":\"None\", \"Hash\":\"None\", \"IsPut\":\"None\", \"ManagerIDs\":\"None\", \"TaskID\":\"None\"}\n",
    "object_df = pd.DataFrame(object_dict).transpose()\n",
    "object_df.index.name = \"ObjectID\"\n",
    "object_df.columns = [\"Data Size\", \"Hash\", \"IsPut\", \"ManagerIDs\", \"TaskID\"]\n",
    "qgrid.show_grid(object_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO-DO: This needs to be fixed so that it uses an API call rather than queries Redis\n",
    "event_names = rc.keys(\"event_log*\")\n",
    "error_profiles = dict()\n",
    "for i in range(len(event_names)):\n",
    "    event_list = rc.lrange(event_names[i], 0, -1)\n",
    "    for event in event_list:\n",
    "        event_dict = json.loads(event)\n",
    "        task_id = \"\"\n",
    "        traceback = \"\"\n",
    "        worker_id = \"\"\n",
    "        start_time = -1\n",
    "    for element in event_dict:\n",
    "        if element[1] == \"ray:task:execute\" and element[2] == 1:\n",
    "            start_time = element[0]\n",
    "        if \"task_id\" in element[3] and \"worker_id\" in element[3]:\n",
    "            task_id = element[3][\"task_id\"]\n",
    "            worker_id = element[3][\"worker_id\"]\n",
    "        if \"traceback\" in element[3]:\n",
    "            traceback = element[3][\"traceback\"]\n",
    "        if task_id != \"\" and worker_id != \"\" and traceback != \"\":\n",
    "            if start_time != -1:\n",
    "                error_profiles[task_id] = dict()\n",
    "                error_profiles[task_id][\"worker_id\"] = worker_id\n",
    "                error_profiles[task_id][\"traceback\"] = traceback\n",
    "                error_profiles[task_id][\"start_time\"] = start_time\n",
    "table = pd.DataFrame.from_dict(error_profiles) \n",
    "qgrid.show_grid(table.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
