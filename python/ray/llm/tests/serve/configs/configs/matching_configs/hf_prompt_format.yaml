runtime_env:
  env_vars:
    HUGGING_FACE_HUB_TOKEN: hf_fake_token

model_loading_config:
  model_id: mistral-community/pixtral-12b
  model_source: "/home/ray/tests/rayllm/backend/server/configs/cached_model_processors/mistral-community--pixtral-12b"

llm_engine: vLLM

engine_kwargs:
  enable_chunked_prefill: true
  max_num_batched_tokens: 2048
  max_num_seqs: 1
  tokenizer_pool_extra_config:
    runtime_env:
      pip: null
  tokenizer_pool_size: 2
  trust_remote_code: true
  max_model_len: 131072

accelerator_type: A10G

lora_config: null

deployment_config:
  autoscaling_config:
    target_ongoing_requests: 32
  max_ongoing_requests: 1
