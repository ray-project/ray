deployment_config: {}
  # autoscaling_config:
  #   target_ongoing_requests: 16
  # max_ongoing_requests: 32

model_loading_config:
  model_id: meta-llama/Llama-3.2-11B-Vision-Instruct

# generation_config:
#   prompt_format:
#     system: "<|start_header_id|>system<|end_header_id|>\n\n{instruction}<|eot_id|>"
#     assistant: "<|start_header_id|>assistant<|end_header_id|>\n\n{instruction}<|eot_id|>"
#     trailing_assistant: "<|start_header_id|>assistant<|end_header_id|>\n\n"
#     user: "<|start_header_id|>user<|end_header_id|>\n\n<|image|>{instruction}<|eot_id|>"
#     system_in_user: false
#     bos: "<|begin_of_text|>"
#     default_system_message: ""
#     vision: true
#   stopping_sequences: [ ]
#   stopping_tokens: [ 128001, 128009 ]  # <|end_of_text|>, <|eot_id|>

# llm_engine: VLLMEngine

engine_kwargs:
  # trust_remote_code: true
  # tokenizer_pool_size: 2
  # tokenizer_pool_extra_config:
  #   runtime_env:
  #     pip: null
  # enforce_eager: true
  tensor_parallel_size: 1

accelerator_type: L40S

lora_config: null
