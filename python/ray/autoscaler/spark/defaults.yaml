# Example command to start a cluster with this config:
#
# ray start --autoscaling-config=default.yaml --head --block
#
cluster_name: spark
max_workers: 8
provider:
    type: spark
    # This must be true since the nodes share the same ip!
    use_node_id_as_ip: True
    disable_node_updaters: True
    disable_launch_config_check: True
available_node_types:
    ray.head.default:
        # You must set this manually to your "head" node resources!! The head
        # node is launched via `ray start` and hence the autoscaler cannot
        # configure its resources. The resources specified for its node type
        # must line up with what Ray detects/is configured with on start.
        resources:
            CPU: 8   # <-- set this to num CPUs used/detected in `ray start`
            GPU: 0   # <-- set this to num GPUs used/detected in `ray start`
        node_config: {}
        max_workers: 0
    ray.worker:
        resources:
            CPU: 1
            object_store_memory: 1000000000
        node_config: {}
        min_workers: 0
        max_workers: 4
head_node_type: ray.head.default
upscaling_speed: 1.0
idle_timeout_minutes: 1.0
#
# !!! Configurations below are not supported in spark cluster mode
#
auth: {}
docker: {}
initialization_commands: []
setup_commands: []
head_setup_commands: []
worker_setup_commands: []
head_start_ray_commands: []
worker_start_ray_commands: []
file_mounts: {}
cluster_synced_files: []
file_mounts_sync_continuously: false
rsync_exclude: []
rsync_filter: []
