# Example command to start a cluster with this config:
#
# RAY_FAKE_CLUSTER=1 ray start --autoscaling-config=example.yaml --head --block
#
# Alternatively, you can programmatically create a fake autoscaling cluster
# using ray.cluster_utils.AutoscalingCluster.
cluster_name: fake_multinode
max_workers: 8
provider:
    type: fake_multinode
    # This must be true since the nodes share the same ip!
    use_node_id_as_ip: True
    disable_node_updaters: True
    disable_launch_config_check: True
available_node_types:
    ray.head.default:
        # You must set this manually to your "head" node resources!! The head
        # node is launched via `ray start` and hence the autoscaler cannot
        # configure its resources. The resources specified for its node type
        # must line up with what Ray detects/is configured with on start.
        resources:
            CPU: 8   # <-- set this to num CPUs used/detected in `ray start`
            GPU: 0   # <-- set this to num GPUs used/detected in `ray start`
        node_config: {}
        max_workers: 0
    ray.worker.cpu:
        resources:
            CPU: 1
            object_store_memory: 1000000000
        node_config: {}
        min_workers: 0
        max_workers: 4
    ray.worker.gpu:
        resources:
            CPU: 4
            GPU: 1
            object_store_memory: 1000000000
        node_config: {}
        min_workers: 0
        max_workers: 2
head_node_type: ray.head.default
upscaling_speed: 1.0
idle_timeout_minutes: 0.1
#
# !!! Configurations below are not supported in fake cluster mode !!!
#
auth: {}
docker: {}
initialization_commands: []
setup_commands: []
head_setup_commands: []
worker_setup_commands: []
head_start_ray_commands: []
worker_start_ray_commands: []
file_mounts: {}
cluster_synced_files: []
file_mounts_sync_continuously: false
rsync_exclude: []
rsync_filter: []
