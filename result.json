{"traceEvents": [{"ph": "M", "pid": 29626, "tid": 29626, "name": "process_name", "args": {"name": "MainProcess"}}, {"ph": "M", "pid": 29626, "tid": 3127766, "name": "thread_name", "args": {"name": "MainThread"}}, {"pid": 29626, "tid": 3127766, "ts": 865886862748.0, "ph": "X", "cat": "fee", "dur": 2.0, "name": "<module> (/Users/sangcho/work/ray/result.json:1)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862747.0, "ph": "X", "cat": "fee", "dur": 5.0, "name": "builtins.exec"}, {"pid": 29626, "tid": 3127766, "ts": 865886862754.02, "ph": "X", "cat": "fee", "dur": 0.02, "name": "info (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:52)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862754.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "debug (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:48)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862755.04, "ph": "X", "cat": "fee", "dur": 0.96, "name": "<lambda> (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:284)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862755.02, "ph": "X", "cat": "fee", "dur": 1.0, "name": "<listcomp> (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:291)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862756.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.sort"}, {"pid": 29626, "tid": 3127766, "ts": 865886862755.0, "ph": "X", "cat": "fee", "dur": 1.08, "name": "_run_finalizers (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:268)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862757.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "current_process (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:37)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862757.06, "ph": "X", "cat": "fee", "dur": 0.94, "name": "_cleanup (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:61)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862757.04, "ph": "X", "cat": "fee", "dur": 0.98, "name": "active_children (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:43)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862758.06, "ph": "X", "cat": "fee", "dur": 0.02, "name": "_cleanup (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:61)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862758.04, "ph": "X", "cat": "fee", "dur": 0.06, "name": "active_children (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:43)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862759.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "debug (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:48)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862759.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "<lambda> (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:282)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862759.06, "ph": "X", "cat": "fee", "dur": 0.06, "name": "<listcomp> (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:291)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862760.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.sort"}, {"pid": 29626, "tid": 3127766, "ts": 865886862760.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "dict.get"}, {"pid": 29626, "tid": 3127766, "ts": 865886862760.08, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sub_debug (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:44)"}, {"pid": 29626, "tid": 3127766, "ts": 865886862761.0, "ph": "X", "cat": "fee", "dur": 0.02, "name": "posix.getpid"}, {"pid": 29626, "tid": 3127766, "ts": 865886862761.04, "ph": "X", "cat": "fee", "dur": 0.02, "name": "sub_debug (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:44)"}], "viztracer_metadata": {"overflow": false, "version": "0.16.0"}, "file_info": {"files": {"/Users/sangcho/work/ray/result.json": ["", 0], "/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py": ["#\n# Module providing various facilities to other parts of the package\n#\n# multiprocessing/util.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\nimport os\nimport itertools\nimport sys\nimport weakref\nimport atexit\nimport threading        # we want threading to install it's\n                        # cleanup function before multiprocessing does\nfrom subprocess import _args_from_interpreter_flags\n\nfrom . import process\n\n__all__ = [\n    'sub_debug', 'debug', 'info', 'sub_warning', 'get_logger',\n    'log_to_stderr', 'get_temp_dir', 'register_after_fork',\n    'is_exiting', 'Finalize', 'ForkAwareThreadLock', 'ForkAwareLocal',\n    'close_all_fds_except', 'SUBDEBUG', 'SUBWARNING',\n    ]\n\n#\n# Logging\n#\n\nNOTSET = 0\nSUBDEBUG = 5\nDEBUG = 10\nINFO = 20\nSUBWARNING = 25\n\nLOGGER_NAME = 'multiprocessing'\nDEFAULT_LOGGING_FORMAT = '[%(levelname)s/%(processName)s] %(message)s'\n\n_logger = None\n_log_to_stderr = False\n\ndef sub_debug(msg, *args):\n    if _logger:\n        _logger.log(SUBDEBUG, msg, *args)\n\ndef debug(msg, *args):\n    if _logger:\n        _logger.log(DEBUG, msg, *args)\n\ndef info(msg, *args):\n    if _logger:\n        _logger.log(INFO, msg, *args)\n\ndef sub_warning(msg, *args):\n    if _logger:\n        _logger.log(SUBWARNING, msg, *args)\n\ndef get_logger():\n    '''\n    Returns logger used by multiprocessing\n    '''\n    global _logger\n    import logging\n\n    logging._acquireLock()\n    try:\n        if not _logger:\n\n            _logger = logging.getLogger(LOGGER_NAME)\n            _logger.propagate = 0\n\n            # XXX multiprocessing should cleanup before logging\n            if hasattr(atexit, 'unregister'):\n                atexit.unregister(_exit_function)\n                atexit.register(_exit_function)\n            else:\n                atexit._exithandlers.remove((_exit_function, (), {}))\n                atexit._exithandlers.append((_exit_function, (), {}))\n\n    finally:\n        logging._releaseLock()\n\n    return _logger\n\ndef log_to_stderr(level=None):\n    '''\n    Turn on logging and add a handler which prints to stderr\n    '''\n    global _log_to_stderr\n    import logging\n\n    logger = get_logger()\n    formatter = logging.Formatter(DEFAULT_LOGGING_FORMAT)\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n    if level:\n        logger.setLevel(level)\n    _log_to_stderr = True\n    return _logger\n\n\n# Abstract socket support\n\ndef _platform_supports_abstract_sockets():\n    if sys.platform == \"linux\":\n        return True\n    if hasattr(sys, 'getandroidapilevel'):\n        return True\n    return False\n\n\ndef is_abstract_socket_namespace(address):\n    if not address:\n        return False\n    if isinstance(address, bytes):\n        return address[0] == 0\n    elif isinstance(address, str):\n        return address[0] == \"\\0\"\n    raise TypeError(f'address type of {address!r} unrecognized')\n\n\nabstract_sockets_supported = _platform_supports_abstract_sockets()\n\n#\n# Function returning a temp directory which will be removed on exit\n#\n\ndef _remove_temp_dir(rmtree, tempdir):\n    rmtree(tempdir)\n\n    current_process = process.current_process()\n    # current_process() can be None if the finalizer is called\n    # late during Python finalization\n    if current_process is not None:\n        current_process._config['tempdir'] = None\n\ndef get_temp_dir():\n    # get name of a temp directory which will be automatically cleaned up\n    tempdir = process.current_process()._config.get('tempdir')\n    if tempdir is None:\n        import shutil, tempfile\n        tempdir = tempfile.mkdtemp(prefix='pymp-')\n        info('created temp directory %s', tempdir)\n        # keep a strong reference to shutil.rmtree(), since the finalizer\n        # can be called late during Python shutdown\n        Finalize(None, _remove_temp_dir, args=(shutil.rmtree, tempdir),\n                 exitpriority=-100)\n        process.current_process()._config['tempdir'] = tempdir\n    return tempdir\n\n#\n# Support for reinitialization of objects when bootstrapping a child process\n#\n\n_afterfork_registry = weakref.WeakValueDictionary()\n_afterfork_counter = itertools.count()\n\ndef _run_after_forkers():\n    items = list(_afterfork_registry.items())\n    items.sort()\n    for (index, ident, func), obj in items:\n        try:\n            func(obj)\n        except Exception as e:\n            info('after forker raised exception %s', e)\n\ndef register_after_fork(obj, func):\n    _afterfork_registry[(next(_afterfork_counter), id(obj), func)] = obj\n\n#\n# Finalization using weakrefs\n#\n\n_finalizer_registry = {}\n_finalizer_counter = itertools.count()\n\n\nclass Finalize(object):\n    '''\n    Class which supports object finalization using weakrefs\n    '''\n    def __init__(self, obj, callback, args=(), kwargs=None, exitpriority=None):\n        if (exitpriority is not None) and not isinstance(exitpriority,int):\n            raise TypeError(\n                \"Exitpriority ({0!r}) must be None or int, not {1!s}\".format(\n                    exitpriority, type(exitpriority)))\n\n        if obj is not None:\n            self._weakref = weakref.ref(obj, self)\n        elif exitpriority is None:\n            raise ValueError(\"Without object, exitpriority cannot be None\")\n\n        self._callback = callback\n        self._args = args\n        self._kwargs = kwargs or {}\n        self._key = (exitpriority, next(_finalizer_counter))\n        self._pid = os.getpid()\n\n        _finalizer_registry[self._key] = self\n\n    def __call__(self, wr=None,\n                 # Need to bind these locally because the globals can have\n                 # been cleared at shutdown\n                 _finalizer_registry=_finalizer_registry,\n                 sub_debug=sub_debug, getpid=os.getpid):\n        '''\n        Run the callback unless it has already been called or cancelled\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            sub_debug('finalizer no longer registered')\n        else:\n            if self._pid != getpid():\n                sub_debug('finalizer ignored because different process')\n                res = None\n            else:\n                sub_debug('finalizer calling %s with args %s and kwargs %s',\n                          self._callback, self._args, self._kwargs)\n                res = self._callback(*self._args, **self._kwargs)\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None\n            return res\n\n    def cancel(self):\n        '''\n        Cancel finalization of the object\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            pass\n        else:\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None\n\n    def still_active(self):\n        '''\n        Return whether this finalizer is still waiting to invoke callback\n        '''\n        return self._key in _finalizer_registry\n\n    def __repr__(self):\n        try:\n            obj = self._weakref()\n        except (AttributeError, TypeError):\n            obj = None\n\n        if obj is None:\n            return '<%s object, dead>' % self.__class__.__name__\n\n        x = '<%s object, callback=%s' % (\n                self.__class__.__name__,\n                getattr(self._callback, '__name__', self._callback))\n        if self._args:\n            x += ', args=' + str(self._args)\n        if self._kwargs:\n            x += ', kwargs=' + str(self._kwargs)\n        if self._key[0] is not None:\n            x += ', exitpriority=' + str(self._key[0])\n        return x + '>'\n\n\ndef _run_finalizers(minpriority=None):\n    '''\n    Run all finalizers whose exit priority is not None and at least minpriority\n\n    Finalizers with highest priority are called first; finalizers with\n    the same priority will be called in reverse order of creation.\n    '''\n    if _finalizer_registry is None:\n        # This function may be called after this module's globals are\n        # destroyed.  See the _exit_function function in this module for more\n        # notes.\n        return\n\n    if minpriority is None:\n        f = lambda p : p[0] is not None\n    else:\n        f = lambda p : p[0] is not None and p[0] >= minpriority\n\n    # Careful: _finalizer_registry may be mutated while this function\n    # is running (either by a GC run or by another thread).\n\n    # list(_finalizer_registry) should be atomic, while\n    # list(_finalizer_registry.items()) is not.\n    keys = [key for key in list(_finalizer_registry) if f(key)]\n    keys.sort(reverse=True)\n\n    for key in keys:\n        finalizer = _finalizer_registry.get(key)\n        # key may have been removed from the registry\n        if finalizer is not None:\n            sub_debug('calling %s', finalizer)\n            try:\n                finalizer()\n            except Exception:\n                import traceback\n                traceback.print_exc()\n\n    if minpriority is None:\n        _finalizer_registry.clear()\n\n#\n# Clean up on exit\n#\n\ndef is_exiting():\n    '''\n    Returns true if the process is shutting down\n    '''\n    return _exiting or _exiting is None\n\n_exiting = False\n\ndef _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\n                   active_children=process.active_children,\n                   current_process=process.current_process):\n    # We hold on to references to functions in the arglist due to the\n    # situation described below, where this function is called after this\n    # module's globals are destroyed.\n\n    global _exiting\n\n    if not _exiting:\n        _exiting = True\n\n        info('process shutting down')\n        debug('running all \"atexit\" finalizers with priority >= 0')\n        _run_finalizers(0)\n\n        if current_process() is not None:\n            # We check if the current process is None here because if\n            # it's None, any call to ``active_children()`` will raise\n            # an AttributeError (active_children winds up trying to\n            # get attributes from util._current_process).  One\n            # situation where this can happen is if someone has\n            # manipulated sys.modules, causing this module to be\n            # garbage collected.  The destructor for the module type\n            # then replaces all values in the module dict with None.\n            # For instance, after setuptools runs a test it replaces\n            # sys.modules with a copy created earlier.  See issues\n            # #9775 and #15881.  Also related: #4106, #9205, and\n            # #9207.\n\n            for p in active_children():\n                if p.daemon:\n                    info('calling terminate() for daemon %s', p.name)\n                    p._popen.terminate()\n\n            for p in active_children():\n                info('calling join() for process %s', p.name)\n                p.join()\n\n        debug('running the remaining \"atexit\" finalizers')\n        _run_finalizers()\n\natexit.register(_exit_function)\n\n#\n# Some fork aware types\n#\n\nclass ForkAwareThreadLock(object):\n    def __init__(self):\n        self._lock = threading.Lock()\n        self.acquire = self._lock.acquire\n        self.release = self._lock.release\n        register_after_fork(self, ForkAwareThreadLock._at_fork_reinit)\n\n    def _at_fork_reinit(self):\n        self._lock._at_fork_reinit()\n\n    def __enter__(self):\n        return self._lock.__enter__()\n\n    def __exit__(self, *args):\n        return self._lock.__exit__(*args)\n\n\nclass ForkAwareLocal(threading.local):\n    def __init__(self):\n        register_after_fork(self, lambda obj : obj.__dict__.clear())\n    def __reduce__(self):\n        return type(self), ()\n\n#\n# Close fds except those specified\n#\n\ntry:\n    MAXFD = os.sysconf(\"SC_OPEN_MAX\")\nexcept Exception:\n    MAXFD = 256\n\ndef close_all_fds_except(fds):\n    fds = list(fds) + [-1, MAXFD]\n    fds.sort()\n    assert fds[-1] == MAXFD, 'fd too large'\n    for i in range(len(fds) - 1):\n        os.closerange(fds[i]+1, fds[i+1])\n#\n# Close sys.stdin and replace stdin with os.devnull\n#\n\ndef _close_stdin():\n    if sys.stdin is None:\n        return\n\n    try:\n        sys.stdin.close()\n    except (OSError, ValueError):\n        pass\n\n    try:\n        fd = os.open(os.devnull, os.O_RDONLY)\n        try:\n            sys.stdin = open(fd, closefd=False)\n        except:\n            os.close(fd)\n            raise\n    except (OSError, ValueError):\n        pass\n\n#\n# Flush standard streams, if any\n#\n\ndef _flush_std_streams():\n    try:\n        sys.stdout.flush()\n    except (AttributeError, ValueError):\n        pass\n    try:\n        sys.stderr.flush()\n    except (AttributeError, ValueError):\n        pass\n\n#\n# Start a program with only specified fds kept open\n#\n\ndef spawnv_passfds(path, args, passfds):\n    import _posixsubprocess\n    passfds = tuple(sorted(map(int, passfds)))\n    errpipe_read, errpipe_write = os.pipe()\n    try:\n        return _posixsubprocess.fork_exec(\n            args, [os.fsencode(path)], True, passfds, None, None,\n            -1, -1, -1, -1, -1, -1, errpipe_read, errpipe_write,\n            False, False, None, None, None, -1, None)\n    finally:\n        os.close(errpipe_read)\n        os.close(errpipe_write)\n\n\ndef close_fds(*fds):\n    \"\"\"Close each file descriptor given as an argument\"\"\"\n    for fd in fds:\n        os.close(fd)\n\n\ndef _cleanup_tests():\n    \"\"\"Cleanup multiprocessing resources when multiprocessing tests\n    completed.\"\"\"\n\n    from test import support\n\n    # cleanup multiprocessing\n    process._cleanup()\n\n    # Stop the ForkServer process if it's running\n    from multiprocessing import forkserver\n    forkserver._forkserver._stop()\n\n    # Stop the ResourceTracker process if it's running\n    from multiprocessing import resource_tracker\n    resource_tracker._resource_tracker._stop()\n\n    # bpo-37421: Explicitly call _run_finalizers() to remove immediately\n    # temporary directories created by multiprocessing.util.get_temp_dir().\n    _run_finalizers()\n    support.gc_collect()\n\n    support.reap_children()\n", 489], "/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py": ["#\n# Module providing the `Process` class which emulates `threading.Thread`\n#\n# multiprocessing/process.py\n#\n# Copyright (c) 2006-2008, R Oudkerk\n# Licensed to PSF under a Contributor Agreement.\n#\n\n__all__ = ['BaseProcess', 'current_process', 'active_children',\n           'parent_process']\n\n#\n# Imports\n#\n\nimport os\nimport sys\nimport signal\nimport itertools\nimport threading\nfrom _weakrefset import WeakSet\n\n#\n#\n#\n\ntry:\n    ORIGINAL_DIR = os.path.abspath(os.getcwd())\nexcept OSError:\n    ORIGINAL_DIR = None\n\n#\n# Public functions\n#\n\ndef current_process():\n    '''\n    Return process object representing the current process\n    '''\n    return _current_process\n\ndef active_children():\n    '''\n    Return list of process objects corresponding to live child processes\n    '''\n    _cleanup()\n    return list(_children)\n\n\ndef parent_process():\n    '''\n    Return process object representing the parent process\n    '''\n    return _parent_process\n\n#\n#\n#\n\ndef _cleanup():\n    # check for processes which have finished\n    for p in list(_children):\n        if p._popen.poll() is not None:\n            _children.discard(p)\n\n#\n# The `Process` class\n#\n\nclass BaseProcess(object):\n    '''\n    Process objects represent activity that is run in a separate process\n\n    The class is analogous to `threading.Thread`\n    '''\n    def _Popen(self):\n        raise NotImplementedError\n\n    def __init__(self, group=None, target=None, name=None, args=(), kwargs={},\n                 *, daemon=None):\n        assert group is None, 'group argument must be None for now'\n        count = next(_process_counter)\n        self._identity = _current_process._identity + (count,)\n        self._config = _current_process._config.copy()\n        self._parent_pid = os.getpid()\n        self._parent_name = _current_process.name\n        self._popen = None\n        self._closed = False\n        self._target = target\n        self._args = tuple(args)\n        self._kwargs = dict(kwargs)\n        self._name = name or type(self).__name__ + '-' + \\\n                     ':'.join(str(i) for i in self._identity)\n        if daemon is not None:\n            self.daemon = daemon\n        _dangling.add(self)\n\n    def _check_closed(self):\n        if self._closed:\n            raise ValueError(\"process object is closed\")\n\n    def run(self):\n        '''\n        Method to be run in sub-process; can be overridden in sub-class\n        '''\n        if self._target:\n            self._target(*self._args, **self._kwargs)\n\n    def start(self):\n        '''\n        Start child process\n        '''\n        self._check_closed()\n        assert self._popen is None, 'cannot start a process twice'\n        assert self._parent_pid == os.getpid(), \\\n               'can only start a process object created by current process'\n        assert not _current_process._config.get('daemon'), \\\n               'daemonic processes are not allowed to have children'\n        _cleanup()\n        self._popen = self._Popen(self)\n        self._sentinel = self._popen.sentinel\n        # Avoid a refcycle if the target function holds an indirect\n        # reference to the process object (see bpo-30775)\n        del self._target, self._args, self._kwargs\n        _children.add(self)\n\n    def terminate(self):\n        '''\n        Terminate process; sends SIGTERM signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.terminate()\n\n    def kill(self):\n        '''\n        Terminate process; sends SIGKILL signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.kill()\n\n    def join(self, timeout=None):\n        '''\n        Wait until child process terminates\n        '''\n        self._check_closed()\n        assert self._parent_pid == os.getpid(), 'can only join a child process'\n        assert self._popen is not None, 'can only join a started process'\n        res = self._popen.wait(timeout)\n        if res is not None:\n            _children.discard(self)\n\n    def is_alive(self):\n        '''\n        Return whether process is alive\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return True\n        assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n        if self._popen is None:\n            return False\n\n        returncode = self._popen.poll()\n        if returncode is None:\n            return True\n        else:\n            _children.discard(self)\n            return False\n\n    def close(self):\n        '''\n        Close the Process object.\n\n        This method releases resources held by the Process object.  It is\n        an error to call this method if the child process is still running.\n        '''\n        if self._popen is not None:\n            if self._popen.poll() is None:\n                raise ValueError(\"Cannot close a process while it is still running. \"\n                                 \"You should first call join() or terminate().\")\n            self._popen.close()\n            self._popen = None\n            del self._sentinel\n            _children.discard(self)\n        self._closed = True\n\n    @property\n    def name(self):\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        assert isinstance(name, str), 'name must be a string'\n        self._name = name\n\n    @property\n    def daemon(self):\n        '''\n        Return whether process is a daemon\n        '''\n        return self._config.get('daemon', False)\n\n    @daemon.setter\n    def daemon(self, daemonic):\n        '''\n        Set whether process is a daemon\n        '''\n        assert self._popen is None, 'process has already started'\n        self._config['daemon'] = daemonic\n\n    @property\n    def authkey(self):\n        return self._config['authkey']\n\n    @authkey.setter\n    def authkey(self, authkey):\n        '''\n        Set authorization key of process\n        '''\n        self._config['authkey'] = AuthenticationString(authkey)\n\n    @property\n    def exitcode(self):\n        '''\n        Return exit code of process or `None` if it has yet to stop\n        '''\n        self._check_closed()\n        if self._popen is None:\n            return self._popen\n        return self._popen.poll()\n\n    @property\n    def ident(self):\n        '''\n        Return identifier (PID) of process or `None` if it has yet to start\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return os.getpid()\n        else:\n            return self._popen and self._popen.pid\n\n    pid = ident\n\n    @property\n    def sentinel(self):\n        '''\n        Return a file descriptor (Unix) or handle (Windows) suitable for\n        waiting for process termination.\n        '''\n        self._check_closed()\n        try:\n            return self._sentinel\n        except AttributeError:\n            raise ValueError(\"process not started\") from None\n\n    def __repr__(self):\n        exitcode = None\n        if self is _current_process:\n            status = 'started'\n        elif self._closed:\n            status = 'closed'\n        elif self._parent_pid != os.getpid():\n            status = 'unknown'\n        elif self._popen is None:\n            status = 'initial'\n        else:\n            exitcode = self._popen.poll()\n            if exitcode is not None:\n                status = 'stopped'\n            else:\n                status = 'started'\n\n        info = [type(self).__name__, 'name=%r' % self._name]\n        if self._popen is not None:\n            info.append('pid=%s' % self._popen.pid)\n        info.append('parent=%s' % self._parent_pid)\n        info.append(status)\n        if exitcode is not None:\n            exitcode = _exitcode_to_name.get(exitcode, exitcode)\n            info.append('exitcode=%s' % exitcode)\n        if self.daemon:\n            info.append('daemon')\n        return '<%s>' % ' '.join(info)\n\n    ##\n\n    def _bootstrap(self, parent_sentinel=None):\n        from . import util, context\n        global _current_process, _parent_process, _process_counter, _children\n\n        try:\n            if self._start_method is not None:\n                context._force_start_method(self._start_method)\n            _process_counter = itertools.count(1)\n            _children = set()\n            util._close_stdin()\n            old_process = _current_process\n            _current_process = self\n            _parent_process = _ParentProcess(\n                self._parent_name, self._parent_pid, parent_sentinel)\n            if threading._HAVE_THREAD_NATIVE_ID:\n                threading.main_thread()._set_native_id()\n            try:\n                util._finalizer_registry.clear()\n                util._run_after_forkers()\n            finally:\n                # delay finalization of the old process object until after\n                # _run_after_forkers() is executed\n                del old_process\n            util.info('child process calling self.run()')\n            try:\n                self.run()\n                exitcode = 0\n            finally:\n                util._exit_function()\n        except SystemExit as e:\n            if e.code is None:\n                exitcode = 0\n            elif isinstance(e.code, int):\n                exitcode = e.code\n            else:\n                sys.stderr.write(str(e.code) + '\\n')\n                exitcode = 1\n        except:\n            exitcode = 1\n            import traceback\n            sys.stderr.write('Process %s:\\n' % self.name)\n            traceback.print_exc()\n        finally:\n            threading._shutdown()\n            util.info('process exiting with exitcode %d' % exitcode)\n            util._flush_std_streams()\n\n        return exitcode\n\n#\n# We subclass bytes to avoid accidental transmission of auth keys over network\n#\n\nclass AuthenticationString(bytes):\n    def __reduce__(self):\n        from .context import get_spawning_popen\n        if get_spawning_popen() is None:\n            raise TypeError(\n                'Pickling an AuthenticationString object is '\n                'disallowed for security reasons'\n                )\n        return AuthenticationString, (bytes(self),)\n\n\n#\n# Create object representing the parent process\n#\n\nclass _ParentProcess(BaseProcess):\n\n    def __init__(self, name, pid, sentinel):\n        self._identity = ()\n        self._name = name\n        self._pid = pid\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._sentinel = sentinel\n        self._config = {}\n\n    def is_alive(self):\n        from multiprocessing.connection import wait\n        return not wait([self._sentinel], timeout=0)\n\n    @property\n    def ident(self):\n        return self._pid\n\n    def join(self, timeout=None):\n        '''\n        Wait until parent process terminates\n        '''\n        from multiprocessing.connection import wait\n        wait([self._sentinel], timeout=timeout)\n\n    pid = ident\n\n#\n# Create object representing the main process\n#\n\nclass _MainProcess(BaseProcess):\n\n    def __init__(self):\n        self._identity = ()\n        self._name = 'MainProcess'\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._config = {'authkey': AuthenticationString(os.urandom(32)),\n                        'semprefix': '/mp'}\n        # Note that some versions of FreeBSD only allow named\n        # semaphores to have names of up to 14 characters.  Therefore\n        # we choose a short prefix.\n        #\n        # On MacOSX in a sandbox it may be necessary to use a\n        # different prefix -- see #19478.\n        #\n        # Everything in self._config will be inherited by descendant\n        # processes.\n\n    def close(self):\n        pass\n\n\n_parent_process = None\n_current_process = _MainProcess()\n_process_counter = itertools.count(1)\n_children = set()\ndel _MainProcess\n\n#\n# Give names to some return codes\n#\n\n_exitcode_to_name = {}\n\nfor name, signum in list(signal.__dict__.items()):\n    if name[:3]=='SIG' and '_' not in name:\n        _exitcode_to_name[-signum] = f'-{name}'\n\n# For debug and leak testing\n_dangling = WeakSet()\n", 432]}, "functions": {"<module> (/Users/sangcho/work/ray/result.json:1)": ["/Users/sangcho/work/ray/result.json", 1], "info (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:52)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py", 52], "debug (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:48)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py", 48], "<lambda> (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:284)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py", 284], "<listcomp> (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:291)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py", 291], "_run_finalizers (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:268)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py", 268], "current_process (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:37)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py", 37], "_cleanup (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:61)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py", 61], "active_children (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py:43)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/process.py", 43], "<lambda> (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:282)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py", 282], "sub_debug (/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py:44)": ["/Users/sangcho/anaconda3/envs/core/lib/python3.9/multiprocessing/util.py", 44]}}}