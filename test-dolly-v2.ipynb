{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RAY_ML_DEV\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading builder script: 100%|██████████| 3.73k/3.73k [00:00<00:00, 3.91MB/s]\n",
      "Downloading metadata: 100%|██████████| 1.90k/1.90k [00:00<00:00, 1.86MB/s]\n",
      "Downloading readme: 100%|██████████| 6.10k/6.10k [00:00<00:00, 5.38MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset tiny_shakespeare/default to /home/ray/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 1.12MB [00:00, 17.4MB/s]                  \n",
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tiny_shakespeare downloaded and prepared to /home/ray/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1025.42it/s]\n",
      "2023-04-30 17:56:59,527\tINFO worker.py:1432 -- Connecting to existing Ray cluster at address: 10.0.17.186:6379...\n",
      "2023-04-30 17:56:59,537\tINFO worker.py:1607 -- Connected to Ray cluster. View the dashboard at https://console.anyscale-staging.com/api/v2/sessions/ses_m411tiqu8eluvt1k5ivfqj4q5r/services?redirect_to=dashboard \n",
      "2023-04-30 17:57:00,132\tINFO packaging.py:520 -- Creating a file package for local directory '/tmp/ray_tmp_module/ray'.\n",
      "2023-04-30 17:57:00,260\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/jars/ray_dist.jar is very large (30.48MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/jars/ray_dist.jar']})`\n",
      "2023-04-30 17:57:00,316\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/_raylet.so is very large (25.37MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/_raylet.so']})`\n",
      "2023-04-30 17:57:00,362\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/core/src/ray/gcs/gcs_server is very large (21.24MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/core/src/ray/gcs/gcs_server']})`\n",
      "2023-04-30 17:57:00,400\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/core/src/ray/raylet/raylet is very large (20.56MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/core/src/ray/raylet/raylet']})`\n",
      "2023-04-30 17:57:01,032\tINFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_8bfad0fcb1030606.zip' (155.25MiB) to Ray cluster...\n",
      "2023-04-30 17:57:01,573\tINFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_8bfad0fcb1030606.zip'.\n",
      "2023-04-30 17:57:02,081\tINFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_e31442e26ed4f60c0dfec60af8ffa7f7.zip' (165.64MiB) to Ray cluster...\n",
      "2023-04-30 17:57:02,675\tINFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_e31442e26ed4f60c0dfec60af8ffa7f7.zip'.\n",
      "2023-04-30 17:57:07,800\tINFO streaming_executor.py:87 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "2023-04-30 17:57:07,801\tINFO streaming_executor.py:88 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-04-30 17:57:07,802\tINFO streaming_executor.py:90 -- Tip: To enable per-operator progress reporting, set RAY_DATA_VERBOSE_PROGRESS=1.\n",
      "                                                                                                                   \r"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import ray\n",
    "from ray.tune.syncer import SyncConfig\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset, load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ray.data.preprocessors import Chain\n",
    "import evaluate\n",
    "\n",
    "MODEL_NAME = \"databricks/dolly-v2-3b\"\n",
    "\n",
    "current_dataset = load_dataset(\"tiny_shakespeare\")\n",
    "\n",
    "from ray.data.preprocessors import BatchMapper\n",
    "\n",
    "\n",
    "def split_text(batch: pd.DataFrame) -> pd.DataFrame:\n",
    "    text = list(batch[\"text\"])\n",
    "    flat_text = \"\".join(text)\n",
    "    split_text = [\n",
    "        x.strip()\n",
    "        for x in flat_text.split(\"\\n\")\n",
    "        if x.strip() and not x.strip()[-1] == \":\"\n",
    "    ]\n",
    "    return pd.DataFrame(split_text, columns=[\"text\"])\n",
    "\n",
    "\n",
    "def tokenize(batch: pd.DataFrame) -> dict:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"left\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    ret = tokenizer(\n",
    "        list(batch[\"text\"]),\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    ret[\"labels\"] = ret[\"input_ids\"].copy()\n",
    "    return dict(ret)\n",
    "\n",
    "\n",
    "splitter = BatchMapper(split_text, batch_format=\"pandas\")\n",
    "tokenizer = BatchMapper(tokenize, batch_format=\"pandas\")\n",
    "preprocessor = Chain(splitter, tokenizer)\n",
    "\n",
    "ray_datasets = ray.data.from_huggingface(current_dataset)\n",
    "\n",
    "\n",
    "total_train_batches = splitter.fit_transform(ray_datasets[\"train\"]).count()\n",
    "\n",
    "from transformers.models.gpt_neox.modeling_gpt_neox import GPTNeoXLayer\n",
    "\n",
    "class DollyV2Model(pl.LightningModule):\n",
    "    def __init__(self, lr=2e-5, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        self.metric = evaluate.load(\"accuracy\")\n",
    "        self.predictions = []\n",
    "        self.references = []\n",
    "\n",
    "    def forward(self, batch):\n",
    "        outputs = self.model(\n",
    "            batch[\"input_ids\"], \n",
    "            attention_mask=batch[\"attention_mask\"], \n",
    "            labels=batch[\"labels\"]\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.forward(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        if self.global_rank == 0 and batch_idx % 10 == 0:\n",
    "            print(\"loss = \", loss.item())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.trainer.model.parameters(), lr=self.lr, eps=self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-30 18:23:35</td></tr>\n",
       "<tr><td>Running for: </td><td>00:26:27.33        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.3/124.4 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/272 CPUs, 0/16 GPUs (0.0/16.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  step</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LightningTrainer_18e2e_00000</td><td>TERMINATED</td><td>10.0.17.186:7290</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          1456.8</td><td style=\"text-align: right;\">    0.175903</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   169</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 17:57:08,147\tWARNING trial_runner.py:1607 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (299 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.\n",
      "(LightningTrainer pid=7290) 2023-04-30 17:57:16,864\tINFO backend_executor.py:128 -- Starting distributed worker processes: ['7494 (10.0.17.186)', '3206 (10.0.37.115)', '3174 (10.0.2.210)', '3191 (10.0.26.185)', '3190 (10.0.42.121)', '3266 (10.0.31.196)', '3178 (10.0.51.169)', '3211 (10.0.16.220)', '3194 (10.0.57.188)', '3160 (10.0.22.19)', '16501 (10.0.30.41)', '3213 (10.0.40.107)', '3258 (10.0.32.28)', '3235 (10.0.14.135)', '3233 (10.0.61.133)', '3178 (10.0.4.204)']\n",
      "(RayTrainWorker pid=7494) 2023-04-30 17:57:19,146\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=16]\n",
      "\n",
      "(pid=7290) Running: 0.0/272.0 CPU, 0.0/16.0 GPU, 0.0 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "(pid=7290) - RandomizeBlockOrder: 0 active, 0 queued, 0.0 MiB objects, 0 output:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "(LightningTrainer pid=7290)                                                                                                   2023-04-30 17:57:19,758\tINFO streaming_executor.py:87 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper->BatchMapper] -> AllToAllOperator[RandomizeBlockOrder]\n",
      "\n",
      "(pid=7290) Running: 0.0/272.0 CPU, 0.0/16.0 GPU, 0.0 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "(LightningTrainer pid=7290)                                                                                                   2023-04-30 17:57:19,758\tINFO streaming_executor.py:88 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\n",
      "(pid=7290) Running: 0.0/272.0 CPU, 0.0/16.0 GPU, 0.0 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "(LightningTrainer pid=7290)                                                                                                   2023-04-30 17:57:19,758\tINFO streaming_executor.py:90 -- Tip: To enable per-operator progress reporting, set RAY_DATA_VERBOSE_PROGRESS=1.\n",
      "\n",
      "(pid=7290) Running: 1.0/272.0 CPU, 0.0/16.0 GPU, 0.96 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 450/450 [00:00<00:00, 67.2kB/s]                                          \n",
      "\n",
      "(pid=7290) Running: 1.0/272.0 CPU, 0.0/16.0 GPU, 0.96 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:03<?, ?it/s]\n",
      "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]                                               \n",
      "\n",
      "(pid=7290) Running: 1.0/272.0 CPU, 0.0/16.0 GPU, 0.96 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:03<?, ?it/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 13.2MB/s]                                      \n",
      "\n",
      "(pid=7290) Running: 1.0/272.0 CPU, 0.0/16.0 GPU, 0.96 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:03<?, ?it/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 228/228 [00:00<00:00, 141kB/s]                                           \n",
      "\n",
      "(pid=7290) Running: 0.0/272.0 CPU, 0.0/16.0 GPU, 0.0 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:06<?, ?it/s]   \n",
      "(pid=7290) - RandomizeBlockOrder: 0 active, 0 queued, 0.0 MiB objects, 1 output:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "(pid=7290) Running: 0.0/272.0 CPU, 0.0/16.0 GPU, 126.69 MiB/73.21 GiB object_store_memory:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "                                                                                                                                        \n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 819/819 [00:00<00:00, 124kB/s]                                          (RayTrainWorker pid=7494) \n",
      "Downloading pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]\n",
      "Downloading pytorch_model.bin:   0%|          | 10.5M/5.68G [00:00<01:06, 85.4MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 819/819 [00:00<00:00, 123kB/s] [repeated 15x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\n",
      "Downloading pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s] [repeated 15x across cluster]\n",
      "Downloading pytorch_model.bin:  18%|█▊        | 1.02G/5.68G [00:04<00:22, 209MB/s] [repeated 624x across cluster]\n",
      "Downloading pytorch_model.bin:  35%|███▌      | 2.00G/5.68G [00:10<00:18, 199MB/s] [repeated 640x across cluster]\n",
      "Downloading pytorch_model.bin:  55%|█████▍    | 3.11G/5.68G [00:14<00:11, 219MB/s] [repeated 629x across cluster]\n",
      "Downloading pytorch_model.bin:  76%|███████▌  | 4.33G/5.68G [00:20<00:05, 229MB/s] [repeated 620x across cluster]\n",
      "Downloading pytorch_model.bin:  91%|█████████▏| 5.19G/5.68G [00:23<00:02, 233MB/s]\n",
      "Downloading pytorch_model.bin:  87%|████████▋ | 4.97G/5.68G [00:24<00:03, 203MB/s] [repeated 528x across cluster]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 5.68G/5.68G [00:25<00:00, 219MB/s]\n",
      "Downloading pytorch_model.bin:  94%|█████████▍| 5.36G/5.68G [00:28<00:01, 198MB/s] [repeated 267x across cluster]\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 6.76MB/s]\n",
      "Downloading pytorch_model.bin:  91%|█████████ | 5.17G/5.68G [00:27<00:02, 196MB/s] [repeated 44x across cluster]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 5.68G/5.68G [00:28<00:00, 200MB/s] [repeated 4x across cluster]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 5.68G/5.68G [00:29<00:00, 190MB/s] [repeated 21x across cluster]\n",
      "(RayTrainWorker pid=16501, ip=10.0.30.41) Using 16bit Automatic Mixed Precision (AMP)\n",
      "(RayTrainWorker pid=3194, ip=10.0.57.188) Missing logger folder: /home/ray/ray_results/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/rank_8/lightning_logs\n",
      "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 3.73MB/s]\n",
      "(RayTrainWorker pid=7494) GPU available: True (cuda), used: True\n",
      "(RayTrainWorker pid=7494) TPU available: False, using: 0 TPU cores\n",
      "(RayTrainWorker pid=7494) IPU available: False, using: 0 IPUs\n",
      "(RayTrainWorker pid=7494) HPU available: False, using: 0 HPUs\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 5.18MB/s] [repeated 14x across cluster]\n",
      "(RayTrainWorker pid=16501, ip=10.0.30.41) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "(RayTrainWorker pid=3213, ip=10.0.40.107) Using 16bit Automatic Mixed Precision (AMP) [repeated 15x across cluster]\n",
      "(RayTrainWorker pid=3213, ip=10.0.40.107) Missing logger folder: /home/ray/ray_results/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/rank_11/lightning_logs [repeated 15x across cluster]\n",
      "(RayTrainWorker pid=7494) \n",
      "(RayTrainWorker pid=7494)   | Name  | Type               | Params\n",
      "(RayTrainWorker pid=7494) ---------------------------------------------\n",
      "(RayTrainWorker pid=7494) 0 | model | GPTNeoXForCausalLM | 157 M \n",
      "(RayTrainWorker pid=7494) ---------------------------------------------\n",
      "(RayTrainWorker pid=7494) 157 M     Trainable params\n",
      "(RayTrainWorker pid=7494) 0         Non-trainable params\n",
      "(RayTrainWorker pid=7494) 157 M     Total params\n",
      "(RayTrainWorker pid=7494) 629.412   Total estimated model params size (MB)\n",
      "(RayTrainWorker pid=3190, ip=10.0.42.121) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] [repeated 15x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/168 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=7494) /home/ray/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "(RayTrainWorker pid=7494)   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=7494) loss =  11.7890625\n",
      "Epoch 0:   1%|          | 1/168 [00:09<25:11,  9.05s/it, v_num=0]\n",
      "Epoch 0:   1%|          | 2/168 [00:16<22:57,  8.30s/it, v_num=0]\n",
      "Epoch 0:   2%|▏         | 3/168 [00:23<21:33,  7.84s/it, v_num=0]\n",
      "Epoch 0:   2%|▏         | 4/168 [00:30<20:59,  7.68s/it, v_num=0]\n",
      "Epoch 0:   3%|▎         | 5/168 [00:37<20:30,  7.55s/it, v_num=0]\n",
      "Epoch 0:   4%|▎         | 6/168 [00:44<20:05,  7.44s/it, v_num=0]\n",
      "Epoch 0:   4%|▍         | 7/168 [00:51<19:44,  7.36s/it, v_num=0]\n",
      "Epoch 0:   5%|▍         | 8/168 [00:58<19:28,  7.30s/it, v_num=0]\n",
      "Epoch 0:   5%|▌         | 9/168 [01:05<19:15,  7.27s/it, v_num=0]\n",
      "Epoch 0:   6%|▌         | 10/168 [01:12<19:10,  7.28s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.3720703125\n",
      "Epoch 0:   7%|▋         | 11/168 [01:20<19:02,  7.28s/it, v_num=0]\n",
      "Epoch 0:   7%|▋         | 12/168 [01:27<18:58,  7.30s/it, v_num=0]\n",
      "Epoch 0:   8%|▊         | 13/168 [01:34<18:48,  7.28s/it, v_num=0]\n",
      "Epoch 0:   8%|▊         | 14/168 [01:42<18:42,  7.29s/it, v_num=0]\n",
      "Epoch 0:   9%|▉         | 15/168 [01:49<18:34,  7.28s/it, v_num=0]\n",
      "Epoch 0:  10%|▉         | 16/168 [01:56<18:27,  7.29s/it, v_num=0]\n",
      "Epoch 0:  10%|█         | 17/168 [02:03<18:19,  7.28s/it, v_num=0]\n",
      "Epoch 0:  11%|█         | 18/168 [02:11<18:11,  7.28s/it, v_num=0]\n",
      "Epoch 0:  11%|█▏        | 19/168 [02:18<18:03,  7.27s/it, v_num=0]\n",
      "Epoch 0:  12%|█▏        | 20/168 [02:25<17:56,  7.28s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.33837890625\n",
      "Epoch 0:  12%|█▎        | 21/168 [02:33<17:51,  7.29s/it, v_num=0]\n",
      "Epoch 0:  13%|█▎        | 22/168 [02:40<17:44,  7.29s/it, v_num=0]\n",
      "Epoch 0:  14%|█▎        | 23/168 [02:47<17:37,  7.29s/it, v_num=0]\n",
      "Epoch 0:  14%|█▍        | 24/168 [02:55<17:30,  7.29s/it, v_num=0]\n",
      "Epoch 0:  15%|█▍        | 25/168 [03:02<17:22,  7.29s/it, v_num=0]\n",
      "Epoch 0:  15%|█▌        | 26/168 [03:09<17:16,  7.30s/it, v_num=0]\n",
      "Epoch 0:  16%|█▌        | 27/168 [03:16<17:07,  7.29s/it, v_num=0]\n",
      "Epoch 0:  17%|█▋        | 28/168 [03:24<17:01,  7.29s/it, v_num=0]\n",
      "Epoch 0:  17%|█▋        | 29/168 [03:31<16:53,  7.29s/it, v_num=0]\n",
      "Epoch 0:  18%|█▊        | 30/168 [03:38<16:45,  7.29s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.230224609375\n",
      "Epoch 0:  18%|█▊        | 31/168 [03:45<16:36,  7.28s/it, v_num=0]\n",
      "Epoch 0:  19%|█▉        | 32/168 [03:52<16:30,  7.28s/it, v_num=0]\n",
      "Epoch 0:  20%|█▉        | 33/168 [03:59<16:21,  7.27s/it, v_num=0]\n",
      "Epoch 0:  20%|██        | 34/168 [04:07<16:14,  7.27s/it, v_num=0]\n",
      "Epoch 0:  21%|██        | 35/168 [04:14<16:07,  7.28s/it, v_num=0]\n",
      "Epoch 0:  21%|██▏       | 36/168 [04:22<16:01,  7.28s/it, v_num=0]\n",
      "Epoch 0:  22%|██▏       | 37/168 [04:29<15:52,  7.27s/it, v_num=0]\n",
      "Epoch 0:  23%|██▎       | 38/168 [04:36<15:45,  7.27s/it, v_num=0]\n",
      "Epoch 0:  23%|██▎       | 39/168 [04:43<15:38,  7.28s/it, v_num=0]\n",
      "Epoch 0:  24%|██▍       | 40/168 [04:51<15:31,  7.28s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.2027587890625\n",
      "Epoch 0:  24%|██▍       | 41/168 [04:58<15:23,  7.27s/it, v_num=0]\n",
      "Epoch 0:  25%|██▌       | 42/168 [05:05<15:16,  7.28s/it, v_num=0]\n",
      "Epoch 0:  26%|██▌       | 43/168 [05:12<15:08,  7.27s/it, v_num=0]\n",
      "Epoch 0:  26%|██▌       | 44/168 [05:19<15:01,  7.27s/it, v_num=0]\n",
      "Epoch 0:  27%|██▋       | 45/168 [05:26<14:53,  7.26s/it, v_num=0]\n",
      "Epoch 0:  27%|██▋       | 46/168 [05:34<14:47,  7.27s/it, v_num=0]\n",
      "Epoch 0:  28%|██▊       | 47/168 [05:41<14:39,  7.27s/it, v_num=0]\n",
      "Epoch 0:  29%|██▊       | 48/168 [05:49<14:32,  7.27s/it, v_num=0]\n",
      "Epoch 0:  29%|██▉       | 49/168 [05:55<14:24,  7.27s/it, v_num=0]\n",
      "Epoch 0:  30%|██▉       | 50/168 [06:03<14:17,  7.27s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.2052001953125\n",
      "Epoch 0:  30%|███       | 51/168 [06:10<14:09,  7.26s/it, v_num=0]\n",
      "Epoch 0:  31%|███       | 52/168 [06:17<14:02,  7.26s/it, v_num=0]\n",
      "Epoch 0:  32%|███▏      | 53/168 [06:24<13:55,  7.26s/it, v_num=0]\n",
      "Epoch 0:  32%|███▏      | 54/168 [06:32<13:48,  7.26s/it, v_num=0]\n",
      "Epoch 0:  33%|███▎      | 55/168 [06:39<13:40,  7.26s/it, v_num=0]\n",
      "Epoch 0:  33%|███▎      | 56/168 [06:46<13:33,  7.26s/it, v_num=0]\n",
      "Epoch 0:  34%|███▍      | 57/168 [06:53<13:25,  7.26s/it, v_num=0]\n",
      "Epoch 0:  35%|███▍      | 58/168 [07:01<13:18,  7.26s/it, v_num=0]\n",
      "Epoch 0:  35%|███▌      | 59/168 [07:08<13:11,  7.26s/it, v_num=0]\n",
      "Epoch 0:  36%|███▌      | 60/168 [07:16<13:05,  7.28s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.264404296875\n",
      "Epoch 0:  36%|███▋      | 61/168 [07:24<12:58,  7.28s/it, v_num=0]\n",
      "Epoch 0:  37%|███▋      | 62/168 [07:31<12:52,  7.28s/it, v_num=0]\n",
      "Epoch 0:  38%|███▊      | 63/168 [07:39<12:45,  7.29s/it, v_num=0]\n",
      "Epoch 0:  38%|███▊      | 64/168 [07:46<12:37,  7.29s/it, v_num=0]\n",
      "Epoch 0:  39%|███▊      | 65/168 [07:54<12:31,  7.29s/it, v_num=0]\n",
      "Epoch 0:  39%|███▉      | 66/168 [08:01<12:24,  7.30s/it, v_num=0]\n",
      "Epoch 0:  40%|███▉      | 67/168 [08:08<12:17,  7.30s/it, v_num=0]\n",
      "Epoch 0:  40%|████      | 68/168 [08:16<12:10,  7.30s/it, v_num=0]\n",
      "Epoch 0:  41%|████      | 69/168 [08:24<12:03,  7.31s/it, v_num=0]\n",
      "Epoch 0:  42%|████▏     | 70/168 [08:31<11:56,  7.31s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.1541748046875\n",
      "Epoch 0:  42%|████▏     | 71/168 [08:39<11:49,  7.32s/it, v_num=0]\n",
      "Epoch 0:  43%|████▎     | 72/168 [08:47<11:43,  7.33s/it, v_num=0]\n",
      "Epoch 0:  43%|████▎     | 73/168 [08:55<11:36,  7.33s/it, v_num=0]\n",
      "Epoch 0:  44%|████▍     | 74/168 [09:02<11:29,  7.34s/it, v_num=0]\n",
      "Epoch 0:  45%|████▍     | 75/168 [09:10<11:22,  7.34s/it, v_num=0]\n",
      "Epoch 0:  45%|████▌     | 76/168 [09:18<11:16,  7.35s/it, v_num=0]\n",
      "Epoch 0:  46%|████▌     | 77/168 [09:26<11:09,  7.35s/it, v_num=0]\n",
      "Epoch 0:  46%|████▋     | 78/168 [09:33<11:02,  7.36s/it, v_num=0]\n",
      "Epoch 0:  47%|████▋     | 79/168 [09:41<10:55,  7.36s/it, v_num=0]\n",
      "Epoch 0:  48%|████▊     | 80/168 [09:49<10:48,  7.37s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.185791015625\n",
      "Epoch 0:  48%|████▊     | 81/168 [09:56<10:40,  7.37s/it, v_num=0]\n",
      "Epoch 0:  49%|████▉     | 82/168 [10:04<10:33,  7.37s/it, v_num=0]\n",
      "Epoch 0:  49%|████▉     | 83/168 [10:11<10:26,  7.37s/it, v_num=0]\n",
      "Epoch 0:  50%|█████     | 84/168 [10:19<10:19,  7.37s/it, v_num=0]\n",
      "Epoch 0:  51%|█████     | 85/168 [10:26<10:11,  7.37s/it, v_num=0]\n",
      "Epoch 0:  51%|█████     | 86/168 [10:33<10:04,  7.37s/it, v_num=0]\n",
      "Epoch 0:  52%|█████▏    | 87/168 [10:41<09:57,  7.37s/it, v_num=0]\n",
      "Epoch 0:  52%|█████▏    | 88/168 [10:49<09:50,  7.38s/it, v_num=0]\n",
      "Epoch 0:  53%|█████▎    | 89/168 [10:56<09:42,  7.38s/it, v_num=0]\n",
      "Epoch 0:  54%|█████▎    | 90/168 [11:04<09:35,  7.38s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.24169921875\n",
      "Epoch 0:  54%|█████▍    | 91/168 [11:11<09:28,  7.38s/it, v_num=0]\n",
      "Epoch 0:  55%|█████▍    | 92/168 [11:19<09:21,  7.38s/it, v_num=0]\n",
      "Epoch 0:  55%|█████▌    | 93/168 [11:26<09:13,  7.38s/it, v_num=0]\n",
      "Epoch 0:  56%|█████▌    | 94/168 [11:34<09:06,  7.39s/it, v_num=0]\n",
      "Epoch 0:  57%|█████▋    | 95/168 [11:42<08:59,  7.39s/it, v_num=0]\n",
      "Epoch 0:  57%|█████▋    | 96/168 [11:49<08:52,  7.39s/it, v_num=0]\n",
      "Epoch 0:  58%|█████▊    | 97/168 [11:57<08:44,  7.39s/it, v_num=0]\n",
      "Epoch 0:  58%|█████▊    | 98/168 [12:04<08:37,  7.40s/it, v_num=0]\n",
      "Epoch 0:  59%|█████▉    | 99/168 [12:12<08:30,  7.40s/it, v_num=0]\n",
      "Epoch 0:  60%|█████▉    | 100/168 [12:19<08:23,  7.40s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.2005615234375\n",
      "Epoch 0:  60%|██████    | 101/168 [12:27<08:15,  7.40s/it, v_num=0]\n",
      "Epoch 0:  61%|██████    | 102/168 [12:35<08:08,  7.40s/it, v_num=0]\n",
      "Epoch 0:  61%|██████▏   | 103/168 [12:42<08:01,  7.40s/it, v_num=0]\n",
      "Epoch 0:  62%|██████▏   | 104/168 [12:49<07:53,  7.40s/it, v_num=0]\n",
      "Epoch 0:  62%|██████▎   | 105/168 [12:57<07:46,  7.41s/it, v_num=0]\n",
      "Epoch 0:  63%|██████▎   | 106/168 [13:05<07:39,  7.41s/it, v_num=0]\n",
      "Epoch 0:  64%|██████▎   | 107/168 [13:13<07:32,  7.41s/it, v_num=0]\n",
      "Epoch 0:  64%|██████▍   | 108/168 [13:20<07:24,  7.42s/it, v_num=0]\n",
      "Epoch 0:  64%|██████▍   | 108/168 [13:20<07:24,  7.42s/it, v_num=0]\n",
      "Epoch 0:  65%|██████▍   | 109/168 [13:28<07:17,  7.42s/it, v_num=0]\n",
      "Epoch 0:  65%|██████▌   | 110/168 [13:36<07:10,  7.42s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.261962890625\n",
      "Epoch 0:  66%|██████▌   | 111/168 [13:43<07:02,  7.42s/it, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 112/168 [13:51<06:55,  7.42s/it, v_num=0]\n",
      "Epoch 0:  67%|██████▋   | 113/168 [13:58<06:48,  7.42s/it, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 114/168 [14:06<06:40,  7.42s/it, v_num=0]\n",
      "Epoch 0:  68%|██████▊   | 115/168 [14:13<06:33,  7.42s/it, v_num=0]\n",
      "Epoch 0:  69%|██████▉   | 116/168 [14:21<06:26,  7.43s/it, v_num=0]\n",
      "Epoch 0:  70%|██████▉   | 117/168 [14:28<06:18,  7.43s/it, v_num=0]\n",
      "Epoch 0:  70%|███████   | 118/168 [14:36<06:11,  7.43s/it, v_num=0]\n",
      "Epoch 0:  71%|███████   | 119/168 [14:44<06:04,  7.43s/it, v_num=0]\n",
      "Epoch 0:  71%|███████▏  | 120/168 [14:51<05:56,  7.43s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.2178955078125\n",
      "Epoch 0:  72%|███████▏  | 121/168 [14:59<05:49,  7.44s/it, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 122/168 [15:07<05:42,  7.44s/it, v_num=0]\n",
      "Epoch 0:  73%|███████▎  | 123/168 [15:15<05:34,  7.44s/it, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 124/168 [15:22<05:27,  7.44s/it, v_num=0]\n",
      "Epoch 0:  74%|███████▍  | 125/168 [15:29<05:19,  7.44s/it, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 126/168 [15:37<05:12,  7.44s/it, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 127/168 [15:44<05:04,  7.44s/it, v_num=0]\n",
      "Epoch 0:  76%|███████▌  | 128/168 [15:52<04:57,  7.44s/it, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 129/168 [15:59<04:50,  7.44s/it, v_num=0]\n",
      "Epoch 0:  77%|███████▋  | 130/168 [16:07<04:42,  7.44s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.1785888671875\n",
      "Epoch 0:  78%|███████▊  | 131/168 [16:14<04:35,  7.44s/it, v_num=0]\n",
      "Epoch 0:  79%|███████▊  | 132/168 [16:22<04:27,  7.44s/it, v_num=0]\n",
      "Epoch 0:  79%|███████▉  | 133/168 [16:29<04:20,  7.44s/it, v_num=0]\n",
      "Epoch 0:  80%|███████▉  | 134/168 [16:37<04:13,  7.44s/it, v_num=0]\n",
      "Epoch 0:  80%|████████  | 135/168 [16:45<04:05,  7.45s/it, v_num=0]\n",
      "Epoch 0:  81%|████████  | 136/168 [16:52<03:58,  7.45s/it, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 137/168 [17:00<03:50,  7.45s/it, v_num=0]\n",
      "Epoch 0:  82%|████████▏ | 138/168 [17:08<03:43,  7.45s/it, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 139/168 [17:16<03:36,  7.46s/it, v_num=0]\n",
      "Epoch 0:  83%|████████▎ | 140/168 [17:23<03:28,  7.46s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.2109375\n",
      "Epoch 0:  84%|████████▍ | 141/168 [17:31<03:21,  7.46s/it, v_num=0]\n",
      "Epoch 0:  85%|████████▍ | 142/168 [17:39<03:13,  7.46s/it, v_num=0]\n",
      "Epoch 0:  85%|████████▌ | 143/168 [17:47<03:06,  7.46s/it, v_num=0]\n",
      "Epoch 0:  86%|████████▌ | 144/168 [17:54<02:59,  7.46s/it, v_num=0]\n",
      "Epoch 0:  86%|████████▋ | 145/168 [18:02<02:51,  7.46s/it, v_num=0]\n",
      "Epoch 0:  87%|████████▋ | 146/168 [18:09<02:44,  7.47s/it, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 147/168 [18:17<02:36,  7.47s/it, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 148/168 [18:25<02:29,  7.47s/it, v_num=0]\n",
      "Epoch 0:  89%|████████▊ | 149/168 [18:33<02:21,  7.47s/it, v_num=0]\n",
      "Epoch 0:  89%|████████▉ | 150/168 [18:40<02:14,  7.47s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.2403564453125\n",
      "Epoch 0:  90%|████████▉ | 151/168 [18:48<02:07,  7.47s/it, v_num=0]\n",
      "Epoch 0:  90%|█████████ | 152/168 [18:55<01:59,  7.47s/it, v_num=0]\n",
      "Epoch 0:  91%|█████████ | 153/168 [19:03<01:52,  7.47s/it, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 154/168 [19:11<01:44,  7.47s/it, v_num=0]\n",
      "Epoch 0:  92%|█████████▏| 155/168 [19:18<01:37,  7.48s/it, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 156/168 [19:26<01:29,  7.48s/it, v_num=0]\n",
      "Epoch 0:  93%|█████████▎| 157/168 [19:34<01:22,  7.48s/it, v_num=0]\n",
      "Epoch 0:  94%|█████████▍| 158/168 [19:42<01:14,  7.48s/it, v_num=0]\n",
      "Epoch 0:  95%|█████████▍| 159/168 [19:49<01:07,  7.48s/it, v_num=0]\n",
      "Epoch 0:  95%|█████████▌| 160/168 [19:57<00:59,  7.49s/it, v_num=0]\n",
      "(RayTrainWorker pid=7494) loss =  0.238037109375\n",
      "Epoch 0:  96%|█████████▌| 161/168 [20:05<00:52,  7.49s/it, v_num=0]\n",
      "Epoch 0:  96%|█████████▋| 162/168 [20:13<00:44,  7.49s/it, v_num=0]\n",
      "Epoch 0:  97%|█████████▋| 163/168 [20:21<00:37,  7.49s/it, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 164/168 [20:28<00:29,  7.49s/it, v_num=0]\n",
      "Epoch 0:  98%|█████████▊| 165/168 [20:36<00:22,  7.49s/it, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 166/168 [20:43<00:14,  7.49s/it, v_num=0]\n",
      "Epoch 0:  99%|█████████▉| 167/168 [20:51<00:07,  7.49s/it, v_num=0]\n",
      "Epoch 0: 100%|██████████| 168/168 [20:58<00:00,  7.49s/it, v_num=0]\n",
      "Epoch 0: : 169it [21:06,  7.49s/it, v_num=0]                       \n",
      "(RayTrainWorker pid=3206, ip=10.0.37.115) lightning_module_state_dict\n",
      "(RayTrainWorker pid=3206, ip=10.0.37.115) \n",
      "(RayTrainWorker pid=3206, ip=10.0.37.115) \n",
      "(RayTrainWorker pid=3206, ip=10.0.37.115) \n",
      "(RayTrainWorker pid=3206, ip=10.0.37.115) \n",
      "Epoch 0: : 169it [21:06,  7.49s/it, v_num=0]lightning_module_state_dict\n",
      "(RayTrainWorker pid=7494) lightning_module_state_dict [repeated 15x across cluster]\n",
      "(RayTrainWorker pid=7494)  [repeated 64x across cluster]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>_report_on     </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname      </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  step</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LightningTrainer_18e2e_00000</td><td>train_epoch_end</td><td>2023-04-30_18-21-31</td><td>True  </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">               0</td><td>ip-10-0-17-186</td><td style=\"text-align: right;\">                         1</td><td>10.0.17.186</td><td style=\"text-align: right;\"> 7290</td><td>True               </td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">              1456.8</td><td style=\"text-align: right;\">            1456.8</td><td style=\"text-align: right;\">        1456.8</td><td style=\"text-align: right;\"> 1682904091</td><td style=\"text-align: right;\">    0.175903</td><td style=\"text-align: right;\">                   1</td><td>18e2e_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 169it [22:47,  8.09s/it, v_num=0]\n",
      "(RayTrainWorker pid=3211, ip=10.0.16.220) lightning_module_state_dict [repeated 15x across cluster]\n",
      "(RayTrainWorker pid=3211, ip=10.0.16.220)  [repeated 60x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=7494) `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "(RayTrainWorker pid=7494) RayFSDPStrategy: tearing down strategy...\n",
      "(LightningTrainer pid=7290) 2023-04-30 18:22:52,022\tWARNING util.py:315 -- Uploading trial artifacts took 61.141 s, which may be a performance bottleneck. Consider saving fewer/smaller artifacts to the trial log directory, or disable artifact syncing with `SyncConfig(sync_artifacts=False)`.\n",
      "2023-04-30 18:23:35,479\tWARNING experiment_state.py:306 -- Syncing the experiment checkpoint to cloud took a long time with 40.79 seconds. This can be due to a large number of trials, large logfiles, or throttling from the remote storage provider for too frequent syncs. If your `CheckpointConfig.num_to_keep` is a low number, this can trigger frequent syncing, in which case you should increase it. \n",
      "2023-04-30 18:23:35,484\tINFO tune.py:1010 -- Total run time: 1587.49 seconds (1546.53 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'_report_on': 'train_epoch_end', 'train_loss': 0.1759033203125, 'epoch': 0, 'step': 169, 'should_checkpoint': True, 'done': True, 'trial_id': '18e2e_00000', 'experiment_tag': '0'},\n",
       "  path='s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08',\n",
       "  checkpoint=LightningCheckpoint(uri=s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from ray.train.lightning import LightningTrainer, LightningConfigBuilder\n",
    "from ray.air.config import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from torch.distributed.fsdp.wrap import size_based_auto_wrap_policy, transformer_auto_wrap_policy\n",
    "from torch.distributed.fsdp import ShardingStrategy, MixedPrecision, CPUOffload, BackwardPrefetch\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "\n",
    "import functools\n",
    "wrap_policy = functools.partial(\n",
    "    transformer_auto_wrap_policy,\n",
    "    transformer_layer_cls = {GPTNeoXLayer}\n",
    ")\n",
    "\n",
    "mixed_precision_policy = MixedPrecision(\n",
    "    param_dtype=torch.float16,\n",
    "    reduce_dtype=torch.float16,\n",
    "    buffer_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "class DollyV2Progressbar(TQDMProgressBar):\n",
    "    def __init__(self, num_iters_per_epoch, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_iters_per_epoch = num_iters_per_epoch\n",
    "    \n",
    "    def on_train_epoch_start(self, trainer, *_):\n",
    "        super().on_train_epoch_start(trainer, *_)\n",
    "        self.train_progress_bar.reset(self.num_iters_per_epoch)\n",
    "    \n",
    "num_workers = 16\n",
    "batch_size_per_worker = 8\n",
    "num_iters_per_epoch = total_train_batches // (num_workers * batch_size_per_worker)\n",
    "progress_bar = DollyV2Progressbar(num_iters_per_epoch)\n",
    "\n",
    "# Define the configs for LightningTrainer\n",
    "lightning_config = (\n",
    "    LightningConfigBuilder()\n",
    "    .module(cls=DollyV2Model, lr=2e-5, eps=1e-8)\n",
    "    .trainer(\n",
    "        max_epochs=1, \n",
    "        accelerator=\"gpu\", \n",
    "        log_every_n_steps=1,\n",
    "        # accumulate_grad_batches=2,\n",
    "        precision=\"16-mixed\",\n",
    "        callbacks=[progress_bar],\n",
    "    )\n",
    "    .checkpointing(save_last=True)\n",
    "    .strategy(\n",
    "        name=\"fsdp\",\n",
    "        sharding_strategy=ShardingStrategy.FULL_SHARD,\n",
    "        backward_prefetch=BackwardPrefetch.BACKWARD_PRE,\n",
    "        forward_prefetch=True,\n",
    "        auto_wrap_policy=wrap_policy,\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "\n",
    "from ray.tune.syncer import SyncConfig\n",
    "\n",
    "# Save AIR checkpoints according to the performance on validation set\n",
    "run_config = RunConfig(\n",
    "    name=\"finetune-dolly-v2\",\n",
    "    storage_path=\"s3://yunxuanx-test/model-checkpoint\",\n",
    "    checkpoint_config=CheckpointConfig(),\n",
    ")\n",
    "\n",
    "# Scale the DDP training workload across 4 GPUs\n",
    "# You can change this config based on your compute resources.\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=num_workers, use_gpu=True, resources_per_worker={\"CPU\": 8, \"GPU\": 1}\n",
    ")\n",
    "\n",
    "\n",
    "trainer = LightningTrainer(\n",
    "    lightning_config=lightning_config,\n",
    "    run_config=run_config,\n",
    "    scaling_config=scaling_config,\n",
    "    datasets={\"train\": ray_datasets[\"train\"]},\n",
    "    datasets_iter_config={\"batch_size\": batch_size_per_worker},\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "result = trainer.fit()\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray.train.lightning import LightningCheckpoint#\n",
    "# ckpt = LightningCheckpoint.from_uri(\"s3://large-dl-models-mirror/models--dolly-v2-3b-fp16/model-checkpoint/ptl-finetune-dolly-v2/LightningTrainer_ede1d_00000_0_2023-04-28_17-29-40/checkpoint_000000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/_preprocessor to ../s3/checkpoint/_preprocessor\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/.metadata.pkl to ../s3/checkpoint/.metadata.pkl\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/.is_checkpoint to ../s3/checkpoint/.is_checkpoint\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/.tune_metadata to ../s3/checkpoint/.tune_metadata\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/model to ../s3/checkpoint/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"aws s3 sync {result.checkpoint.uri} /home/ray/s3/checkpoint\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-3b\", padding_side=\"right\")\n",
    "dolly = DollyV2Model.load_from_checkpoint(\"/home/ray/s3/checkpoint/model\").cuda()\n",
    "nlp_pipeline = pipeline(task=\"text-generation\", model=dolly.model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Romeo and juliet, Romeo and Juliet, Romeo and Juliet! Romeo, Romeo! Juliet, Juliet! Romeo, Romeo! Juliet, Juliet'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp_pipeline(\"I pray the gods\", max_new_tokens=30)\n",
    "nlp_pipeline(\"Romeo and juliet\", max_new_tokens=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from instruct_pipeline import InstructionTextGenerationPipeline\n",
    "# generate_text = InstructionTextGenerationPipeline(model=dolly, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = generate_text(\"中国队勇夺世界杯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res[0][\"generated_text\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
