{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Dolly-v2-3b with Ray AIR LightningTrainer and FSDP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install some requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Requirements\n",
    "! pip install \"datasets\" \"evaluate\" \"transformers>=4.26.0\" \"torch>=1.12.0\" \"pytorch_lightning>=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from typing import Any\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from ray.tune.syncer import SyncConfig\n",
    "from ray.data.preprocessors import Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RAY_ML_DEV\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"databricks/dolly-v2-7b\"\n",
    "MODEL_NAME = \"databricks/dolly-v2-3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ray.data.preprocessors import BatchMapper\n",
    "\n",
    "\n",
    "def split_text(batch: pd.DataFrame) -> pd.DataFrame:\n",
    "    text = list(batch[\"text\"])\n",
    "    flat_text = \"\".join(text)\n",
    "    split_text = [\n",
    "        x.strip()\n",
    "        for x in flat_text.split(\"\\n\")\n",
    "        if x.strip() and not x.strip()[-1] == \":\"\n",
    "    ]\n",
    "    return pd.DataFrame(split_text, columns=[\"text\"])\n",
    "\n",
    "\n",
    "def tokenize(batch: pd.DataFrame) -> dict:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"left\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    ret = tokenizer(\n",
    "        list(batch[\"text\"]),\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    ret[\"labels\"] = ret[\"input_ids\"].copy()\n",
    "    return dict(ret)\n",
    "\n",
    "splitter = BatchMapper(split_text, batch_format=\"pandas\")\n",
    "tokenizer = BatchMapper(tokenize, batch_format=\"pandas\")\n",
    "preprocessor = Chain(splitter, tokenizer)\n",
    "\n",
    "hf_dataset = load_dataset(\"tiny_shakespeare\")\n",
    "ray_datasets = ray.data.from_huggingface(hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset tiny_shakespeare (/home/ray/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1081.56it/s]\n",
      "2023-05-01 00:56:50,821\tINFO worker.py:1432 -- Connecting to existing Ray cluster at address: 10.0.43.253:6379...\n",
      "2023-05-01 00:56:50,830\tINFO worker.py:1607 -- Connected to Ray cluster. View the dashboard at https://console.anyscale-staging.com/api/v2/sessions/ses_m411tiqu8eluvt1k5ivfqj4q5r/services?redirect_to=dashboard \n",
      "2023-05-01 00:56:51,432\tINFO packaging.py:520 -- Creating a file package for local directory '/tmp/ray_tmp_module/ray'.\n",
      "2023-05-01 00:56:51,562\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/jars/ray_dist.jar is very large (30.48MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/jars/ray_dist.jar']})`\n",
      "2023-05-01 00:56:51,617\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/_raylet.so is very large (25.37MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/_raylet.so']})`\n",
      "2023-05-01 00:56:51,663\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/core/src/ray/gcs/gcs_server is very large (21.24MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/core/src/ray/gcs/gcs_server']})`\n",
      "2023-05-01 00:56:51,702\tWARNING packaging.py:394 -- File /tmp/ray_tmp_module/ray/core/src/ray/raylet/raylet is very large (20.56MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/tmp/ray_tmp_module/ray/core/src/ray/raylet/raylet']})`\n",
      "2023-05-01 00:56:52,344\tINFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_be300ec1f2b48a35.zip' (155.57MiB) to Ray cluster...\n",
      "2023-05-01 00:56:52,879\tINFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_be300ec1f2b48a35.zip'.\n",
      "2023-05-01 00:56:53,392\tINFO packaging.py:347 -- Pushing file package 'gcs://_ray_pkg_bf41e97d15a2c2f3e23b7dd36d3e0f0a.zip' (165.65MiB) to Ray cluster...\n",
      "2023-05-01 00:56:53,954\tINFO packaging.py:360 -- Successfully pushed file package 'gcs://_ray_pkg_bf41e97d15a2c2f3e23b7dd36d3e0f0a.zip'.\n",
      "2023-05-01 00:56:59,362\tINFO streaming_executor.py:87 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[BatchMapper]\n",
      "2023-05-01 00:56:59,363\tINFO streaming_executor.py:88 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-05-01 00:56:59,364\tINFO streaming_executor.py:90 -- Tip: To enable per-operator progress reporting, set RAY_DATA_VERBOSE_PROGRESS=1.\n",
      "                                                                                                                   \r"
     ]
    }
   ],
   "source": [
    "class DollyV2Model(pl.LightningModule):\n",
    "    def __init__(self, lr=2e-5, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        self.metric = evaluate.load(\"accuracy\")\n",
    "        self.predictions = []\n",
    "        self.references = []\n",
    "\n",
    "    def forward(self, batch):\n",
    "        outputs = self.model(\n",
    "            batch[\"input_ids\"], \n",
    "            attention_mask=batch[\"attention_mask\"], \n",
    "            labels=batch[\"labels\"]\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.forward(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        if self.global_rank == 0 and batch_idx % 10 == 0:\n",
    "            print(\"loss = \", loss.item())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.trainer.model.parameters(), lr=self.lr, eps=self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 16\n",
    "batch_size_per_worker = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.lightning import LightningTrainer, LightningConfigBuilder\n",
    "from ray.air.config import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from torch.distributed.fsdp.wrap import transformer_auto_wrap_policy\n",
    "from torch.distributed.fsdp import ShardingStrategy, BackwardPrefetch\n",
    "from transformers.models.gpt_neox.modeling_gpt_neox import GPTNeoXLayer\n",
    "import functools\n",
    "\n",
    "auto_wrap_policy = functools.partial(\n",
    "    transformer_auto_wrap_policy,\n",
    "    transformer_layer_cls = {GPTNeoXLayer}\n",
    ")\n",
    "\n",
    "# Define the configs for LightningTrainer\n",
    "lightning_config = (\n",
    "    LightningConfigBuilder()\n",
    "    .module(cls=DollyV2Model, lr=2e-5, eps=1e-8)\n",
    "    .trainer(\n",
    "        max_epochs=1, \n",
    "        accelerator=\"gpu\", \n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "    )\n",
    "    .strategy(\n",
    "        name=\"fsdp\",\n",
    "        sharding_strategy=ShardingStrategy.FULL_SHARD,\n",
    "        backward_prefetch=BackwardPrefetch.BACKWARD_PRE,\n",
    "        forward_prefetch=True,\n",
    "        auto_wrap_policy=auto_wrap_policy,\n",
    "    )\n",
    "    .checkpointing(save_last=True)\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "class DollyV2ProgressBar(TQDMProgressBar):\n",
    "    def __init__(self, num_iters_per_epoch, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_iters_per_epoch = num_iters_per_epoch\n",
    "    \n",
    "    def on_train_epoch_start(self, trainer, *_):\n",
    "        super().on_train_epoch_start(trainer, *_)\n",
    "        self.train_progress_bar.reset(self.num_iters_per_epoch)\n",
    "\n",
    "total_train_batches = splitter.fit_transform(ray_datasets[\"train\"]).count()\n",
    "num_iters_per_epoch = total_train_batches // (num_workers * batch_size_per_worker)\n",
    "progress_bar = DollyV2ProgressBar(num_iters_per_epoch)\n",
    "lightning_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from ray.tune.syncer import SyncConfig\n",
    "\n",
    "# Save AIR checkpoints according to the performance on validation set\n",
    "run_config = RunConfig(\n",
    "    name=f\"finetune-{MODEL_NAME}\",\n",
    "    storage_path=\"s3://yunxuanx-test/model-checkpoint\",\n",
    "    checkpoint_config=CheckpointConfig(),\n",
    ")\n",
    "\n",
    "# Scale the DDP training workload across 16 GPUs\n",
    "# You can change this config based on your compute resources.\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=num_workers, use_gpu=True, resources_per_worker={\"CPU\": 14, \"GPU\": 1}\n",
    ")\n",
    "\n",
    "\n",
    "trainer = LightningTrainer(\n",
    "    lightning_config=lightning_config,\n",
    "    run_config=run_config,\n",
    "    scaling_config=scaling_config,\n",
    "    datasets={\"train\": ray_datasets[\"train\"]},\n",
    "    datasets_iter_config={\"batch_size\": batch_size_per_worker},\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "result = trainer.fit()\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint_uri = result.checkpoint.uri\n",
    "checkpoint_uri = \"s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/\"\n",
    "checkpoint_local_dir = \"/home/ray/s3/checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/.is_checkpoint to ../s3/checkpoint/.is_checkpoint\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/.metadata.pkl to ../s3/checkpoint/.metadata.pkl\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/_preprocessor to ../s3/checkpoint/_preprocessor\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/.tune_metadata to ../s3/checkpoint/.tune_metadata\n",
      "download: s3://yunxuanx-test/model-checkpoint/finetune-dolly-v2/LightningTrainer_18e2e_00000_0_2023-04-30_17-57-08/checkpoint_000000/model to ../s3/checkpoint/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"aws s3 sync {checkpoint_uri} {checkpoint_local_dir}\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from ray.train.lightning import LightningCheckpoint\n",
    "# checkpoint = LightningCheckpoint.from_uri(checkpoint_uri)\n",
    "# # Very slow!\n",
    "# air_model = checkpoint.get_model(DollyV2Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"right\")\n",
    "dolly = DollyV2Model.load_from_checkpoint(f\"{checkpoint_local_dir}/model\").cuda()\n",
    "nlp_pipeline = pipeline(task=\"text-generation\", model=dolly.model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'This is the day that I was born, and this is the day that I shall die.'}]\n",
      "[{'generated_text': 'I am a poor man, sir, and I am a soldier.'}]\n",
      "[{'generated_text': 'Once more, my lord, I am your servant.'}]\n"
     ]
    }
   ],
   "source": [
    "for prompt in [\"This is\", \"I am\", \"Once more\"]:\n",
    "    print(nlp_pipeline(prompt, max_new_tokens=30, pad_token_id=tokenizer.eos_token_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
