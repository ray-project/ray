{
    "_dashboard_memory_usage_mb": 169.508864,
    "_dashboard_test_success": true,
    "_peak_memory": 3.48,
    "_peak_process_memory": "PID\tMEM\tCOMMAND\n216\t0.42GiB\t/home/ray/anaconda3/lib/python3.8/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/s\n322\t0.15GiB\t/home/ray/anaconda3/bin/python /home/ray/anaconda3/lib/python3.8/site-packages/ray/dashboard/dashboa\n3068\t0.15GiB\tpython distributed/test_many_tasks.py --num-tasks=1000\n59\t0.08GiB\t/home/ray/anaconda3/bin/python /home/ray/anaconda3/bin/anyscale session web_terminal_server --deploy\n409\t0.07GiB\t/home/ray/anaconda3/bin/python -u /home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/runti\n2896\t0.06GiB\tray::JobSupervisor\n3291\t0.06GiB\tray::StateAPIGeneratorActor.start\n52\t0.06GiB\t/home/ray/anaconda3/bin/python /home/ray/anaconda3/bin/jupyter-lab --allow-root --ip=127.0.0.1 --no-\n3255\t0.06GiB\tray::DashboardTester.run\n407\t0.06GiB\t/home/ray/anaconda3/bin/python -u /home/ray/anaconda3/lib/python3.8/site-packages/ray/dashboard/agen",
    "num_tasks": 1000,
    "perf_metrics": [
        {
            "perf_metric_name": "tasks_per_second",
            "perf_metric_type": "THROUGHPUT",
            "perf_metric_value": 275.25470863736416
        },
        {
            "perf_metric_name": "used_cpus_by_deadline",
            "perf_metric_type": "THROUGHPUT",
            "perf_metric_value": 250.0
        },
        {
            "perf_metric_name": "dashboard_p50_latency_ms",
            "perf_metric_type": "LATENCY",
            "perf_metric_value": 3.687
        },
        {
            "perf_metric_name": "dashboard_p95_latency_ms",
            "perf_metric_type": "LATENCY",
            "perf_metric_value": 46.348
        },
        {
            "perf_metric_name": "dashboard_p99_latency_ms",
            "perf_metric_type": "LATENCY",
            "perf_metric_value": 145.645
        }
    ],
    "success": "1",
    "tasks_per_second": 275.25470863736416,
    "time": 303.6329987049103,
    "used_cpus": 250.0
}
