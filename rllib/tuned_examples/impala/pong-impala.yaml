# This can reach 18-19 reward within 10 minutes on a Tesla M60 GPU (e.g., G3 EC2 node):
#   128 workers -> 8 minutes
#    32 workers -> 17 minutes
#    16 workers -> 40 min+
# See also: pong-impala-fast.yaml, pong-impala-vectorized.yaml
pong-impala:
    env: ALE/Pong-v5
    run: IMPALA
    config:
        # Make analogous to old v4 + NoFrameskip.
        env_config:
            frameskip: 1
            full_action_space: false
            repeat_action_probability: 0.0
        rollout_fragment_length: 50
        train_batch_size: 500
        num_workers: 128
        num_envs_per_worker: 1
