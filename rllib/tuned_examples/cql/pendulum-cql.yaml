# Given a SAC-generated offline file generated via:
# rllib train -f tuned_examples/sac/pendulum-sac.yaml --no-ray-ui

# Pendulum CQL can attain ~ -300 reward in 10k from that file.
pendulum-cql:
    env: Pendulum-v0
    run: CQL
    stop:
        #episode_reward_mean: -300
        time_total_s: 10
    config:
        # Works for both torch and tf.
        framework: tf
        # Use one or more offline files or "input: sampler" for online learning.
        input: ["tests/data/pendulum/enormous.zip"]
        horizon: 200
        soft_horizon: true
        Q_model:
          fcnet_activation: relu
          fcnet_hiddens: [256, 256]
        policy_model:
          fcnet_activation: relu
          fcnet_hiddens: [256, 256]
        bc_iters: 200
        no_done_at_end: true
        n_step: 3
        prioritized_replay: false
        timesteps_per_iteration: 1000
        learning_starts: 256
        evaluation_num_workers: 1
        evaluation_interval: 1
        metrics_smoothing_episodes: 5
        # Evaluate in an actual environment.
        evaluation_config:
            input: sampler
            explore: False
