cartpole-ppo:
    env: "ray.rllib.examples.env.repeat_after_me_env.RepeatAfterMeEnv"
    run: PPO
    stop:
        episode_reward_mean: 150
        timesteps_total: 100000
    config:
        # Works for both torch and tf.
        framework: tf
        env_config:
          config:
            repeat_delay: 2
        gamma: 0.9
        lr: 0.0003
          #grid_search: 0.0003  #[0.0003, 0.0001, 0.001]
        num_workers: 0
        num_envs_per_worker: 20
        #observation_filter: MeanStdFilter
        num_sgd_iter: 5
        vf_share_layers: true
          #grid_search: [true, false]
        entropy_coeff: 0.00001
        model:
            use_lstm: true
            lstm_cell_size: 64
            max_seq_len: 20
            fcnet_hiddens: [64]
