# NOTE: This example will not run w/o a proper config.multiagent setup,
#       which currently cannot be done in yaml.
unity3d-soccer-strikers-vs-goalie-ppo:
    env: ray.rllib.env.unity3d_env.Unity3DEnv
    run: PPO
    stop:
        timesteps_total: 1000000
    config:
        # Works for both torch and tf.
        framework: tf
        env_config:
          config:
            episode_horizon: 3000
        lr: 0.0003
        lambda: 0.95
        gamma: 0.99
        sgd_minibatch_size: 256
        train_batch_size: 4000
        clip_param: 0.2
        # For running in editor, just use one Worker (we only have
        # one Unity running)!
        num_workers: 0
        num_sgd_iter: 20
        rollout_fragment_length: 200
        no_done_at_end: true
        model:
          fcnet_hiddens: [512, 512]
        # If no executable is provided (use Unity3D editor), do not evaluate,
        # b/c the editor only allows one connection at a time.
        evaluation_interval: 0
        evaluation_num_episodes: 1
        # NOTE: Will not run w/o the following multiagent setup:
        # Multi-agent setup for SoccerStrikersVsGoalie Unity3D Env.
        # multiagent:
        #    policies: [policies list]
        #    policy_mapping_fn: [agent-to-policy mapping function]
