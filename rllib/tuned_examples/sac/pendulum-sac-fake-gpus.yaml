pendulum-sac-fake-gpus:
    env: Pendulum-v0
    run: SAC
    stop:
        episode_reward_mean: -600
        training_iteration: 200
    config:
        # Works for both torch and tf.
        framework: tf
        horizon: 200
        soft_horizon: true
        Q_model:
          fcnet_activation: relu
          fcnet_hiddens: [256, 256]
        policy_model:
          fcnet_activation: relu
          fcnet_hiddens: [256, 256]
        tau: 0.005
        target_entropy: auto
        initial_alpha: 0.001
        no_done_at_end: true
        n_step: 3
        rollout_fragment_length: 1
        prioritized_replay: true
        target_network_update_freq: 1
        timesteps_per_iteration: 1000
        learning_starts: 256
        num_workers: 0
        clip_actions: false
        normalize_actions: true
        metrics_smoothing_episodes: 5

        # Double batch size (2 GPUs).
        train_batch_size: 512
        optimization:
          actor_learning_rate: 0.0005
          critic_learning_rate: 0.0005
          entropy_learning_rate: 0.0005

        # Fake 2 GPUs.
        num_gpus: 2
        _fake_gpus: true
